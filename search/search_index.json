{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Levridge Overview Levridge is dedicated to building modern, user-friendly business solutions for the agricultural industry. The Levridge solution enables Ag Retailers, Ag Cooperatives and Commodity Processors to run businesses in a modern, connected way. Agronomy This cloud-based solution infinitely increases efficiencies in agronomy through the elimination of paper and the need for manual double entries, better visibility into inventory and procurement and the opportunity for real-time invoicing. Using the many functions and features of customer relationship management Levridge has multiple tools to help the agronomist overcome challenges with tracking data related to the grower, employee and contractor. This includes providing access to vital historical information, addressing knowledge sharing amongst employees, application and chemical certifications, and licensing and DOT tracking. Vital features for the agronomist include Outlook integration, email tracking, visibility to sales activities and follow up. Most importantly, it provides a 360-degree view of the client in a way that is accessible to all team members who need it. Agronomy Overview Grain Grain Overview Accounting and Retail Split billing is a unique and necessary challenge for the ag industry. Levridge includes billing split management and the ability to clearly define splits by collecting data and using grower confirmation to maintain accuracy. The ag retail functionality includes the ability for customers and vendors to prepay and the opportunity to track and make adjustments based on consumption and usage. Levridge includes a modern and integrated approach to reaching low net pricing by seamlessly handling grower rebates and pricing. By taking advantage of the commissions, rebates and trade agreement set up functions that are native to the Dynamics 365 solution. Account and Retail Overview Feed Veterinary Feed Directives (VFDs) are prescriptions for antibiotics written by veterinarians for livestock. The antibiotics specified in VFDs are dispensed in certain dosages for a herd and are placed/hosted with the feed given to livestock. VFDs and the antibiotics with them are governed and restricted differently by the various states and countries. Levridge supports the legal tracking, creation and consumption of Veterinary Feed Directives (VFD) within host feed items. Feed Overview Commodity Processing No more dealing with inflexible reporting. A modern cloud-based platform with integration to the Microsoft Office suite and the ability to work with multiple other software applications gives Levridge an enhanced commodity accounting experience. With a built-in connection to the back office and your accounting team, access to information is seamless. Commodity Accounting Overview Scale With the fastest-speed on the market, the Levridge scale is built with real-time synchronization to see ticket information almost immediately. The Levridge scale can connect to any ERP system within minimal hardware and only one system to maintain and service. The Levridge scale is NTEP certified. Scale Overview Equity Management Due to the many factors involved and difficulty tracking revolving member equity and stock allocations, this has been traditionally handled outside of the central accounting application. It is very likely stored in Excel or some other system that integrates with your accounting or agribusiness solution. In Levridge equity and stock allocations are managed within ONE solution. Equity tracking, from build-up, to current balance to pay-out is handled within the Levridge solution. Equity Management Overview","title":"Home"},{"location":"#levridge","text":"","title":"Levridge"},{"location":"#overview","text":"Levridge is dedicated to building modern, user-friendly business solutions for the agricultural industry. The Levridge solution enables Ag Retailers, Ag Cooperatives and Commodity Processors to run businesses in a modern, connected way.","title":"Overview"},{"location":"#agronomy","text":"This cloud-based solution infinitely increases efficiencies in agronomy through the elimination of paper and the need for manual double entries, better visibility into inventory and procurement and the opportunity for real-time invoicing. Using the many functions and features of customer relationship management Levridge has multiple tools to help the agronomist overcome challenges with tracking data related to the grower, employee and contractor. This includes providing access to vital historical information, addressing knowledge sharing amongst employees, application and chemical certifications, and licensing and DOT tracking. Vital features for the agronomist include Outlook integration, email tracking, visibility to sales activities and follow up. Most importantly, it provides a 360-degree view of the client in a way that is accessible to all team members who need it. Agronomy Overview","title":"Agronomy"},{"location":"#grain","text":"Grain Overview","title":"Grain"},{"location":"#accounting-and-retail","text":"Split billing is a unique and necessary challenge for the ag industry. Levridge includes billing split management and the ability to clearly define splits by collecting data and using grower confirmation to maintain accuracy. The ag retail functionality includes the ability for customers and vendors to prepay and the opportunity to track and make adjustments based on consumption and usage. Levridge includes a modern and integrated approach to reaching low net pricing by seamlessly handling grower rebates and pricing. By taking advantage of the commissions, rebates and trade agreement set up functions that are native to the Dynamics 365 solution. Account and Retail Overview","title":"Accounting and Retail"},{"location":"#feed","text":"Veterinary Feed Directives (VFDs) are prescriptions for antibiotics written by veterinarians for livestock. The antibiotics specified in VFDs are dispensed in certain dosages for a herd and are placed/hosted with the feed given to livestock. VFDs and the antibiotics with them are governed and restricted differently by the various states and countries. Levridge supports the legal tracking, creation and consumption of Veterinary Feed Directives (VFD) within host feed items. Feed Overview","title":"Feed"},{"location":"#commodity-processing","text":"No more dealing with inflexible reporting. A modern cloud-based platform with integration to the Microsoft Office suite and the ability to work with multiple other software applications gives Levridge an enhanced commodity accounting experience. With a built-in connection to the back office and your accounting team, access to information is seamless. Commodity Accounting Overview","title":"Commodity Processing"},{"location":"#scale","text":"With the fastest-speed on the market, the Levridge scale is built with real-time synchronization to see ticket information almost immediately. The Levridge scale can connect to any ERP system within minimal hardware and only one system to maintain and service. The Levridge scale is NTEP certified. Scale Overview","title":"Scale"},{"location":"#equity-management","text":"Due to the many factors involved and difficulty tracking revolving member equity and stock allocations, this has been traditionally handled outside of the central accounting application. It is very likely stored in Excel or some other system that integrates with your accounting or agribusiness solution. In Levridge equity and stock allocations are managed within ONE solution. Equity tracking, from build-up, to current balance to pay-out is handled within the Levridge solution. Equity Management Overview","title":"Equity Management"},{"location":"AddAddressForDeliveryAndInvoice/","text":"Add Address for Delivery and Invoice Brief introduction of the module, component or feature being documented. This document explains ... Add Address for Delivery and Invoice Go to Accounts receivable > Customers > All customers. In the list, find and select the desired record. In the list, click the link in the selected row. In the list, click the link in the selected row. In the list, click the link in the selected row. In the list, click the link in the selected row. Click Add. In the Name or description field, type a value. In the Purpose field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. In the list, select row 7. Click Select. In the Zip/Postal code field, type a value. In the Street field, type a value. Click OK.","title":"Add Address for Delivery and Invoice"},{"location":"AddAddressForDeliveryAndInvoice/#add-address-for-delivery-and-invoice","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Add Address for Delivery and Invoice"},{"location":"AddAddressForDeliveryAndInvoice/#add-address-for-delivery-and-invoice_1","text":"Go to Accounts receivable > Customers > All customers. In the list, find and select the desired record. In the list, click the link in the selected row. In the list, click the link in the selected row. In the list, click the link in the selected row. In the list, click the link in the selected row. Click Add. In the Name or description field, type a value. In the Purpose field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. In the list, select row 7. Click Select. In the Zip/Postal code field, type a value. In the Street field, type a value. Click OK.","title":"Add Address for Delivery and Invoice"},{"location":"Address_Data_Mapping/","text":"Address Data Mapping Overview Address Data Mapping functions to set a primary addresses on the Account and Contact form which come from the Account Address, Account Electronic Address, Contact Address, and Contact Electronic Address ESG. This is done through the use of the LevridgeCore.AddressDataMap plugin and Address data Mapping configuration records. The plugin will be part of the solution, but pluggin steps will need to be created for the entities you want the address data mapping on. Address Data Mapping records will need to be either migrated into the environment or they will need to be created by the implementation team. The Address Data Map plugin currently will set the address fields and electronic address fields on the default Account and Contact form. In order to create an Address Data Mapping file, navigate to your environment>Advanced Find>Look for Address Data Maps>Results> New Address Data Map. Above is an Address Data Map for the Account Address. Essentially the main areas you need to focus on is entering in a name, correct primary entity, in this case it is Account, and then the Child entity which is lev_address. Because this is the not dealing with the electronic addresses, you can set the electronic address field as none. In the Data Mapping section you will want to focus on mapping the address fields to the fields present on the form you are mapping to. In the Case you are creating an Electronic Address Address Data Map, you will once again enter in a Name, primary and child entity. Now you will select an Electronic Address Type, in the case below it is an Email Address. In the Electronic Address section you will have to map the field in which you want the Primary Electronic Address to present. Click Save, and make sure to activate the record. Setting up the plugin steps for Address Data Mapping You will need to setup a create and update plugin step for each entity utilizing the address data mapping such as the Account Address or Contact Address. To set up the plugin steps for address data mapping, you will use the Plugin Registration Tool which is a Microsoft tool. 1. Connect to your CRM environment. 2. Click/expand the LevridgeCore assembly, then click on the LevridgeCore.AddressDataMap pluggin With the plugin selected, click the Register dropdown on the top left of the screen, and click Register New Step Next fill out the form using the Template in the screenshot below, one is for Create and another for Update. Then click Register Step","title":"Address Data Mapping"},{"location":"Address_Data_Mapping/#address-data-mapping","text":"","title":"Address Data Mapping"},{"location":"Address_Data_Mapping/#overview","text":"Address Data Mapping functions to set a primary addresses on the Account and Contact form which come from the Account Address, Account Electronic Address, Contact Address, and Contact Electronic Address ESG. This is done through the use of the LevridgeCore.AddressDataMap plugin and Address data Mapping configuration records. The plugin will be part of the solution, but pluggin steps will need to be created for the entities you want the address data mapping on. Address Data Mapping records will need to be either migrated into the environment or they will need to be created by the implementation team. The Address Data Map plugin currently will set the address fields and electronic address fields on the default Account and Contact form. In order to create an Address Data Mapping file, navigate to your environment>Advanced Find>Look for Address Data Maps>Results> New Address Data Map. Above is an Address Data Map for the Account Address. Essentially the main areas you need to focus on is entering in a name, correct primary entity, in this case it is Account, and then the Child entity which is lev_address. Because this is the not dealing with the electronic addresses, you can set the electronic address field as none. In the Data Mapping section you will want to focus on mapping the address fields to the fields present on the form you are mapping to. In the Case you are creating an Electronic Address Address Data Map, you will once again enter in a Name, primary and child entity. Now you will select an Electronic Address Type, in the case below it is an Email Address. In the Electronic Address section you will have to map the field in which you want the Primary Electronic Address to present. Click Save, and make sure to activate the record.","title":"Overview"},{"location":"Address_Data_Mapping/#setting-up-the-plugin-steps-for-address-data-mapping","text":"You will need to setup a create and update plugin step for each entity utilizing the address data mapping such as the Account Address or Contact Address. To set up the plugin steps for address data mapping, you will use the Plugin Registration Tool which is a Microsoft tool. 1. Connect to your CRM environment. 2. Click/expand the LevridgeCore assembly, then click on the LevridgeCore.AddressDataMap pluggin With the plugin selected, click the Register dropdown on the top left of the screen, and click Register New Step Next fill out the form using the Template in the screenshot below, one is for Create and another for Update. Then click Register Step","title":"Setting up the plugin steps for Address Data Mapping"},{"location":"AdjustFIFOInventoryValue/","text":"Adjust FIFO Inventory Value Brief introduction of the module, component or feature being documented. This document explains ... How to Adjust FIFO Inventory Value Close the page. Go to Inventory Management > Periodic tasks > Closing and Adjustment. Click Adjustment. Click On-hand. Click Select. Expand the Records to include section. Click Filter. In the list, find and select the desired record. In the list, find and select the desired record. In the Criteria field, type a value. Click OK. Click OK. In the list, mark the selected row. In the Unit cost field, enter a number. Click Post. Click OK. Click Details. Click Voucher. Close the page. Click Details. Click Adjustments report. Click Cancel. Click Details. Click Settlements. Click to follow the link in the Item number field. Click to follow the link in the Item number field. On the Action pane, click Manage Inventory. Click On-hand inventory. Refresh the page. Click Transactions. Close the page. Go to Inventory management > Inquiries and reports > On-hand list. Apply the following filters: Enter a filter value of \"\" on the \"Item number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Site\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Warehouse\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Serial number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Batch number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Search name\" field using the \"begins with\" filter operator Click Intercompany on-hand. Click the On-hand tab.","title":"Adjust FIFO Inventory Value"},{"location":"AdjustFIFOInventoryValue/#adjust-fifo-inventory-value","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Adjust FIFO Inventory Value"},{"location":"AdjustFIFOInventoryValue/#how-to-adjust-fifo-inventory-value","text":"Close the page. Go to Inventory Management > Periodic tasks > Closing and Adjustment. Click Adjustment. Click On-hand. Click Select. Expand the Records to include section. Click Filter. In the list, find and select the desired record. In the list, find and select the desired record. In the Criteria field, type a value. Click OK. Click OK. In the list, mark the selected row. In the Unit cost field, enter a number. Click Post. Click OK. Click Details. Click Voucher. Close the page. Click Details. Click Adjustments report. Click Cancel. Click Details. Click Settlements. Click to follow the link in the Item number field. Click to follow the link in the Item number field. On the Action pane, click Manage Inventory. Click On-hand inventory. Refresh the page. Click Transactions. Close the page. Go to Inventory management > Inquiries and reports > On-hand list. Apply the following filters: Enter a filter value of \"\" on the \"Item number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Site\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Warehouse\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Serial number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Batch number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Search name\" field using the \"begins with\" filter operator Click Intercompany on-hand. Click the On-hand tab.","title":"How to Adjust FIFO Inventory Value"},{"location":"AgSyncEndpoint/","text":"AgSyncEndpoint Settings AgSyncEndpoint is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the integration between FinOps and Agsync master data. Example \"AgSyncEndpoint\": { \"MustUseWktProcessor\": true, \"UuidSource\": \"Agsync\", \"BaseFieldUri\": \"https://fields.agsync.com/api/\", \"BaseOrderUri\": \"https://orders.agsync.com/api/\", \"tokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"ClientId\": \"[Agsync assigned client ID]\", \"ClientPass\": \"[Agsync assigned client password]\", \"VaultURL\": \"https://levridgeagsynckeyvault.vault.azure.net/\", \"AgSyncTokenKey\": \"AgsyncAccessToken\", \"RedirectUri\": \"[Agsync Integration Base URL]/api/AgsyncAuth\", \"IntegrationId\": \"[Agsync assigned integration Id]\" } Definition UuidSource BaseFieldUri BaseOrderUri tokenUrl ClientId ClientPass VaultURL AgSyncTokenKey RedirectUri IntegrationId","title":"AgSyncEndpoint Settings"},{"location":"AgSyncEndpoint/#agsyncendpoint-settings","text":"AgSyncEndpoint is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the integration between FinOps and Agsync master data.","title":"AgSyncEndpoint Settings"},{"location":"AgSyncEndpoint/#example","text":"\"AgSyncEndpoint\": { \"MustUseWktProcessor\": true, \"UuidSource\": \"Agsync\", \"BaseFieldUri\": \"https://fields.agsync.com/api/\", \"BaseOrderUri\": \"https://orders.agsync.com/api/\", \"tokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"ClientId\": \"[Agsync assigned client ID]\", \"ClientPass\": \"[Agsync assigned client password]\", \"VaultURL\": \"https://levridgeagsynckeyvault.vault.azure.net/\", \"AgSyncTokenKey\": \"AgsyncAccessToken\", \"RedirectUri\": \"[Agsync Integration Base URL]/api/AgsyncAuth\", \"IntegrationId\": \"[Agsync assigned integration Id]\" }","title":"Example"},{"location":"AgSyncEndpoint/#definition","text":"","title":"Definition"},{"location":"AgSyncEndpoint/#uuidsource","text":"","title":"UuidSource"},{"location":"AgSyncEndpoint/#basefielduri","text":"","title":"BaseFieldUri"},{"location":"AgSyncEndpoint/#baseorderuri","text":"","title":"BaseOrderUri"},{"location":"AgSyncEndpoint/#tokenurl","text":"","title":"tokenUrl"},{"location":"AgSyncEndpoint/#clientid","text":"","title":"ClientId"},{"location":"AgSyncEndpoint/#clientpass","text":"","title":"ClientPass"},{"location":"AgSyncEndpoint/#vaulturl","text":"","title":"VaultURL"},{"location":"AgSyncEndpoint/#agsynctokenkey","text":"","title":"AgSyncTokenKey"},{"location":"AgSyncEndpoint/#redirecturi","text":"","title":"RedirectUri"},{"location":"AgSyncEndpoint/#integrationid","text":"","title":"IntegrationId"},{"location":"Agriculture_Tax/","text":"Agriculture Tax Calculation Functionality has been added to support the calculation of agricultural taxes. Feature Summary Multi-Taxing: Made it possible for Customers, Vendors, Addresses and Items to be assigned multiple tax groups. Taxation is determined based on the intersection of assigned tax types and groups between Items and the relevant Customers, Vendors and/or Addresses. Multi-Taxing Levridge allows users to assign a Customers, Vendors and Items to multiple tax groups, to support agricultural tax calculations. Customers can also have different Agricultural Tax Groups assigned at the address level to facilitate taxation for multiple delivery locations. Agricultural Taxes are categorized into one of three different Agricultural Tax Types: Tonnage Tax Pesticide Tax Indemnity Fund Agricultural Sales Tax tables have been added to the Customer, Vendor, Address and Item forms to allow for assignment of the applicable Agricultural Tax Groups. Items can be assigned one Item Sales Tax Group from each of the four Agricultural Tax Types. Customers, Vendors, and Addresses can be assigned as many Sales Tax Groups from each of the Agricultural Tax Types as needed. In addition to standard sales tax calculation, each Sales Order or Purchase Order line can be subject to one of each of the above Agricultural Tax Types. The applicable tax groups are assigned by identifying matching tax groups between the Item and the Customer (or Vendor) information on the order. All matching tax groups will be applied.","title":"Agriculture Tax Calculation"},{"location":"Agriculture_Tax/#agriculture-tax-calculation","text":"Functionality has been added to support the calculation of agricultural taxes.","title":"Agriculture Tax Calculation"},{"location":"Agriculture_Tax/#feature-summary","text":"Multi-Taxing: Made it possible for Customers, Vendors, Addresses and Items to be assigned multiple tax groups. Taxation is determined based on the intersection of assigned tax types and groups between Items and the relevant Customers, Vendors and/or Addresses.","title":"Feature Summary"},{"location":"Agriculture_Tax/#multi-taxing","text":"Levridge allows users to assign a Customers, Vendors and Items to multiple tax groups, to support agricultural tax calculations. Customers can also have different Agricultural Tax Groups assigned at the address level to facilitate taxation for multiple delivery locations. Agricultural Taxes are categorized into one of three different Agricultural Tax Types: Tonnage Tax Pesticide Tax Indemnity Fund Agricultural Sales Tax tables have been added to the Customer, Vendor, Address and Item forms to allow for assignment of the applicable Agricultural Tax Groups. Items can be assigned one Item Sales Tax Group from each of the four Agricultural Tax Types. Customers, Vendors, and Addresses can be assigned as many Sales Tax Groups from each of the Agricultural Tax Types as needed. In addition to standard sales tax calculation, each Sales Order or Purchase Order line can be subject to one of each of the above Agricultural Tax Types. The applicable tax groups are assigned by identifying matching tax groups between the Item and the Customer (or Vendor) information on the order. All matching tax groups will be applied.","title":"Multi-Taxing"},{"location":"AgronomistEnd-to-EndScenarios/","text":"Agronomy Processes Overview There are three distinct end-to-end business processes in which Agronomists will participate. Field Plan to Agronomy Contract - A set of sales tools within CE used to price product and transition growers into contracts. Fertilizer Calculation - A utility that allows a salesperson to determine and calculate fertilizer requirements such as what product best fits the need of the customer and how much of that product is needed to fulfill the order (some work order is still needed and is anticipated to be ready in Fall 2020). Sales Order Management - The integration of all Levridge pieces, specifically split billing, and its close integration with sales orders in F&O. Field Plan to Agronomy Contract There are three methods for kicking off a field plan to agronomy contract with Dynamics 365 CE: Batch plans [^10] Regular plans Proposals Batch Plans Batch plans are a way to quickly create a proposal or sale agreement. There are three types of batch plans that can be used: [^1] Field type \u2013 The field batch plan type is used to ... [^2] All product needs across all fields may be added as a batch. Individual products can then be added after the plan is created. For example, fertilizer, and chemical may be the same for all fields, with the seed added to different areas of the field after the batch process. Required to know field details, but not customer. [^3] Prospect type \u2013 Potential customer information is added to capture pricing for products in a proposal to provide to the prospect. Limitations include not able to move proposal to a contract. This is a draft proposal for beginning negotiation. Customer type \u2013 Does not require field details. Creates proposal for seed, fertilizer or crop protection as needed. You can generate a proposal or go directly to a sales agreement for the field and customer types. The prospect type ... [^2] To use the batch plan method to create an agronomy contract: 1. Select the Bath Plans tab 2. Select Generate new 3. Populate required fields - Name: this field will auto populate when you click save - Proposal Type: there are three proposal types: Customer, Field, Prospect. The default proposal type is Customer. - Customer Operation - Split Group - Sales Period: Needed to accurately price 4. Select Save 5. Select the Programs tab 6. Populate fields: - Farmable Acreage: This field is required - Preconfigured set of products: In many cases on agronomist recommends the same products at the same time so instead of calculating these rates each time, you can set up a program so it automatically calculates product and rate. 6. Add products utilizing the tabs across the top of the batch plan (seed, fertilizer, chemical, etc.) 7. After adding your products, you can either: - Generate a proposal - Generate a sales agreement Proposal Types [^4] Programs, recommendations, plans and batch plans include products. Proposals will now include pricing. Proposal is way to take all the products for field or group of fields for an operation, puts them on one document and adds pricing for a grower. The proposal rolls all of the same products together. A detailed breakdown is available that includes how much product for each field with breakdown by owner for financial responsibility based on split groups. The pricing service is an integration with FinOps where product, accounts in split group, individual product quantities for the product are shared. FinOps will look at trade agreements per sale period to capture the appropriate pricing. The customer has the option to include volume pricing, which will review previous contracts for this sales year which can then be applied to pricing. The initial price is returned from FinOps to CE. Charge codes may be added in CE to provide a discount. Thresholds are defined in the charge code and validated for each proposal line. If the threshold is exceeded, management must approve or deny the discount. Example, an LCR (local competitive response) charge code may be added in CE to the proposal at $15. Management has setup a threshold of $10 for that charge code, therefore during the approval process the system would send the proposal to the agronomist manager to approval prior to submission to the grower. Credit checking is also validated for the customers on the proposal through FinOps and returns a yes or no. If no, the overage for the credit limit is displayed. This could be in the form of a warning or a stop. Note: If a customer is on credit hold, a plan would not be allowed. Once the proposal is approved, the proposal form may be printed for the customer. \u2003 There are three different proposal types within a batch plan: Customer, Prospect, and Field. [^5] Customer: Simplest proposal type and is the most used proposal type for a batch plan Prospect: Individual the salesperson is pursuing that is not a current client and would like to generate a price for product and contract. Generate contract Sales period Farmable Acreage approximation Navigate to the seed, fertilizer, or chemical tab(s) to add product Create proposal Open proposal Proposal lines tab Run report Print proposal Give to potential client Field: Least common proposal type used Only benefit of the field is if we go through and make individual plans You can add products once to all applicable fields Creating a Regular Plan Sales agreements are generated from proposals that have been approved by a grower. Agreements are separated by product types of seed, fertilizer and chemicals. This is standard as there may be different fiduciary requirements for these different product types. For example, 3 agreements could be created, one for seed, one for fertilizer and one for chemicals. The sale agreements include customer, prepayment details, payment terms, with products, quantity and pricing. Each agreement can be associated with company branch. [^6] These sales agreements are integrated with FinOps. [^7] Plan to sales agreement [^8] Plans Generate new plan record Populate applicable fields Account Customer Operation Customer Site: Physical piece of land that you are putting product on Split group Description: Multiple plans for a field may be created so a detailed description is important Desired Crop Growing Season: The year the product will be applied to the field Utilize the tabs (Programs and Reccomendations, seed, fertilizer, or chemical) to add applicable product(s) Programs and Recommendations: Programs: Ability to add existing or new programs Recommendations: Attachment to precision mapping tools Seed (unit): Seed calculator: Helps to easily populate the quantity field Add product line(s) for all required seed Fertilizer: Timing: When to apply product Product Rate Unit/Rate This calculation not only helps get the product pricing but also helps to know when the grower needs specific products applied. Chemical: Timing: When to apply product Product Rate Unit/Rate This calculation not only helps get the product pricing but also helps to know when the grower needs specific products applied. Plan is complete and proposal can be generated New Proposal Plan to sales agreement Proposals Generate new proposal Populate applicable fields Description Amount Customer Operation Split Group Growing Season Sales Period Manager: the client will have a workflow that sets who the Manager is so it is auto-generated. This is a customization. Associated plans Add existing plans Select all associated plans created for this specific grower Add Create lines This function goes through each plan taking all product information and the split groups behind them and generates individual product lines for them and creates pricing. Item category terms Allow syou to set different payment methods by product. Select item category (product) select payment method Save Proposal lines Discounts/incentives to support with proposal price Launch line you would like to discount Charge codes Add new proposal line change Select charge code: Charge codes are user defined data that are defined in F&O/AX and are integrated over to CE Value: dollar amount to be deducated off total product price Save Refresh Proposal line will be updated to reflect new unit price after charge code has been applied. Unit price: You can manually override this field to decrease price as well. Calculate prices Add product lines from proposal lines tab In some instances, a customer will decide to add products after you have generated the proposal. Using the add new proposal line within the proposal lines tab will allow you to add last minute products to the proposal and recalculate prices. (+) New proposal line Select product Quantity save Calculate prices Line will be added to the proposal lines toab and price will be updated for that product from data from F&O/AX. Submit for Approval Once your proposal is priced and complete, it is ready to be submitted for approval. The submit for approval function/button ensures that margin on products are maintained throughout the sales process. Submit for approval Looks for any charge code or line item changes that were made and compares them to the defined thresholds that have been set. If any changes rise above threshold set it will stop the process, lock down proposal, and send to the Manager that the proposal needs approval before moving forward to contract/agreement Seed: Patented traits owned by specific manufacturer that you must have a license from before you can purchase and use product The system will look and see if grower has avalid agreement to buy this product and if there is configuration fin F&O/AX to either warn or stop theprocess. With seed, you will typically use the \"warn\" function instead of full stopping the process. Restricted used pesticides: Based on federal and state laws, before restricted products can be picked up, we must ensure the applicator has a valid license to apply the product. This license number needs to be physically listed on the invoice. This will warn the process this item needs to be reviewed. At this point in the process, it is important to check back in unti lthe license number has been documented. Generate sales agreement The sales agreement will be sent to F&O/AX once generated. The process is then complete within CE. The final step in the sales process would be to pull up the third-party integration (ex: Hello Sign) to capture a digital signature. Setting up Dynamics 365 CE Record information setup in CE is shared with FinOps for processing of data. [^9] Crops : CE>Agronomy>Configuration>Crops A prepopulated list is available that includes crops such as alfalfa, canola, or corn. A user may add/edit/delete records from the crop list. Required Crop Units : CE>Agronomy>Required Crop Units Defines the crop unit size. How many seeds are in the bag? 80,000 kernels of corn in a bag. Other crops by be sold by pound. No link to unit of measure. This is used on the seed calculator which calculates the number of seeds to cover a field and converts to quantity of seed in a bag, and therefore, how many bags are needed. Timings under agronomy : Timing defines when the product, program or plan will be used. For example, the timing of applying chemicals to a crop could be considered pre or post planting or based on the amount of vegetation such as V1 or V2. Charge Code Configurations : CE> Agronomy>Charge code configurations Allows percentage or amount thresholds to be defined for the charge code. When charge code is used, validation to this configuration is completed. Approval would be required to override the configuration. For example, a price override threshold may be setup for a proposal. If the threshold is exceeded, further approval may be required. Pest Types : CE>Agronomy>Pest Types A data package will be provide for this listing including examples of bacterial, fungal, or insect. Pests : CE>Agronomy>Pests A data package will be provided that includes a list of pests with type of pests. Examples include Aspergillus Ear Rot (fungal), Bean Leaf Beetle (Insect). Pests may be identified in a work order to apply herbicides to the field. This information may be manually added to crop history for review by the agronomist for future planning. Note: A pest applicator license if required by federal and state to apply. Item Categories : CE>Agronomy>Item Categories Sync with FinOps including path. Used for filtering in CE, for example, fertilizer or chemical categories. Flex Grids within the plan and batch plan are filtered by item category. Process #2 Fertilizer Calculator The Fertilizer Calculator is a tool used to generate blends of fertility products. 1. Planning Tools 2. Fertilizer Calculator 3. Generate New 4. Populate applicable fields - Customer - Customer Operation - Batch size: Blender capacity when generated relays how many batches will need to occur to fill order. - Fertilizer State - Dry - Liquid Save Blend lines will populate with nutrient and product Input either input value (lbs.) or ratio (percentage) Click Calculate to populate output Quantity needed Total blend amount Number of batches needed Blend percent Generate sales order and release report to blender facilities to begin blending product (this function is not currently available but will be once it is fully developed and tested.) Process #3 Sales Order Process The sales order is comprised of two pieces: the sales order and the work order. Both are tightly integrated within FinOps. The purpose of the sales order is to give users that only have access to CE the ability to enter orders for delivery and perform some of the functions that are usually completed in FinOps. Generating New Sales Order in CE Sales order tab Generate new Populate applicable sales order fields Account Customer Operation: It will default to one if the customer only has one operation. Split group: The individual paying for the product Delivery address: A requirement for many of the actions in F&O Inventory site: Where the inventory is arriving from Branch: Who is responsible for the customer or in charge of handling the billing Sales period: Used to price products against Ship date: Will default if not manually if not populated. Not a requirement. Save Enter Sales Order Lines Add product Pick quantity Save After saving the estimated price, which is pulled from CE, will be populated. This may not be the price that is actually paid but is a stored list price that adjustments can be made to. Submit for Approval Checks for any products that need an applicator license Checks for any seed tech licenses that may be required Credit check ( based off the credit settings with F&O. It will either warn or deny a generating sales order. ) Generate Sales Order Once your submission has been approved, you will need to generate a sales order in F&O. You will receive a pop-up notifying you the sales order was created successfully in F&O/AX. Once order is acted upon in F&O, you can go into details within CE and will provide more information on the split group allocations so the person in CE has access to details. Work Order The work order is a type of sales order where the Ag Retailer will be performing a service. A work order requires more detail than a basic sales order. A third-party dispatching software defines the following setups and integrates with FinOps to create a work order type of sales order: Field(s) where products will used The product to be used on the field(s) The proper ratio to blend the fertilizer or chemicals for the field(s) Define the service to apply the product to the field(s) Within FinOps the work order type of sales order which includes the products and services from the dispatching software. CE will be updated with a summary view of the work order from FinOps. When a work order comes into CE an auto print service will print the work order and driving directions to be shared with the driver. Blending and Dispensing Lastly the work order information integrates with an additional third-party application to create a production order. Setups regarding the product and warehouse storage within the third-party application is required. This order will provide the blending and dispensing of the fertilizer or chemicals and confirm the completed quantities. Once the production order is complete: Transfer orders will be created for the movement of inventory Inventory will be reduced in the sales location Sales agreement will be applied to the details of the work order Equipment usage will be shared with the Rolling Stock module To generate a new work order: Orders Work Orders Generate new Populate applicable fields Account Customer Operation Customer Site Auto Print: Printer logic exists to automatically print a report remotely. Would be needed when a hard copy is necessary for the remote location to send with the driver. Sales site: Party who is responsible for the sale of the product. Application Site: Paraty performing task Application Operation: Type of work beign done (synced with AgSync). Application Date: Anticipated application date of the product Application Window: For chemical product this is important because depending on stage of the crop, it could cause harm if applied outside a specific timeframe. Crop: Crop the product will be applied to Order Status: Planned: Occurring in the future Booked: Occurring in the future Released: Moved to queue to get done and application date is set Scheduled: Has been assigned to an applicator for a scheduled date In-Progress: Product was administered partially and due to an unforeseen event, the job was not completed and requires further attention. Completed Pending Review: Applicatoin is complete. Archived Rejected Work Order ID: Generated number out of AgSync Dispensing Order Number: Only comes into effect if there is a blender/Kahler integration. This number is created when the picking list/mixed ticket is dispatched out to the warehouse. Ordering Notes: Notes that are specific to the field Notes that are specific to the application Application Notes: Notes or observations the equipment operator made while in the field. Save Enter Work Order Lines Work Order Lines tab Add new line Populate applicable fields Sales Sites Customer Product Pests: Certain states require documentation that states the application and purpose of the sprayed chemical. Application Site Quantity Submit for Approval If this is an integrated order from AgSync or a third-party dispatch, the submit for approval function would not be present. The \"Submit for Proposal\" would show up if generated in CE. If you open a work order line, you will be able to view the Work Order Completion tab which provides more information on the application and applicator. Application Worker Application License Rolling Rock: Equipment that was used to perform application Weather data: Required by law to be tracked Wind speed Wind Direction Temperature Humidity Completion date State/End Times [^1]: I'm not sure if this is correct information. I am assuming from the context. [^2]: Should add a sentence for each type explaining the purpose of each type [^3]: The last part of the sentence about seed doesn't make sense. The next sentence isn't a complete sentence. [^4]: This doesn't seem like a list of proposal types. Probably has the wrong header name Much of this doesn't include full sentences. It should be rewritten using sentences. [^5]: This is redundant. There is an entire section for this above. Combine this information with the information above [^6]: Explain why this is significant. What is the purpose for specifying a branch for each contract? [^7]: This sentence doesn't make sense standing alone like this. It obviously isn't explaining the list below it. What is the purpose. There should be a sentence or paragraph explaining the list below. What is that list? [^8]: Every place there is a step instruction, be clear what the step is. For example: Select \"Batch Plan\" or Select the \"Batch Plan\" menu. [^9]: What is this sentence? It doesn't look like a user instruction. [^10]: Add links to the sections for each item. I added the first one.","title":"Agronomy Processes"},{"location":"AgronomistEnd-to-EndScenarios/#agronomy-processes","text":"","title":"Agronomy Processes"},{"location":"AgronomistEnd-to-EndScenarios/#overview","text":"There are three distinct end-to-end business processes in which Agronomists will participate. Field Plan to Agronomy Contract - A set of sales tools within CE used to price product and transition growers into contracts. Fertilizer Calculation - A utility that allows a salesperson to determine and calculate fertilizer requirements such as what product best fits the need of the customer and how much of that product is needed to fulfill the order (some work order is still needed and is anticipated to be ready in Fall 2020). Sales Order Management - The integration of all Levridge pieces, specifically split billing, and its close integration with sales orders in F&O.","title":"Overview"},{"location":"AgronomistEnd-to-EndScenarios/#field-plan-to-agronomy-contract","text":"There are three methods for kicking off a field plan to agronomy contract with Dynamics 365 CE: Batch plans [^10] Regular plans Proposals","title":"Field Plan to Agronomy Contract"},{"location":"AgronomistEnd-to-EndScenarios/#batch-plans","text":"Batch plans are a way to quickly create a proposal or sale agreement. There are three types of batch plans that can be used: [^1] Field type \u2013 The field batch plan type is used to ... [^2] All product needs across all fields may be added as a batch. Individual products can then be added after the plan is created. For example, fertilizer, and chemical may be the same for all fields, with the seed added to different areas of the field after the batch process. Required to know field details, but not customer. [^3] Prospect type \u2013 Potential customer information is added to capture pricing for products in a proposal to provide to the prospect. Limitations include not able to move proposal to a contract. This is a draft proposal for beginning negotiation. Customer type \u2013 Does not require field details. Creates proposal for seed, fertilizer or crop protection as needed. You can generate a proposal or go directly to a sales agreement for the field and customer types. The prospect type ... [^2] To use the batch plan method to create an agronomy contract: 1. Select the Bath Plans tab 2. Select Generate new 3. Populate required fields - Name: this field will auto populate when you click save - Proposal Type: there are three proposal types: Customer, Field, Prospect. The default proposal type is Customer. - Customer Operation - Split Group - Sales Period: Needed to accurately price 4. Select Save 5. Select the Programs tab 6. Populate fields: - Farmable Acreage: This field is required - Preconfigured set of products: In many cases on agronomist recommends the same products at the same time so instead of calculating these rates each time, you can set up a program so it automatically calculates product and rate. 6. Add products utilizing the tabs across the top of the batch plan (seed, fertilizer, chemical, etc.) 7. After adding your products, you can either: - Generate a proposal - Generate a sales agreement","title":"Batch Plans"},{"location":"AgronomistEnd-to-EndScenarios/#proposal-types-4","text":"Programs, recommendations, plans and batch plans include products. Proposals will now include pricing. Proposal is way to take all the products for field or group of fields for an operation, puts them on one document and adds pricing for a grower. The proposal rolls all of the same products together. A detailed breakdown is available that includes how much product for each field with breakdown by owner for financial responsibility based on split groups. The pricing service is an integration with FinOps where product, accounts in split group, individual product quantities for the product are shared. FinOps will look at trade agreements per sale period to capture the appropriate pricing. The customer has the option to include volume pricing, which will review previous contracts for this sales year which can then be applied to pricing. The initial price is returned from FinOps to CE. Charge codes may be added in CE to provide a discount. Thresholds are defined in the charge code and validated for each proposal line. If the threshold is exceeded, management must approve or deny the discount. Example, an LCR (local competitive response) charge code may be added in CE to the proposal at $15. Management has setup a threshold of $10 for that charge code, therefore during the approval process the system would send the proposal to the agronomist manager to approval prior to submission to the grower. Credit checking is also validated for the customers on the proposal through FinOps and returns a yes or no. If no, the overage for the credit limit is displayed. This could be in the form of a warning or a stop. Note: If a customer is on credit hold, a plan would not be allowed. Once the proposal is approved, the proposal form may be printed for the customer. \u2003 There are three different proposal types within a batch plan: Customer, Prospect, and Field. [^5] Customer: Simplest proposal type and is the most used proposal type for a batch plan Prospect: Individual the salesperson is pursuing that is not a current client and would like to generate a price for product and contract. Generate contract Sales period Farmable Acreage approximation Navigate to the seed, fertilizer, or chemical tab(s) to add product Create proposal Open proposal Proposal lines tab Run report Print proposal Give to potential client Field: Least common proposal type used Only benefit of the field is if we go through and make individual plans You can add products once to all applicable fields","title":"Proposal Types [^4]"},{"location":"AgronomistEnd-to-EndScenarios/#creating-a-regular-plan","text":"Sales agreements are generated from proposals that have been approved by a grower. Agreements are separated by product types of seed, fertilizer and chemicals. This is standard as there may be different fiduciary requirements for these different product types. For example, 3 agreements could be created, one for seed, one for fertilizer and one for chemicals. The sale agreements include customer, prepayment details, payment terms, with products, quantity and pricing. Each agreement can be associated with company branch. [^6] These sales agreements are integrated with FinOps. [^7] Plan to sales agreement [^8] Plans Generate new plan record Populate applicable fields Account Customer Operation Customer Site: Physical piece of land that you are putting product on Split group Description: Multiple plans for a field may be created so a detailed description is important Desired Crop Growing Season: The year the product will be applied to the field Utilize the tabs (Programs and Reccomendations, seed, fertilizer, or chemical) to add applicable product(s) Programs and Recommendations: Programs: Ability to add existing or new programs Recommendations: Attachment to precision mapping tools Seed (unit): Seed calculator: Helps to easily populate the quantity field Add product line(s) for all required seed Fertilizer: Timing: When to apply product Product Rate Unit/Rate This calculation not only helps get the product pricing but also helps to know when the grower needs specific products applied. Chemical: Timing: When to apply product Product Rate Unit/Rate This calculation not only helps get the product pricing but also helps to know when the grower needs specific products applied. Plan is complete and proposal can be generated","title":"Creating a Regular Plan"},{"location":"AgronomistEnd-to-EndScenarios/#new-proposal","text":"Plan to sales agreement Proposals Generate new proposal Populate applicable fields Description Amount Customer Operation Split Group Growing Season Sales Period Manager: the client will have a workflow that sets who the Manager is so it is auto-generated. This is a customization. Associated plans Add existing plans Select all associated plans created for this specific grower Add Create lines This function goes through each plan taking all product information and the split groups behind them and generates individual product lines for them and creates pricing. Item category terms Allow syou to set different payment methods by product. Select item category (product) select payment method Save Proposal lines Discounts/incentives to support with proposal price Launch line you would like to discount Charge codes Add new proposal line change Select charge code: Charge codes are user defined data that are defined in F&O/AX and are integrated over to CE Value: dollar amount to be deducated off total product price Save Refresh Proposal line will be updated to reflect new unit price after charge code has been applied. Unit price: You can manually override this field to decrease price as well. Calculate prices","title":"New Proposal"},{"location":"AgronomistEnd-to-EndScenarios/#add-product-lines-from-proposal-lines-tab","text":"In some instances, a customer will decide to add products after you have generated the proposal. Using the add new proposal line within the proposal lines tab will allow you to add last minute products to the proposal and recalculate prices. (+) New proposal line Select product Quantity save Calculate prices Line will be added to the proposal lines toab and price will be updated for that product from data from F&O/AX.","title":"Add product lines from proposal lines tab"},{"location":"AgronomistEnd-to-EndScenarios/#submit-for-approval","text":"Once your proposal is priced and complete, it is ready to be submitted for approval. The submit for approval function/button ensures that margin on products are maintained throughout the sales process. Submit for approval Looks for any charge code or line item changes that were made and compares them to the defined thresholds that have been set. If any changes rise above threshold set it will stop the process, lock down proposal, and send to the Manager that the proposal needs approval before moving forward to contract/agreement Seed: Patented traits owned by specific manufacturer that you must have a license from before you can purchase and use product The system will look and see if grower has avalid agreement to buy this product and if there is configuration fin F&O/AX to either warn or stop theprocess. With seed, you will typically use the \"warn\" function instead of full stopping the process. Restricted used pesticides: Based on federal and state laws, before restricted products can be picked up, we must ensure the applicator has a valid license to apply the product. This license number needs to be physically listed on the invoice. This will warn the process this item needs to be reviewed. At this point in the process, it is important to check back in unti lthe license number has been documented. Generate sales agreement The sales agreement will be sent to F&O/AX once generated. The process is then complete within CE. The final step in the sales process would be to pull up the third-party integration (ex: Hello Sign) to capture a digital signature.","title":"Submit for Approval"},{"location":"AgronomistEnd-to-EndScenarios/#setting-up-dynamics-365-ce","text":"Record information setup in CE is shared with FinOps for processing of data. [^9] Crops : CE>Agronomy>Configuration>Crops A prepopulated list is available that includes crops such as alfalfa, canola, or corn. A user may add/edit/delete records from the crop list. Required Crop Units : CE>Agronomy>Required Crop Units Defines the crop unit size. How many seeds are in the bag? 80,000 kernels of corn in a bag. Other crops by be sold by pound. No link to unit of measure. This is used on the seed calculator which calculates the number of seeds to cover a field and converts to quantity of seed in a bag, and therefore, how many bags are needed. Timings under agronomy : Timing defines when the product, program or plan will be used. For example, the timing of applying chemicals to a crop could be considered pre or post planting or based on the amount of vegetation such as V1 or V2. Charge Code Configurations : CE> Agronomy>Charge code configurations Allows percentage or amount thresholds to be defined for the charge code. When charge code is used, validation to this configuration is completed. Approval would be required to override the configuration. For example, a price override threshold may be setup for a proposal. If the threshold is exceeded, further approval may be required. Pest Types : CE>Agronomy>Pest Types A data package will be provide for this listing including examples of bacterial, fungal, or insect. Pests : CE>Agronomy>Pests A data package will be provided that includes a list of pests with type of pests. Examples include Aspergillus Ear Rot (fungal), Bean Leaf Beetle (Insect). Pests may be identified in a work order to apply herbicides to the field. This information may be manually added to crop history for review by the agronomist for future planning. Note: A pest applicator license if required by federal and state to apply. Item Categories : CE>Agronomy>Item Categories Sync with FinOps including path. Used for filtering in CE, for example, fertilizer or chemical categories. Flex Grids within the plan and batch plan are filtered by item category.","title":"Setting up Dynamics 365 CE"},{"location":"AgronomistEnd-to-EndScenarios/#process-2-fertilizer-calculator","text":"The Fertilizer Calculator is a tool used to generate blends of fertility products. 1. Planning Tools 2. Fertilizer Calculator 3. Generate New 4. Populate applicable fields - Customer - Customer Operation - Batch size: Blender capacity when generated relays how many batches will need to occur to fill order. - Fertilizer State - Dry - Liquid Save Blend lines will populate with nutrient and product Input either input value (lbs.) or ratio (percentage) Click Calculate to populate output Quantity needed Total blend amount Number of batches needed Blend percent Generate sales order and release report to blender facilities to begin blending product (this function is not currently available but will be once it is fully developed and tested.)","title":"Process #2 Fertilizer Calculator"},{"location":"AgronomistEnd-to-EndScenarios/#process-3-sales-order-process","text":"The sales order is comprised of two pieces: the sales order and the work order. Both are tightly integrated within FinOps. The purpose of the sales order is to give users that only have access to CE the ability to enter orders for delivery and perform some of the functions that are usually completed in FinOps.","title":"Process #3 Sales Order Process"},{"location":"AgronomistEnd-to-EndScenarios/#generating-new-sales-order-in-ce","text":"Sales order tab Generate new Populate applicable sales order fields Account Customer Operation: It will default to one if the customer only has one operation. Split group: The individual paying for the product Delivery address: A requirement for many of the actions in F&O Inventory site: Where the inventory is arriving from Branch: Who is responsible for the customer or in charge of handling the billing Sales period: Used to price products against Ship date: Will default if not manually if not populated. Not a requirement. Save","title":"Generating New Sales Order in CE"},{"location":"AgronomistEnd-to-EndScenarios/#enter-sales-order-lines","text":"Add product Pick quantity Save After saving the estimated price, which is pulled from CE, will be populated. This may not be the price that is actually paid but is a stored list price that adjustments can be made to. Submit for Approval Checks for any products that need an applicator license Checks for any seed tech licenses that may be required Credit check ( based off the credit settings with F&O. It will either warn or deny a generating sales order. ) Generate Sales Order Once your submission has been approved, you will need to generate a sales order in F&O. You will receive a pop-up notifying you the sales order was created successfully in F&O/AX. Once order is acted upon in F&O, you can go into details within CE and will provide more information on the split group allocations so the person in CE has access to details.","title":"Enter Sales Order Lines"},{"location":"AgronomistEnd-to-EndScenarios/#work-order","text":"The work order is a type of sales order where the Ag Retailer will be performing a service. A work order requires more detail than a basic sales order. A third-party dispatching software defines the following setups and integrates with FinOps to create a work order type of sales order: Field(s) where products will used The product to be used on the field(s) The proper ratio to blend the fertilizer or chemicals for the field(s) Define the service to apply the product to the field(s) Within FinOps the work order type of sales order which includes the products and services from the dispatching software. CE will be updated with a summary view of the work order from FinOps. When a work order comes into CE an auto print service will print the work order and driving directions to be shared with the driver.","title":"Work Order"},{"location":"AgronomistEnd-to-EndScenarios/#blending-and-dispensing","text":"Lastly the work order information integrates with an additional third-party application to create a production order. Setups regarding the product and warehouse storage within the third-party application is required. This order will provide the blending and dispensing of the fertilizer or chemicals and confirm the completed quantities. Once the production order is complete: Transfer orders will be created for the movement of inventory Inventory will be reduced in the sales location Sales agreement will be applied to the details of the work order Equipment usage will be shared with the Rolling Stock module To generate a new work order: Orders Work Orders Generate new Populate applicable fields Account Customer Operation Customer Site Auto Print: Printer logic exists to automatically print a report remotely. Would be needed when a hard copy is necessary for the remote location to send with the driver. Sales site: Party who is responsible for the sale of the product. Application Site: Paraty performing task Application Operation: Type of work beign done (synced with AgSync). Application Date: Anticipated application date of the product Application Window: For chemical product this is important because depending on stage of the crop, it could cause harm if applied outside a specific timeframe. Crop: Crop the product will be applied to Order Status: Planned: Occurring in the future Booked: Occurring in the future Released: Moved to queue to get done and application date is set Scheduled: Has been assigned to an applicator for a scheduled date In-Progress: Product was administered partially and due to an unforeseen event, the job was not completed and requires further attention. Completed Pending Review: Applicatoin is complete. Archived Rejected Work Order ID: Generated number out of AgSync Dispensing Order Number: Only comes into effect if there is a blender/Kahler integration. This number is created when the picking list/mixed ticket is dispatched out to the warehouse. Ordering Notes: Notes that are specific to the field Notes that are specific to the application Application Notes: Notes or observations the equipment operator made while in the field. Save","title":"Blending and Dispensing"},{"location":"AgronomistEnd-to-EndScenarios/#enter-work-order-lines","text":"Work Order Lines tab Add new line Populate applicable fields Sales Sites Customer Product Pests: Certain states require documentation that states the application and purpose of the sprayed chemical. Application Site Quantity Submit for Approval If this is an integrated order from AgSync or a third-party dispatch, the submit for approval function would not be present. The \"Submit for Proposal\" would show up if generated in CE. If you open a work order line, you will be able to view the Work Order Completion tab which provides more information on the application and applicator. Application Worker Application License Rolling Rock: Equipment that was used to perform application Weather data: Required by law to be tracked Wind speed Wind Direction Temperature Humidity Completion date State/End Times [^1]: I'm not sure if this is correct information. I am assuming from the context. [^2]: Should add a sentence for each type explaining the purpose of each type [^3]: The last part of the sentence about seed doesn't make sense. The next sentence isn't a complete sentence. [^4]: This doesn't seem like a list of proposal types. Probably has the wrong header name Much of this doesn't include full sentences. It should be rewritten using sentences. [^5]: This is redundant. There is an entire section for this above. Combine this information with the information above [^6]: Explain why this is significant. What is the purpose for specifying a branch for each contract? [^7]: This sentence doesn't make sense standing alone like this. It obviously isn't explaining the list below it. What is the purpose. There should be a sentence or paragraph explaining the list below. What is that list? [^8]: Every place there is a step instruction, be clear what the step is. For example: Select \"Batch Plan\" or Select the \"Batch Plan\" menu. [^9]: What is this sentence? It doesn't look like a user instruction. [^10]: Add links to the sections for each item. I added the first one.","title":"Enter Work Order Lines"},{"location":"Agronomy/","text":"Agronomy Overview Agronomist End-to-End Scenarios Agronomy Implementation Activities Licensing and Certifications Rolling Stock Management","title":"Agronomy"},{"location":"Agronomy/#agronomy","text":"","title":"Agronomy"},{"location":"Agronomy/#overview","text":"Agronomist End-to-End Scenarios Agronomy Implementation Activities Licensing and Certifications Rolling Stock Management","title":"Overview"},{"location":"AgronomyImplementationActivities/","text":"Agronomy Implementation Activities and Estimates Overview The following is an overview of the implementation activities necessary for: - Integrations with AgSync and Kahler to FinOps - CE Integrations to FinOps - Agronomy for CE: A stand-alone CE instances without integration to FinOps Integrations with AgSync and Kahler to FinOps (+ Field Reveal) Which spot does the client want to be the source of truth for customer operations and site? Can be defined in Field Reveal, or AgSync or FinOps If in Field Reveal - do they want to migrate the data to FinOps? Determine if the client wants to use the customer site - adds some overhead Recommend FinOps as the master Discovery and deployment of Kahler TM2 module - Client does this piece. Kahler specific configurations Collaboration between client and Kahler Deploy and install Kahler integration on client machines Local install Uses IIS Start preparing data for data migrations - Client does this piece. If FinOps is the source of truth, this process can be streamlined Master data setup Determine if product masters are going to be used Build blended items/product configurator products Setup dispatching account Configure Levridge flags in inventory warehouse - Automatic BOM creator, warehouse items within each product/dispatching warehouse Id Setup unit rates Work order parameters Set site specific settings - default warehouse and site for each product that will be used in a work order Setup rolling stock - needs to correspond to AgSync Determine units of measure for products Sell UOM vs Application UOM Send clean data to 3rd parties (AgSync and Field Reveal) Setup and populate CDS with the known Ids from each party (FinOps, AgSync and Field Reveal) Also needs the blended items Get Azure AppServices and ServiceBus deployed and configured Can be done in parallel with the data preparation Setup event framework in FinOps for integrations With CE integration to FinOps All of the above for integrations with AgSync and Kahler to FinOps CE environment setup Import solutions Setup security roles on users Create an application user for use by the integration and services References the App Id setup in Azure tenet Get Azure AppServices and ServiceBus deployed and configured Get connection string to configure CE to FinOps integration plug-ins Create secure and unsecure configuration records Import flex grid configurations Determine which way data entities will be moving between CE and FinOps Where will entities be mastered Split groups, customer sites Setup relationship types in FinOps Needed for the integration of data between systems Takes multiple iterations to sort out Determine how charge codes are going to be setup Charge codes determine how discounting is done in CRM on agronomy contracts Setup the event framework to include more data for integrations Import CE system data and run integration push from FinOps Timing, crops, pests, etc. Configure master data Crop units, blend configurations, fertilizer settings, product nutrients, batch sizes Determine desired UI changes or customizations This is up to the client and can take many iterations Agronomy for CE Stand-alone CE instance without integration to FinOps.","title":"Agronomy Implementation Activities and Estimates"},{"location":"AgronomyImplementationActivities/#agronomy-implementation-activities-and-estimates","text":"","title":"Agronomy Implementation Activities and Estimates"},{"location":"AgronomyImplementationActivities/#overview","text":"The following is an overview of the implementation activities necessary for: - Integrations with AgSync and Kahler to FinOps - CE Integrations to FinOps - Agronomy for CE: A stand-alone CE instances without integration to FinOps","title":"Overview"},{"location":"AgronomyImplementationActivities/#integrations-with-agsync-and-kahler-to-finops-field-reveal","text":"Which spot does the client want to be the source of truth for customer operations and site? Can be defined in Field Reveal, or AgSync or FinOps If in Field Reveal - do they want to migrate the data to FinOps? Determine if the client wants to use the customer site - adds some overhead Recommend FinOps as the master Discovery and deployment of Kahler TM2 module - Client does this piece. Kahler specific configurations Collaboration between client and Kahler Deploy and install Kahler integration on client machines Local install Uses IIS Start preparing data for data migrations - Client does this piece. If FinOps is the source of truth, this process can be streamlined Master data setup Determine if product masters are going to be used Build blended items/product configurator products Setup dispatching account Configure Levridge flags in inventory warehouse - Automatic BOM creator, warehouse items within each product/dispatching warehouse Id Setup unit rates Work order parameters Set site specific settings - default warehouse and site for each product that will be used in a work order Setup rolling stock - needs to correspond to AgSync Determine units of measure for products Sell UOM vs Application UOM Send clean data to 3rd parties (AgSync and Field Reveal) Setup and populate CDS with the known Ids from each party (FinOps, AgSync and Field Reveal) Also needs the blended items Get Azure AppServices and ServiceBus deployed and configured Can be done in parallel with the data preparation Setup event framework in FinOps for integrations","title":"Integrations with AgSync and Kahler to FinOps (+ Field Reveal)"},{"location":"AgronomyImplementationActivities/#with-ce-integration-to-finops","text":"All of the above for integrations with AgSync and Kahler to FinOps CE environment setup Import solutions Setup security roles on users Create an application user for use by the integration and services References the App Id setup in Azure tenet Get Azure AppServices and ServiceBus deployed and configured Get connection string to configure CE to FinOps integration plug-ins Create secure and unsecure configuration records Import flex grid configurations Determine which way data entities will be moving between CE and FinOps Where will entities be mastered Split groups, customer sites Setup relationship types in FinOps Needed for the integration of data between systems Takes multiple iterations to sort out Determine how charge codes are going to be setup Charge codes determine how discounting is done in CRM on agronomy contracts Setup the event framework to include more data for integrations Import CE system data and run integration push from FinOps Timing, crops, pests, etc. Configure master data Crop units, blend configurations, fertilizer settings, product nutrients, batch sizes Determine desired UI changes or customizations This is up to the client and can take many iterations","title":"With CE integration to FinOps"},{"location":"AgronomyImplementationActivities/#agronomy-for-ce","text":"Stand-alone CE instance without integration to FinOps.","title":"Agronomy for CE"},{"location":"AgronomySales/","text":"Agronomy Sales Overview How to Create a Split Group in F&O Manage Splits, Sales Contracts and Prepayments Agronomy Sales Implementation Activities Customer Finance Programs Managing Fertilizer Contracts for Ag Retailers Agriculture Tax Calculation Prepayments Commissions Pricing Discounts Purchase Agreements Vendor Purchasing Rebates","title":"Agronomy Sales"},{"location":"AgronomySales/#agronomy-sales","text":"","title":"Agronomy Sales"},{"location":"AgronomySales/#overview","text":"How to Create a Split Group in F&O Manage Splits, Sales Contracts and Prepayments Agronomy Sales Implementation Activities Customer Finance Programs Managing Fertilizer Contracts for Ag Retailers Agriculture Tax Calculation Prepayments Commissions Pricing Discounts Purchase Agreements Vendor Purchasing Rebates","title":"Overview"},{"location":"AgronomySalesImplementationActivities/","text":"Agronomy Sales Implementation Activities Overview The following is an overview of the Agronomy Sales implementation activities. Enter setup data under Accounts Receivable > Setup > Agriculture (if not previously imported) a. Customer operation types b. Customer site types c. Growing seasons d. Sales periods e. Lines of business f. Finance programs g. Seed and technology agreement compliance h. Dispatching accounts Enter setup data under Organization administration > Global address book > Relationship types a. Need to define a relationship from customer to customer operation Enter sales agreement classifications under Accounts Receivable > Setup > Sales agreement classifications Under General Ledger > Journal setup > Journal names set the Prepayment posting profile flag to identify journals used for customer prepayments Configure parameters under Accounts Receivable > Setup > Agriculture > Agriculture parameters Under Organization administration > Number sequences > Number sequences enter or generate number sequences Enter setup data under Accounts payable > Payment: a. Terms of payment - set prepayment fields b. Cash discounts - set prepayment fields i. Within cash discounts set up cash discount schedules Configure ag specific settings in Accounts Receivable > Setup > Accounts receivable parameters: a. Credit rating b. Credit limits c. Prices Enter vendor zones under Procurement and sourcing > Setup > Prices and discounts > Vendor zones Enter master data - involves a lot of client feedback a. Customers i. Ag specific settings are: 1. Zone address 2. Dispatching account id if using a 3rd party dispatching system (like AgSync) 3. Seed and technology agreements 4. Membership fast tab for patronage 5. Taxation fast tab 6. On customer addresses set ag taxes 7. Billing notes b. Split groups c. Customer operations d. Customer sites e. Customer finance programs f. Vendors (if not the same as customers in the Ag parameters config form) i. On vendor addresses set ag taxes g. Rolling stock i. Cab configuration ii. Drive train iii. Equipment types iv. Status v. Equipment reasons vi. Equipment parameters vii. Equipment h. Contacts i. Setup applicator licenses Enter indirect ag taxes under Tax > Indirect taxes > Sales tax: a. Sales tax codes b. Sales tax groups c. Item sales tax groups d. Sales tax settlement periods e. Tax reasons Under Inventory management > Setup > Inventory breakdown setup sites and warehouse set ag tax values Prepare and enter products by setting up ag settings in: a. Product information management > Setup > Categories and attributes > Category hierarchies b. Accounts receivable > Setup > License and certification: i. Certificate types ii. Certificates compliance iii. Regulated products iv. Restricted product regional lists c. Feed and livestock > Setup > Veterinary feed directive (VFD): i. Veterinary feed directive (VFD) drug groups ii. Veterinary feed directive (VFD) compliance d. On released products, set the default order settings for each valid site and warehouse for the product i. If using Kahler with this item, under Manage inventory on Action pane > Warehouse items > Set the dispensing method e. On released products: - Assign regional lists - Assign certificates - Assign drug groups - Assign active ingredients - Assign nutrients - If using scale - set flag to recognize the product as one that will be used at scale - If using TMS - under Transportation fast tab set enable TMS and identify the default carrier service - Define ag specific settings on supplementary sales items i. Setup up substitute items Under Accounts receivable > Setup > Trade agreement journals enter trade agreement journals including ag specific settings Define transfer order charges Under Inventory management > Setup > Transfer order charges If using Transportation management: Configure TMS Parameters under Transportation management > Setup > Transportation management parameters i. General > Vendor invoice Write vendor invoice journal - set to yes Assign vendor journal name Freight bill invoice text ii. General > Loads Set flags for when loads get created automatically Enable split of transfer order ship confirmation - set to yes if they want the ability to reverse shipment iii. General > Dispensing loads Set flags for when loads get created (Kahler integration only) iv. General > Freight reconciliation Enable freight reconciliation - set to yes Configure data under Transportation management > Setup > Load building i. Load templates ii. Equipment Configure data under Transportation management > Setup > Carriers: i. Carrier service codes ii. Mode iii. Transportation methods Shipping carriers - Name - Specific structure required - Activate Carrier flag set to yes - Assign vendor account - Activate carrier rating - set to yes - Services - Assign services - Rating profiles Enter data under Transportation management > Setup > Rating i. Carrier accessorial charge ii. Break master iii. Rate master - Rate base iv. Rating profile v. Rating metadata vi. Miscellaneous charges Enter data under Transportation management > Setup> Freight reconciliation i. Reconciliation reasons ii. Freight bill type assignments iii. Audit master Enter data under Transportation management > Setup > Bing map usage key (if using mapping which most clients will be doing) Enter data under Transportation management > Setup > Transportation standards i. NMFC codes ii. LTL classes Enter data under Transportation management > Setup > Engines i. Mileage engine ii. Rate engine iii. Transit time engine iv. Zone master Warehouse Management Configurations Warehouse management > Setup > Warehouse > Warehouses i. Warehouse > Use warehouse management processes \u2013 set flag to yes for all warehouses that will use TMS b. Warehouse Management > Setup > Load posting methods > Regenerate methods (button) c. Warehouse Management > Setup > Warehouse > Location formats i. Configure one location format d. Warehouse Management > Setup > Warehouse > Location types i. Configure two location types; Dock and User e. Warehouse Management > Setup > Location profiles i. Configure two profiles; Default and User f. Configure Warehouse management parameters under Warehouse management > Setup > Warehouse management parameters i. General > Assign location profile & Location Type g. Warehouse Management > Setup > Load > Item load i. By item group indicate the load template id Under Inventory management > Setup > Agriculture > Agriculture parameters a. Dispensing > Load template ID Under Accounts receivable > Setup > Agriculture > Agriculture parameters a. Dispensing > Load template ID Under Product information management > Products > Released products a. Transportation > Use transportation management processes b. Transportation > Carrier service c. Manage Inventory > Net Weight","title":"Agronomy Sales Implementation Activities"},{"location":"AgronomySalesImplementationActivities/#agronomy-sales-implementation-activities","text":"","title":"Agronomy Sales Implementation Activities"},{"location":"AgronomySalesImplementationActivities/#overview","text":"The following is an overview of the Agronomy Sales implementation activities. Enter setup data under Accounts Receivable > Setup > Agriculture (if not previously imported) a. Customer operation types b. Customer site types c. Growing seasons d. Sales periods e. Lines of business f. Finance programs g. Seed and technology agreement compliance h. Dispatching accounts Enter setup data under Organization administration > Global address book > Relationship types a. Need to define a relationship from customer to customer operation Enter sales agreement classifications under Accounts Receivable > Setup > Sales agreement classifications Under General Ledger > Journal setup > Journal names set the Prepayment posting profile flag to identify journals used for customer prepayments Configure parameters under Accounts Receivable > Setup > Agriculture > Agriculture parameters Under Organization administration > Number sequences > Number sequences enter or generate number sequences Enter setup data under Accounts payable > Payment: a. Terms of payment - set prepayment fields b. Cash discounts - set prepayment fields i. Within cash discounts set up cash discount schedules Configure ag specific settings in Accounts Receivable > Setup > Accounts receivable parameters: a. Credit rating b. Credit limits c. Prices Enter vendor zones under Procurement and sourcing > Setup > Prices and discounts > Vendor zones Enter master data - involves a lot of client feedback a. Customers i. Ag specific settings are: 1. Zone address 2. Dispatching account id if using a 3rd party dispatching system (like AgSync) 3. Seed and technology agreements 4. Membership fast tab for patronage 5. Taxation fast tab 6. On customer addresses set ag taxes 7. Billing notes b. Split groups c. Customer operations d. Customer sites e. Customer finance programs f. Vendors (if not the same as customers in the Ag parameters config form) i. On vendor addresses set ag taxes g. Rolling stock i. Cab configuration ii. Drive train iii. Equipment types iv. Status v. Equipment reasons vi. Equipment parameters vii. Equipment h. Contacts i. Setup applicator licenses Enter indirect ag taxes under Tax > Indirect taxes > Sales tax: a. Sales tax codes b. Sales tax groups c. Item sales tax groups d. Sales tax settlement periods e. Tax reasons Under Inventory management > Setup > Inventory breakdown setup sites and warehouse set ag tax values Prepare and enter products by setting up ag settings in: a. Product information management > Setup > Categories and attributes > Category hierarchies b. Accounts receivable > Setup > License and certification: i. Certificate types ii. Certificates compliance iii. Regulated products iv. Restricted product regional lists c. Feed and livestock > Setup > Veterinary feed directive (VFD): i. Veterinary feed directive (VFD) drug groups ii. Veterinary feed directive (VFD) compliance d. On released products, set the default order settings for each valid site and warehouse for the product i. If using Kahler with this item, under Manage inventory on Action pane > Warehouse items > Set the dispensing method e. On released products: - Assign regional lists - Assign certificates - Assign drug groups - Assign active ingredients - Assign nutrients - If using scale - set flag to recognize the product as one that will be used at scale - If using TMS - under Transportation fast tab set enable TMS and identify the default carrier service - Define ag specific settings on supplementary sales items i. Setup up substitute items Under Accounts receivable > Setup > Trade agreement journals enter trade agreement journals including ag specific settings Define transfer order charges Under Inventory management > Setup > Transfer order charges If using Transportation management: Configure TMS Parameters under Transportation management > Setup > Transportation management parameters i. General > Vendor invoice Write vendor invoice journal - set to yes Assign vendor journal name Freight bill invoice text ii. General > Loads Set flags for when loads get created automatically Enable split of transfer order ship confirmation - set to yes if they want the ability to reverse shipment iii. General > Dispensing loads Set flags for when loads get created (Kahler integration only) iv. General > Freight reconciliation Enable freight reconciliation - set to yes Configure data under Transportation management > Setup > Load building i. Load templates ii. Equipment Configure data under Transportation management > Setup > Carriers: i. Carrier service codes ii. Mode iii. Transportation methods Shipping carriers - Name - Specific structure required - Activate Carrier flag set to yes - Assign vendor account - Activate carrier rating - set to yes - Services - Assign services - Rating profiles Enter data under Transportation management > Setup > Rating i. Carrier accessorial charge ii. Break master iii. Rate master - Rate base iv. Rating profile v. Rating metadata vi. Miscellaneous charges Enter data under Transportation management > Setup> Freight reconciliation i. Reconciliation reasons ii. Freight bill type assignments iii. Audit master Enter data under Transportation management > Setup > Bing map usage key (if using mapping which most clients will be doing) Enter data under Transportation management > Setup > Transportation standards i. NMFC codes ii. LTL classes Enter data under Transportation management > Setup > Engines i. Mileage engine ii. Rate engine iii. Transit time engine iv. Zone master Warehouse Management Configurations Warehouse management > Setup > Warehouse > Warehouses i. Warehouse > Use warehouse management processes \u2013 set flag to yes for all warehouses that will use TMS b. Warehouse Management > Setup > Load posting methods > Regenerate methods (button) c. Warehouse Management > Setup > Warehouse > Location formats i. Configure one location format d. Warehouse Management > Setup > Warehouse > Location types i. Configure two location types; Dock and User e. Warehouse Management > Setup > Location profiles i. Configure two profiles; Default and User f. Configure Warehouse management parameters under Warehouse management > Setup > Warehouse management parameters i. General > Assign location profile & Location Type g. Warehouse Management > Setup > Load > Item load i. By item group indicate the load template id Under Inventory management > Setup > Agriculture > Agriculture parameters a. Dispensing > Load template ID Under Accounts receivable > Setup > Agriculture > Agriculture parameters a. Dispensing > Load template ID Under Product information management > Products > Released products a. Transportation > Use transportation management processes b. Transportation > Carrier service c. Manage Inventory > Net Weight","title":"Overview"},{"location":"Agsync/","text":"Agsync AgSync is a dispatching application owned by Raven Industries. AgSync is used by ag retailers to dispatch applicators and their equipment to different fields. More specifically, within AgSync agronomists can schedule out the days for applicators and their equipment pointing them to field A, then B, then C based on the location of the fields and the machinery and products the applicator takes with them. Levridge has built an integration between D365 finance and AgSync to connect the systems together. Within the integration, there are multiple types of data moving both ways. Master data moves from D365 to AgSync telling AgSync what customers, fields and products the ag retailer has. AgSync uses work orders to schedule the work on specific fields. Once created, work orders are sent from AgSync to D365 as sales orders. It is a bidirectional integration that consists of a Topic for Master Data that goes from D365 F&O to AgSync and Work Orders that go from AgSync to D365 F&O. The Work Order integration utilize a background service running in the same application as the Webhook controller so there is no need for two integration application instances. There are a few unique aspects to the AgSync integration that is different from other integrations: - The Workorder integration service runs in the same app service as the controller and the Master Data integration service. - The Workorder integration service does all the transformation directly rather than using an EntityMapper. - The Workorder integration service makes a direct service call to D365 F&O rather than using a data source. - We are using CDS to provide lookup services for mapping entity identifiers between systems. - We utilize a filter on the event in F&O to send only the customers that need to to be sent from F&O to AgSync. This document will provide an overview of the integration framework used to move the data and then it will describe the data moving within the integration. Let's start with the technology behind the integration. Integration Description Levridge's Integration Framework can be viewed in Integration Overview . Standard Master Data Integration The standard master data integration configuration is shown below. External UUID Master Data Integration There is an alternate configuration that may be required when integrating with Field Reveal when Field Reveal is the master source for customer fields. In this scenario Field Reveal will provide the UUIDs it generates so we can provide those values to Agsync when we create the corresponding records in Agsync. This scenario is complicated and should be avoided if possible. The reason it is necessary is because when Field Reveal creates a work order in Agsync directly it uses an old Agsync API that uses a UUID as the Sync ID. Field Reveal generates the UUID and needs to provide those to Levridge so they can be used when creating the master record in Agsync. In this scenario, it is imperative that the Customer and Customer Operation is not sent from F&O until they have been updated in Field Reveal and a Field created in Field Reveal. Once a record is created in Agsync the UUID for it cannot be modified. The order of creation is as follows: Customer and Customer Operation are created in FinOps. Grower and Farm are created in Field Reveal and SyncIds are added in Field Reveal. Field is created in Field Reveal. This will cause a Field record to be sent from Field Reveal to the Levridge Field controller . The Field data will be placed on a service bus topic that has two subscriptions: One subscription will be serviced by the FieldToCDS integration service. This will use the UUID information to create a lookup record in CDS. The other subscription will be serviced by the FieldToAX integration service This will create the Customer Site in FinOps. When the record is created in FinOps it will trigger the event that sends the data to Agsync. The creation of the Customer Site entity causes the event to be evaluated. The filter that checks to make sure a Customer has an operation that has a site that corresponds to a field passes. The Customer, Operation and Site are all sent to the FinOpsToAgsync service bus topic. The AxToAgsync integration service receives the message and looks up the UUIDs from CDS then sends the records to Agsync for creation. Agsync creates the records and sends back a GUID. The AxToAgsync integration updates CDS with the GUID values. This communication diagram depicts this interaction: Common Data Service (CDS) The Common Data Service (CDS) is a solution from Microsoft built on top of the Power Platform. CDS tables are used in the integrations between D365 and AgSync to translate values that are different between the 2 systems. For example, in AgSync, customers have unique identifiers called GUIDs. These values are different from the unique identifiers D365 has for the same customer accounts. Levridge has implemented new tables in CDS to translate the D365 Customer account to the AgSync GUID. For the CDS environment there are two purchasing options: If the ag retailer has an existing CE instance, use it. A portion of the CE instance can be firewalled off for security purposes and then it can be used to host the CDS solution. Buy a specific CDS environment for only the CDS solution. This is more expensive. There are 7 types of data stored in CDS: Dispatch Accounts Customers Customer Operations Customer Sites Customer Site Locations Master Items Workers All these types are stored differently in AgSync than they are in D365 so they must be translated using the data in CDS. Products and Employees must be manually entered into the CDS database while Dispatch Accounts, Customers, Customer Operations Customer Sites and Customer Site Locations can be populated using a script that queries the data in AgSync and populates the data in CDS. All this data must exist in CDS prior to using the work order integrations. The Master Item entity translates AgSync operations to D365 Product and Service Items. This states which task you are performing and included in every work order. Product ID Numbers (this relates to the Master item in D365). AgSync has the ability to generate blends (ex: blending multiple ingredients to produce the fertilizer to be used on a field). There is a Master Item Table in CDS configured specifically for the operation. If there is a blend flag on an order change, it will pull from the Master Item Table. The Worker Table is a translation table required to map the applicator (worker) set up in AgSync to D365. This provides the information of who applied the product to the field and their applicator license number. An applicator license number is required on the sales order. Three entities need to be manually entered in CDS. The CDS setup includes: CE Levridge AgSync Solution Choose appropriate UI Form Once the CDS solution is deployed to an environment, an Application User will need to be created. Work Order Integration Below is the process to generate a work order in AgSync: Select Customer State where the application or service location will be completed out of Include what work is being done State the work order status (planned or released) Planned: These are premade orders ready for a certain time. The action is not ready to be performed. Not all users can view planned status due to security measures in place (ex: dispatcher unable to see planned work status). Released: The work orders are released and assigned to complete field work. The work order comes to F&O regardless of status. State the performed operation State the products being utilized Indicate the impacted crop(s) Add in any additional notes Save Order After a work order is saved, AgSync calls the Levridge AgsyncOrderChanged webhook sending over the work order data. The Levridge AgsyncOrderChanged webhook transforms the work order data and sends it to F&O where it creates or updates a corresponding sales order. If F&O accounts receivables are configured to perform a credit check and the credit check fails, F&O will send back a response indicating that the credit check did not pass. Then a rejection request is sent to Agsync to mark the work order as rejected. When F&O receives an updated work order from Agsync, F&O will remove all existing sales order line(s) and create new sale order line(s) to match the Agsync updated work order. This is done to keep the F&O sale order in sync with the possible changes that came through with Agsync updated work order. If a F&O sale's order has an active dispensing work order associated to it, then F&O will not delete or create new sales order line(s). An important item to note: A business process needs to be in place in the situation if AgSync creates a scheduled work order which gets scheduled, and then a dispensing work order is created and gets sent to Kahler. F&O will not pick up new changes if AgSync tries to go back to a release status and make changes and try to reschedule it. AgSync needs to cancel the Kahler order and F&O dispensing order and reschedule their AgSync work order. Microsoft Azure App Service The Levridge Integration Framework has been written as a web application that hosts HTTP endpoints as REST APIs and background processes that handle integrations. It is most commonly run in the cloud as an Azure App Serivce. It can also run as a windows service or as an IIS application. The Integration Overview provides additional information about the deployment options. Most of the setup will occur in Azure App Service. This is a requirement for AgSync in which AgSync pulls from Levridge's Azure Service Bus and an HTTP-based service for hosting web applications. Azure hosts our web app integration. The steps needed to create an App Service can be found under the Integration Overview . After the App ID has been generated along with the deployed integration code to App Service , there is an application configuration file named appsettings.json . This file is located within the generated Azure Service. In the App Services portion of the Azure Portal there is a Kudos button on the left-hand side, with a function to ZipDeploy code . This is where one would deploy the integration code. After deployed, back in Azure Service and right below Kudos button, there is an App Service Editor where one would deploy the App Settings json file to, which will give a list of all the files part of the integration. One of those is called AppSettings.json where the configuration is made for the Azure Service. Configuration Set up the logging level . The next section to be configured would outline what direction information is flowing within the service itself. There is a target configuration and source configuration which is needed to specify: Which system is the source system and which system is the target system. Which configuration section contains data connection information. Which section contains the service bus configuration to use. In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with service bus topic and subscription for Agsync Master Data]\", \"ODataConfigName\": \"[section name with F&O data configuration]\", \"SystemName\": \"DynamicsAx\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with Agsync endpoint configuration]\", \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"AgSync\", \"Direction\": \"Target\", } You must also include the controller entry to have the controller loaded: \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" } You must also configure two objects for Agsync integration: AgSyncEndpoint Agsync Configuration Object Here is a sample template for the entire appsettings.json file used for the integration from FinOps to Agsync: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"SourceConfig\": { \"ServiceBusConfigName\": \"AgsyncMasterDataServiceBus\", \"ODataConfigName\": \"DynamicsAX\", \"SystemName\": \"DynamicsAx\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"AgSyncEndpoint\", \"SystemName\": \"AgSync\", \"Direction\": \"Target\", \"CDSConfigName\": \"CDS\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"CDS\": { \"UriString\": \"[URL to CDS or Localhost]\", \"ActiveDirectoryResource\": \"[URL to CDS]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to CDS]/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"AgSyncEndpoint\": { \"MustUseWktProcessor\": true, \"baseUri\": \"https://fields.agsync.com/api/\", \"tokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"ClientId\": \"[client ID assigned by Agsync]\", // customer specific \"ClientPass\": \"[Client Secret assigned by Agsync]\", // customer specific \"ValutURL\": \"[URL to customer Azure Key Vault]\", \"AgSyncTokenKey\": \"AgsyncAccessToken\", \"RedirectUri\": \"[URL to AgsyncAuth controller]\", // customer specific \"IntegrationId\": \"CustomerIntegrationID\" // customer specific }, \"agsync\": { // used by Webhook \"MustUseWktProcessor\": true, \"ConnectionString\": \"[connection string to Agsync master data topic]\", \"TopicName\": \"[Agsync master data topic]\", \"RequiresSession\": true, \"RedirectUri\": \"[URL to AgsyncAuth controller]\", \"TokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"AuthorizeUrl\": \"https://auth.agsync.com/core/connect/authorize\", \"baseUri\": \"https://fields.agsync.com/api/\", \"ClientId\": \"[client ID assigned by Agsync]\", \"ClientPass\": \"[Client Secret assigned by Agsync]\", \"ValutURL\": \"[URL to customer Azure Key Vault]\", \"AgSyncTokenKey\": \"AgsyncAccessToken\" }, \"AgsyncMasterDataServiceBus\": { \"ConnectionString\": \"[connection string to Agsync master data topic]\", \"TopicName\": \"[Agsync master data topic]\", \"SubscriptionName\": \"[Agsync master data subscription name]\", \"RequiresSession\": true } } Microsoft Azure Service Bus Microsoft Azure Service Bus is a message bus for businesses to exchange documents and messages in the Cloud. There are two main tiers: Standard Service Bus: Supports 250 Kilobytes of data Premium Service Bus: Supports 1 Megabyte of data Most Levridge clients will be able to utilize the Standard Service Bus tier, however, if a client is integrating well-known-text (WKT) files with their work orders it may push the workorder size over the 250K data limit and they should look at upgrading to Premium Service Bus. Microsoft outlines how to create an Azure Service bus . The Azure Key Vault is a tool for securely storing and accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, or certificates. The vault enables us to securely store passwords, certificates, etc. with secure access. The key vault stores the authorization credentials for AgSync and by providing the secret to AgSync it lets AgSync know it is Levridge talking to them. This is required for all AgSync integrations. One can read how to setup the Azure Key Vault . When customer entities are sent from D365 to the Azure service bus, the agsync integration queries CDS to find the stored Customer ID. If there is no matching customer record the record is sent as a Create to AgSync. The customer is created in AgSync and the response from Agsync contains the Agsync specific ID for that customer. The newly generated AgSync ID is saved in combination with the D365 customer account in CDS. If CDS did have an existing record for the D365 customer, the message is updated to include the Agsync ID for that customer and the messages is sent to Agsync as an Update. Once a sales order is created in F&O, we will message back to AgSync and update them with the sales order number and the dispensing work order number (if available at the time of creation). This requires an entity setup in the event framework. Integration purchase requirements include: CDS Instance CE License Azure Subscription Service Bus App Service Key Vault AgSync Subscription Setup Internal setup time for configuration is 24 hours. To integrate from D365 F&O to Agsync you will need to: Create an Azure Service bus topic Create a subscription on the topic above Configure Event Endpoint in F&O Configure Levridge Entity Events Create Filter on Entity Event to only send agronomy customers Get Client ID and CLient password from Agsync Get Customer Specific Integration ID from Agsync Client Redirect URL is [Azure Webapp base URL]/api/AgsyncAuth Setup Azure Keyvault Create an application ID for the integration framework to authenticate to D365 CE Create an application user in D365 CRM and assign the proper role(s) A webhook is an API provided by the Levridge Integration Framework that gives AgSync the ability to send workorders to Levridge. AgSync sends workorders to the Levridge API which places the order on the service bus. The customer's specific URL needs to be whitelisted by AgSync. To whitelist a URL, one would log into AgSync and create a helpdesk ticket requesting AgSync to add the AgsyncOrderChanged URL into their setup file. The expected service time is between 24-48 hours. Escalate after 48 hours. General setup timelines: Deploying code to App Service takes the longest. 400 table lines for all three. The worker table is refreshed once a quarter Service item data is refreshed once a year Master item data is refreshed once every three year Data Moving Within the Integration: There are 4 types of master records sent from D365 to AgSync: Customers Customer Operations Customer Sites LevAgSyncSalesDetailEntity The LevAgSyncSalesDetailEntity stores sales, order number, dispensing work order numbers, and a unique work order ID that identifies the AgSync work order that needs to update. A Dispensing Account ID field has been added in F&O on the customer account under the sales order tab. Its purpose is to indicate which dispensing branch the customer receives services from. The dispensing branch within AgSync can be set up as either: An inventory site indicating where the product is physically located Commission/Sales groups indicating the agronomist that sold the service to the customer (Confirm and clarify this statement) Integration Framework Setup for Sending Customers \"Out of the Box Customer V3\" is being utilized and the code in the integration is choosing the data fields the entities pass through. The Dispatching Account ID is included on the customer form to only send accounts that have a dispatching account tied to it to AgSync. This is filtered by the Event Framework V3 Entity. An example is a client might have 100K in their database but for work order purposes there are only 30K that will ever work with AgSync. Filtering is again used in the Event Framework V3 Entity in the Customer Operation. This is a more sophisticated filter due to multiple types of operations an individual customer could have. Customer Operation is setup by four different filters: Customer Operation Type A filter is added so customer information which do not have a site is not sent. Example: Customer operations will not be sent to AgSync if they do not have sites tied to them. Customer Site Types Dispensing Site ID Release Status Process A work order is created at release status. Take release in AgSync and schedule work order. (Scheduling is assigning it out to an applicator to be applied). Dispatcher is going to see all released orders. Dispatcher takes orders, creates task packet, assigns to worker, annotates which piece of application equipment is going to be running, and saves as scheduled packet. The message is once again generated to webhook in F&O. Status is updated to \"scheduled\" if a blend. This creates an automatically explode bomb at scheduled date. (ex: if a client is using automatic fertilizer, dispensing ticket is released at the scheduled state which kicks off another integration to Kahler, so they can blend and send product out to field that is going to be applied.) Controllers Agsync Auth Controller The AgsyncAuth controller is used to generate a token needed to integrate with Agsync. Agsync Auth Test Controller Agsync Order Changed Controller The AgsyncOrderChanged controller is used by Agsync to send work orders as they are created or updated. This controller will bundle the work order into a message and place it in the message topic. Agsync Sync Accounts Controller The AgsyncSyncAccounts controller is used to query Agsync for master data and write the information into CDS. This is done during go-live to populate the lookup data in CDS. Agsync UUID Controller The AgsyncUUID controller provides UUIDs based on Sync Ids passed to the controller. This is used by Field Reveal to obtain the UUID from the Sync ID entered into Field Reveal.","title":"Agsync"},{"location":"Agsync/#agsync","text":"AgSync is a dispatching application owned by Raven Industries. AgSync is used by ag retailers to dispatch applicators and their equipment to different fields. More specifically, within AgSync agronomists can schedule out the days for applicators and their equipment pointing them to field A, then B, then C based on the location of the fields and the machinery and products the applicator takes with them. Levridge has built an integration between D365 finance and AgSync to connect the systems together. Within the integration, there are multiple types of data moving both ways. Master data moves from D365 to AgSync telling AgSync what customers, fields and products the ag retailer has. AgSync uses work orders to schedule the work on specific fields. Once created, work orders are sent from AgSync to D365 as sales orders. It is a bidirectional integration that consists of a Topic for Master Data that goes from D365 F&O to AgSync and Work Orders that go from AgSync to D365 F&O. The Work Order integration utilize a background service running in the same application as the Webhook controller so there is no need for two integration application instances. There are a few unique aspects to the AgSync integration that is different from other integrations: - The Workorder integration service runs in the same app service as the controller and the Master Data integration service. - The Workorder integration service does all the transformation directly rather than using an EntityMapper. - The Workorder integration service makes a direct service call to D365 F&O rather than using a data source. - We are using CDS to provide lookup services for mapping entity identifiers between systems. - We utilize a filter on the event in F&O to send only the customers that need to to be sent from F&O to AgSync. This document will provide an overview of the integration framework used to move the data and then it will describe the data moving within the integration. Let's start with the technology behind the integration.","title":"Agsync"},{"location":"Agsync/#integration-description","text":"Levridge's Integration Framework can be viewed in Integration Overview .","title":"Integration Description"},{"location":"Agsync/#standard-master-data-integration","text":"The standard master data integration configuration is shown below.","title":"Standard Master Data Integration"},{"location":"Agsync/#external-uuid-master-data-integration","text":"There is an alternate configuration that may be required when integrating with Field Reveal when Field Reveal is the master source for customer fields. In this scenario Field Reveal will provide the UUIDs it generates so we can provide those values to Agsync when we create the corresponding records in Agsync. This scenario is complicated and should be avoided if possible. The reason it is necessary is because when Field Reveal creates a work order in Agsync directly it uses an old Agsync API that uses a UUID as the Sync ID. Field Reveal generates the UUID and needs to provide those to Levridge so they can be used when creating the master record in Agsync. In this scenario, it is imperative that the Customer and Customer Operation is not sent from F&O until they have been updated in Field Reveal and a Field created in Field Reveal. Once a record is created in Agsync the UUID for it cannot be modified. The order of creation is as follows: Customer and Customer Operation are created in FinOps. Grower and Farm are created in Field Reveal and SyncIds are added in Field Reveal. Field is created in Field Reveal. This will cause a Field record to be sent from Field Reveal to the Levridge Field controller . The Field data will be placed on a service bus topic that has two subscriptions: One subscription will be serviced by the FieldToCDS integration service. This will use the UUID information to create a lookup record in CDS. The other subscription will be serviced by the FieldToAX integration service This will create the Customer Site in FinOps. When the record is created in FinOps it will trigger the event that sends the data to Agsync. The creation of the Customer Site entity causes the event to be evaluated. The filter that checks to make sure a Customer has an operation that has a site that corresponds to a field passes. The Customer, Operation and Site are all sent to the FinOpsToAgsync service bus topic. The AxToAgsync integration service receives the message and looks up the UUIDs from CDS then sends the records to Agsync for creation. Agsync creates the records and sends back a GUID. The AxToAgsync integration updates CDS with the GUID values. This communication diagram depicts this interaction:","title":"External UUID Master Data Integration"},{"location":"Agsync/#common-data-service-cds","text":"The Common Data Service (CDS) is a solution from Microsoft built on top of the Power Platform. CDS tables are used in the integrations between D365 and AgSync to translate values that are different between the 2 systems. For example, in AgSync, customers have unique identifiers called GUIDs. These values are different from the unique identifiers D365 has for the same customer accounts. Levridge has implemented new tables in CDS to translate the D365 Customer account to the AgSync GUID. For the CDS environment there are two purchasing options: If the ag retailer has an existing CE instance, use it. A portion of the CE instance can be firewalled off for security purposes and then it can be used to host the CDS solution. Buy a specific CDS environment for only the CDS solution. This is more expensive. There are 7 types of data stored in CDS: Dispatch Accounts Customers Customer Operations Customer Sites Customer Site Locations Master Items Workers All these types are stored differently in AgSync than they are in D365 so they must be translated using the data in CDS. Products and Employees must be manually entered into the CDS database while Dispatch Accounts, Customers, Customer Operations Customer Sites and Customer Site Locations can be populated using a script that queries the data in AgSync and populates the data in CDS. All this data must exist in CDS prior to using the work order integrations. The Master Item entity translates AgSync operations to D365 Product and Service Items. This states which task you are performing and included in every work order. Product ID Numbers (this relates to the Master item in D365). AgSync has the ability to generate blends (ex: blending multiple ingredients to produce the fertilizer to be used on a field). There is a Master Item Table in CDS configured specifically for the operation. If there is a blend flag on an order change, it will pull from the Master Item Table. The Worker Table is a translation table required to map the applicator (worker) set up in AgSync to D365. This provides the information of who applied the product to the field and their applicator license number. An applicator license number is required on the sales order. Three entities need to be manually entered in CDS. The CDS setup includes: CE Levridge AgSync Solution Choose appropriate UI Form Once the CDS solution is deployed to an environment, an Application User will need to be created.","title":"Common Data Service (CDS)"},{"location":"Agsync/#work-order-integration","text":"Below is the process to generate a work order in AgSync: Select Customer State where the application or service location will be completed out of Include what work is being done State the work order status (planned or released) Planned: These are premade orders ready for a certain time. The action is not ready to be performed. Not all users can view planned status due to security measures in place (ex: dispatcher unable to see planned work status). Released: The work orders are released and assigned to complete field work. The work order comes to F&O regardless of status. State the performed operation State the products being utilized Indicate the impacted crop(s) Add in any additional notes Save Order After a work order is saved, AgSync calls the Levridge AgsyncOrderChanged webhook sending over the work order data. The Levridge AgsyncOrderChanged webhook transforms the work order data and sends it to F&O where it creates or updates a corresponding sales order. If F&O accounts receivables are configured to perform a credit check and the credit check fails, F&O will send back a response indicating that the credit check did not pass. Then a rejection request is sent to Agsync to mark the work order as rejected. When F&O receives an updated work order from Agsync, F&O will remove all existing sales order line(s) and create new sale order line(s) to match the Agsync updated work order. This is done to keep the F&O sale order in sync with the possible changes that came through with Agsync updated work order. If a F&O sale's order has an active dispensing work order associated to it, then F&O will not delete or create new sales order line(s). An important item to note: A business process needs to be in place in the situation if AgSync creates a scheduled work order which gets scheduled, and then a dispensing work order is created and gets sent to Kahler. F&O will not pick up new changes if AgSync tries to go back to a release status and make changes and try to reschedule it. AgSync needs to cancel the Kahler order and F&O dispensing order and reschedule their AgSync work order.","title":"Work Order Integration"},{"location":"Agsync/#microsoft-azure-app-service","text":"The Levridge Integration Framework has been written as a web application that hosts HTTP endpoints as REST APIs and background processes that handle integrations. It is most commonly run in the cloud as an Azure App Serivce. It can also run as a windows service or as an IIS application. The Integration Overview provides additional information about the deployment options. Most of the setup will occur in Azure App Service. This is a requirement for AgSync in which AgSync pulls from Levridge's Azure Service Bus and an HTTP-based service for hosting web applications. Azure hosts our web app integration. The steps needed to create an App Service can be found under the Integration Overview . After the App ID has been generated along with the deployed integration code to App Service , there is an application configuration file named appsettings.json . This file is located within the generated Azure Service. In the App Services portion of the Azure Portal there is a Kudos button on the left-hand side, with a function to ZipDeploy code . This is where one would deploy the integration code. After deployed, back in Azure Service and right below Kudos button, there is an App Service Editor where one would deploy the App Settings json file to, which will give a list of all the files part of the integration. One of those is called AppSettings.json where the configuration is made for the Azure Service.","title":"Microsoft Azure App Service"},{"location":"Agsync/#configuration","text":"Set up the logging level . The next section to be configured would outline what direction information is flowing within the service itself. There is a target configuration and source configuration which is needed to specify: Which system is the source system and which system is the target system. Which configuration section contains data connection information. Which section contains the service bus configuration to use. In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with service bus topic and subscription for Agsync Master Data]\", \"ODataConfigName\": \"[section name with F&O data configuration]\", \"SystemName\": \"DynamicsAx\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with Agsync endpoint configuration]\", \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"AgSync\", \"Direction\": \"Target\", } You must also include the controller entry to have the controller loaded: \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" } You must also configure two objects for Agsync integration: AgSyncEndpoint Agsync Configuration Object Here is a sample template for the entire appsettings.json file used for the integration from FinOps to Agsync: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"SourceConfig\": { \"ServiceBusConfigName\": \"AgsyncMasterDataServiceBus\", \"ODataConfigName\": \"DynamicsAX\", \"SystemName\": \"DynamicsAx\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"AgSyncEndpoint\", \"SystemName\": \"AgSync\", \"Direction\": \"Target\", \"CDSConfigName\": \"CDS\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"CDS\": { \"UriString\": \"[URL to CDS or Localhost]\", \"ActiveDirectoryResource\": \"[URL to CDS]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to CDS]/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"AgSyncEndpoint\": { \"MustUseWktProcessor\": true, \"baseUri\": \"https://fields.agsync.com/api/\", \"tokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"ClientId\": \"[client ID assigned by Agsync]\", // customer specific \"ClientPass\": \"[Client Secret assigned by Agsync]\", // customer specific \"ValutURL\": \"[URL to customer Azure Key Vault]\", \"AgSyncTokenKey\": \"AgsyncAccessToken\", \"RedirectUri\": \"[URL to AgsyncAuth controller]\", // customer specific \"IntegrationId\": \"CustomerIntegrationID\" // customer specific }, \"agsync\": { // used by Webhook \"MustUseWktProcessor\": true, \"ConnectionString\": \"[connection string to Agsync master data topic]\", \"TopicName\": \"[Agsync master data topic]\", \"RequiresSession\": true, \"RedirectUri\": \"[URL to AgsyncAuth controller]\", \"TokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"AuthorizeUrl\": \"https://auth.agsync.com/core/connect/authorize\", \"baseUri\": \"https://fields.agsync.com/api/\", \"ClientId\": \"[client ID assigned by Agsync]\", \"ClientPass\": \"[Client Secret assigned by Agsync]\", \"ValutURL\": \"[URL to customer Azure Key Vault]\", \"AgSyncTokenKey\": \"AgsyncAccessToken\" }, \"AgsyncMasterDataServiceBus\": { \"ConnectionString\": \"[connection string to Agsync master data topic]\", \"TopicName\": \"[Agsync master data topic]\", \"SubscriptionName\": \"[Agsync master data subscription name]\", \"RequiresSession\": true } }","title":"Configuration"},{"location":"Agsync/#microsoft-azure-service-bus","text":"Microsoft Azure Service Bus is a message bus for businesses to exchange documents and messages in the Cloud. There are two main tiers: Standard Service Bus: Supports 250 Kilobytes of data Premium Service Bus: Supports 1 Megabyte of data Most Levridge clients will be able to utilize the Standard Service Bus tier, however, if a client is integrating well-known-text (WKT) files with their work orders it may push the workorder size over the 250K data limit and they should look at upgrading to Premium Service Bus. Microsoft outlines how to create an Azure Service bus . The Azure Key Vault is a tool for securely storing and accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, or certificates. The vault enables us to securely store passwords, certificates, etc. with secure access. The key vault stores the authorization credentials for AgSync and by providing the secret to AgSync it lets AgSync know it is Levridge talking to them. This is required for all AgSync integrations. One can read how to setup the Azure Key Vault . When customer entities are sent from D365 to the Azure service bus, the agsync integration queries CDS to find the stored Customer ID. If there is no matching customer record the record is sent as a Create to AgSync. The customer is created in AgSync and the response from Agsync contains the Agsync specific ID for that customer. The newly generated AgSync ID is saved in combination with the D365 customer account in CDS. If CDS did have an existing record for the D365 customer, the message is updated to include the Agsync ID for that customer and the messages is sent to Agsync as an Update. Once a sales order is created in F&O, we will message back to AgSync and update them with the sales order number and the dispensing work order number (if available at the time of creation). This requires an entity setup in the event framework. Integration purchase requirements include: CDS Instance CE License Azure Subscription Service Bus App Service Key Vault AgSync Subscription","title":"Microsoft Azure Service Bus"},{"location":"Agsync/#setup","text":"Internal setup time for configuration is 24 hours. To integrate from D365 F&O to Agsync you will need to: Create an Azure Service bus topic Create a subscription on the topic above Configure Event Endpoint in F&O Configure Levridge Entity Events Create Filter on Entity Event to only send agronomy customers Get Client ID and CLient password from Agsync Get Customer Specific Integration ID from Agsync Client Redirect URL is [Azure Webapp base URL]/api/AgsyncAuth Setup Azure Keyvault Create an application ID for the integration framework to authenticate to D365 CE Create an application user in D365 CRM and assign the proper role(s) A webhook is an API provided by the Levridge Integration Framework that gives AgSync the ability to send workorders to Levridge. AgSync sends workorders to the Levridge API which places the order on the service bus. The customer's specific URL needs to be whitelisted by AgSync. To whitelist a URL, one would log into AgSync and create a helpdesk ticket requesting AgSync to add the AgsyncOrderChanged URL into their setup file. The expected service time is between 24-48 hours. Escalate after 48 hours.","title":"Setup"},{"location":"Agsync/#general-setup-timelines","text":"Deploying code to App Service takes the longest. 400 table lines for all three. The worker table is refreshed once a quarter Service item data is refreshed once a year Master item data is refreshed once every three year","title":"General setup timelines:"},{"location":"Agsync/#data-moving-within-the-integration","text":"There are 4 types of master records sent from D365 to AgSync: Customers Customer Operations Customer Sites LevAgSyncSalesDetailEntity The LevAgSyncSalesDetailEntity stores sales, order number, dispensing work order numbers, and a unique work order ID that identifies the AgSync work order that needs to update. A Dispensing Account ID field has been added in F&O on the customer account under the sales order tab. Its purpose is to indicate which dispensing branch the customer receives services from. The dispensing branch within AgSync can be set up as either: An inventory site indicating where the product is physically located Commission/Sales groups indicating the agronomist that sold the service to the customer (Confirm and clarify this statement)","title":"Data Moving Within the Integration:"},{"location":"Agsync/#integration-framework-setup-for-sending-customers","text":"\"Out of the Box Customer V3\" is being utilized and the code in the integration is choosing the data fields the entities pass through. The Dispatching Account ID is included on the customer form to only send accounts that have a dispatching account tied to it to AgSync. This is filtered by the Event Framework V3 Entity. An example is a client might have 100K in their database but for work order purposes there are only 30K that will ever work with AgSync. Filtering is again used in the Event Framework V3 Entity in the Customer Operation. This is a more sophisticated filter due to multiple types of operations an individual customer could have. Customer Operation is setup by four different filters: Customer Operation Type A filter is added so customer information which do not have a site is not sent. Example: Customer operations will not be sent to AgSync if they do not have sites tied to them. Customer Site Types Dispensing Site ID","title":"Integration Framework Setup for Sending Customers"},{"location":"Agsync/#release-status-process","text":"A work order is created at release status. Take release in AgSync and schedule work order. (Scheduling is assigning it out to an applicator to be applied). Dispatcher is going to see all released orders. Dispatcher takes orders, creates task packet, assigns to worker, annotates which piece of application equipment is going to be running, and saves as scheduled packet. The message is once again generated to webhook in F&O. Status is updated to \"scheduled\" if a blend. This creates an automatically explode bomb at scheduled date. (ex: if a client is using automatic fertilizer, dispensing ticket is released at the scheduled state which kicks off another integration to Kahler, so they can blend and send product out to field that is going to be applied.)","title":"Release Status Process"},{"location":"Agsync/#controllers","text":"","title":"Controllers"},{"location":"Agsync/#agsync-auth-controller","text":"The AgsyncAuth controller is used to generate a token needed to integrate with Agsync.","title":"Agsync Auth Controller"},{"location":"Agsync/#agsync-auth-test-controller","text":"","title":"Agsync Auth Test Controller"},{"location":"Agsync/#agsync-order-changed-controller","text":"The AgsyncOrderChanged controller is used by Agsync to send work orders as they are created or updated. This controller will bundle the work order into a message and place it in the message topic.","title":"Agsync Order Changed Controller"},{"location":"Agsync/#agsync-sync-accounts-controller","text":"The AgsyncSyncAccounts controller is used to query Agsync for master data and write the information into CDS. This is done during go-live to populate the lookup data in CDS.","title":"Agsync Sync Accounts Controller"},{"location":"Agsync/#agsync-uuid-controller","text":"The AgsyncUUID controller provides UUIDs based on Sync Ids passed to the controller. This is used by Field Reveal to obtain the UUID from the Sync ID entered into Field Reveal.","title":"Agsync UUID Controller"},{"location":"AgsyncUUID/","text":"AgsyncUUID Controller The AgsyncUUID controller returns Agsync UUID values based on SyncIds provided to the controller. Overview The AgsyncUUID controller has one GET method and two POST methods. GET Method The GET method in the form of [BaseURL]/api/AgsyncUUID/[recordType]/[id]. The valid record types are: - Account - Grower - Farm - Field POST Methods The two POST methods both take a UuidCompositeRequest and return UuidCompositeResponse as a response. One URL accepts a record type (one of the valid strings above) in the form of [BaseURL]/api/AgsyncUUID/[recordType] with a UuidCompositeRequest in the body. This action will populate the UuidCompositeResponse in a hierarchical manner. For example, if the record type is \"Account\" only the account values will be returned. If the record type is \"Grower\" then the grower and account values will be returned. If the record type is \"Field\" then all record values will be returned. The second POST does not take a record type. It will simply take a UuidCompositeRequest in the body and will populate the values for any non-empty ID. For example, if the UuidCompositeRequest.AccountId and the UuidCompositeRequest.FieldId have values their respective identifying values will be returned in the UuidCompositeResponse . If there are any errors, they will always be reported in the UuidCompositResponse.FieldName value.","title":"AgsyncUUID Controller"},{"location":"AgsyncUUID/#agsyncuuid-controller","text":"The AgsyncUUID controller returns Agsync UUID values based on SyncIds provided to the controller.","title":"AgsyncUUID Controller"},{"location":"AgsyncUUID/#overview","text":"The AgsyncUUID controller has one GET method and two POST methods.","title":"Overview"},{"location":"AgsyncUUID/#get-method","text":"The GET method in the form of [BaseURL]/api/AgsyncUUID/[recordType]/[id]. The valid record types are: - Account - Grower - Farm - Field","title":"GET Method"},{"location":"AgsyncUUID/#post-methods","text":"The two POST methods both take a UuidCompositeRequest and return UuidCompositeResponse as a response. One URL accepts a record type (one of the valid strings above) in the form of [BaseURL]/api/AgsyncUUID/[recordType] with a UuidCompositeRequest in the body. This action will populate the UuidCompositeResponse in a hierarchical manner. For example, if the record type is \"Account\" only the account values will be returned. If the record type is \"Grower\" then the grower and account values will be returned. If the record type is \"Field\" then all record values will be returned. The second POST does not take a record type. It will simply take a UuidCompositeRequest in the body and will populate the values for any non-empty ID. For example, if the UuidCompositeRequest.AccountId and the UuidCompositeRequest.FieldId have values their respective identifying values will be returned in the UuidCompositeResponse . If there are any errors, they will always be reported in the UuidCompositResponse.FieldName value.","title":"POST Methods"},{"location":"ApplicationConfiguration/","text":"Application Configuration The Levridge Integration Framework utilizes standard Microsoft Configuration for ASP.NET Core to mange configuration settings. This document explains what configuration settings are managed and the definition, location and valid options for each setting. Overview There are five sources that are utilized for configuration data. Those sources are: web.config file command-line arguments hostsettings.json file Environment variables appsettings.json file Azure Key Vault","title":"Application Settings Configuration"},{"location":"ApplicationConfiguration/#application-configuration","text":"The Levridge Integration Framework utilizes standard Microsoft Configuration for ASP.NET Core to mange configuration settings. This document explains what configuration settings are managed and the definition, location and valid options for each setting.","title":"Application Configuration"},{"location":"ApplicationConfiguration/#overview","text":"There are five sources that are utilized for configuration data. Those sources are: web.config file command-line arguments hostsettings.json file Environment variables appsettings.json file Azure Key Vault","title":"Overview"},{"location":"AssignItemToProcurementCategory/","text":"Assign an Item to a Procurement Category Brief introduction of the module, component or feature being documented. This document explains ... How to Assign an Item to a Procurement Category Go to Product Information Management > Products > Released Products. In the list, find and select the desired record. Click Product categories. Click Edit. In the Category field, enter or select a value. In the tree, select 'ALL (New Category)\\Farm Supplies (New Category)'. Click OK. Click Save. In the Category field, enter or select a value. In the tree, select 'ALL (New Category)\\Natural Gas (New Category)'. Click OK. Click Save. Close the page. Close the page. Go to Procurement and Sourcing > Procurement Categories. In the tree, expand 'Landus\\Corporate'. In the tree, select 'Landus\\Corporate\\Equipment lease'. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. Click OK. Click Save. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the Item number field with a value of '110.1' Click Product Categories.","title":"Assign an Item to a Procurement Category"},{"location":"AssignItemToProcurementCategory/#assign-an-item-to-a-procurement-category","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Assign an Item to a Procurement Category"},{"location":"AssignItemToProcurementCategory/#how-to-assign-an-item-to-a-procurement-category","text":"Go to Product Information Management > Products > Released Products. In the list, find and select the desired record. Click Product categories. Click Edit. In the Category field, enter or select a value. In the tree, select 'ALL (New Category)\\Farm Supplies (New Category)'. Click OK. Click Save. In the Category field, enter or select a value. In the tree, select 'ALL (New Category)\\Natural Gas (New Category)'. Click OK. Click Save. Close the page. Close the page. Go to Procurement and Sourcing > Procurement Categories. In the tree, expand 'Landus\\Corporate'. In the tree, select 'Landus\\Corporate\\Equipment lease'. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. Click OK. Click Save. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the Item number field with a value of '110.1' Click Product Categories.","title":"How to Assign an Item to a Procurement Category"},{"location":"AssignPostingProfiletoProcurementCategory/","text":"Assign Posting Profile to Procurement Category Brief introduction of the module, component or feature being documented. This document explains ... How to Assign a Posting Profile to a Procurement Category Go to Inventory Management > Setup > Posting > Posting. Click the Purchase Order tab. In the Select field, select an option. Click New. In the list, mark the selected row. In the Item code field, select an option. In the Category Relation field, enter or select a value. In the tree, expand 'Landus (New category)\\Corporate (Corporate)'. In the tree, select 'Landus (New category)\\Corporate (Corporate)\\Office Supplies (New category)'. Click OK. In the list, find and select the desired record. In the Category relation field, enter or select a value. In the tree, select 'Landus (New Category)\\Animal Nutrition (Animal Nutrition)'. Click OK. In the Main account field, specify the desired values. Click Save. In the list, find and select the desired record. Close the page.","title":"Assign Posting Profile to Procurement Category"},{"location":"AssignPostingProfiletoProcurementCategory/#assign-posting-profile-to-procurement-category","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Assign Posting Profile to Procurement Category"},{"location":"AssignPostingProfiletoProcurementCategory/#how-to-assign-a-posting-profile-to-a-procurement-category","text":"Go to Inventory Management > Setup > Posting > Posting. Click the Purchase Order tab. In the Select field, select an option. Click New. In the list, mark the selected row. In the Item code field, select an option. In the Category Relation field, enter or select a value. In the tree, expand 'Landus (New category)\\Corporate (Corporate)'. In the tree, select 'Landus (New category)\\Corporate (Corporate)\\Office Supplies (New category)'. Click OK. In the list, find and select the desired record. In the Category relation field, enter or select a value. In the tree, select 'Landus (New Category)\\Animal Nutrition (Animal Nutrition)'. Click OK. In the Main account field, specify the desired values. Click Save. In the list, find and select the desired record. Close the page.","title":"How to Assign a Posting Profile to a Procurement Category"},{"location":"AzureAd/","text":"AzureAd Settings Optional Example \"AzureAd\": { \"Instance\": \"https://login.microsoftonline.com/\", \"Domain\": \"stoneridgesoftware.com\", \"TenantId\": \"[Tenant ID GUID]\", \"ClientId\": \"[Client ID GUID]\", \"CallbackPath\": \"/signin-oidc\", \"SignedOutCallbackPath \": \"/signout-callback-oidc\" } Definition AzureAd Instance Required No Default value The azure cloud instance to use for authentication. Most of the time this value should be \"https://login.microsoftonline.com/\" for the Azure public cloud. There may be a use for country specific instances such as \"https://login.microsoftonline.de/\" for Azure AD Germany. Domain Required No Default value The domain of the AD tenant used for authentication. This may be your domain (i.e. stoneridgesoftware.com) or it may be sub-domain of onmicrosoft. (i.e. contoso.onmicrosoft.com) TenantId Required No Default value The TenantId (aka audience) that will be used for authentication. The following values are valid: \"TenantId\" as a GUID obtained from the Azure portal to sign in users in your organization \"organizations\" to sign in users in any work or school account \"common\" to sign in users with any work or school account or Microsoft personal account \"consumers\" to sign in users with a Microsoft personal account only ClientId Required No Default value The Client ID (aka application ID) assigned in the Azure Portal. This client ID is obtained by enabling Authentication and Authorization in the Azure Portal. Once Authentication is enabled you can obtain the ClientId from the Authentication / Authorization section of the app service. Select Azure Active Directory and then select the Azure AD App. CallbackPath Optional Default = false SignedOutCallbackPath Optional Default = false","title":"AzureAd Settings"},{"location":"AzureAd/#azuread-settings","text":"Optional","title":"AzureAd Settings"},{"location":"AzureAd/#example","text":"\"AzureAd\": { \"Instance\": \"https://login.microsoftonline.com/\", \"Domain\": \"stoneridgesoftware.com\", \"TenantId\": \"[Tenant ID GUID]\", \"ClientId\": \"[Client ID GUID]\", \"CallbackPath\": \"/signin-oidc\", \"SignedOutCallbackPath \": \"/signout-callback-oidc\" }","title":"Example"},{"location":"AzureAd/#definition","text":"","title":"Definition"},{"location":"AzureAd/#azuread","text":"","title":"AzureAd"},{"location":"AzureAd/#instance","text":"Required No Default value The azure cloud instance to use for authentication. Most of the time this value should be \"https://login.microsoftonline.com/\" for the Azure public cloud. There may be a use for country specific instances such as \"https://login.microsoftonline.de/\" for Azure AD Germany.","title":"Instance"},{"location":"AzureAd/#domain","text":"Required No Default value The domain of the AD tenant used for authentication. This may be your domain (i.e. stoneridgesoftware.com) or it may be sub-domain of onmicrosoft. (i.e. contoso.onmicrosoft.com)","title":"Domain"},{"location":"AzureAd/#tenantid","text":"Required No Default value The TenantId (aka audience) that will be used for authentication. The following values are valid: \"TenantId\" as a GUID obtained from the Azure portal to sign in users in your organization \"organizations\" to sign in users in any work or school account \"common\" to sign in users with any work or school account or Microsoft personal account \"consumers\" to sign in users with a Microsoft personal account only","title":"TenantId"},{"location":"AzureAd/#clientid","text":"Required No Default value The Client ID (aka application ID) assigned in the Azure Portal. This client ID is obtained by enabling Authentication and Authorization in the Azure Portal. Once Authentication is enabled you can obtain the ClientId from the Authentication / Authorization section of the app service. Select Azure Active Directory and then select the Azure AD App.","title":"ClientId"},{"location":"AzureAd/#callbackpath","text":"Optional Default = false","title":"CallbackPath"},{"location":"AzureAd/#signedoutcallbackpath","text":"Optional Default = false","title":"SignedOutCallbackPath"},{"location":"AzureKeyVault/","text":"Azure Key Vault Azure Key Vault is a cloud service for securely storing and accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, or cryptographic keys. Overview Key Vault service supports two types of containers: vaults and managed HSM pools. Vaults support storing software and HSM-backed keys, secrets, and certificates. Managed HSM pools only support HSM-backed keys. See Azure Key Vault Overview for complete details. Configuration There are two properties needed in the configuration to use the Azure Key Vault. - Vault URI - Vault Key Currently these values are part of each integration configuration that uses the Azure Key Vault. These values will be provided in the integration configuration in the appsettings.json file. Refer to the integration configuration for specific information required for the use of Azure Key Vault for that integration. Vault URI The Vault URI can be obtained from the Azure Portal. It is in the Overview page of the Key Vault being used. Vault Key The Vault Key is the name given to the secret being stored in the vault. This value is used to store and retrieve the secret needed by the integration. This value is obtained from the Keys page of the Key Vault being used. Azure Key Vault Setup This section should include any instructions necessary to deploy this integration. This section may not be needed if the deployment follows a standard deployment process that is documented elsewhere. In this case it would be helpful to direct the reader to that standard documentation.","title":"Azure Key Vault"},{"location":"AzureKeyVault/#azure-key-vault","text":"Azure Key Vault is a cloud service for securely storing and accessing secrets. A secret is anything that you want to tightly control access to, such as API keys, passwords, certificates, or cryptographic keys.","title":"Azure Key Vault"},{"location":"AzureKeyVault/#overview","text":"Key Vault service supports two types of containers: vaults and managed HSM pools. Vaults support storing software and HSM-backed keys, secrets, and certificates. Managed HSM pools only support HSM-backed keys. See Azure Key Vault Overview for complete details.","title":"Overview"},{"location":"AzureKeyVault/#configuration","text":"There are two properties needed in the configuration to use the Azure Key Vault. - Vault URI - Vault Key Currently these values are part of each integration configuration that uses the Azure Key Vault. These values will be provided in the integration configuration in the appsettings.json file. Refer to the integration configuration for specific information required for the use of Azure Key Vault for that integration.","title":"Configuration"},{"location":"AzureKeyVault/#vault-uri","text":"The Vault URI can be obtained from the Azure Portal. It is in the Overview page of the Key Vault being used.","title":"Vault URI"},{"location":"AzureKeyVault/#vault-key","text":"The Vault Key is the name given to the secret being stored in the vault. This value is used to store and retrieve the secret needed by the integration. This value is obtained from the Keys page of the Key Vault being used.","title":"Vault Key"},{"location":"AzureKeyVault/#azure-key-vault-setup","text":"This section should include any instructions necessary to deploy this integration. This section may not be needed if the deployment follows a standard deployment process that is documented elsewhere. In this case it would be helpful to direct the reader to that standard documentation.","title":"Azure Key Vault Setup"},{"location":"AzureServiceBusSetup/","text":"Azure Service Bus Setup Overview Namespace Settings Pricing Tier The pricing tier options are Basic, Standard, or Premium. Levridge recommends using topics and subscriptions for the integration and that is not supported on the Basic tier so you must use either Standard or Premium. The Premium tier provides more consistent high throughput and allows for larger message sizes. Currently, Levridge has found the use of the Standard tier to be adequate and more cost effective. We recommend using the Standard tier. For more information on the differences between the two tiers see this Microsoft document. Recommended value = Standard Topics Partitioning Microsoft desribes partitioned queues and topics like this: Service Bus partitions enable queues and topics, or messaging entities, to be partitioned across multiple message brokers and messaging stores. Partitioning means that the overall throughput of a partitioned entity is no longer limited by the performance of a single message broker or messaging store. In addition, a temporary outage of a messaging store does not render a partitioned queue or topic unavailable. Subscriptions Definition ConnectionString TopicName SubscriptionName MaxConcurrentCount The maximum number of messages that will be allowed to be processed simultaneously.","title":"Azure Service Bus Setup"},{"location":"AzureServiceBusSetup/#azure-service-bus-setup","text":"","title":"Azure Service Bus Setup"},{"location":"AzureServiceBusSetup/#overview","text":"","title":"Overview"},{"location":"AzureServiceBusSetup/#namespace-settings","text":"","title":"Namespace Settings"},{"location":"AzureServiceBusSetup/#pricing-tier","text":"The pricing tier options are Basic, Standard, or Premium. Levridge recommends using topics and subscriptions for the integration and that is not supported on the Basic tier so you must use either Standard or Premium. The Premium tier provides more consistent high throughput and allows for larger message sizes. Currently, Levridge has found the use of the Standard tier to be adequate and more cost effective. We recommend using the Standard tier. For more information on the differences between the two tiers see this Microsoft document. Recommended value = Standard","title":"Pricing Tier"},{"location":"AzureServiceBusSetup/#topics","text":"","title":"Topics"},{"location":"AzureServiceBusSetup/#partitioning","text":"Microsoft desribes partitioned queues and topics like this: Service Bus partitions enable queues and topics, or messaging entities, to be partitioned across multiple message brokers and messaging stores. Partitioning means that the overall throughput of a partitioned entity is no longer limited by the performance of a single message broker or messaging store. In addition, a temporary outage of a messaging store does not render a partitioned queue or topic unavailable.","title":"Partitioning"},{"location":"AzureServiceBusSetup/#subscriptions","text":"","title":"Subscriptions"},{"location":"AzureServiceBusSetup/#definition","text":"","title":"Definition"},{"location":"AzureServiceBusSetup/#connectionstring","text":"","title":"ConnectionString"},{"location":"AzureServiceBusSetup/#topicname","text":"","title":"TopicName"},{"location":"AzureServiceBusSetup/#subscriptionname","text":"","title":"SubscriptionName"},{"location":"AzureServiceBusSetup/#maxconcurrentcount","text":"The maximum number of messages that will be allowed to be processed simultaneously.","title":"MaxConcurrentCount"},{"location":"AzureTableEntityConfiguration/","text":"AzureTableEntityConfiguration Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"AzureTableEntityConfiguration"},{"location":"AzureTableEntityConfiguration/#azuretableentityconfiguration","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"AzureTableEntityConfiguration"},{"location":"AzureTableEntityConfiguration/#overview","text":"","title":"Overview"},{"location":"AzureTableEntityConfiguration/#main-point-1","text":"","title":"Main Point 1"},{"location":"AzureTableEntityConfiguration/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"BaseFinanceProgram/","text":"Create a Base Finance Program This document explains how to create a base Finance Program. Overview Go to Accounts receivable > Setup > Agriculture > Finance programs. Click New. In the Name field, type a value. In the Description field, type a value. Click to follow the link in the Method of payment field. (If establishing a NEW method, otherwise select the appropriate one) a. Depending on how payments are received/processed, as well as bank configuration, there will need to be some thought given to how these should be established. Period, Payment status, Bank transaction type, file formats, payment control and payment attributes should all be considered. Click New. (Minimum setup required, but should be established in more detail & consideration) In the Method of payment field, type a value. In the Description field, type a value. In the Account type field, select an option. Click Save. Close the page. In the Method of payment field, enter or select a value. If desired, in the address section: Click Add. In the Name or description field, type a value. In the City field, type a value. In the State field, type a value. In the City field, enter or select a value. In the ZIP/postal code field, enter or select a value. In the Street field, enter a value. Click OK. In the Contact section, if desired : Click Add. In the Description field, type a relevant value such as the finance prog mgr name In the Contact number/address field, type a relevant value like '641-555-1999'. Click Add. In the Description field, type a relevant value such as the Finance prog mgr email In the Type field, select 'Email address'. In the Contact number/address field, type a relevant value like 'Test@124.com'. Click Save.","title":"Create a Base Finance Program"},{"location":"BaseFinanceProgram/#create-a-base-finance-program","text":"This document explains how to create a base Finance Program.","title":"Create a Base Finance Program"},{"location":"BaseFinanceProgram/#overview","text":"Go to Accounts receivable > Setup > Agriculture > Finance programs. Click New. In the Name field, type a value. In the Description field, type a value. Click to follow the link in the Method of payment field. (If establishing a NEW method, otherwise select the appropriate one) a. Depending on how payments are received/processed, as well as bank configuration, there will need to be some thought given to how these should be established. Period, Payment status, Bank transaction type, file formats, payment control and payment attributes should all be considered. Click New. (Minimum setup required, but should be established in more detail & consideration) In the Method of payment field, type a value. In the Description field, type a value. In the Account type field, select an option. Click Save. Close the page. In the Method of payment field, enter or select a value. If desired, in the address section: Click Add. In the Name or description field, type a value. In the City field, type a value. In the State field, type a value. In the City field, enter or select a value. In the ZIP/postal code field, enter or select a value. In the Street field, enter a value. Click OK. In the Contact section, if desired : Click Add. In the Description field, type a relevant value such as the finance prog mgr name In the Contact number/address field, type a relevant value like '641-555-1999'. Click Add. In the Description field, type a relevant value such as the Finance prog mgr email In the Type field, select 'Email address'. In the Contact number/address field, type a relevant value like 'Test@124.com'. Click Save.","title":"Overview"},{"location":"BasicCustomerPriceSetup/","text":"Basic Customer Price Setup Brief introduction of the module, component or feature being documented. This document explains ... Basic Customer Price Setup Go to Product information management > Products > Released products. In the list, click the link in the selected row. Click Edit. In the Price field, enter a number. Click Save. Close the page. Go to Accounts receivable > Orders > All sales orders. In the list, find and select the desired record. In the list, click the link in the selected row. Click Remove. Click Yes. Click Add line. In the Item number field, type a value. In the Site field, type a value. In the Warehouse field, type a value.","title":"Basic Customer Price Setup"},{"location":"BasicCustomerPriceSetup/#basic-customer-price-setup","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Basic Customer Price Setup"},{"location":"BasicCustomerPriceSetup/#basic-customer-price-setup_1","text":"Go to Product information management > Products > Released products. In the list, click the link in the selected row. Click Edit. In the Price field, enter a number. Click Save. Close the page. Go to Accounts receivable > Orders > All sales orders. In the list, find and select the desired record. In the list, click the link in the selected row. Click Remove. Click Yes. Click Add line. In the Item number field, type a value. In the Site field, type a value. In the Warehouse field, type a value.","title":"Basic Customer Price Setup"},{"location":"BasicVendorPriceWithPriceUpdate/","text":"Basic Vendor Price with Price Update Brief introduction of the module, component or feature being documented. This document explains ... Basic Vendor Price with Price Update Go to Product Information Management > Products > Released Products. In the list, click the link in the selected row. Click Edit. Select Yes in the Latest pruchase price field. In the Price field, enter a number. Click Save. Close the page. Go to Procurement and Sourcing > Puchase Orders > All purchase orders. In the list, find and select the desired record. In the list, click the link in the selected row. Click Remove. Click Yes. Click Add line. In the Item number field, type a value. In the list, mark the selected row. In the unit price field, enter a number. Click Save. On the Action Pane, click Purchase. Click Confirm. On the Action Pane, click Receive. Click Product Receipt. In the list, mark the selected row. Open Product receipt column filter. Sort A to Z In the Product receipt field, type a value. Click OK. On the Action Pane, click Invoice. Click Invoice. In the Number field, type a value. Click Post. Click Update match status. Click Post. Close the page. Close the page. Go to Product Information Management > Products > Released Products. In the list, click the link in the selected row.","title":"Basic Vendor Price with Price Update"},{"location":"BasicVendorPriceWithPriceUpdate/#basic-vendor-price-with-price-update","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Basic Vendor Price with Price Update"},{"location":"BasicVendorPriceWithPriceUpdate/#basic-vendor-price-with-price-update_1","text":"Go to Product Information Management > Products > Released Products. In the list, click the link in the selected row. Click Edit. Select Yes in the Latest pruchase price field. In the Price field, enter a number. Click Save. Close the page. Go to Procurement and Sourcing > Puchase Orders > All purchase orders. In the list, find and select the desired record. In the list, click the link in the selected row. Click Remove. Click Yes. Click Add line. In the Item number field, type a value. In the list, mark the selected row. In the unit price field, enter a number. Click Save. On the Action Pane, click Purchase. Click Confirm. On the Action Pane, click Receive. Click Product Receipt. In the list, mark the selected row. Open Product receipt column filter. Sort A to Z In the Product receipt field, type a value. Click OK. On the Action Pane, click Invoice. Click Invoice. In the Number field, type a value. Click Post. Click Update match status. Click Post. Close the page. Close the page. Go to Product Information Management > Products > Released Products. In the list, click the link in the selected row.","title":"Basic Vendor Price with Price Update"},{"location":"BasicVendorPurchasePrice/","text":"Basic Vendor Purchase Price Brief introduction of the module, component or feature being documented. This document explains ... Basic Vendor Purchase Price Go to Product information management > Products > Released products. In the list, click the link in the selected row. Click Edit. In the Price field, enter a number. Click Save. Close the page. Go to Procurement and sourcing > Purchase orders > All purchase orders. Click New. In the Vendor account field, type a value. In the Warehouse field, type a value. Click OK. In the Item number field, type a value.","title":"Basic Vendor Purchase Price"},{"location":"BasicVendorPurchasePrice/#basic-vendor-purchase-price","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Basic Vendor Purchase Price"},{"location":"BasicVendorPurchasePrice/#basic-vendor-purchase-price_1","text":"Go to Product information management > Products > Released products. In the list, click the link in the selected row. Click Edit. In the Price field, enter a number. Click Save. Close the page. Go to Procurement and sourcing > Purchase orders > All purchase orders. Click New. In the Vendor account field, type a value. In the Warehouse field, type a value. Click OK. In the Item number field, type a value.","title":"Basic Vendor Purchase Price"},{"location":"CDSConfig/","text":"","title":"CDSConfig"},{"location":"CE_Customization_Best_Practices/","text":"CE Customization Best Practices Objectives All Dynamics CE implementation modifications should be made in a development environment and then imported as a managed solution into Test and Production environments after the Levridge solution has been applied. There are two goals when creating and merging implementation specific modifications with the Levridge solutions. Retain customizations when Levridge upgrades are applied. Prevent customizations from masking changes included in Levridge upgrades. Form Modifications The best way to meet our objectives when modifying a Levridge form is to place all new fields within your own new \u201cSection\u201d on the form. This will prevent subsequent updates of Levridge from removing or reordering your fields. View Modifications We recommend that if you want to add additional fields to a view, you instead create a copy of the Levridge view you want to use as a base and save your changes to this copy. Your new view will not automatically receive modifications from subsequent Levridge upgrades, but this method will prevent upgrades from overwriting your modifications. Entity Modifications It is important to choose which assets you will include in your solutions judiciously. It is common for customizers to include inappropriate assets in their solution which cause a layer to be placed over the Levridge solution and masks desirable Levridge functionality. When adding entities to your solution we recommend the following options be chosen initially. Then, after the entity is in the solution you can selectively add only the subcomponents and required components that you want to customize. Inadvertent Unmanaged Layers It is also common to make inadvertent unmanaged layers when working in a development environment. If a customizer customizes a component and then immediately undoes that customization there is still an unmanaged layer left behind. This becomes an issue when Levridge later releases an upgrade and this unmanaged layer masks included changes. Dynamics CE now makes it easier to view and manipulate these unmanaged layers. Select a component and then press the solution layers button. This will show you all managed and unmanaged layers applied to this component. By clicking the ellipse and remove active customizations you can remove any inadvertent change you\u2019ve made to the component. Importing Solutions Understanding and choosing the appropriate options when importing a solution is important. For Solution Action you want to choose Upgrade for the fastest completion time. For more control you can perform a two step process by choosing Stage for upgrade. This option leaves both versions of the solution applied to the environment. This can be useful if you want to migrate data from a deprecated field or troubleshoot modification to your environment that are preventing a solution from being applied. It\u2019s particularly important to choose maintain customizations when importing into a development environment or your implementation specific customizations may be irrevocably lost. Choosing to overwrite customizations may be appropriate against a test or production environment if inadvertent unmanaged layers have been created, but we prefer to investigate and manually remove these layers using the technique described above. While these best practices will help you avoid the more common pitfalls, a comprehensive understanding of CE solution laying is the best way to administer a layered environment with confidence. Resources for further reading about CE solutions include: Solution Lifecycle Management for Dynamics 365 for Customer Engagement apps (You can also find the documentation under Stoneridge Teams > Playbook > General > Asset Library) How Managed Solutions Are Merged","title":"CE Customization Best Practices"},{"location":"CE_Customization_Best_Practices/#ce-customization-best-practices","text":"","title":"CE Customization Best Practices"},{"location":"CE_Customization_Best_Practices/#objectives","text":"All Dynamics CE implementation modifications should be made in a development environment and then imported as a managed solution into Test and Production environments after the Levridge solution has been applied. There are two goals when creating and merging implementation specific modifications with the Levridge solutions. Retain customizations when Levridge upgrades are applied. Prevent customizations from masking changes included in Levridge upgrades.","title":"Objectives"},{"location":"CE_Customization_Best_Practices/#form-modifications","text":"The best way to meet our objectives when modifying a Levridge form is to place all new fields within your own new \u201cSection\u201d on the form. This will prevent subsequent updates of Levridge from removing or reordering your fields.","title":"Form Modifications"},{"location":"CE_Customization_Best_Practices/#view-modifications","text":"We recommend that if you want to add additional fields to a view, you instead create a copy of the Levridge view you want to use as a base and save your changes to this copy. Your new view will not automatically receive modifications from subsequent Levridge upgrades, but this method will prevent upgrades from overwriting your modifications.","title":"View Modifications"},{"location":"CE_Customization_Best_Practices/#entity-modifications","text":"It is important to choose which assets you will include in your solutions judiciously. It is common for customizers to include inappropriate assets in their solution which cause a layer to be placed over the Levridge solution and masks desirable Levridge functionality. When adding entities to your solution we recommend the following options be chosen initially. Then, after the entity is in the solution you can selectively add only the subcomponents and required components that you want to customize.","title":"Entity Modifications"},{"location":"CE_Customization_Best_Practices/#inadvertent-unmanaged-layers","text":"It is also common to make inadvertent unmanaged layers when working in a development environment. If a customizer customizes a component and then immediately undoes that customization there is still an unmanaged layer left behind. This becomes an issue when Levridge later releases an upgrade and this unmanaged layer masks included changes. Dynamics CE now makes it easier to view and manipulate these unmanaged layers. Select a component and then press the solution layers button. This will show you all managed and unmanaged layers applied to this component. By clicking the ellipse and remove active customizations you can remove any inadvertent change you\u2019ve made to the component.","title":"Inadvertent Unmanaged Layers"},{"location":"CE_Customization_Best_Practices/#importing-solutions","text":"Understanding and choosing the appropriate options when importing a solution is important. For Solution Action you want to choose Upgrade for the fastest completion time. For more control you can perform a two step process by choosing Stage for upgrade. This option leaves both versions of the solution applied to the environment. This can be useful if you want to migrate data from a deprecated field or troubleshoot modification to your environment that are preventing a solution from being applied. It\u2019s particularly important to choose maintain customizations when importing into a development environment or your implementation specific customizations may be irrevocably lost. Choosing to overwrite customizations may be appropriate against a test or production environment if inadvertent unmanaged layers have been created, but we prefer to investigate and manually remove these layers using the technique described above. While these best practices will help you avoid the more common pitfalls, a comprehensive understanding of CE solution laying is the best way to administer a layered environment with confidence. Resources for further reading about CE solutions include: Solution Lifecycle Management for Dynamics 365 for Customer Engagement apps (You can also find the documentation under Stoneridge Teams > Playbook > General > Asset Library) How Managed Solutions Are Merged","title":"Importing Solutions"},{"location":"CE_Implementation_Checklist/","text":"Levridge CE Implementation Checklist Listed are the steps one would want to take to implement CE. CE Setup Secure and Unsecure config populated in CE Address Data Mapping Configured Set up flexgrids Remote printing setup Base Data import Unit of Measure Setup These steps fall within the CE to AX Integration Implementation Checklist .","title":"CE Implementation Checklist"},{"location":"CE_Implementation_Checklist/#levridge-ce-implementation-checklist","text":"Listed are the steps one would want to take to implement CE. CE Setup Secure and Unsecure config populated in CE Address Data Mapping Configured Set up flexgrids Remote printing setup Base Data import Unit of Measure Setup These steps fall within the CE to AX Integration Implementation Checklist .","title":"Levridge CE Implementation Checklist"},{"location":"CE_Plugin_Endpoint_Configuration/","text":"CE Plugin Endpoint Configuration In order to set up your CE to F&O endpoints, you will need to get your shared access key from your service bus endpoint. This is located in the Azure portal. Use the Azure portal to create a Service Bus topic and subscriptions to the topic . Once you have your key you will use it to update the Core and Agronomy service endpoint registrations using the plugin registration tool. 1. Update the endpoint (levridgetory in the case with your customers endpoing) 2. Update the topic name to what you are using (crm to ax) 3. Past in the SAS Key you got from the Azure portal. 4. Click Save.","title":"CE Plugin Endpoint Configuration"},{"location":"CE_Plugin_Endpoint_Configuration/#ce-plugin-endpoint-configuration","text":"In order to set up your CE to F&O endpoints, you will need to get your shared access key from your service bus endpoint. This is located in the Azure portal. Use the Azure portal to create a Service Bus topic and subscriptions to the topic . Once you have your key you will use it to update the Core and Agronomy service endpoint registrations using the plugin registration tool. 1. Update the endpoint (levridgetory in the case with your customers endpoing) 2. Update the topic name to what you are using (crm to ax) 3. Past in the SAS Key you got from the Azure portal. 4. Click Save.","title":"CE Plugin Endpoint Configuration"},{"location":"CE_Setup_Records/","text":"CE Setup Records Initial CE setup records can be created multiple ways depending on client requirements. They can be set up through the integration, manually created in CE, or imported with tools. Entities in pink must be set up in CE. Entities in yellow will integrate over from FinOps. Entities in green will integrate from Agsync. Once item categories have been either created or imported in, the filtered xmls on the Plans and Batch Plans will need to be updated to reflect the item category GUIDs within your environment. The Proposal OOB Proposal line Subgrids will also require filter updates to reflect the Item Category's in your environment.","title":"CE Setup Records"},{"location":"CE_Setup_Records/#ce-setup-records","text":"Initial CE setup records can be created multiple ways depending on client requirements. They can be set up through the integration, manually created in CE, or imported with tools. Entities in pink must be set up in CE. Entities in yellow will integrate over from FinOps. Entities in green will integrate from Agsync. Once item categories have been either created or imported in, the filtered xmls on the Plans and Batch Plans will need to be updated to reflect the item category GUIDs within your environment. The Proposal OOB Proposal line Subgrids will also require filter updates to reflect the Item Category's in your environment.","title":"CE Setup Records"},{"location":"CE_to_AX_Integration_Implementation_Checklist/","text":"CE to AX Integration Implementation Checklist Overview Implementation checklist for the CE to AX Integration including CE specific items. Azure App Service(s) Created Given Dynamics CE impersonation rights Microsoft Tutorial: Register an app with Azure Active Directory Given AX rights User set up in AX Default Company set up in AX Set up as an application user in CE Create users and assign security roles Setup Azure Service Bus Topic Subscription CE Setup Secure and Unsecure config populated in CE CE Plugin Endpoint Configuration CE Implementation Checklist Create Initial Setup Records Pricing Service Setup F&O Setup Fill out Azure Active Directory Application in F&O By allowing an external application to access your data you are affirming that you understand that the data handling and compliance standards of the external application may not be the same as those provided by Microsoft. Please consult the documentation for the application that you are enabling to learn more. Your privacy is important to us. For more information, see privacy statement. Set correct default company for application user in F&O Integration Setup D365 F&O to D365 CE D365 CE to D365 F&O appsettings.json Configuration File Create source and target config for F&O to CE Create source and target config for CE to F&O Logging Settings Use warning or error for product Set Instance Config","title":"CE to AX Integration Implementation Checklist"},{"location":"CE_to_AX_Integration_Implementation_Checklist/#ce-to-ax-integration-implementation-checklist","text":"","title":"CE to AX Integration Implementation Checklist"},{"location":"CE_to_AX_Integration_Implementation_Checklist/#overview","text":"Implementation checklist for the CE to AX Integration including CE specific items.","title":"Overview"},{"location":"CE_to_AX_Integration_Implementation_Checklist/#azure-app-services","text":"Created Given Dynamics CE impersonation rights Microsoft Tutorial: Register an app with Azure Active Directory Given AX rights User set up in AX Default Company set up in AX Set up as an application user in CE Create users and assign security roles","title":"Azure App Service(s)"},{"location":"CE_to_AX_Integration_Implementation_Checklist/#setup-azure-service-bus","text":"Topic Subscription","title":"Setup Azure Service Bus"},{"location":"CE_to_AX_Integration_Implementation_Checklist/#ce-setup","text":"Secure and Unsecure config populated in CE CE Plugin Endpoint Configuration CE Implementation Checklist Create Initial Setup Records Pricing Service Setup","title":"CE Setup"},{"location":"CE_to_AX_Integration_Implementation_Checklist/#fo-setup","text":"Fill out Azure Active Directory Application in F&O By allowing an external application to access your data you are affirming that you understand that the data handling and compliance standards of the external application may not be the same as those provided by Microsoft. Please consult the documentation for the application that you are enabling to learn more. Your privacy is important to us. For more information, see privacy statement. Set correct default company for application user in F&O","title":"F&amp;O Setup"},{"location":"CE_to_AX_Integration_Implementation_Checklist/#integration-setup","text":"D365 F&O to D365 CE D365 CE to D365 F&O appsettings.json Configuration File Create source and target config for F&O to CE Create source and target config for CE to F&O Logging Settings Use warning or error for product Set Instance Config","title":"Integration Setup"},{"location":"Class.Method.Template/","text":"ClassName.MethodName Method Namespace: [Enter Namespace Name] Assemblies: [Enter Assembly FileName] Describe the method here Overloads Overload Description MethodName (ParameterType1 Parameter1) description of overload MethodName (ParameterType1 Parameter1, ParameterType2 Parameter2) description of overload MethodName (ParameterType1 Parameter1) description of overload public Return MethodName<TA, TB>(ParameterType1 Parameter1); Parameters Returns Exceptions Examples MethodName (ParameterType1 Parameter1, ParameterType2 Parameter2) description of overload public Return MethodName<TA, TB>(ParameterType1 Parameter1, ParameterType2 Parameter2); Parameters Returns Exceptions Examples","title":"ClassName.MethodName Method"},{"location":"Class.Method.Template/#classnamemethodname-method","text":"Namespace: [Enter Namespace Name] Assemblies: [Enter Assembly FileName] Describe the method here","title":"ClassName.MethodName Method"},{"location":"Class.Method.Template/#overloads","text":"Overload Description MethodName (ParameterType1 Parameter1) description of overload MethodName (ParameterType1 Parameter1, ParameterType2 Parameter2) description of overload","title":"Overloads"},{"location":"Class.Method.Template/#methodnameparametertype1-parameter1","text":"description of overload public Return MethodName<TA, TB>(ParameterType1 Parameter1);","title":"MethodName(ParameterType1 Parameter1)"},{"location":"Class.Method.Template/#parameters","text":"","title":"Parameters"},{"location":"Class.Method.Template/#returns","text":"","title":"Returns"},{"location":"Class.Method.Template/#exceptions","text":"","title":"Exceptions"},{"location":"Class.Method.Template/#examples","text":"","title":"Examples"},{"location":"Class.Method.Template/#methodnameparametertype1-parameter1-parametertype2-parameter2","text":"description of overload public Return MethodName<TA, TB>(ParameterType1 Parameter1, ParameterType2 Parameter2);","title":"MethodName(ParameterType1 Parameter1, ParameterType2 Parameter2)"},{"location":"Class.Method.Template/#parameters_1","text":"","title":"Parameters"},{"location":"Class.Method.Template/#returns_1","text":"","title":"Returns"},{"location":"Class.Method.Template/#exceptions_1","text":"","title":"Exceptions"},{"location":"Class.Method.Template/#examples_1","text":"","title":"Examples"},{"location":"CloseInventory/","text":"Close Inventory Brief introduction of the module, component or feature being documented. This document explains ... How to Close Inventory Go to Inventory Management > Periodic Tasks > Closing and Adjustment. Click Close Procedure. Click Close Inventory. Expand the Run in the background section. In the Close Inventory up to field, enter a date. Click OK. Click Yes. Click Cancel.","title":"Close Inventory"},{"location":"CloseInventory/#close-inventory","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Close Inventory"},{"location":"CloseInventory/#how-to-close-inventory","text":"Go to Inventory Management > Periodic Tasks > Closing and Adjustment. Click Close Procedure. Click Close Inventory. Expand the Run in the background section. In the Close Inventory up to field, enter a date. Click OK. Click Yes. Click Cancel.","title":"How to Close Inventory"},{"location":"CommandLineParameters/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"CommandLineParameters/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"CommandLineParameters/#overview","text":"","title":"Overview"},{"location":"CommandLineParameters/#main-point-1","text":"","title":"Main Point 1"},{"location":"CommandLineParameters/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"Commissions/","text":"Commissions Levridge Commission Enhancements provide the following features: Sales Regions Sales regions can be setup to organize your commissions. You have the option to select a sales lead for each sales region. Commission Sales Groups You can setup a commission sales group for all items/customers, group of items/customers, or a single item/customer. You can link the sales group to a sales region. You are able to set the date range for that commission sales group. Sales orders: On the sales order split group line details tab, the system will assign the region and sales lead based off the commission sales group definition. You are able to modify those defaults as needed. When the sales order line has been delivered, the region and sales lead from the split group tab will default to the split group allocation lines. These values can also be changed up to the point the allocation line is invoiced at which time the fields are locked.","title":"Commissions"},{"location":"Commissions/#commissions","text":"","title":"Commissions"},{"location":"Commissions/#levridge-commission-enhancements-provide-the-following-features","text":"","title":"Levridge Commission Enhancements provide the following features:"},{"location":"Commissions/#sales-regions","text":"Sales regions can be setup to organize your commissions. You have the option to select a sales lead for each sales region.","title":"Sales Regions"},{"location":"Commissions/#commission-sales-groups","text":"You can setup a commission sales group for all items/customers, group of items/customers, or a single item/customer. You can link the sales group to a sales region. You are able to set the date range for that commission sales group. Sales orders: On the sales order split group line details tab, the system will assign the region and sales lead based off the commission sales group definition. You are able to modify those defaults as needed. When the sales order line has been delivered, the region and sales lead from the split group tab will default to the split group allocation lines. These values can also be changed up to the point the allocation line is invoiced at which time the fields are locked.","title":"Commission Sales Groups"},{"location":"Commodities/","text":"Commodity Accounting Overview Commodity Accounting Implementation Activities Rolling Stock Management","title":"Commodity Accounting"},{"location":"Commodities/#commodity-accounting","text":"","title":"Commodity Accounting"},{"location":"Commodities/#overview","text":"Commodity Accounting Implementation Activities Rolling Stock Management","title":"Overview"},{"location":"CommodityImplementationActivities/","text":"Commodity Accounting Implementation Activities Overview The following is an overview of the implementation activities necessary for Commodity Accounting. Activities All of the following tasks are in FinOps: In Product information management > Setup > Categories and attributes > Category hierarchies Create product categories for commodities and add commodities to the categories In Product information management > Products > Released products On each product that is a commodity, enter values into the Commodity fast tab Enter units of measures and conversions specific to commodities In Accounts receivable > Customers > All customers Set up lien holders for commodity customer Enter ship to addresses for scale tickets, sales contracts and transportation management (often imported with data migration activities) In Accounts receivable > Setup > Agriculture > Split groups Enter split groups used for commodity accounting In Accounts receivable > Customers > All customers > Agriculture tab in the action pane > Operations On customer operations and sites set the commodity split defaults for each commodity customer In Accounts receivable > Setup > Agriculture Create growing seasons for use on scale tickets In Cash and bank management > Bank accounts Enter bank accounts that will be used as hedge accounts In General ledger > Journal setup > Journal names Verify a customer prepayment journal type exists for sales advances Create journals to be used for grain settlements and payments To utilize the Daily position report (DPR) set up Power BI In Commodity accounting > Setup Configure Commodity accounting parameters Setup Inbound ticket auto apply schedule In Commodity accounting > Setup > Discounts and fees Create discount tables and schedules Create fee schedules and tables In Commodity accounting > Setup > Contracts Enter contract types Enter weights to govern Enter grades to govern In Commodity accounting > Setup > Quality and grade factors Enter grade factors Enter quality grades Enter grade averaging schedules In Commodity accounting > Setup > Risk Create dispositions Configure DPR parameters Enter hedge charge codes Enter Market zones In Commodity accounting > Risk management Enter commodity tickers Create delivery periods Enter the bid sheet configuration Enter discount schedule defaults Enter grade average defaults","title":"Commodity Accounting Implementation Activities"},{"location":"CommodityImplementationActivities/#commodity-accounting-implementation-activities","text":"","title":"Commodity Accounting Implementation Activities"},{"location":"CommodityImplementationActivities/#overview","text":"The following is an overview of the implementation activities necessary for Commodity Accounting.","title":"Overview"},{"location":"CommodityImplementationActivities/#activities","text":"All of the following tasks are in FinOps: In Product information management > Setup > Categories and attributes > Category hierarchies Create product categories for commodities and add commodities to the categories In Product information management > Products > Released products On each product that is a commodity, enter values into the Commodity fast tab Enter units of measures and conversions specific to commodities In Accounts receivable > Customers > All customers Set up lien holders for commodity customer Enter ship to addresses for scale tickets, sales contracts and transportation management (often imported with data migration activities) In Accounts receivable > Setup > Agriculture > Split groups Enter split groups used for commodity accounting In Accounts receivable > Customers > All customers > Agriculture tab in the action pane > Operations On customer operations and sites set the commodity split defaults for each commodity customer In Accounts receivable > Setup > Agriculture Create growing seasons for use on scale tickets In Cash and bank management > Bank accounts Enter bank accounts that will be used as hedge accounts In General ledger > Journal setup > Journal names Verify a customer prepayment journal type exists for sales advances Create journals to be used for grain settlements and payments To utilize the Daily position report (DPR) set up Power BI In Commodity accounting > Setup Configure Commodity accounting parameters Setup Inbound ticket auto apply schedule In Commodity accounting > Setup > Discounts and fees Create discount tables and schedules Create fee schedules and tables In Commodity accounting > Setup > Contracts Enter contract types Enter weights to govern Enter grades to govern In Commodity accounting > Setup > Quality and grade factors Enter grade factors Enter quality grades Enter grade averaging schedules In Commodity accounting > Setup > Risk Create dispositions Configure DPR parameters Enter hedge charge codes Enter Market zones In Commodity accounting > Risk management Enter commodity tickers Create delivery periods Enter the bid sheet configuration Enter discount schedule defaults Enter grade average defaults","title":"Activities"},{"location":"ConfigurationTemplate/","text":"Custom Mapping Assemblies Config Settings Example { ConfigEntry } Definition ConfigEntry Not Required Default:","title":"Custom Mapping Assemblies Config Settings"},{"location":"ConfigurationTemplate/#custom-mapping-assemblies-config-settings","text":"","title":"Custom Mapping Assemblies Config Settings"},{"location":"ConfigurationTemplate/#example","text":"{ ConfigEntry }","title":"Example"},{"location":"ConfigurationTemplate/#definition","text":"","title":"Definition"},{"location":"ConfigurationTemplate/#configentry","text":"Not Required Default:","title":"ConfigEntry"},{"location":"ConfigureAuthentication/","text":"Configure Authentication Register your application To register your application and manually add the app's registration information to your solution, follow these steps: Sign in to the Azure portal using either a work or school account, or a personal Microsoft account. If your account gives you access to more than one tenant, select your account in the top right corner, and set your portal session to the desired Azure AD tenant. Navigate to the Microsoft identity platform for developers App registrations page. Select New registration. When the Register an application page appears, enter your application's registration information: In the Name section, enter a meaningful application name that will be displayed to users of the app, for example AspNetCore-Quickstart. In Redirect URI, add https://localhost:44321/, and select Register. Select the Authentication menu, and then add the following information: In Redirect URIs, add https://localhost:44321/signin-oidc, and select Save. In the Advanced settings section, set Logout URL to https://localhost:44321/signout-oidc. Under Implicit grant, check ID tokens. Select Save. Create a section in Appsettings.json named AzureAd . \"AzureAd\": { \"Instance\": \"https://login.microsoftonline.com/\", \"Domain\": \"yourdomain.com\", \"TenantId\": \"00000000-0000-0000-0000-000000000000\", \"ClientId\": \"00000000-0000-0000-0000-000000000000\", \"CallbackPath\": \"/signin-oidc\" } Taken from Quickstart: Add sign-in with Microsoft to an ASP.NET Core web app .","title":"Configure Authentication"},{"location":"ConfigureAuthentication/#configure-authentication","text":"","title":"Configure Authentication"},{"location":"ConfigureAuthentication/#register-your-application","text":"To register your application and manually add the app's registration information to your solution, follow these steps: Sign in to the Azure portal using either a work or school account, or a personal Microsoft account. If your account gives you access to more than one tenant, select your account in the top right corner, and set your portal session to the desired Azure AD tenant. Navigate to the Microsoft identity platform for developers App registrations page. Select New registration. When the Register an application page appears, enter your application's registration information: In the Name section, enter a meaningful application name that will be displayed to users of the app, for example AspNetCore-Quickstart. In Redirect URI, add https://localhost:44321/, and select Register. Select the Authentication menu, and then add the following information: In Redirect URIs, add https://localhost:44321/signin-oidc, and select Save. In the Advanced settings section, set Logout URL to https://localhost:44321/signout-oidc. Under Implicit grant, check ID tokens. Select Save. Create a section in Appsettings.json named AzureAd . \"AzureAd\": { \"Instance\": \"https://login.microsoftonline.com/\", \"Domain\": \"yourdomain.com\", \"TenantId\": \"00000000-0000-0000-0000-000000000000\", \"ClientId\": \"00000000-0000-0000-0000-000000000000\", \"CallbackPath\": \"/signin-oidc\" } Taken from Quickstart: Add sign-in with Microsoft to an ASP.NET Core web app .","title":"Register your application"},{"location":"Configuring-Levridge-Entity-Event-Endpoint/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"Configuring-Levridge-Entity-Event-Endpoint/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Configuring-Levridge-Entity-Event-Endpoint/#overview","text":"","title":"Overview"},{"location":"Configuring-Levridge-Entity-Event-Endpoint/#main-point-1","text":"","title":"Main Point 1"},{"location":"Configuring-Levridge-Entity-Event-Endpoint/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"ControllerSecurity/","text":"Configuring Controller Security Overview Levridge has provided configurable security for our controllers. Once a controller is secured each instance of the Integration Framework in which it is used must be configured in the Active Directory to expose the API. Here is a link to the Microsoft documentation that explains the process of registering an application in Azure Active Directory. Application Managed Identity If the Levridge Integration Framework is deployed in an Azure tenant Microsoft recommends using a managed identity. This makes is much simpler to manage access to Azure resources such as the Azure Service Bus, Azure Key Vault and Azure Configuration Serivice. To setup a system managed identity, use the instructions provided here . You will still need to provide a ClientId . To obtain a ClientId you will need to turn on Security in the Azure Portal. Follow the instructions here to enable security. In one of the steps it has you select the Express option for Azure Active Directory. This creates an Application Registration for you. You can also select an existing Application Registration if you have already created one for the app service. It is the ClientId of the Application Registration that will be used in the AzureAd node of the appsettings.json file. Application Permissions (Roles) Since controllers are generally called by applications that are not using the Azure Active Directory to authenticate users we have configured our controllers to utilize Application Permissions rather than Delegated permissions . Exposing Application Permissions To expose application permissions you must add one or more roles to the registered application manifest. Use this link for specific instructions. Don't forget to provide admin consent. Assigning Application Permissions Once you have exposed application permissions you will need to assign those permissions to the application that will be calling the API. You will assign Application Permissions as opposed to Delegated Permisions. Use this link for specific instructions. Configuring Authorized Roles Once the role(s) are defined as application permissions and the calling application is assigned the necessary permissions you will need to add the role(s) to the InstanceConfig appsettings.json . Configure AzureAd Settings You will need to provide the information necessary to utilize Azure AD to authenticate calls to the controller. See AzureAd Settings for more information. Enabling Security on a Controller At the time of this writing (5/15/2020) we only have security enabled on the default controller. Be careful about enabling security on controllers. Many of the controllers are called by applcations that expect anonymous access. To enable security you will need to add the following attribute to the controller class: [Authorize(AuthenticationSchemes = OpenIdConnectDefaults.AuthenticationScheme + \",\" + JwtBearerDefaults.AuthenticationScheme)] You can simply add the JwtBearer authentication scheme but then you will not be able to access the API from a browser. Allowing Anonymous Access If you have enabled security on a controller but you want certain actions to allow anonymous access you can add the [AllowAnonymous] attribute to the method. If you want all but a few actions to allow anonymous access you can simply add the [Authorize] attribute only to the actions that you want to secure and don't add it to the class. Be sure to specify the Authentication Schemes you want to use or it will simply use the default which is OpenIdConnect.","title":"Configuring Controller Security"},{"location":"ControllerSecurity/#configuring-controller-security","text":"","title":"Configuring Controller Security"},{"location":"ControllerSecurity/#overview","text":"Levridge has provided configurable security for our controllers. Once a controller is secured each instance of the Integration Framework in which it is used must be configured in the Active Directory to expose the API. Here is a link to the Microsoft documentation that explains the process of registering an application in Azure Active Directory.","title":"Overview"},{"location":"ControllerSecurity/#application-managed-identity","text":"If the Levridge Integration Framework is deployed in an Azure tenant Microsoft recommends using a managed identity. This makes is much simpler to manage access to Azure resources such as the Azure Service Bus, Azure Key Vault and Azure Configuration Serivice. To setup a system managed identity, use the instructions provided here . You will still need to provide a ClientId . To obtain a ClientId you will need to turn on Security in the Azure Portal. Follow the instructions here to enable security. In one of the steps it has you select the Express option for Azure Active Directory. This creates an Application Registration for you. You can also select an existing Application Registration if you have already created one for the app service. It is the ClientId of the Application Registration that will be used in the AzureAd node of the appsettings.json file.","title":"Application Managed Identity"},{"location":"ControllerSecurity/#application-permissions-roles","text":"Since controllers are generally called by applications that are not using the Azure Active Directory to authenticate users we have configured our controllers to utilize Application Permissions rather than Delegated permissions .","title":"Application Permissions (Roles)"},{"location":"ControllerSecurity/#exposing-application-permissions","text":"To expose application permissions you must add one or more roles to the registered application manifest. Use this link for specific instructions. Don't forget to provide admin consent.","title":"Exposing Application Permissions"},{"location":"ControllerSecurity/#assigning-application-permissions","text":"Once you have exposed application permissions you will need to assign those permissions to the application that will be calling the API. You will assign Application Permissions as opposed to Delegated Permisions. Use this link for specific instructions.","title":"Assigning Application Permissions"},{"location":"ControllerSecurity/#configuring-authorized-roles","text":"Once the role(s) are defined as application permissions and the calling application is assigned the necessary permissions you will need to add the role(s) to the InstanceConfig appsettings.json .","title":"Configuring Authorized Roles"},{"location":"ControllerSecurity/#configure-azuread-settings","text":"You will need to provide the information necessary to utilize Azure AD to authenticate calls to the controller. See AzureAd Settings for more information.","title":"Configure AzureAd Settings"},{"location":"ControllerSecurity/#enabling-security-on-a-controller","text":"At the time of this writing (5/15/2020) we only have security enabled on the default controller. Be careful about enabling security on controllers. Many of the controllers are called by applcations that expect anonymous access. To enable security you will need to add the following attribute to the controller class: [Authorize(AuthenticationSchemes = OpenIdConnectDefaults.AuthenticationScheme + \",\" + JwtBearerDefaults.AuthenticationScheme)] You can simply add the JwtBearer authentication scheme but then you will not be able to access the API from a browser.","title":"Enabling Security on a Controller"},{"location":"ControllerSecurity/#allowing-anonymous-access","text":"If you have enabled security on a controller but you want certain actions to allow anonymous access you can add the [AllowAnonymous] attribute to the method. If you want all but a few actions to allow anonymous access you can simply add the [Authorize] attribute only to the actions that you want to secure and don't add it to the class. Be sure to specify the Authentication Schemes you want to use or it will simply use the default which is OpenIdConnect.","title":"Allowing Anonymous Access"},{"location":"Controllers/","text":"Controllers Settings Controllers section is a json object in the appsettings.json file used by the Levridge Integration Framework to define which controllers to load for the current Levridge Integration Framework instance. Example \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" }, Definition Controllers The controllers json object is comma delimited list of json objects that define which controllers to load for the current Levridge Integration Framework instance. Each json object contains a name and an assembly name. The name is not used by the system, but is used to provide a human friendly name for the assembly referenced with it. In the example above, the Controllers object informs the Levridge Integration Framework to load two assemblies: - \"Levridge.Integration.Host.DefaultController\" - \"Levridge.Integration.Host.AgSyncController\" See Also Controller Security","title":"Controllers Settings"},{"location":"Controllers/#controllers-settings","text":"Controllers section is a json object in the appsettings.json file used by the Levridge Integration Framework to define which controllers to load for the current Levridge Integration Framework instance.","title":"Controllers Settings"},{"location":"Controllers/#example","text":"\"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" },","title":"Example"},{"location":"Controllers/#definition","text":"","title":"Definition"},{"location":"Controllers/#controllers","text":"The controllers json object is comma delimited list of json objects that define which controllers to load for the current Levridge Integration Framework instance. Each json object contains a name and an assembly name. The name is not used by the system, but is used to provide a human friendly name for the assembly referenced with it. In the example above, the Controllers object informs the Levridge Integration Framework to load two assemblies: - \"Levridge.Integration.Host.DefaultController\" - \"Levridge.Integration.Host.AgSyncController\"","title":"Controllers"},{"location":"Controllers/#see-also","text":"Controller Security","title":"See Also"},{"location":"Create-Split-Group/","text":"Create a New Split Group Steps Split Group Setup: - In Accounts Receivable > Customers > All customers > Select a customer and under the \u201cAgriculture\u201d tab - Click on \"Split groups\" under \"Operation Management\" - The Split Group screen will show the specific split groups associated to the customer. - There is no limit to the number of split groups that can be created per customer. - A specific split group can be set to active or inactive when it is no longer needed. - After a split group is created and made active, it can be selected for use on sales agreements and sales orders. Prepayments are applied against a sales invoice according to the split selected on the sales order. Steps Expected Result 1. Navigate to Accounts Receivable > Setup >Agriculture > Split Groups The split groups grid will display. 2. From the top menu bar click the +New button. A fly-out menu on the right sidebar will appear. The split group code field will automatically be assigned a sequential number sequence. 3. Select/change the Start Date to reflect the split group start date by clicking on the calendar icon and choosing a date or enter a date manually. The start date will default to today's date but can be changed to the actual start date. Once a date is selected from the calendar or manually a date should appear in the Start Date field. 4. Select/change the End Date to reflect the split group end date by clicking on the calendar icon and choosing a date or enter a date manually. The end date will default to the system's infinity date but can be changed to the actual end date. Once a date is selected from the calendar or manually, a date should appear in the End Date field. This field should always contain a date later than the start date.","title":"Create a New Split Group"},{"location":"Create-Split-Group/#create-a-new-split-group","text":"","title":"Create a New Split Group"},{"location":"Create-Split-Group/#steps","text":"Split Group Setup: - In Accounts Receivable > Customers > All customers > Select a customer and under the \u201cAgriculture\u201d tab - Click on \"Split groups\" under \"Operation Management\" - The Split Group screen will show the specific split groups associated to the customer. - There is no limit to the number of split groups that can be created per customer. - A specific split group can be set to active or inactive when it is no longer needed. - After a split group is created and made active, it can be selected for use on sales agreements and sales orders. Prepayments are applied against a sales invoice according to the split selected on the sales order. Steps Expected Result 1. Navigate to Accounts Receivable > Setup >Agriculture > Split Groups The split groups grid will display. 2. From the top menu bar click the +New button. A fly-out menu on the right sidebar will appear. The split group code field will automatically be assigned a sequential number sequence. 3. Select/change the Start Date to reflect the split group start date by clicking on the calendar icon and choosing a date or enter a date manually. The start date will default to today's date but can be changed to the actual start date. Once a date is selected from the calendar or manually a date should appear in the Start Date field. 4. Select/change the End Date to reflect the split group end date by clicking on the calendar icon and choosing a date or enter a date manually. The end date will default to the system's infinity date but can be changed to the actual end date. Once a date is selected from the calendar or manually, a date should appear in the End Date field. This field should always contain a date later than the start date.","title":"Steps"},{"location":"CreateMaintainMonitorCustomerPrograms/","text":"Create, Maintain, Monitor Customer Programs This document explains how to create, maintain, and monitor customer programs. Create a New Customer Program Go to Accounts receivable > Customers > All customers. In the list, find and select the desired record. On the Action Pane, click Agriculture. Click Customer finance programs. Click New. In the Finance program field, enter or select a value. In the Program account number field, type a value. a. Required field. Enter N/A if an account number is not relevant. In the Maximum amount field, enter a number. In the Renewable field, select an option (Yes/No). In the From date field, enter a start date. In the To date field, enter a date. In the Notes field, type a value, if applicable. In the Address field, select a value. \u2013 Would like this to default if there is only one value In the Contact information field, select a value. \u2013 Would like this to default if there is only one value Click Save. Close the page. View or Edit a Customer Program Go to Accounts receivable > Customers > All customers. In the list, find and select the desired record. On the Action Pane, click Agriculture. Click Customer finance programs. View program information or edit as appropriate. If applicable, Click Recalculate balances. \u2013 Would like to add a batch process Status of \"Active\" is defaulted from the base program value. Date columns, as well as most other data is available to sort/filter to limit this view over time. To view all customer transactions or the transactions that account for the \"Amount used\" and/or \"Uncollected amount\" follow these steps: a. Go to Accounts receivable > Customers > All customers. b. In the list, find and select the desired record. c. On the Action Pane, click Customer. d. Click Transactions. e. Default view displays \"All\" transactions. i. Hint: the user may personalize the transaction list to include and display the Method of payment. ii. Corrections: when the Method of payment is visible in the list, it is available for edit with appropriate security access. This allows for transactions not assigned correctly to be adjusted to the intended Method of payment. If adjustment is made, the \"Recalculate balances\" process must be executed in order to update the displayed values for Amount used and Uncollected amount. f. Select show \"Open\", if applicable to display unapplied payments and unpaid/unsettled invoices For the date range applicable to the Finance program (& the Method of payment), the Amount used is the sum of all sales order, free text, or credit memo transactions. For the date range applicable to the Finance program (& the Method of payment), the Uncollected amount is the sum of all sales order, free text, or credit memo transactions where the balance of the transaction is not = zero. PLUS any payments with the same criteria. View All Customer Finance Programs Go to Accounts receivable > Financing > Customer finance programs. Click Recalculate balances. Would like to add a batch process This is available for export to excel. Status of \"Active\" is defaulted from the base program value. Date columns, as well as most other data is available to sort/filter to limit this view over time. Process Finance Program Payments Go to Accounts receivable > Payments > Customer payment journal. Click New. In the list, select the applicable journal. Click Enter customer payments. In the Customer field, specify the value or search for a value. In the Payment reference (check # or ACH trans code) field, enter a value. In the Amount (of payment) field, enter a number. In the Description field, type a value such a JDF payment. In the Method of payment field, enter or select the value which represents the Finance program. If applicable, Mark any transactions for settlement. a. Hint: the user may personalize the transaction list to include and display the Method of payment. If not settled, the payment credit will be available for manually matching of current or future transactions. Click Save in journal. Close the page. When the journal has been completed. Click Post.","title":"Create, Maintain, Monitor Customer Programs"},{"location":"CreateMaintainMonitorCustomerPrograms/#create-maintain-monitor-customer-programs","text":"This document explains how to create, maintain, and monitor customer programs.","title":"Create, Maintain, Monitor Customer Programs"},{"location":"CreateMaintainMonitorCustomerPrograms/#create-a-new-customer-program","text":"Go to Accounts receivable > Customers > All customers. In the list, find and select the desired record. On the Action Pane, click Agriculture. Click Customer finance programs. Click New. In the Finance program field, enter or select a value. In the Program account number field, type a value. a. Required field. Enter N/A if an account number is not relevant. In the Maximum amount field, enter a number. In the Renewable field, select an option (Yes/No). In the From date field, enter a start date. In the To date field, enter a date. In the Notes field, type a value, if applicable. In the Address field, select a value. \u2013 Would like this to default if there is only one value In the Contact information field, select a value. \u2013 Would like this to default if there is only one value Click Save. Close the page.","title":"Create a New Customer Program"},{"location":"CreateMaintainMonitorCustomerPrograms/#view-or-edit-a-customer-program","text":"Go to Accounts receivable > Customers > All customers. In the list, find and select the desired record. On the Action Pane, click Agriculture. Click Customer finance programs. View program information or edit as appropriate. If applicable, Click Recalculate balances. \u2013 Would like to add a batch process Status of \"Active\" is defaulted from the base program value. Date columns, as well as most other data is available to sort/filter to limit this view over time. To view all customer transactions or the transactions that account for the \"Amount used\" and/or \"Uncollected amount\" follow these steps: a. Go to Accounts receivable > Customers > All customers. b. In the list, find and select the desired record. c. On the Action Pane, click Customer. d. Click Transactions. e. Default view displays \"All\" transactions. i. Hint: the user may personalize the transaction list to include and display the Method of payment. ii. Corrections: when the Method of payment is visible in the list, it is available for edit with appropriate security access. This allows for transactions not assigned correctly to be adjusted to the intended Method of payment. If adjustment is made, the \"Recalculate balances\" process must be executed in order to update the displayed values for Amount used and Uncollected amount. f. Select show \"Open\", if applicable to display unapplied payments and unpaid/unsettled invoices For the date range applicable to the Finance program (& the Method of payment), the Amount used is the sum of all sales order, free text, or credit memo transactions. For the date range applicable to the Finance program (& the Method of payment), the Uncollected amount is the sum of all sales order, free text, or credit memo transactions where the balance of the transaction is not = zero. PLUS any payments with the same criteria.","title":"View or Edit a Customer Program"},{"location":"CreateMaintainMonitorCustomerPrograms/#view-all-customer-finance-programs","text":"Go to Accounts receivable > Financing > Customer finance programs. Click Recalculate balances. Would like to add a batch process This is available for export to excel. Status of \"Active\" is defaulted from the base program value. Date columns, as well as most other data is available to sort/filter to limit this view over time.","title":"View All Customer Finance Programs"},{"location":"CreateMaintainMonitorCustomerPrograms/#process-finance-program-payments","text":"Go to Accounts receivable > Payments > Customer payment journal. Click New. In the list, select the applicable journal. Click Enter customer payments. In the Customer field, specify the value or search for a value. In the Payment reference (check # or ACH trans code) field, enter a value. In the Amount (of payment) field, enter a number. In the Description field, type a value such a JDF payment. In the Method of payment field, enter or select the value which represents the Finance program. If applicable, Mark any transactions for settlement. a. Hint: the user may personalize the transaction list to include and display the Method of payment. If not settled, the payment credit will be available for manually matching of current or future transactions. Click Save in journal. Close the page. When the journal has been completed. Click Post.","title":"Process Finance Program Payments"},{"location":"CreateProcurementCategory/","text":"Creating a Procurement Category Brief introduction of the module, component or feature being documented. This document explains ... How to Create a Procurement Category, Assign an Item, and Assign a GL Go to Product Information Management > Setup > Categories and Attributes > Category Hierarchies. In the list, find and select the desired record. In the list, click the link in the selected row. Click New category node. In the Name field, type a value. Click Save. Click Save. Click Add. Use the Quick Filter to find records. For example, filter on the Product number field with a value of '1987'. In the list, mark the selected row. Click Add. Click OK. Close the page. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the Item number field with a value of '1987'. Click Product categories. Click New. In the Category hierarchy field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Category field, enter or select a value. In the tree, select 'Landus (New Category)\\Monsanto (New Category)'. Click OK. Click Save. Click Delete. Click Save. Close the page. Close the page. Go to Inventory Management > Setup > Posting > Posting. Click the Purchase order tab. In the Select field, select an option. Click New. In the list, mark the selected row. In the Item code field, select an option. In the Category relation field, enter or select a value. In the tree, select 'Lanuds (New Category)\\Monsanto (New Category)'. Click OK. In the Main account field, specify the desired values. Click Save. Close the page.","title":"Creating a Procurement Category"},{"location":"CreateProcurementCategory/#creating-a-procurement-category","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Creating a Procurement Category"},{"location":"CreateProcurementCategory/#how-to-create-a-procurement-category-assign-an-item-and-assign-a-gl","text":"Go to Product Information Management > Setup > Categories and Attributes > Category Hierarchies. In the list, find and select the desired record. In the list, click the link in the selected row. Click New category node. In the Name field, type a value. Click Save. Click Save. Click Add. Use the Quick Filter to find records. For example, filter on the Product number field with a value of '1987'. In the list, mark the selected row. Click Add. Click OK. Close the page. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the Item number field with a value of '1987'. Click Product categories. Click New. In the Category hierarchy field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Category field, enter or select a value. In the tree, select 'Landus (New Category)\\Monsanto (New Category)'. Click OK. Click Save. Click Delete. Click Save. Close the page. Close the page. Go to Inventory Management > Setup > Posting > Posting. Click the Purchase order tab. In the Select field, select an option. Click New. In the list, mark the selected row. In the Item code field, select an option. In the Category relation field, enter or select a value. In the tree, select 'Lanuds (New Category)\\Monsanto (New Category)'. Click OK. In the Main account field, specify the desired values. Click Save. Close the page.","title":"How to Create a Procurement Category, Assign an Item, and Assign a GL"},{"location":"CreateProcurementHierarchy/","text":"Create Procurement Hierarchy Brief introduction of the module, component or feature being documented. This document explains ... How to Create Procurement Hierarchy Go to Product Information Management > Setup > Categories and Attributes > Category Hierarchies. Click New. In the Name field, type a value. In the Description field, type a value. Click Create. Click New Category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. In the tree, select 'Procurement'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement\\Agronomy'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement\\Feed'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. Expand the Products section. In the tree, select 'Procurement\\Agronomy\\Fert'. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. In the list, find and select the desired record. Click Add. Click OK. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. Click OK. Click Save.","title":"Create Procurement Hierarchy"},{"location":"CreateProcurementHierarchy/#create-procurement-hierarchy","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Create Procurement Hierarchy"},{"location":"CreateProcurementHierarchy/#how-to-create-procurement-hierarchy","text":"Go to Product Information Management > Setup > Categories and Attributes > Category Hierarchies. Click New. In the Name field, type a value. In the Description field, type a value. Click Create. Click New Category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. In the tree, select 'Procurement'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement\\Agronomy'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement\\Feed'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. Expand the Products section. In the tree, select 'Procurement\\Agronomy\\Fert'. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. In the list, find and select the desired record. Click Add. Click OK. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. Click OK. Click Save.","title":"How to Create Procurement Hierarchy"},{"location":"CreatePurchaseRequistionAndConsolidation/","text":"Create a Purchase Requisition and Consolidation Brief introduction of the module, component or feature being documented. This document explains ... How to Create a Purchase Requisition and Consolidation Go to Procurement and sourcing > Purchase Requisitions > All purchase requisitions. Click New. In the Name field, type a value. Click OK. In the Reason field, enter or select a value. In the list, click the link in the selected row. Click Add line. In the list, mark the selected row. In the Item number field, type a value. In the Quantity field, enter a number. Click Save. Click the Inventory Dimensions tab. In the Site field, type a value. In the Warehouse field, enter or select a value. In the list, click the link in the selected row. Click Save. Click Workflow to open the drop dialog. Click Submit. Click Workflow to open the drop dialog. Close the page. Click Workflow to open the drog dialog. Click Approve. Close the page. How to Create a Purchase Consolidation Go to Procurement and Sourcing > Purchase Requisitions > Approved Purchase requisition processing > Consolidation Opportunities. Click New to open the drop dialog. In the Name field, type a value. Click Ok. Click Add to opportunity. In the list, find and select the desired record. In the list, find and select the desired record. Click OK. Click Close Opportunity. In the list, mark the selected row. In the Consolidation quotation number field, type a value. In the list, find and select the desired record. In the list, find and select the desired record. In the Consolidation quotation number field, type a value. In the list, find and select the desired record. In the list, unmark the selected row. In the list, mark the selected row. In the Vendor account field, enter or select a value. In the list, click the link in the selected row. In the list, find and select the desired record. In the Vendor account field, type a value. In the list, find and select the desired record. In the list, unmark the selected row. In the list, mark the selected row. In the Consolidation quotation number field, type a value. In the list, mark or unmark all rows. Click Close opportunity. In the list, mark or unmark all rows. Click Create Purchase Order.","title":"Create a Purchase Requisition and Consolidation"},{"location":"CreatePurchaseRequistionAndConsolidation/#create-a-purchase-requisition-and-consolidation","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Create a Purchase Requisition and Consolidation"},{"location":"CreatePurchaseRequistionAndConsolidation/#how-to-create-a-purchase-requisition-and-consolidation","text":"Go to Procurement and sourcing > Purchase Requisitions > All purchase requisitions. Click New. In the Name field, type a value. Click OK. In the Reason field, enter or select a value. In the list, click the link in the selected row. Click Add line. In the list, mark the selected row. In the Item number field, type a value. In the Quantity field, enter a number. Click Save. Click the Inventory Dimensions tab. In the Site field, type a value. In the Warehouse field, enter or select a value. In the list, click the link in the selected row. Click Save. Click Workflow to open the drop dialog. Click Submit. Click Workflow to open the drop dialog. Close the page. Click Workflow to open the drog dialog. Click Approve. Close the page.","title":"How to Create a Purchase Requisition and Consolidation"},{"location":"CreatePurchaseRequistionAndConsolidation/#how-to-create-a-purchase-consolidation","text":"Go to Procurement and Sourcing > Purchase Requisitions > Approved Purchase requisition processing > Consolidation Opportunities. Click New to open the drop dialog. In the Name field, type a value. Click Ok. Click Add to opportunity. In the list, find and select the desired record. In the list, find and select the desired record. Click OK. Click Close Opportunity. In the list, mark the selected row. In the Consolidation quotation number field, type a value. In the list, find and select the desired record. In the list, find and select the desired record. In the Consolidation quotation number field, type a value. In the list, find and select the desired record. In the list, unmark the selected row. In the list, mark the selected row. In the Vendor account field, enter or select a value. In the list, click the link in the selected row. In the list, find and select the desired record. In the Vendor account field, type a value. In the list, find and select the desired record. In the list, unmark the selected row. In the list, mark the selected row. In the Consolidation quotation number field, type a value. In the list, mark or unmark all rows. Click Close opportunity. In the list, mark or unmark all rows. Click Create Purchase Order.","title":"How to Create a Purchase Consolidation"},{"location":"CustomPluginAssemblyConfig/","text":"Custom Plugin Assemblies Config Settings The CustomPluginAssemblies configuration node is used to define any custom plugin assemblies to be loaded by the integration framework and the class method to call to register the custom plugin from the assembly. This node is a list (not an array) of named CustomPluginAssemblyConfig json objects. Example \"CustomPluginAssemblies\": { \"CustomFieldsAssembly\": { \"Path\": \".\\\\plugins\", \"AssemblyName\": \"Levridge.Integration.IntegrationService.Mapping.CustomFields\", \"Namespace\": \"Levridge.Integration.IntegrationService.Mapping.CustomFields\", \"ClassName\": \"CustomFieldsEntityMapBuilderExtensions\", \"MethodName\": \"AddCustomFields\" } }, Definition The CustomMappingAssemblies node above has a single CustomPluginAssemblyConfig object named \"CustomeFieldAssembly\". Name Required Default: No default value. This is the name of the custom mapping assembly configuration. Each configuration in the list must have a unique name. Because you can have multiple classes and or multiple methods we do not use the AssemblyName as the configuration name. Path Not Required Default: The path of Levridge.Integration.Host This is the path for the custom plugin assembly. It can be specified as an absolute path or a relative path. The relative path is relative to the current execution directory. (Directory.GetCurrentDirectory()) AssemblyName Required Default: No default value. This is the actual name of the assembly, not the file name. In the current version the file name is assumed to be the \"[AssemblyName].dll\". Do not add the file extension or a file path to this value. NameSpace Required Default: No default value. This property must contain the namespace that contains the class. This value will be added to the class name to obtain the class type. ClassName Required Default: No default value. This property is the name of the class that contains the method used to register the custom mapping. Do not include the namespace. The namespace will be added to the class name to obtain the type. MethodName Required Default: No default value. This property is the name of the method that will be called on the class that is used to register the custom mapping. Do not include the class name here.","title":"Custom Plugin Assemblies Config Settings"},{"location":"CustomPluginAssemblyConfig/#custom-plugin-assemblies-config-settings","text":"The CustomPluginAssemblies configuration node is used to define any custom plugin assemblies to be loaded by the integration framework and the class method to call to register the custom plugin from the assembly. This node is a list (not an array) of named CustomPluginAssemblyConfig json objects.","title":"Custom Plugin Assemblies Config Settings"},{"location":"CustomPluginAssemblyConfig/#example","text":"\"CustomPluginAssemblies\": { \"CustomFieldsAssembly\": { \"Path\": \".\\\\plugins\", \"AssemblyName\": \"Levridge.Integration.IntegrationService.Mapping.CustomFields\", \"Namespace\": \"Levridge.Integration.IntegrationService.Mapping.CustomFields\", \"ClassName\": \"CustomFieldsEntityMapBuilderExtensions\", \"MethodName\": \"AddCustomFields\" } },","title":"Example"},{"location":"CustomPluginAssemblyConfig/#definition","text":"The CustomMappingAssemblies node above has a single CustomPluginAssemblyConfig object named \"CustomeFieldAssembly\".","title":"Definition"},{"location":"CustomPluginAssemblyConfig/#name","text":"Required Default: No default value. This is the name of the custom mapping assembly configuration. Each configuration in the list must have a unique name. Because you can have multiple classes and or multiple methods we do not use the AssemblyName as the configuration name.","title":"Name"},{"location":"CustomPluginAssemblyConfig/#path","text":"Not Required Default: The path of Levridge.Integration.Host This is the path for the custom plugin assembly. It can be specified as an absolute path or a relative path. The relative path is relative to the current execution directory. (Directory.GetCurrentDirectory())","title":"Path"},{"location":"CustomPluginAssemblyConfig/#assemblyname","text":"Required Default: No default value. This is the actual name of the assembly, not the file name. In the current version the file name is assumed to be the \"[AssemblyName].dll\". Do not add the file extension or a file path to this value.","title":"AssemblyName"},{"location":"CustomPluginAssemblyConfig/#namespace","text":"Required Default: No default value. This property must contain the namespace that contains the class. This value will be added to the class name to obtain the class type.","title":"NameSpace"},{"location":"CustomPluginAssemblyConfig/#classname","text":"Required Default: No default value. This property is the name of the class that contains the method used to register the custom mapping. Do not include the namespace. The namespace will be added to the class name to obtain the type.","title":"ClassName"},{"location":"CustomPluginAssemblyConfig/#methodname","text":"Required Default: No default value. This property is the name of the method that will be called on the class that is used to register the custom mapping. Do not include the class name here.","title":"MethodName"},{"location":"CustomerCreation/","text":"Customer Creation Go to Accounts receivable > Customers > All Customers. Click New. Click OK. In the First name field, type a value. In the Last name field, type a value. In the Customer group field, enter or select a value. In the list, click the link in the selected row. In the Terms of payment field, enter or select a value. In the list, click the link in the selected row. In the ZIP/postal code field, type a value. In the Street field, type a value. In the Street field, type a value. Click Save. Expand the Addresses section. Click Add. In the Description field, type a value. In the Contact number/address field, type a value. Select the Primary check box. Click Add. In the Type field, select an option. In the Contact number/address field, type a value. Expand the Credit and collections section. In the Credit limit field, enter a number. In the Credit rating field, type a value. In the Method of payment field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. Expand the Financial dimensions section. In the LocationSite value field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Close the page.","title":"Customer Creation"},{"location":"CustomerCreation/#customer-creation","text":"Go to Accounts receivable > Customers > All Customers. Click New. Click OK. In the First name field, type a value. In the Last name field, type a value. In the Customer group field, enter or select a value. In the list, click the link in the selected row. In the Terms of payment field, enter or select a value. In the list, click the link in the selected row. In the ZIP/postal code field, type a value. In the Street field, type a value. In the Street field, type a value. Click Save. Expand the Addresses section. Click Add. In the Description field, type a value. In the Contact number/address field, type a value. Select the Primary check box. Click Add. In the Type field, select an option. In the Contact number/address field, type a value. Expand the Credit and collections section. In the Credit limit field, enter a number. In the Credit rating field, type a value. In the Method of payment field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. Expand the Financial dimensions section. In the LocationSite value field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Close the page.","title":"Customer Creation"},{"location":"CustomerCreationOrganization/","text":"Customer Creation Organzation Brief introduction of the module, component or feature being documented. This document explains ... Customer Creation Organization Go to Accounts Receivable > Customers > All Customers. Click New. Click OK. In the Type field, select an option. Click OK. In the Name field, type a value. In the Customer group field, enter or select a value. In the list, select row 2. In the list, click the link in the select row. In the Terms of Payment field, enter or select a value. In the list, click the link in the select row. In the ZIP/postal code field, type a value. In the Street field, type a value. Click Save. Click Show more fields. Click Add. In the Description field, type a value. In the Contact number/address field, type a value. Select the Primary check box. Click Add. In the Type field, select an option. In the Contact number/address field, type a value. In the Sales group field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Method of payment field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. In the LocationSite value field, enter or select a value. In the list, click the link in the selected row. Click Save.","title":"Customer Creation Organzation"},{"location":"CustomerCreationOrganization/#customer-creation-organzation","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Customer Creation Organzation"},{"location":"CustomerCreationOrganization/#customer-creation-organization","text":"Go to Accounts Receivable > Customers > All Customers. Click New. Click OK. In the Type field, select an option. Click OK. In the Name field, type a value. In the Customer group field, enter or select a value. In the list, select row 2. In the list, click the link in the select row. In the Terms of Payment field, enter or select a value. In the list, click the link in the select row. In the ZIP/postal code field, type a value. In the Street field, type a value. Click Save. Click Show more fields. Click Add. In the Description field, type a value. In the Contact number/address field, type a value. Select the Primary check box. Click Add. In the Type field, select an option. In the Contact number/address field, type a value. In the Sales group field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Method of payment field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. In the LocationSite value field, enter or select a value. In the list, click the link in the selected row. Click Save.","title":"Customer Creation Organization"},{"location":"CustomerFinancePrograms/","text":"Customer Finance Programs Overview Create a Finance Program Create, Maintain, Monitor Customer Programs Finance Program Processes Agronomy Sales","title":"Customer Finance Programs"},{"location":"CustomerFinancePrograms/#customer-finance-programs","text":"","title":"Customer Finance Programs"},{"location":"CustomerFinancePrograms/#overview","text":"Create a Finance Program Create, Maintain, Monitor Customer Programs Finance Program Processes Agronomy Sales","title":"Overview"},{"location":"CustomerOperations_CustomerSites_SplitGroups/","text":"Customer Operations, Customer Sites and Split Groups Overview The following provides an overview of customer operations, customer sites and split groups in Levridge. Customer operations and sites are master data concepts in Levridge. They are defined as: Account/Customer: A farm or production organization Customer operation: A farm or livestock operation Customer site: A field or barn Customer site location: A zone in a field or a pen in a barn Contact: Members of a farm or livestock organization. These contacts can be involved in the organization in different ways. For example, a veterinarian or farm hand might be contacts for a farm. An account or customer is who the ag retailer does business with. This party is often referred to as the grower. This party has the financial responsibilities with the Ag retailer. Customer Operation The customer operation is the business entity the account or customer participates in. A customer might be part of multiple customer operations. Products and services are exchanged between the Ag retailer and the customer and the operation the customer is participating in. In Levridge, an Ag retailer could provide feedback in the form of a return on investment (ROI) or balance sheet to the grower based on information delivered to a specific customer operation. Historical information can also be tracked to individuals assigned to or working on the specific operation (ex: agronomist, feed salesperson, tractor driver). This is helpful for corporate farms to be able to break down who is handling what operation. Customer operations are a way to organize and track how your growers organize and manage their business. This could be a farm. Accounts and people with financial responsibility can change, but data is tied to one spot. Grower/farm/field or Ranch/barn/bin is standard, however Levridge offers the flexibility to allow grower to have breakdown with different operation types with lines of business including agronomy, livestock, energy uses, etc. For example, a farm may be broken down by different managers, therefore creating different operations. Another example, a customer may have operations for crops versus cattle. Or a hog operation with different locations and multiple barns, may define each barn as an operation. A farm may be owned by a father, mother, with some fields that are rented. This helps to control dividends or patronage by operation. Levridge permits you to mirror within the system the structure of your grower\u2019s operation. A default for ordering split group and commodity split group may be setup under the customer operation. Customer operations allow the ability to create a customized profit/loss statement by customer operation. The setup of customer types resides at: FinOps>Accounts Receivable>Setup>Agriculture>Customer operation types Types may be viewed in CE at CE>Core>Configuration>Customer Operation Types The setup of the customer operations resides at: FinOps>Accounts Receivable>Customers>All Customers>Agriculture>Operations Operations may be viewed in CE at CE>Agronomy>Customer Operations Customer Site A customer site is a subset of a customer operation. A customer operation might have many customer sites/fields. Data is stored on customer sites and tasks are performed against the sites. Customer sites represent the main transactional point in Levridge and defines a breakdown of an operation. For example, this could represent fields (customer sites) within a farm (customer operation) or pens (customer sites) within a barn (customer operation). The customer site may represent the field, barn, feed lot or pasture. Customer sites include the following information: Address, legal description, and geo points details Tracking of field boundaries and data layers (field maps with product detail) Default ordering split groups tied to allow splitting of revenue and cost Contacts may be defined for quick point of contact when deliver feed, etc. Historical data, some of which is also tracked in CE including yields, crop history, & pest pressure. Ability to create a customized profit/loss statement by customer site The following example tasks that can be performed against customer sites: Applications \u2013 track all applications per growing season Soil Samples \u2013 track all sampling activity As a customer operation can have several customer sites, within the animal feed space, customer sites can have several customer site locations. For example, a barn can have several bins. Customer Site Locations This depends on the type of site. For example, if the site is a field, then the field can be split into halves or thirds based on productivity. Different seed or fertilizer. Allows work orders to be stored by subsection of a field. There may be a barn, site locations would represent pens within the barn. For delivery of feed. Physical field or piece of dirt could include grain bins \u2013 site location allows tracking of the seed, etc. Territory Entity, or way to assign sales people or company sites, for commission and reporting purposes onto a customer operation. For example, if I am an agronomist that is covering 40 different operations, it is a way to quickly link for reporting purposes. Can breakout sales and other analytics. Split Groups Split groups (commonly referred to as splits) are the link between customers and customer operations. Split groups define how to allocate costs or revenue across the one or more customers involved in the split. For example, if there are 3 different participants involved in a single customer operation, the split group might look like this: Customer A \u2013 40% Customer B \u2013 30% Customer C \u2013 30% Default split groups can be defined for ordering purposes and for commodity interactions with the Ag retailer. These default splits can be set on customer operations or on each customer site which means, if desired, each field can have a different default split group. Default split groups can also be defined at the item category or product level as well. In Levridge, there are two different types of default split groups: 1. Ordering split 2. Commodity split The Commodity default split defines ownership of products when the grower is selling to the Ag retailer. The Ordering default split is used when the grower is buying products from the Ag retailer (that will be utilized in customer sites and operations). Splits allow the percentage of financial responsibility to be recognized for relationships on sales orders or in CE through proposal or batch. Splits may be defined by partnerships, renters, or by family relationships (father/son). Splits also identify the customer to receive any rounding value. Levridge handles splits uniquely due to customer structure. Most are rigid, however customer operations will allow splitting of revenue and costs. The function that allows you to view and maintain all split groups is at F&O>Accounts Receivable>Setup>Agriculture>Split Groups OR CE>Agronomy or Core>Split Groups. All the split groups that a customer is participating in may be viewed and maintained under the customer account. Go to F&F>Accounts Receivable>Customer>All Customers>Agriculture>Split Group. Split Group setups are synced between F&O and CE. Within the split group setup, each line will define a customer account, the percentage applied to the customer account and which customer will receive rounding. The setups include a \u2018Where Used\u2019 view that displays all records related to the split group such as customer operations or sales orders. Here is How to Create a Split Group in F&O and information on how to Manage Splits, Sales Contracts and Prepayments .","title":"Customer Operations, Customer Sites and Split Groups"},{"location":"CustomerOperations_CustomerSites_SplitGroups/#customer-operations-customer-sites-and-split-groups","text":"","title":"Customer Operations, Customer Sites and Split Groups"},{"location":"CustomerOperations_CustomerSites_SplitGroups/#overview","text":"The following provides an overview of customer operations, customer sites and split groups in Levridge. Customer operations and sites are master data concepts in Levridge. They are defined as: Account/Customer: A farm or production organization Customer operation: A farm or livestock operation Customer site: A field or barn Customer site location: A zone in a field or a pen in a barn Contact: Members of a farm or livestock organization. These contacts can be involved in the organization in different ways. For example, a veterinarian or farm hand might be contacts for a farm. An account or customer is who the ag retailer does business with. This party is often referred to as the grower. This party has the financial responsibilities with the Ag retailer.","title":"Overview"},{"location":"CustomerOperations_CustomerSites_SplitGroups/#customer-operation","text":"The customer operation is the business entity the account or customer participates in. A customer might be part of multiple customer operations. Products and services are exchanged between the Ag retailer and the customer and the operation the customer is participating in. In Levridge, an Ag retailer could provide feedback in the form of a return on investment (ROI) or balance sheet to the grower based on information delivered to a specific customer operation. Historical information can also be tracked to individuals assigned to or working on the specific operation (ex: agronomist, feed salesperson, tractor driver). This is helpful for corporate farms to be able to break down who is handling what operation. Customer operations are a way to organize and track how your growers organize and manage their business. This could be a farm. Accounts and people with financial responsibility can change, but data is tied to one spot. Grower/farm/field or Ranch/barn/bin is standard, however Levridge offers the flexibility to allow grower to have breakdown with different operation types with lines of business including agronomy, livestock, energy uses, etc. For example, a farm may be broken down by different managers, therefore creating different operations. Another example, a customer may have operations for crops versus cattle. Or a hog operation with different locations and multiple barns, may define each barn as an operation. A farm may be owned by a father, mother, with some fields that are rented. This helps to control dividends or patronage by operation. Levridge permits you to mirror within the system the structure of your grower\u2019s operation. A default for ordering split group and commodity split group may be setup under the customer operation. Customer operations allow the ability to create a customized profit/loss statement by customer operation. The setup of customer types resides at: FinOps>Accounts Receivable>Setup>Agriculture>Customer operation types Types may be viewed in CE at CE>Core>Configuration>Customer Operation Types The setup of the customer operations resides at: FinOps>Accounts Receivable>Customers>All Customers>Agriculture>Operations Operations may be viewed in CE at CE>Agronomy>Customer Operations","title":"Customer Operation"},{"location":"CustomerOperations_CustomerSites_SplitGroups/#customer-site","text":"A customer site is a subset of a customer operation. A customer operation might have many customer sites/fields. Data is stored on customer sites and tasks are performed against the sites. Customer sites represent the main transactional point in Levridge and defines a breakdown of an operation. For example, this could represent fields (customer sites) within a farm (customer operation) or pens (customer sites) within a barn (customer operation). The customer site may represent the field, barn, feed lot or pasture. Customer sites include the following information: Address, legal description, and geo points details Tracking of field boundaries and data layers (field maps with product detail) Default ordering split groups tied to allow splitting of revenue and cost Contacts may be defined for quick point of contact when deliver feed, etc. Historical data, some of which is also tracked in CE including yields, crop history, & pest pressure. Ability to create a customized profit/loss statement by customer site The following example tasks that can be performed against customer sites: Applications \u2013 track all applications per growing season Soil Samples \u2013 track all sampling activity As a customer operation can have several customer sites, within the animal feed space, customer sites can have several customer site locations. For example, a barn can have several bins.","title":"Customer Site"},{"location":"CustomerOperations_CustomerSites_SplitGroups/#customer-site-locations","text":"This depends on the type of site. For example, if the site is a field, then the field can be split into halves or thirds based on productivity. Different seed or fertilizer. Allows work orders to be stored by subsection of a field. There may be a barn, site locations would represent pens within the barn. For delivery of feed. Physical field or piece of dirt could include grain bins \u2013 site location allows tracking of the seed, etc.","title":"Customer Site Locations"},{"location":"CustomerOperations_CustomerSites_SplitGroups/#territory","text":"Entity, or way to assign sales people or company sites, for commission and reporting purposes onto a customer operation. For example, if I am an agronomist that is covering 40 different operations, it is a way to quickly link for reporting purposes. Can breakout sales and other analytics.","title":"Territory"},{"location":"CustomerOperations_CustomerSites_SplitGroups/#split-groups","text":"Split groups (commonly referred to as splits) are the link between customers and customer operations. Split groups define how to allocate costs or revenue across the one or more customers involved in the split. For example, if there are 3 different participants involved in a single customer operation, the split group might look like this: Customer A \u2013 40% Customer B \u2013 30% Customer C \u2013 30% Default split groups can be defined for ordering purposes and for commodity interactions with the Ag retailer. These default splits can be set on customer operations or on each customer site which means, if desired, each field can have a different default split group. Default split groups can also be defined at the item category or product level as well. In Levridge, there are two different types of default split groups: 1. Ordering split 2. Commodity split The Commodity default split defines ownership of products when the grower is selling to the Ag retailer. The Ordering default split is used when the grower is buying products from the Ag retailer (that will be utilized in customer sites and operations). Splits allow the percentage of financial responsibility to be recognized for relationships on sales orders or in CE through proposal or batch. Splits may be defined by partnerships, renters, or by family relationships (father/son). Splits also identify the customer to receive any rounding value. Levridge handles splits uniquely due to customer structure. Most are rigid, however customer operations will allow splitting of revenue and costs. The function that allows you to view and maintain all split groups is at F&O>Accounts Receivable>Setup>Agriculture>Split Groups OR CE>Agronomy or Core>Split Groups. All the split groups that a customer is participating in may be viewed and maintained under the customer account. Go to F&F>Accounts Receivable>Customer>All Customers>Agriculture>Split Group. Split Group setups are synced between F&O and CE. Within the split group setup, each line will define a customer account, the percentage applied to the customer account and which customer will receive rounding. The setups include a \u2018Where Used\u2019 view that displays all records related to the split group such as customer operations or sales orders. Here is How to Create a Split Group in F&O and information on how to Manage Splits, Sales Contracts and Prepayments .","title":"Split Groups"},{"location":"CustomerTemplate/","text":"Customer Template Brief introduction of the module, component or feature being documented. This document explains ... Customer Template Close the page. Go to Accounts Receivable > Customers > All Customers. In the list, find and select the desired record. Click Record Info. Click New. In the list, find and select the desired record. Select the Is Default check box. Click OK. Click Cancel.","title":"Customer Template"},{"location":"CustomerTemplate/#customer-template","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Customer Template"},{"location":"CustomerTemplate/#customer-template_1","text":"Close the page. Go to Accounts Receivable > Customers > All Customers. In the list, find and select the desired record. Click Record Info. Click New. In the list, find and select the desired record. Select the Is Default check box. Click OK. Click Cancel.","title":"Customer Template"},{"location":"D365-CE-to-D365-F%26O/","text":"D365 CE to D365 F&O Setup To integrate from D365 CE to D365 F&O you will need to: - Configure Azure Service Bus Endpoint in CE - Configure Azure Service Bus plug-in on the appropriate entities - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic - Create a subscription on the topic above Note: Because CE does not support sending messages to topics with subscriptions that require sessions, it is important to make sure that the subscription is created without enabling sessions. In order to support message ordering without the use of sessions the TopicDescription.SupportOrdering property must be set to true on the topic. You will need to use the service bus explorer to set this. Configuration In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with CRM data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with F&O data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }","title":"D365 CE to D365 F&O"},{"location":"D365-CE-to-D365-F%26O/#d365-ce-to-d365-fo","text":"","title":"D365 CE to D365 F&amp;O"},{"location":"D365-CE-to-D365-F%26O/#setup","text":"To integrate from D365 CE to D365 F&O you will need to: - Configure Azure Service Bus Endpoint in CE - Configure Azure Service Bus plug-in on the appropriate entities - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic - Create a subscription on the topic above Note: Because CE does not support sending messages to topics with subscriptions that require sessions, it is important to make sure that the subscription is created without enabling sessions. In order to support message ordering without the use of sessions the TopicDescription.SupportOrdering property must be set to true on the topic. You will need to use the service bus explorer to set this.","title":"Setup"},{"location":"D365-CE-to-D365-F%26O/#configuration","text":"In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with CRM data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with F&O data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }","title":"Configuration"},{"location":"D365-F%26O-to-D365-CE/","text":"D365 F&O to D365 CE Setup To integrate from D365 F&O to D365 CE you will need to: - Configure Event Endpoint in F&O - Configure Levridge Entity Events - Create an application ID for the integration framework to authenticate to D365 CE - Create an application user in D365 CE and assign the proper role(s) - Create an Azure Service bus topic - Create a subscription on the topic above Configuration In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with F&O data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" }","title":"D365 F&O to D365 CE"},{"location":"D365-F%26O-to-D365-CE/#d365-fo-to-d365-ce","text":"","title":"D365 F&amp;O to D365 CE"},{"location":"D365-F%26O-to-D365-CE/#setup","text":"To integrate from D365 F&O to D365 CE you will need to: - Configure Event Endpoint in F&O - Configure Levridge Entity Events - Create an application ID for the integration framework to authenticate to D365 CE - Create an application user in D365 CE and assign the proper role(s) - Create an Azure Service bus topic - Create a subscription on the topic above","title":"Setup"},{"location":"D365-F%26O-to-D365-CE/#configuration","text":"In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with F&O data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" }","title":"Configuration"},{"location":"Deploy-Integration-As-A-Service/","text":"Introduction This webhost application can be run in three modes: As a web application (in Azure or IIS) As a console application As a service Run as a service To run as a service it must be installed. To install as a service you must get the code and place it in the folder from which you want the service to run. The simplest way to get the code is to get the zip file from the latest build. Here are some instructsion for getting the latest code. Get the zip file and unzip it into the folder from which you want the service to run. Deployed with the code should bethree powershell scripts: InstallService.ps1 - this script will install the service InstallEventSource.ps1 - this script will install an event source on the Application EventLog on the local machine RemoveService.ps1 - this script will uninstall / remove the service InstallService.ps1 This script installs a service and sets it to automatically run on startup. It accepts the following command line parameters: PublishPath - the path to the folder from which you want the service to run ServiceUser - user account under which the service will run (default = $env:computername+\"\\IntegrationHost\") ServiceName - the name of the service (default = \"Levridge.Integration.Host\") ServiceDescription - the description for the service (default = \"Levridge Integration Host Service\") ServiceDisplayName - the display name for the service (default = \"Levridge Integration Host\") SourceName - the source name under which EventLog entries should be logged (default = $ServiceName) This script will also execute the InstallEventSource.ps1 InstallEventSource.ps1 This script will install the specified EventLog source. It accepts the following command line parameter: SourceName - the source name under which EventLog entries should be logged (default = \"Levridge.Integration.Host\") RemoveService.ps1 This script will remove the specified service. It accepts the following command line parameter: ServiceName Command line parameters This application can be run with the following command line parameters: debug (-d) - This will cause the application to wait for a debugger to be attached before it continues. This can be helpful to debug startup issues for services or web applications. service (-s) - This will cause the application to run as a service (if the debugger is not attached). SourceName (sn) - This will cause the application to use the specified source name for the application EventLog Source Name. If no source name is specified, the default application source name is use.","title":"Introduction"},{"location":"Deploy-Integration-As-A-Service/#introduction","text":"This webhost application can be run in three modes: As a web application (in Azure or IIS) As a console application As a service","title":"Introduction"},{"location":"Deploy-Integration-As-A-Service/#run-as-a-service","text":"To run as a service it must be installed. To install as a service you must get the code and place it in the folder from which you want the service to run. The simplest way to get the code is to get the zip file from the latest build. Here are some instructsion for getting the latest code. Get the zip file and unzip it into the folder from which you want the service to run. Deployed with the code should bethree powershell scripts: InstallService.ps1 - this script will install the service InstallEventSource.ps1 - this script will install an event source on the Application EventLog on the local machine RemoveService.ps1 - this script will uninstall / remove the service","title":"Run as a service"},{"location":"Deploy-Integration-As-A-Service/#installserviceps1","text":"This script installs a service and sets it to automatically run on startup. It accepts the following command line parameters: PublishPath - the path to the folder from which you want the service to run ServiceUser - user account under which the service will run (default = $env:computername+\"\\IntegrationHost\") ServiceName - the name of the service (default = \"Levridge.Integration.Host\") ServiceDescription - the description for the service (default = \"Levridge Integration Host Service\") ServiceDisplayName - the display name for the service (default = \"Levridge Integration Host\") SourceName - the source name under which EventLog entries should be logged (default = $ServiceName) This script will also execute the InstallEventSource.ps1","title":"InstallService.ps1"},{"location":"Deploy-Integration-As-A-Service/#installeventsourceps1","text":"This script will install the specified EventLog source. It accepts the following command line parameter: SourceName - the source name under which EventLog entries should be logged (default = \"Levridge.Integration.Host\")","title":"InstallEventSource.ps1"},{"location":"Deploy-Integration-As-A-Service/#removeserviceps1","text":"This script will remove the specified service. It accepts the following command line parameter: ServiceName","title":"RemoveService.ps1"},{"location":"Deploy-Integration-As-A-Service/#command-line-parameters","text":"This application can be run with the following command line parameters: debug (-d) - This will cause the application to wait for a debugger to be attached before it continues. This can be helpful to debug startup issues for services or web applications. service (-s) - This will cause the application to run as a service (if the debugger is not attached). SourceName (sn) - This will cause the application to use the specified source name for the application EventLog Source Name. If no source name is specified, the default application source name is use.","title":"Command line parameters"},{"location":"Deploy-Integration-Framework-as-Zip-File/","text":"Deploy Integration Framework as a Zip File At Levridge we build the Integration Framework every night. The output of the build is stored at \\\\devvmhost\\releases . Each build has two folders, \"Integration Framework Main\" and \"Levridge Main\". The integration framework is in the \"drop\" sub-folder of \"Integration Framework Main\". The entire integration framework is contained in the Levridge.Integration.Host.zip file. To deploy the build: Open a browser and navigate to https://<App Service Name>.scm.azurewebsites.net/ZipDeployUI example: https://levdevag.scm.azurewebsites.net/ZipDeployUI From the \"Integration Main\\drop\" folder drag the Levridge.Integration.Host.zip and drop it on the file explorer area on the web page. When deployment is in progress, an icon in the top right corner shows you the progress in percentage. The page also shows verbose messages for the operation below the explorer area. When it is finished, the last deployment message should say \"Deployment successful\". Because this will overwrite the appsettings.json you will need to updated the settings to your desired configuration. Resources Microsoft documentation","title":"Deploy Integration Framework as Zip File"},{"location":"Deploy-Integration-Framework-as-Zip-File/#deploy-integration-framework-as-a-zip-file","text":"At Levridge we build the Integration Framework every night. The output of the build is stored at \\\\devvmhost\\releases . Each build has two folders, \"Integration Framework Main\" and \"Levridge Main\". The integration framework is in the \"drop\" sub-folder of \"Integration Framework Main\". The entire integration framework is contained in the Levridge.Integration.Host.zip file. To deploy the build: Open a browser and navigate to https://<App Service Name>.scm.azurewebsites.net/ZipDeployUI example: https://levdevag.scm.azurewebsites.net/ZipDeployUI From the \"Integration Main\\drop\" folder drag the Levridge.Integration.Host.zip and drop it on the file explorer area on the web page. When deployment is in progress, an icon in the top right corner shows you the progress in percentage. The page also shows verbose messages for the operation below the explorer area. When it is finished, the last deployment message should say \"Deployment successful\". Because this will overwrite the appsettings.json you will need to updated the settings to your desired configuration.","title":"Deploy Integration Framework as a Zip File"},{"location":"Deploy-Integration-Framework-as-Zip-File/#resources","text":"Microsoft documentation","title":"Resources"},{"location":"Deploying-Integration-Framework/","text":"Deploying the Integration Framework There are several ways to deploy the integration framework. Since the framework is a standard Azure App Service we can use any of the deployment options available. The simplest deployment is to deploy a zip file . Select one of the following options for more information on Deploying to Azure: Deploy as Zip file Deploy via FTP Deploy with Script The Integration Framework can also be deployed as a Windows Service . In order to integrate with D365 you must register the integration framework in Active Directory. Here are some articles that explain how to do that: - https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal - https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/use-single-tenant-server-server-authentication#azure-application-registration - https://docs.microsoft.com/en-us/azure/active-directory/azuread-dev/v1-protocols-oauth-code#register-your-application-with-your-ad-tenant In order to access certain Azure resources like Azure Key Vault you will need to make sure your App Service has a system-assigned identity . Next Steps Create Service Bus Configure the application","title":"Deploying the Integration Framework"},{"location":"Deploying-Integration-Framework/#deploying-the-integration-framework","text":"There are several ways to deploy the integration framework. Since the framework is a standard Azure App Service we can use any of the deployment options available. The simplest deployment is to deploy a zip file . Select one of the following options for more information on Deploying to Azure: Deploy as Zip file Deploy via FTP Deploy with Script The Integration Framework can also be deployed as a Windows Service . In order to integrate with D365 you must register the integration framework in Active Directory. Here are some articles that explain how to do that: - https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal - https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/use-single-tenant-server-server-authentication#azure-application-registration - https://docs.microsoft.com/en-us/azure/active-directory/azuread-dev/v1-protocols-oauth-code#register-your-application-with-your-ad-tenant In order to access certain Azure resources like Azure Key Vault you will need to make sure your App Service has a system-assigned identity .","title":"Deploying the Integration Framework"},{"location":"Deploying-Integration-Framework/#next-steps","text":"Create Service Bus Configure the application","title":"Next Steps"},{"location":"DeployingCDS/","text":"Introduction the Levridge Integration Framework uses the CDS repository to store reference data. Because CDS licenses are included with every Dynamics 365 user, this should not result in an additional licensing fees to our customers. This document explains the steps necessary to deploy CDS to a customer environment. Deployment Overview The following steps are necessary to deploy the CDS solutions and data to customer. Create the CDS Environment Create the CDS Database Set Data Loss Prevention policies Configure database security Deploy Solution Deploy Applications Setup Users Import Data","title":"Deploying CDS"},{"location":"DeployingCDS/#introduction","text":"the Levridge Integration Framework uses the CDS repository to store reference data. Because CDS licenses are included with every Dynamics 365 user, this should not result in an additional licensing fees to our customers. This document explains the steps necessary to deploy CDS to a customer environment.","title":"Introduction"},{"location":"DeployingCDS/#deployment","text":"","title":"Deployment"},{"location":"DeployingCDS/#overview","text":"The following steps are necessary to deploy the CDS solutions and data to customer. Create the CDS Environment Create the CDS Database Set Data Loss Prevention policies Configure database security Deploy Solution Deploy Applications Setup Users Import Data","title":"Overview"},{"location":"DeployingCustomFieldMappingAssemblies/","text":"Deploying Custom Plugin Assemblies This document explains how to deploy a custom plugin assembly. Custom plugins can be used for numerous purposes, but the most common is for field mapping assemblies. See Integrating Custom Fields for instructions on how to create a custom field mapping assembly. Overview If you have developed custom plugin assembly you will have to deploy it to a Levridge Integration Framework instance. You will need to deploy the assembly library and any custom dependencies you may have built. Deployment It is important to deploy only the custom assemblies and not any referenced assemblies that are shared with the Levridge Integration Framework. The referenced assemblies will already be deployed with the Levridge Integration Framework. To avoid deploying the shared referenced assemblies, be sure to follow the instructions in the section titled Update the references to be excluded from deployment . You can use visual studio to deploy to a local folder or use Azure DevOps to obtain a zipped folder or your custom assemblies. You will need to copy the custom assemblies into the same folder as the Levridge Integration Framework. Configuration You will need to add a CustomMappingAssemblies node to the appsettings.json file.","title":"Deploying Custom Field Mapping Assemblies"},{"location":"DeployingCustomFieldMappingAssemblies/#deploying-custom-plugin-assemblies","text":"This document explains how to deploy a custom plugin assembly. Custom plugins can be used for numerous purposes, but the most common is for field mapping assemblies. See Integrating Custom Fields for instructions on how to create a custom field mapping assembly.","title":"Deploying Custom Plugin Assemblies"},{"location":"DeployingCustomFieldMappingAssemblies/#overview","text":"If you have developed custom plugin assembly you will have to deploy it to a Levridge Integration Framework instance. You will need to deploy the assembly library and any custom dependencies you may have built.","title":"Overview"},{"location":"DeployingCustomFieldMappingAssemblies/#deployment","text":"It is important to deploy only the custom assemblies and not any referenced assemblies that are shared with the Levridge Integration Framework. The referenced assemblies will already be deployed with the Levridge Integration Framework. To avoid deploying the shared referenced assemblies, be sure to follow the instructions in the section titled Update the references to be excluded from deployment . You can use visual studio to deploy to a local folder or use Azure DevOps to obtain a zipped folder or your custom assemblies. You will need to copy the custom assemblies into the same folder as the Levridge Integration Framework.","title":"Deployment"},{"location":"DeployingCustomFieldMappingAssemblies/#configuration","text":"You will need to add a CustomMappingAssemblies node to the appsettings.json file.","title":"Configuration"},{"location":"EntityMap.AddFieldMap/","text":"EntityMap.AddFieldMap Method Namespace: Levridge.Integration.IntegrationService.Mapping Assemblies: Levridge.Integration.IntegrationService.Mapping.dll Adds a field map to an EntityMap. A field map contains the defintion of the source and target fields to be mapped and any transformation code necessary to perform the map. Overloads Overload Description AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, TB> transformA2B, Func<IEntityField, IEntityField, TA> transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TB> transformA2B, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TA> transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB); Parameters Returns Exceptions Examples AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, TB> transformA2B, Func<IEntityField, IEntityField, TA> transformB2A); Parameters Returns Exceptions Examples AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TB> transformA2B, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TA> transformB2A); Parameters Returns Exceptions Examples","title":"EntityMap.AddFieldMap Method"},{"location":"EntityMap.AddFieldMap/#entitymapaddfieldmap-method","text":"Namespace: Levridge.Integration.IntegrationService.Mapping Assemblies: Levridge.Integration.IntegrationService.Mapping.dll Adds a field map to an EntityMap. A field map contains the defintion of the source and target fields to be mapped and any transformation code necessary to perform the map.","title":"EntityMap.AddFieldMap Method"},{"location":"EntityMap.AddFieldMap/#overloads","text":"Overload Description AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, TB> transformA2B, Func<IEntityField, IEntityField, TA> transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TB> transformA2B, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TA> transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources.","title":"Overloads"},{"location":"EntityMap.AddFieldMap/#addfieldmapientityfield-sourcefielda-ientityfield-sourcefieldb","text":"Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB);","title":"AddFieldMap(IEntityField sourceFieldA, IEntityField sourceFieldB)"},{"location":"EntityMap.AddFieldMap/#parameters","text":"","title":"Parameters"},{"location":"EntityMap.AddFieldMap/#returns","text":"","title":"Returns"},{"location":"EntityMap.AddFieldMap/#exceptions","text":"","title":"Exceptions"},{"location":"EntityMap.AddFieldMap/#examples","text":"","title":"Examples"},{"location":"EntityMap.AddFieldMap/#addfieldmapientityfield-sourcefielda-ientityfield-sourcefieldb-func-transforma2b-func-transformb2a","text":"Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, TB> transformA2B, Func<IEntityField, IEntityField, TA> transformB2A);","title":"AddFieldMap(IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A)"},{"location":"EntityMap.AddFieldMap/#parameters_1","text":"","title":"Parameters"},{"location":"EntityMap.AddFieldMap/#returns_1","text":"","title":"Returns"},{"location":"EntityMap.AddFieldMap/#exceptions_1","text":"","title":"Exceptions"},{"location":"EntityMap.AddFieldMap/#examples_1","text":"","title":"Examples"},{"location":"EntityMap.AddFieldMap/#addfieldmapientityfield-sourcefielda-ientityfield-sourcefieldb-func-transforma2b-func-transformb2a_1","text":"Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TB> transformA2B, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TA> transformB2A);","title":"AddFieldMap(IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A)"},{"location":"EntityMap.AddFieldMap/#parameters_2","text":"","title":"Parameters"},{"location":"EntityMap.AddFieldMap/#returns_2","text":"","title":"Returns"},{"location":"EntityMap.AddFieldMap/#exceptions_2","text":"","title":"Exceptions"},{"location":"EntityMap.AddFieldMap/#examples_2","text":"","title":"Examples"},{"location":"EntityMapBuilderExtensions.AddEntityMap/","text":"EntityMapBuilderExtensions.AddEntityMap Method Namespace: Levridge.Integration.IntegrationService.Mapping Assemblies: Levridge.Integration.IntegrationService.Mapping.dll Adds an entity to the EntityMap. An entity map contains the defintion of the source and target entities to be mapped and the necessary code to configure the field maps for the entity. Overloads Overload Description AddEntityMap (this IEntityMapBuilder builder, Action > configure) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action configure) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. AddEntityMap (this IEntityMapBuilder builder, Action > configure) Adds an Entity Map to the IEntityMapBuilder and provides a configuration action to configure the Entity Mapping. public static IEntityMapBuilder AddEntityMap<TLeft, TRight>(this IEntityMapBuilder builder, Action<EntityMap<TLeft, TRight>> configure); Parameters Returns Exceptions Examples AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action configure) Adds an Entity Map to the IEntityMapBuilder and provides a configuration action to configure the Entity Mapping. public static IEntityMapBuilder AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action<EntityMap> configure); Parameters Returns Exceptions Examples","title":"EntityMapBuilderExtensions.AddEntityMap Method"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#entitymapbuilderextensionsaddentitymap-method","text":"Namespace: Levridge.Integration.IntegrationService.Mapping Assemblies: Levridge.Integration.IntegrationService.Mapping.dll Adds an entity to the EntityMap. An entity map contains the defintion of the source and target entities to be mapped and the necessary code to configure the field maps for the entity.","title":"EntityMapBuilderExtensions.AddEntityMap Method"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#overloads","text":"Overload Description AddEntityMap (this IEntityMapBuilder builder, Action > configure) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action configure) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations.","title":"Overloads"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#addentitymapthis-ientitymapbuilder-builder-action-configure","text":"Adds an Entity Map to the IEntityMapBuilder and provides a configuration action to configure the Entity Mapping. public static IEntityMapBuilder AddEntityMap<TLeft, TRight>(this IEntityMapBuilder builder, Action<EntityMap<TLeft, TRight>> configure);","title":"AddEntityMap(this IEntityMapBuilder builder, Action configure)"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#parameters","text":"","title":"Parameters"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#returns","text":"","title":"Returns"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#exceptions","text":"","title":"Exceptions"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#examples","text":"","title":"Examples"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#addentitymapthis-ientitymapbuilder-builder-string-entitytypea-string-entitytypeb-action-configure","text":"Adds an Entity Map to the IEntityMapBuilder and provides a configuration action to configure the Entity Mapping. public static IEntityMapBuilder AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action<EntityMap> configure);","title":"AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action configure)"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#parameters_1","text":"","title":"Parameters"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#returns_1","text":"","title":"Returns"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#exceptions_1","text":"","title":"Exceptions"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#examples_1","text":"","title":"Examples"},{"location":"Environment-variables/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"Environment-variables/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Environment-variables/#overview","text":"","title":"Overview"},{"location":"Environment-variables/#main-point-1","text":"","title":"Main Point 1"},{"location":"Environment-variables/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"EnvironmentPlanning/","text":"Environment Planning A standard D365 implementation is used when launching a Levridge environment plan. The standard D365 implementation guidelines are captured in the Stoneridge Software Asset Library . Overview D365 is set up with Levridge sitting on top of the functionality. With the start of a new project, the team performs a technical review of what is required and outlines a plan that fits the client\u2019s needs. The team utilizes the latest Microsoft Environment planning when implementing a new project due to information continually being revised and updated. The Microsoft Environment planning provides an overview of various aspects that you must consider while you plan for your project's environment. To help guarantee a successful cloud implementation, it is important that you discuss and plan your environment early in the project. Getting Started Configure your Azure Subscription Create a D365 Subscription Create Azure Active Directory accounts Request vCPU quota increase for planned environments Azure VM Quota Increase Deploy your Azure DevOps project Microsoft Azure Dev Ops Create a security token using your D365Admin account (Used for integration with Lifecycle Services) Deploy your Lifecycle Services project (D365 licensing required) Microsoft Dynamics Lifecycle Services Complete the Lifecycle Services Onboarding workflow Includes DevOps integration and Azure integration for environment deployments Project Onboarding Deploy environments Deployed via Lifecycle Services Lifecycle Services (LCS) user guide Configure Levridge Integrations Levridge Integration Deployment Procedures D365 F&O System Requirements Azure Tenant Azure Active Directory Accounts D365Admin D365Test1 D365Test2 LevridgeIntegrations Azure Execution Account (Manage Azure VM schedules) Lifecycle Services Project (included with D365 licensing) Azure DevOps (Cloud based) D365 F&O Environments (Deploy from Lifecycle Services) D365 CE Environments (Deploy from 365 Admin Portal) Azure Integration Components Document Routing Agent (Installed on local infrastructure to support server-based network printing) Power BI Subscription","title":"Environment Planning"},{"location":"EnvironmentPlanning/#environment-planning","text":"A standard D365 implementation is used when launching a Levridge environment plan. The standard D365 implementation guidelines are captured in the Stoneridge Software Asset Library .","title":"Environment Planning"},{"location":"EnvironmentPlanning/#overview","text":"D365 is set up with Levridge sitting on top of the functionality. With the start of a new project, the team performs a technical review of what is required and outlines a plan that fits the client\u2019s needs. The team utilizes the latest Microsoft Environment planning when implementing a new project due to information continually being revised and updated. The Microsoft Environment planning provides an overview of various aspects that you must consider while you plan for your project's environment. To help guarantee a successful cloud implementation, it is important that you discuss and plan your environment early in the project.","title":"Overview"},{"location":"EnvironmentPlanning/#getting-started","text":"Configure your Azure Subscription Create a D365 Subscription Create Azure Active Directory accounts Request vCPU quota increase for planned environments Azure VM Quota Increase Deploy your Azure DevOps project Microsoft Azure Dev Ops Create a security token using your D365Admin account (Used for integration with Lifecycle Services) Deploy your Lifecycle Services project (D365 licensing required) Microsoft Dynamics Lifecycle Services Complete the Lifecycle Services Onboarding workflow Includes DevOps integration and Azure integration for environment deployments Project Onboarding Deploy environments Deployed via Lifecycle Services Lifecycle Services (LCS) user guide Configure Levridge Integrations Levridge Integration Deployment Procedures","title":"Getting Started"},{"location":"EnvironmentPlanning/#d365-fo-system-requirements","text":"Azure Tenant Azure Active Directory Accounts D365Admin D365Test1 D365Test2 LevridgeIntegrations Azure Execution Account (Manage Azure VM schedules) Lifecycle Services Project (included with D365 licensing) Azure DevOps (Cloud based) D365 F&O Environments (Deploy from Lifecycle Services) D365 CE Environments (Deploy from 365 Admin Portal) Azure Integration Components Document Routing Agent (Installed on local infrastructure to support server-based network printing) Power BI Subscription","title":"D365 F&amp;O System Requirements"},{"location":"Equity/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"Equity/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Equity/#overview","text":"","title":"Overview"},{"location":"Equity/#main-point-1","text":"","title":"Main Point 1"},{"location":"Equity/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"Feed/","text":"Feed Overview Veterinary Feed Directives","title":"Feed"},{"location":"Feed/#feed","text":"","title":"Feed"},{"location":"Feed/#overview","text":"Veterinary Feed Directives","title":"Overview"},{"location":"Field-Integration/","text":"Field Integration The Field integration is a unidirectional integration that receives messages to create a Levridge Customer Site using a configured Customer Site Type that represents a customer field. Overview The Field Integration API is a Webhook that receives a posted message that is used to create a new Customer Site in Levridge. API POST /api/field HTTP/1.1 Host: [Customer Integration Framework Host] Content-Type: application/json { \"growerID\": \"CUS-000071\", \"growerUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f170\", \"farmID\": \"COP000010\", \"farmUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f171\", \"fieldID\": \"CST-000150\", \"fieldUuid\":\"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\", \"fieldName\": \"Test Field Type\", \"fieldWkt\" : \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\", \"farmableAcres\" : 19.5 } Authentication Error Codes Rate limit Message Example { \"growerID\": \"CUS-000071\", \"growerUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f170\", \"farmID\": \"COP000010\", \"farmUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f171\", \"fieldID\": \"CST-000150\", \"fieldUuid\":\"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\", \"fieldName\": \"Test Field Type\", \"fieldWkt\" : \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\", \"farmableAcres\" : 19.5 } Message Schema 1 { 2 \"definitions\": {}, 3 \"$schema\": \"http://json-schema.org/draft-07/schema#\", 4 \"$id\": \"http://example.com/root.json\", 5 \"type\": \"object\", 6 \"title\": \"The Root Schema\", 7 \"required\": [ 8 \"growerID\", 9 \"farmID\", 10 \"fieldID\", 11 \"fieldName\" 12 ], 13 \"properties\": { 14 \"growerID\": { 15 \"$id\": \"#/properties/growerID\", 16 \"type\": \"string\", 17 \"title\": \"The Growerid Schema\", 18 \"default\": \"\", 19 \"examples\": [ 20 \"CUS-000071\" 21 ], 22 \"pattern\": \"^(.*)$\" 23 }, 24 \"growerUuid\": { 25 \"$id\": \"#/properties/growerUuid\", 26 \"type\": \"string\", 27 \"title\": \"The Groweruuid Schema\", 28 \"default\": \"\", 29 \"examples\": [ 30 \"\" 31 ], 32 \"pattern\": \"^(.*)$\" 33 }, 34 \"farmID\": { 35 \"$id\": \"#/properties/farmID\", 36 \"type\": \"string\", 37 \"title\": \"The Farmid Schema\", 38 \"default\": \"\", 39 \"examples\": [ 40 \"COP000010\" 41 ], 42 \"pattern\": \"^(.*)$\" 43 }, 44 \"farmUuid\": { 45 \"$id\": \"#/properties/farmUuid\", 46 \"type\": \"string\", 47 \"title\": \"The Farmuuid Schema\", 48 \"default\": \"\", 49 \"examples\": [ 50 \"\" 51 ], 52 \"pattern\": \"^(.*)$\" 53 }, 54 \"fieldID\": { 55 \"$id\": \"#/properties/fieldID\", 56 \"type\": \"string\", 57 \"title\": \"The Fieldid Schema\", 58 \"default\": \"\", 59 \"examples\": [ 60 \"CST-000150\" 61 ], 62 \"pattern\": \"^(.*)$\" 63 }, 64 \"fieldUuid\": { 65 \"$id\": \"#/properties/fieldUuid\", 66 \"type\": \"string\", 67 \"title\": \"The Fielduuid Schema\", 68 \"default\": \"\", 69 \"examples\": [ 70 \"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\" 71 ], 72 \"pattern\": \"^(.*)$\" 73 }, 74 \"fieldName\": { 75 \"$id\": \"#/properties/fieldName\", 76 \"type\": \"string\", 77 \"title\": \"The Fieldname Schema\", 78 \"default\": \"\", 79 \"examples\": [ 80 \"Test Field Type\" 81 ], 82 \"pattern\": \"^(.*)$\" 83 }, 84 \"fieldWkt\": { 85 \"$id\": \"#/properties/fieldWkt\", 86 \"type\": \"string\", 87 \"title\": \"The Fieldwkt Schema\", 88 \"default\": \"\", 89 \"examples\": [ 90 \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\" 91 ], 92 \"pattern\": \"^(.*)$\" 93 }, 94 \"farmableAcres\": { 95 \"$id\": \"#/properties/farmableAcres\", 96 \"type\": \"number\", 97 \"title\": \"The Farmableacres Schema\", 98 \"default\": 0.0, 99 \"examples\": [ 100 19.5 101 ] 102 } 103 } 104 } Configuration In the appsettings.json you will need to define a section named \"Levridge.Integration.Host.FieldController\". The controller looks for this section to get the Service Bus information needed to place messages into a Topic. You can run the Field to CRM integration in the same instance simply by pointing the SourceConfig.ServiceBusConfigName to \"Levridge.Integration.Host.FieldController\" also, or a section that defines a connection to the same topic the controller is sending the message to. For the instance that handles the integration mapping the SourceConfig and TargetConfig nodes should be setup as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": \"\", \"SystemName\": \"Field\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" } In the appsettings.json you will need to add the assembly into the list of controllers. It doesn't matter what name you assign to the assembly entry but the assembly name must be \"Levridge.Integration.Host.FieldController\". In the example below the assembly is named \"FieldController\". (i.e. \"FieldController\": \"Levridge.Integration.Host.FieldController\") \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"FieldController\": \"Levridge.Integration.Host.FieldController\" } The \"Controllers\" section above will load the DefaultController and the FieldController. { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"FieldController\": \"Levridge.Integration.Host.FieldController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfiguration\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Levridge.Integration.Host.FieldController\", \"ODataConfigName\": \"CDS\", \"SystemName\": \"Field\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsCRM\", \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\", \"CDSConfigName\": \"CDS\" }, \"DynamicsCRM\": { \"UriString\": \"https://localhost\", \"ActiveDirectoryResource\": \"https://[Customer CRM Instance].crm.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/2e14a5b1-fbf8-415b-bc7d-93e20829e510\", \"ActiveDirectoryClientAppId\": \"[Application ID]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret]\", \"ODataEntityPath\": \"https://[Customer CRM Instance].crm.dynamics.com/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.DynamicsCRM\", \"AssemblyFile\": \"Levridge.ODataDataSources.DynamicsCRM.dll\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.DynamicsCRM\", \"MetadataResource\": \"CRMMetadata.xml\" }, \"CDS\": { \"UriString\": \"https://localhost\", \"ActiveDirectoryResource\": \"https://[Customer CDS Instance].api.crm.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/2e14a5b1-fbf8-415b-bc7d-93e20829e510\", \"ActiveDirectoryClientAppId\": \"[Application ID]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret]\", \"ODataEntityPath\": \"https://[Customer CDS Instance].api.crm.dynamics.com/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"AzureTableConfiguration\": { \"ConnectionString\": \"DefaultEndpointsProtocol=https;AccountName=levridgegeneralstorage;AccountKey=MFkzIfLUU1KyCMxfZVPk7HelhWlC0TZyBnFDMEty4y3D4YnqgA4RHSHu8es+R91C/MmDNjtuKJ1x8yDMJ4vLGA==;EndpointSuffix=core.windows.net\", \"Table\": \"FinOpsAndCRM\" }, \"Levridge.Integration.Host.FieldController\": { // used by Webhook \"ConnectionString\": \"Endpoint=sb://[Customer Service Bus Instance].servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=[Customer Access Key]\", \"TopicName\": \"[Customer Topic Name]\", \"SubscriptionName\": \"[Customer Subscription Name]\", \"RequiresSession\": true, \"CustomerSiteTypeCode\": \"[CustomerSite TypeCode from FinOps]\", \"IdOption\": \"FieldId\" } }","title":"Field Integration"},{"location":"Field-Integration/#field-integration","text":"The Field integration is a unidirectional integration that receives messages to create a Levridge Customer Site using a configured Customer Site Type that represents a customer field.","title":"Field Integration"},{"location":"Field-Integration/#overview","text":"The Field Integration API is a Webhook that receives a posted message that is used to create a new Customer Site in Levridge.","title":"Overview"},{"location":"Field-Integration/#api","text":"POST /api/field HTTP/1.1 Host: [Customer Integration Framework Host] Content-Type: application/json { \"growerID\": \"CUS-000071\", \"growerUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f170\", \"farmID\": \"COP000010\", \"farmUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f171\", \"fieldID\": \"CST-000150\", \"fieldUuid\":\"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\", \"fieldName\": \"Test Field Type\", \"fieldWkt\" : \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\", \"farmableAcres\" : 19.5 }","title":"API"},{"location":"Field-Integration/#authentication","text":"","title":"Authentication"},{"location":"Field-Integration/#error-codes","text":"","title":"Error Codes"},{"location":"Field-Integration/#rate-limit","text":"","title":"Rate limit"},{"location":"Field-Integration/#message-example","text":"{ \"growerID\": \"CUS-000071\", \"growerUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f170\", \"farmID\": \"COP000010\", \"farmUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f171\", \"fieldID\": \"CST-000150\", \"fieldUuid\":\"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\", \"fieldName\": \"Test Field Type\", \"fieldWkt\" : \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\", \"farmableAcres\" : 19.5 }","title":"Message Example"},{"location":"Field-Integration/#message-schema","text":"1 { 2 \"definitions\": {}, 3 \"$schema\": \"http://json-schema.org/draft-07/schema#\", 4 \"$id\": \"http://example.com/root.json\", 5 \"type\": \"object\", 6 \"title\": \"The Root Schema\", 7 \"required\": [ 8 \"growerID\", 9 \"farmID\", 10 \"fieldID\", 11 \"fieldName\" 12 ], 13 \"properties\": { 14 \"growerID\": { 15 \"$id\": \"#/properties/growerID\", 16 \"type\": \"string\", 17 \"title\": \"The Growerid Schema\", 18 \"default\": \"\", 19 \"examples\": [ 20 \"CUS-000071\" 21 ], 22 \"pattern\": \"^(.*)$\" 23 }, 24 \"growerUuid\": { 25 \"$id\": \"#/properties/growerUuid\", 26 \"type\": \"string\", 27 \"title\": \"The Groweruuid Schema\", 28 \"default\": \"\", 29 \"examples\": [ 30 \"\" 31 ], 32 \"pattern\": \"^(.*)$\" 33 }, 34 \"farmID\": { 35 \"$id\": \"#/properties/farmID\", 36 \"type\": \"string\", 37 \"title\": \"The Farmid Schema\", 38 \"default\": \"\", 39 \"examples\": [ 40 \"COP000010\" 41 ], 42 \"pattern\": \"^(.*)$\" 43 }, 44 \"farmUuid\": { 45 \"$id\": \"#/properties/farmUuid\", 46 \"type\": \"string\", 47 \"title\": \"The Farmuuid Schema\", 48 \"default\": \"\", 49 \"examples\": [ 50 \"\" 51 ], 52 \"pattern\": \"^(.*)$\" 53 }, 54 \"fieldID\": { 55 \"$id\": \"#/properties/fieldID\", 56 \"type\": \"string\", 57 \"title\": \"The Fieldid Schema\", 58 \"default\": \"\", 59 \"examples\": [ 60 \"CST-000150\" 61 ], 62 \"pattern\": \"^(.*)$\" 63 }, 64 \"fieldUuid\": { 65 \"$id\": \"#/properties/fieldUuid\", 66 \"type\": \"string\", 67 \"title\": \"The Fielduuid Schema\", 68 \"default\": \"\", 69 \"examples\": [ 70 \"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\" 71 ], 72 \"pattern\": \"^(.*)$\" 73 }, 74 \"fieldName\": { 75 \"$id\": \"#/properties/fieldName\", 76 \"type\": \"string\", 77 \"title\": \"The Fieldname Schema\", 78 \"default\": \"\", 79 \"examples\": [ 80 \"Test Field Type\" 81 ], 82 \"pattern\": \"^(.*)$\" 83 }, 84 \"fieldWkt\": { 85 \"$id\": \"#/properties/fieldWkt\", 86 \"type\": \"string\", 87 \"title\": \"The Fieldwkt Schema\", 88 \"default\": \"\", 89 \"examples\": [ 90 \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\" 91 ], 92 \"pattern\": \"^(.*)$\" 93 }, 94 \"farmableAcres\": { 95 \"$id\": \"#/properties/farmableAcres\", 96 \"type\": \"number\", 97 \"title\": \"The Farmableacres Schema\", 98 \"default\": 0.0, 99 \"examples\": [ 100 19.5 101 ] 102 } 103 } 104 }","title":"Message Schema"},{"location":"Field-Integration/#configuration","text":"In the appsettings.json you will need to define a section named \"Levridge.Integration.Host.FieldController\". The controller looks for this section to get the Service Bus information needed to place messages into a Topic. You can run the Field to CRM integration in the same instance simply by pointing the SourceConfig.ServiceBusConfigName to \"Levridge.Integration.Host.FieldController\" also, or a section that defines a connection to the same topic the controller is sending the message to. For the instance that handles the integration mapping the SourceConfig and TargetConfig nodes should be setup as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": \"\", \"SystemName\": \"Field\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" } In the appsettings.json you will need to add the assembly into the list of controllers. It doesn't matter what name you assign to the assembly entry but the assembly name must be \"Levridge.Integration.Host.FieldController\". In the example below the assembly is named \"FieldController\". (i.e. \"FieldController\": \"Levridge.Integration.Host.FieldController\") \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"FieldController\": \"Levridge.Integration.Host.FieldController\" } The \"Controllers\" section above will load the DefaultController and the FieldController. { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"FieldController\": \"Levridge.Integration.Host.FieldController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfiguration\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Levridge.Integration.Host.FieldController\", \"ODataConfigName\": \"CDS\", \"SystemName\": \"Field\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsCRM\", \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\", \"CDSConfigName\": \"CDS\" }, \"DynamicsCRM\": { \"UriString\": \"https://localhost\", \"ActiveDirectoryResource\": \"https://[Customer CRM Instance].crm.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/2e14a5b1-fbf8-415b-bc7d-93e20829e510\", \"ActiveDirectoryClientAppId\": \"[Application ID]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret]\", \"ODataEntityPath\": \"https://[Customer CRM Instance].crm.dynamics.com/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.DynamicsCRM\", \"AssemblyFile\": \"Levridge.ODataDataSources.DynamicsCRM.dll\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.DynamicsCRM\", \"MetadataResource\": \"CRMMetadata.xml\" }, \"CDS\": { \"UriString\": \"https://localhost\", \"ActiveDirectoryResource\": \"https://[Customer CDS Instance].api.crm.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/2e14a5b1-fbf8-415b-bc7d-93e20829e510\", \"ActiveDirectoryClientAppId\": \"[Application ID]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret]\", \"ODataEntityPath\": \"https://[Customer CDS Instance].api.crm.dynamics.com/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"AzureTableConfiguration\": { \"ConnectionString\": \"DefaultEndpointsProtocol=https;AccountName=levridgegeneralstorage;AccountKey=MFkzIfLUU1KyCMxfZVPk7HelhWlC0TZyBnFDMEty4y3D4YnqgA4RHSHu8es+R91C/MmDNjtuKJ1x8yDMJ4vLGA==;EndpointSuffix=core.windows.net\", \"Table\": \"FinOpsAndCRM\" }, \"Levridge.Integration.Host.FieldController\": { // used by Webhook \"ConnectionString\": \"Endpoint=sb://[Customer Service Bus Instance].servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=[Customer Access Key]\", \"TopicName\": \"[Customer Topic Name]\", \"SubscriptionName\": \"[Customer Subscription Name]\", \"RequiresSession\": true, \"CustomerSiteTypeCode\": \"[CustomerSite TypeCode from FinOps]\", \"IdOption\": \"FieldId\" } }","title":"Configuration"},{"location":"Field-Reveal/","text":"Field Reveal Integration There are two aspects of integration with Field Reveal . Recommendations Fields Recommendation Integrations The Recommendation Integration is a general integration provided by the Levridge API. Field Reveal has built the capabillites to send a perscription for a specific field to Levridge through our Recommendation Integration API . Field Integrations The Field Integration is a general integration provided by the Levridge API. Field Reveal has built the capabillites to send field information to Levridge through our Field Integration API .","title":"Field Reveal"},{"location":"Field-Reveal/#field-reveal-integration","text":"There are two aspects of integration with Field Reveal . Recommendations Fields","title":"Field Reveal Integration"},{"location":"Field-Reveal/#recommendation-integrations","text":"The Recommendation Integration is a general integration provided by the Levridge API. Field Reveal has built the capabillites to send a perscription for a specific field to Levridge through our Recommendation Integration API .","title":"Recommendation Integrations"},{"location":"Field-Reveal/#field-integrations","text":"The Field Integration is a general integration provided by the Levridge API. Field Reveal has built the capabillites to send field information to Levridge through our Field Integration API .","title":"Field Integrations"},{"location":"FinanceProgramProcesses/","text":"Finance Program Processes This document outlines other finance program related processes. Process Finance Program Payments via Transfer Scenario: Payment is accepted to a central customer account for the Finance program. Funds are then transferred from this account to the intended Customer(s) using a specially configured Customer payment journal. Go to Accounts receivable > Payments > Customer payment journal. Click New. In the list, select the applicable journal that supports a transfer between customer accounts. Click Lines. In the Account field, specify the customer to transfer payment FROM. Tab off the account field. The customer name will populate to the field. Click Settle transactions. In the list, locate the payment/credit transaction to be transferred. a. Hint: May need to add personalization to settlement screen to include and display the Method of payment. Select the Mark check box. Click OK. The debit value will default to the journal line. In the Description field, type a value such a JDF payment transfer. Offset account type is already set to Customer. In the Offset account field, specify the customer to transfer payment TO. a. Alternate: Click the arrow down key to enter multiple lines for multiple customers to transfer TO. Be sure to enter the appropriate Credit value for each added line before using arrow down to ensure the voucher number is retained. In the Method of payment field, enter or select the value which represents the Finance program. Click Validate. Address any errors. To verify the accounting entry is the expected outcome: a. Click Print. b. Click Journal. c. Set Totals = Yes d. Click OK. Close the page when review is complete. When the journal has been completed. Click Post. Process Finance Program Refund via Transfer Scenario: Payment is applied to a customer account for the Finance program from the finance company. Funds are not used and must be refunded back to the Finance company. The Finance company has a customer account. Funds are transferred from the Customer(s) to the Finance account using a specially configured Customer payment journal. Once this journal is posted, the Reimbursement process may be executed. Go to Accounts receivable > Payments > Customer payment journal. Click New. In the list, select the applicable journal that supports a transfer between customer accounts. Click Lines. In the Account field, specify the customer to transfer payment FROM. Tab off the account field. The customer name will populate to the field. Click Settle transactions. In the list, locate the payment/credit transaction to be transferred. a. Hint: May need to add personalization to settlement screen to include and display the Method of payment. Select the Mark check box. Click OK. The debit value will default to the journal line. In the Description field, type a value such a JDF payment refund. Offset account type is already set to Customer. In the Offset account field, specify the customer to transfer payment TO. In the Method of payment field, enter or select the value which represents the Finance program. Click Validate. Address any errors. To verify the accounting entry is the expected outcome: a. Click Print. b. Click Journal. c. Set Totals = Yes d. Click OK. Close the page when review is complete. When the journal has been completed. Click Post. Reimbursement/Issue Refund Process Go to Accounts receivable > Customers > All customers. Use the Quick Filter to find records. For example, filter on the Name field or Account number. Select the record. Click the Collect tab in the ribbon. Click Reimburse customer. Click OK. On the ribbon, click Customer. Click Balance. Verify the change in Customer and Vendor balances as expected. Close the page. Accounts Payable Processing Steps Go to Accounts payable > Payments > Vendor payment journal. In the list, find and select the desired record. OR create a new payment journal. Click Lines. In the Account field, specify the Customer vendor value. (Located on the Misc fast tab of the customer account) Click Settle transactions. Select the Mark check box. Click OK. In the Description field, type a value. Process for review and payment per usual processes. Process Finance Program Refund via Journal Scenario: Payment is applied to a customer account for the Finance program from the finance company. Funds are not used and must be refunded back to the Finance company. The Finance company has a vendor account. Funds are transferred from the Customer(s) to the Finance account using a specially configured Customer payment journal. Once this journal is posted, the AP process may be executed. Go to Accounts receivable > Payments > Customer payment journal. Click New. In the list, select the applicable journal that supports a refund to a vendor account. Click Lines. In the Account field, specify the customer to transfer payment FROM. Tab off the account field. The customer name will populate to the field. Click Settle transactions. In the list, locate the payment/credit transaction to be transferred. a. Hint: May need to add personalization to settlement screen to include and display the Method of payment. Select the Mark check box. Click OK. The debit value will default to the journal line. In the Description field, type a value such a JDF payment refund. Offset account type is already set to Vendor. In the Offset account field, the vendor is already set. Verify this value. In the Method of payment field, enter or select the value which represents the Finance program. Click Validate. Address any errors. To verify the accounting entry is the expected outcome: a. Click Print. b. Click Journal. c. Set Totals = Yes d. Click OK. Close the page when review is complete. When the journal has been completed. Click Post. Accounts payable Processing Steps Go to Accounts payable > Payments > Vendor payment journal. In the list, find and select the desired record. OR create a new payment journal. Click Lines. In the Account field, specify the Customer vendor value. (Located on the Misc fast tab of the customer account) Click Settle transactions. Select the Mark check box. Click OK. In the Description field, type a value. Process for review and payment per usual processes.","title":"Finance Program Processes"},{"location":"FinanceProgramProcesses/#finance-program-processes","text":"This document outlines other finance program related processes.","title":"Finance Program Processes"},{"location":"FinanceProgramProcesses/#process-finance-program-payments-via-transfer","text":"Scenario: Payment is accepted to a central customer account for the Finance program. Funds are then transferred from this account to the intended Customer(s) using a specially configured Customer payment journal. Go to Accounts receivable > Payments > Customer payment journal. Click New. In the list, select the applicable journal that supports a transfer between customer accounts. Click Lines. In the Account field, specify the customer to transfer payment FROM. Tab off the account field. The customer name will populate to the field. Click Settle transactions. In the list, locate the payment/credit transaction to be transferred. a. Hint: May need to add personalization to settlement screen to include and display the Method of payment. Select the Mark check box. Click OK. The debit value will default to the journal line. In the Description field, type a value such a JDF payment transfer. Offset account type is already set to Customer. In the Offset account field, specify the customer to transfer payment TO. a. Alternate: Click the arrow down key to enter multiple lines for multiple customers to transfer TO. Be sure to enter the appropriate Credit value for each added line before using arrow down to ensure the voucher number is retained. In the Method of payment field, enter or select the value which represents the Finance program. Click Validate. Address any errors. To verify the accounting entry is the expected outcome: a. Click Print. b. Click Journal. c. Set Totals = Yes d. Click OK. Close the page when review is complete. When the journal has been completed. Click Post.","title":"Process Finance Program Payments via Transfer"},{"location":"FinanceProgramProcesses/#process-finance-program-refund-via-transfer","text":"Scenario: Payment is applied to a customer account for the Finance program from the finance company. Funds are not used and must be refunded back to the Finance company. The Finance company has a customer account. Funds are transferred from the Customer(s) to the Finance account using a specially configured Customer payment journal. Once this journal is posted, the Reimbursement process may be executed. Go to Accounts receivable > Payments > Customer payment journal. Click New. In the list, select the applicable journal that supports a transfer between customer accounts. Click Lines. In the Account field, specify the customer to transfer payment FROM. Tab off the account field. The customer name will populate to the field. Click Settle transactions. In the list, locate the payment/credit transaction to be transferred. a. Hint: May need to add personalization to settlement screen to include and display the Method of payment. Select the Mark check box. Click OK. The debit value will default to the journal line. In the Description field, type a value such a JDF payment refund. Offset account type is already set to Customer. In the Offset account field, specify the customer to transfer payment TO. In the Method of payment field, enter or select the value which represents the Finance program. Click Validate. Address any errors. To verify the accounting entry is the expected outcome: a. Click Print. b. Click Journal. c. Set Totals = Yes d. Click OK. Close the page when review is complete. When the journal has been completed. Click Post.","title":"Process Finance Program Refund via Transfer"},{"location":"FinanceProgramProcesses/#reimbursementissue-refund-process","text":"Go to Accounts receivable > Customers > All customers. Use the Quick Filter to find records. For example, filter on the Name field or Account number. Select the record. Click the Collect tab in the ribbon. Click Reimburse customer. Click OK. On the ribbon, click Customer. Click Balance. Verify the change in Customer and Vendor balances as expected. Close the page.","title":"Reimbursement/Issue Refund Process"},{"location":"FinanceProgramProcesses/#accounts-payable-processing-steps","text":"Go to Accounts payable > Payments > Vendor payment journal. In the list, find and select the desired record. OR create a new payment journal. Click Lines. In the Account field, specify the Customer vendor value. (Located on the Misc fast tab of the customer account) Click Settle transactions. Select the Mark check box. Click OK. In the Description field, type a value. Process for review and payment per usual processes.","title":"Accounts Payable Processing Steps"},{"location":"FinanceProgramProcesses/#process-finance-program-refund-via-journal","text":"Scenario: Payment is applied to a customer account for the Finance program from the finance company. Funds are not used and must be refunded back to the Finance company. The Finance company has a vendor account. Funds are transferred from the Customer(s) to the Finance account using a specially configured Customer payment journal. Once this journal is posted, the AP process may be executed. Go to Accounts receivable > Payments > Customer payment journal. Click New. In the list, select the applicable journal that supports a refund to a vendor account. Click Lines. In the Account field, specify the customer to transfer payment FROM. Tab off the account field. The customer name will populate to the field. Click Settle transactions. In the list, locate the payment/credit transaction to be transferred. a. Hint: May need to add personalization to settlement screen to include and display the Method of payment. Select the Mark check box. Click OK. The debit value will default to the journal line. In the Description field, type a value such a JDF payment refund. Offset account type is already set to Vendor. In the Offset account field, the vendor is already set. Verify this value. In the Method of payment field, enter or select the value which represents the Finance program. Click Validate. Address any errors. To verify the accounting entry is the expected outcome: a. Click Print. b. Click Journal. c. Set Totals = Yes d. Click OK. Close the page when review is complete. When the journal has been completed. Click Post.","title":"Process Finance Program Refund via Journal"},{"location":"FinanceProgramProcesses/#accounts-payable-processing-steps_1","text":"Go to Accounts payable > Payments > Vendor payment journal. In the list, find and select the desired record. OR create a new payment journal. Click Lines. In the Account field, specify the Customer vendor value. (Located on the Misc fast tab of the customer account) Click Settle transactions. Select the Mark check box. Click OK. In the Description field, type a value. Process for review and payment per usual processes.","title":"Accounts payable Processing Steps"},{"location":"Grain/","text":"Grain Overview Grain - Outbound Processes Grain - Inbound Processes","title":"Grain"},{"location":"Grain/#grain","text":"","title":"Grain"},{"location":"Grain/#overview","text":"Grain - Outbound Processes Grain - Inbound Processes","title":"Overview"},{"location":"Grain_Inbound_Processes/","text":"Grain - Inbound Processes Overview An overview of the inbound grain process beginning with contracts and working through settlements. The in-bound process will be used for anyone buying in a commodity. Finance & Operations > Modules > Commodity Accounting From the commodity accounting menu, the outbound process consists of: Contracts Offers Purchase contracts Storage agreements Contract expiration Open contracts Delivery Settlement Contracts Offers Commodity Accounting > Inbound > Contract > Offers The Offers My view shows a list of open offers. Open offers can be filtered by Branch, Commodity and Executed offers. Executed Offers is a yes/no toggle button if flipped to \u201cYes\u201d will show the contracts that have been filled with a purchase contract issued to the contract. To create a new offer, click New. A Create offer window will appear on the right-hand side. The Create offer fields include: Branch Offer date Offer type Notification - Before offer can be executed, the user needs to contact whoever created the offer and ask if they want the contract to be executed. Market offer - If the current market or bid at this location reaches offer level, the contract is executed automatically. Customer Commodity Contract type Delivery period Offer quantity Ticket default: Automatically defaults. The input is reflective of selected Delivery period. Board price Basis Net price Expiration date FOB location Notes Click Create. A review of the contract is then generated. Click Save. Created offers can be removed. Purchase Contracts The Create purchase contract is generated by clicking New and opening an offer. A Create offer window will appear on the right-hand side. This is the same Create purchase contract window shown in the Create Contracts section. Click Create. The system will show the created Purchase contract. The Line view includes General and Delivery and pricing information. The General view outlines the line detail part of the contract capturing the contract information currently in the system. The Customer operation field is a farm field type development. The Delivery and pricing information view show the delivery information. The Header view shows additional detail: General contract information Includes Direct Ship information Contract dates and quantities Once tickets are applied to the contract, the system begins tracking what has been delivered. Part of a commodity can also be canceled. Sent date: The ability to track whether the contract has been signed Date returned: The date when the contract was returned Contract expires: The date when the contract expires. There is a contract expiration program track and get rid of contracts that have expired. Discounts, fees and freight The \u201cUse discount schedule in place at time of delivery\u201d is a yes/no toggle button with the option to have commodity and branch set up with a default discount schedule. In the setup page, there is a setup flag to use a discount schedule which would default to every contract or scale ticket. Fee schedule: Storage charges or assessments. Market to market adjustment: if the user is bringing contracts to market and you want to bring them back to market at one location, you can use a basis or freight adjustment to add/subtract to price to get the right calculation of bringing contracts to market. Freight included in basis: information of basis level of how much was freight. Addresses Multiple addresses to use on contract. These addresses can be overwritten Ship from name Ship to name: Defaults to branch previously entered in FOB name: Where ownership changes Miscellaneous details Can identify who in your company created contract. If a Broker was used, this can be identified along with the Broker commission rate. The commission rate is not processed and is just for informational purposes. It does not create a payable. Hedge commodity The commodity will default in. Additional hedge commodities can be entered. Can get long/short to run by hedge commodity. Pricing of a Contract Commodity > Inbound > Contract > Purchase contracts The Delivery and Pricing view is available under the \u201cLine\u201d My view. To set a price, highlight the delivery period. Click on Set price. The Contract pricing window will appear on the right-hand side. The user can change the Price quantity, Board price, and Basis to match what should be on the contract. The Net price is calculated from Board Price, subtracted Basis, and gave Net price. Click Create. A new delivery period line is created. Throughout system, you will see same contract number, but it will have two delivery period lines showing up. Within the contract entry, additional functionality includes: View: Scale tickets and load requests issued against a contract, along with load orders tied to a contract. Generate: Pricing confirmation. This can be printed. Fill: Ability to fill at market price or contract price. Market price: Takes quantity against current market. The system calculates gain/loss to create either a payable or receivable Contract price: Takes quantity against current contract price. There is no gain or losses. Delivery Process on In-bound Grain Commodity accounting > Inbound > Delivery Delivery Process on in-bound grain includes: Inbound scale tickets Delivery sheets Inbound scale ticket application Unit trains Inbound Scale Tickets Commodity accounting > Inbound > Delivery > Inbound scale tickets Most of the inbound scale tickets will be imported in from scale a scale interface. But you do have the ability to add new scale tickets or edit existing scale tickets that have been imported. To create a new scale ticket, click on New. A Create scale ticket window will appear on the right-hand side. Ticket type Commodity Branch Warehouse Customer account Name Ticket date: this is a user field and can be overridden Customer operation: There can be multiple operations for a customer. Must choose one. A customer operation is required. Customer site: This field is not required but can choose for tracking purposes. Split Group: Will default in with the customer operation. This can be overridden. Click Create. The below image shows a newly created inbound scale ticket. Additional information and categories one can enter attached to a scale ticket. Scale ticket split details: If there were multiple splits, the system would preview the split they would be receiving. Weights: The system calculates net weight. This is a toggle on/off button (defaults Driver to on). The user can select scale operation and grader if they want the information recorded on the ticket. Date/Time: Can be viewed on the printed ticket. Notes: There are two types of notes: External and Internal. External will print on scale ticket. Grade factors: Grade factors are set up in the system and assigned to the commodity. The sequence they show up in the table is user defined. There is the ability for the moisture and test weight depending on equipment person has but can import moisture and test weight (TW). User can enter other discount factors as well. Those are used to defer back to the discount schedules that are attached to any contract or storage agreement user has and calculate any premium or charges that are due based off those discounts. Transportation Details: This is not a required entry but can be provided. It is a way to identify the driver delivering the commodity for informational purposes and when the truck comes back empty. The Unit number is primary used in rail shipments can add and group this ticket with others. Sometimes previously hauled commodity is a required field so that there wasn\u2019t hazardous material hauled prior to commodity. The next step is to Post to Inventory so all commodity received will show up in inventory to track and update DPR for inventory amounts. DPR: daily position report. After the ticket is posted, it is locked in and ready to be used in other parts of the system. This concludes the inbound scale ticket option. Inbound scale ticket application process The Inbound scale ticket application process takes scale tickets received and provides the user the option to determine how the scale tickets will be used. The contract number can be changed. Inbound scale ticket auto-apply: The user can set up a sequence in the system to auto apply on each contract. e.g. If you have it set up to sequence if you want your first application contract, second agreement storage agreement. The system will automatically apply your scale ticket or a portion of it to an existing purchase contract or to an existing storage agreement based on the sequences set up on your auto-apply functionality. Inbound scale ticket un-apply Ability to unassign scale tickets from contracts Can select a scale ticket not previously assigned to a contract (if let\u2019s say it was un-applied as mentioned above) the user can click on the scale ticket and allocate it to a purchase contract or a storage agreement. Or you can do the full amount or part of a contract. This is what the inbound scale ticket application program will do to get commodities moved to the specific obligations a customer may have. Delivery Sheets Delivery Sheets is a way to group multiple tickets together for same commodity and same customer. You can also use delivery sheet to calculate average grades. It is a delivery sheet to group tickets together and process them as a group instead of individually. The system automatically assigns Delivery Sheet number. If you want to see completed sheets, you can click on the Show Completed toggle button (Yes/No). You can also show the Voided delivery sheets as well (toggle button). To create a new delivery sheet, click New. The Create delivery sheet window will appear on the right-hand side of the window. Branch: Defaults to last branch used Date: Defaults to current date Customer account: Enter account name or number Commodity: Choose commodity Customer operation: Choose the customer operation Customer Site: Choose customer site Split group: The system assigns a split group, but this can be overridden Estimated start date: not required fields. Some customers use a planning process. Estimated delivery quantity: \u201cabove\u201d helps with planning purposes. Click Create. A new delivery sheet will be created and open in the main window. Under the Delivery sheet ownership splits section: All tickets applied to the delivery sheet will be assigned to the one account. You can have multiple accounts with different percentages applied and as the ability to complete splits. Can choose default disposition. Each time the user applies a ticket to the delivery sheet, it will be applied to that specific contract. The user can choose what they intend to do with the storage agreement. There is the option of the tickets to be applied when added to the delivery sheet. Delivery sheet completion details: Details the splits and dispositions of the delivery sheet After these sections are reviewed and filled out, the user can complete the delivery sheet. This finishes the process and lock down the calculations. The user cannot settle any of the tickets delivered until it is completed. The tickets will not show up as available to settle until the complete function has been done. Unit Trains If unit trains are received within a facility, this is a simple program to create a Unit train number, which is an alphanumeric field. After creating a number, click save. These numbers are now available within the system to be used and attached to a scale ticket. Settlement Commodity accounting > Inbound > Settlement Settlement requests Settlement payments Discounts, fees and charging invoicing Settle options with grower Warehouse receipts Settlement sheet reprint Settlement Requests Commodity accounting > Inbound > Settlement > Settlement requests Settlement request window shows all settlement requests with a status of either opened, invoiced, or paid. To create new settlement request, click New. Select a customer, commodity, and branch. The disposition is a drop-down field asking the location of the contracts (Stored, Price later, Priced contract). After choosing, click Next. If chosen Priced Contract, the system shows all the scale tickets that have been applied to a priced contract that have not been settled yet. These are available to be settled. After choosing the contracts to be settled, click Next. The system provides a Preliminary summary with the contract number, delivery period, end price, settled quantity, and settled amount (gross dollar amount). Discounts, fees and charges would be summarized as well in the bottom quadrant. Click Next. The system will take the user to the Remittance screen. This screen summarizes the remittance portion. The Deferred payment function is utilized frequently. This is the option to lock in a commodity price and selling the commodity in a future date. The Requested payment date can change to reflect the future date. The Deferred charge code and Deferred Terms code are utilized along with the deferred payment option. The user can choose to have a premium on the deferred payment. Add/Split Payments is another function with the ability to issue additional checks. Click Next. The system is now ready to issue the check(s). The Settlement request summary provides a summary of the Settlement Request. Click Finish. From there, the user can go to Settlement Payment. Settlement and Payment Process Settlement and Payment Process is a two-step process: Confirm Confirm and Pay After the user selects one of the above options (self-explanatory), the system will validate the settlement and post in journal. Discount, fees, and charges invoicing. Functionality not completed as of October 2020. Warehouse receipt This is a legal tender document. If the document is listed as a negotiable warehouse receipt, it is a legal tender. A non-negotiable document does not have the same legal tender but has same protection level. To issue a new warehouse receipt, Click New. The Create warehouse receipt will appear on the right-hand side in a new window. After completing the warehouse receipt, the user would choose a Storage agreement. Click Save. A warehouse receipt will then be issued. This is another form of storage for the grower. Settle options with grower Functionality not completed as of October 2020. Settle sheet reprint This is the option to be able to reprint a settlement sheet. The Grain Outbound Processes can be found under Grain Outbound Processes","title":"Grain Inbound Processes"},{"location":"Grain_Inbound_Processes/#grain-inbound-processes","text":"","title":"Grain - Inbound Processes"},{"location":"Grain_Inbound_Processes/#overview","text":"An overview of the inbound grain process beginning with contracts and working through settlements. The in-bound process will be used for anyone buying in a commodity. Finance & Operations > Modules > Commodity Accounting From the commodity accounting menu, the outbound process consists of: Contracts Offers Purchase contracts Storage agreements Contract expiration Open contracts Delivery Settlement","title":"Overview"},{"location":"Grain_Inbound_Processes/#contracts","text":"","title":"Contracts"},{"location":"Grain_Inbound_Processes/#offers","text":"Commodity Accounting > Inbound > Contract > Offers The Offers My view shows a list of open offers. Open offers can be filtered by Branch, Commodity and Executed offers. Executed Offers is a yes/no toggle button if flipped to \u201cYes\u201d will show the contracts that have been filled with a purchase contract issued to the contract. To create a new offer, click New. A Create offer window will appear on the right-hand side. The Create offer fields include: Branch Offer date Offer type Notification - Before offer can be executed, the user needs to contact whoever created the offer and ask if they want the contract to be executed. Market offer - If the current market or bid at this location reaches offer level, the contract is executed automatically. Customer Commodity Contract type Delivery period Offer quantity Ticket default: Automatically defaults. The input is reflective of selected Delivery period. Board price Basis Net price Expiration date FOB location Notes Click Create. A review of the contract is then generated. Click Save. Created offers can be removed.","title":"Offers"},{"location":"Grain_Inbound_Processes/#purchase-contracts","text":"The Create purchase contract is generated by clicking New and opening an offer. A Create offer window will appear on the right-hand side. This is the same Create purchase contract window shown in the Create Contracts section. Click Create. The system will show the created Purchase contract. The Line view includes General and Delivery and pricing information. The General view outlines the line detail part of the contract capturing the contract information currently in the system. The Customer operation field is a farm field type development. The Delivery and pricing information view show the delivery information. The Header view shows additional detail: General contract information Includes Direct Ship information Contract dates and quantities Once tickets are applied to the contract, the system begins tracking what has been delivered. Part of a commodity can also be canceled. Sent date: The ability to track whether the contract has been signed Date returned: The date when the contract was returned Contract expires: The date when the contract expires. There is a contract expiration program track and get rid of contracts that have expired. Discounts, fees and freight The \u201cUse discount schedule in place at time of delivery\u201d is a yes/no toggle button with the option to have commodity and branch set up with a default discount schedule. In the setup page, there is a setup flag to use a discount schedule which would default to every contract or scale ticket. Fee schedule: Storage charges or assessments. Market to market adjustment: if the user is bringing contracts to market and you want to bring them back to market at one location, you can use a basis or freight adjustment to add/subtract to price to get the right calculation of bringing contracts to market. Freight included in basis: information of basis level of how much was freight. Addresses Multiple addresses to use on contract. These addresses can be overwritten Ship from name Ship to name: Defaults to branch previously entered in FOB name: Where ownership changes Miscellaneous details Can identify who in your company created contract. If a Broker was used, this can be identified along with the Broker commission rate. The commission rate is not processed and is just for informational purposes. It does not create a payable. Hedge commodity The commodity will default in. Additional hedge commodities can be entered. Can get long/short to run by hedge commodity.","title":"Purchase Contracts"},{"location":"Grain_Inbound_Processes/#pricing-of-a-contract","text":"Commodity > Inbound > Contract > Purchase contracts The Delivery and Pricing view is available under the \u201cLine\u201d My view. To set a price, highlight the delivery period. Click on Set price. The Contract pricing window will appear on the right-hand side. The user can change the Price quantity, Board price, and Basis to match what should be on the contract. The Net price is calculated from Board Price, subtracted Basis, and gave Net price. Click Create. A new delivery period line is created. Throughout system, you will see same contract number, but it will have two delivery period lines showing up. Within the contract entry, additional functionality includes: View: Scale tickets and load requests issued against a contract, along with load orders tied to a contract. Generate: Pricing confirmation. This can be printed. Fill: Ability to fill at market price or contract price. Market price: Takes quantity against current market. The system calculates gain/loss to create either a payable or receivable Contract price: Takes quantity against current contract price. There is no gain or losses.","title":"Pricing of a Contract"},{"location":"Grain_Inbound_Processes/#delivery-process-on-in-bound-grain","text":"Commodity accounting > Inbound > Delivery Delivery Process on in-bound grain includes: Inbound scale tickets Delivery sheets Inbound scale ticket application Unit trains","title":"Delivery Process on In-bound Grain"},{"location":"Grain_Inbound_Processes/#inbound-scale-tickets","text":"Commodity accounting > Inbound > Delivery > Inbound scale tickets Most of the inbound scale tickets will be imported in from scale a scale interface. But you do have the ability to add new scale tickets or edit existing scale tickets that have been imported. To create a new scale ticket, click on New. A Create scale ticket window will appear on the right-hand side. Ticket type Commodity Branch Warehouse Customer account Name Ticket date: this is a user field and can be overridden Customer operation: There can be multiple operations for a customer. Must choose one. A customer operation is required. Customer site: This field is not required but can choose for tracking purposes. Split Group: Will default in with the customer operation. This can be overridden. Click Create. The below image shows a newly created inbound scale ticket. Additional information and categories one can enter attached to a scale ticket. Scale ticket split details: If there were multiple splits, the system would preview the split they would be receiving. Weights: The system calculates net weight. This is a toggle on/off button (defaults Driver to on). The user can select scale operation and grader if they want the information recorded on the ticket. Date/Time: Can be viewed on the printed ticket. Notes: There are two types of notes: External and Internal. External will print on scale ticket. Grade factors: Grade factors are set up in the system and assigned to the commodity. The sequence they show up in the table is user defined. There is the ability for the moisture and test weight depending on equipment person has but can import moisture and test weight (TW). User can enter other discount factors as well. Those are used to defer back to the discount schedules that are attached to any contract or storage agreement user has and calculate any premium or charges that are due based off those discounts. Transportation Details: This is not a required entry but can be provided. It is a way to identify the driver delivering the commodity for informational purposes and when the truck comes back empty. The Unit number is primary used in rail shipments can add and group this ticket with others. Sometimes previously hauled commodity is a required field so that there wasn\u2019t hazardous material hauled prior to commodity. The next step is to Post to Inventory so all commodity received will show up in inventory to track and update DPR for inventory amounts. DPR: daily position report. After the ticket is posted, it is locked in and ready to be used in other parts of the system. This concludes the inbound scale ticket option.","title":"Inbound Scale Tickets"},{"location":"Grain_Inbound_Processes/#inbound-scale-ticket-application-process","text":"The Inbound scale ticket application process takes scale tickets received and provides the user the option to determine how the scale tickets will be used. The contract number can be changed. Inbound scale ticket auto-apply: The user can set up a sequence in the system to auto apply on each contract. e.g. If you have it set up to sequence if you want your first application contract, second agreement storage agreement. The system will automatically apply your scale ticket or a portion of it to an existing purchase contract or to an existing storage agreement based on the sequences set up on your auto-apply functionality. Inbound scale ticket un-apply Ability to unassign scale tickets from contracts Can select a scale ticket not previously assigned to a contract (if let\u2019s say it was un-applied as mentioned above) the user can click on the scale ticket and allocate it to a purchase contract or a storage agreement. Or you can do the full amount or part of a contract. This is what the inbound scale ticket application program will do to get commodities moved to the specific obligations a customer may have.","title":"Inbound scale ticket application process"},{"location":"Grain_Inbound_Processes/#delivery-sheets","text":"Delivery Sheets is a way to group multiple tickets together for same commodity and same customer. You can also use delivery sheet to calculate average grades. It is a delivery sheet to group tickets together and process them as a group instead of individually. The system automatically assigns Delivery Sheet number. If you want to see completed sheets, you can click on the Show Completed toggle button (Yes/No). You can also show the Voided delivery sheets as well (toggle button). To create a new delivery sheet, click New. The Create delivery sheet window will appear on the right-hand side of the window. Branch: Defaults to last branch used Date: Defaults to current date Customer account: Enter account name or number Commodity: Choose commodity Customer operation: Choose the customer operation Customer Site: Choose customer site Split group: The system assigns a split group, but this can be overridden Estimated start date: not required fields. Some customers use a planning process. Estimated delivery quantity: \u201cabove\u201d helps with planning purposes. Click Create. A new delivery sheet will be created and open in the main window. Under the Delivery sheet ownership splits section: All tickets applied to the delivery sheet will be assigned to the one account. You can have multiple accounts with different percentages applied and as the ability to complete splits. Can choose default disposition. Each time the user applies a ticket to the delivery sheet, it will be applied to that specific contract. The user can choose what they intend to do with the storage agreement. There is the option of the tickets to be applied when added to the delivery sheet. Delivery sheet completion details: Details the splits and dispositions of the delivery sheet After these sections are reviewed and filled out, the user can complete the delivery sheet. This finishes the process and lock down the calculations. The user cannot settle any of the tickets delivered until it is completed. The tickets will not show up as available to settle until the complete function has been done.","title":"Delivery Sheets"},{"location":"Grain_Inbound_Processes/#unit-trains","text":"If unit trains are received within a facility, this is a simple program to create a Unit train number, which is an alphanumeric field. After creating a number, click save. These numbers are now available within the system to be used and attached to a scale ticket.","title":"Unit Trains"},{"location":"Grain_Inbound_Processes/#settlement","text":"Commodity accounting > Inbound > Settlement Settlement requests Settlement payments Discounts, fees and charging invoicing Settle options with grower Warehouse receipts Settlement sheet reprint","title":"Settlement"},{"location":"Grain_Inbound_Processes/#settlement-requests","text":"Commodity accounting > Inbound > Settlement > Settlement requests Settlement request window shows all settlement requests with a status of either opened, invoiced, or paid. To create new settlement request, click New. Select a customer, commodity, and branch. The disposition is a drop-down field asking the location of the contracts (Stored, Price later, Priced contract). After choosing, click Next. If chosen Priced Contract, the system shows all the scale tickets that have been applied to a priced contract that have not been settled yet. These are available to be settled. After choosing the contracts to be settled, click Next. The system provides a Preliminary summary with the contract number, delivery period, end price, settled quantity, and settled amount (gross dollar amount). Discounts, fees and charges would be summarized as well in the bottom quadrant. Click Next. The system will take the user to the Remittance screen. This screen summarizes the remittance portion. The Deferred payment function is utilized frequently. This is the option to lock in a commodity price and selling the commodity in a future date. The Requested payment date can change to reflect the future date. The Deferred charge code and Deferred Terms code are utilized along with the deferred payment option. The user can choose to have a premium on the deferred payment. Add/Split Payments is another function with the ability to issue additional checks. Click Next. The system is now ready to issue the check(s). The Settlement request summary provides a summary of the Settlement Request. Click Finish. From there, the user can go to Settlement Payment.","title":"Settlement Requests"},{"location":"Grain_Inbound_Processes/#settlement-and-payment-process","text":"Settlement and Payment Process is a two-step process: Confirm Confirm and Pay After the user selects one of the above options (self-explanatory), the system will validate the settlement and post in journal.","title":"Settlement and Payment Process"},{"location":"Grain_Inbound_Processes/#discount-fees-and-charges-invoicing","text":"Functionality not completed as of October 2020.","title":"Discount, fees, and charges invoicing."},{"location":"Grain_Inbound_Processes/#warehouse-receipt","text":"This is a legal tender document. If the document is listed as a negotiable warehouse receipt, it is a legal tender. A non-negotiable document does not have the same legal tender but has same protection level. To issue a new warehouse receipt, Click New. The Create warehouse receipt will appear on the right-hand side in a new window. After completing the warehouse receipt, the user would choose a Storage agreement. Click Save. A warehouse receipt will then be issued. This is another form of storage for the grower.","title":"Warehouse receipt"},{"location":"Grain_Inbound_Processes/#settle-options-with-grower","text":"Functionality not completed as of October 2020.","title":"Settle options with grower"},{"location":"Grain_Inbound_Processes/#settle-sheet-reprint","text":"This is the option to be able to reprint a settlement sheet. The Grain Outbound Processes can be found under Grain Outbound Processes","title":"Settle sheet reprint"},{"location":"Grain_Outbound_Processes/","text":"Grain - Outbound Processes Overview An overview of the outbound grain process beginning with contracts and working through shipments and invoicing. Finance & Operations > Modules > Commodity Accounting From the commodity accounting menu, the outbound process consists of: Sales contracts Sales commodity contracts for load requests Load requests Outbound scale tickets Outbound scale ticket application Open contracts One also has the Invoicing option, which includes: Grain shipped not invoiced Outbound scale ticket destination weights and grades Shipped not invoiced \u2013 Bulk All sales advances Sales Contracts Creating a New Sales Contract There are two sections of Sales Contracts: - Line Detail - Header The following items are viewable in the Line Detail section. To enter a new sales contract (grain that is being shipped to another individual or company), click on Sales contracts. The new window will show a listing of all the sales contracts that currently exist. Click New located on the tab bar. The Create sales contract window will appear on the right-hand side and will default in the Branch one is located at. The Branch location can be changed. Additional items to be entered include: Contract Type: user defined Customer account: Automatically defaulted; can be changed Commodity: user defined Contract quantity: Amount of commodity available for the contract Load based: This is a toggle field set to yes / no. If set to no, the Number of loads will default to the Contract quantity. If set to yes: the contract is only satisfied by the number of loads. One would indicate the number of loads requested, which the system would calculate the load size. The Contract quantity is not significant to satisfy the contract. The Load size is user-defined with the Number of loads being reflective of the Load size. Discount schedule: you can choose discount schedule you would like in order to calculate the discounts that will be charged to you based off grain you deliver. Delivery Terms: user-defined. Majority of commodities are shipped on a Delivered basis. Grades to govern: user-defined. Defaults to Destination Weights to govern: user-defined. Defaults to Destination Delivery Period: Choose specific month and year Ticker: Pricing purposes Board Price: Becomes grayed out (un-usable) if Basis contract is used. Net Price: Becomes grayed out (un-usable) if Basis contract is used. Basis: Enter basis price if Basis contract is used. If Cash contract is used, it opens up board price and basis. Would need to enter both of those and the system will calculate Net price. Click Create After the contract is created, the Sales contract is available to view in the Sales contract header. The Delivery Period section shows the commodity scheduled for that delivery period. There can be multiple delivery periods along with the option to enter additional delivery periods and remove delivery periods. Setting the Price on a Basis Contract Basis contracts are required to have a price set. This is done by clicking on \u201cSet price\u201d under Delivery Periods. The system will open a Contract pricing slider where the user can enter a Price quantity for the contract. The user can price out the whole quantity or a portion of the quantity. The Net price will be generated with the entering of the Price quantity, along with the Board price and previously entered Basis. Click Create A new delivery period line is created with the set price contract. Alternate Delivery Pricing A function available with Sales Contract is the alternate delivery pricing. This functionality allows one to choose a different shipping address and a different price in (adjustment for shipping). Depending on when the ticket is entered and the chosen shipping address, the system will know what price to pull from. Contract Entry The Header section includes the following fields: Sales contract header Miscellaneous details The ability to identify the trader, broker, and broker commission rates. The system does not create a payable based off commission rate. This would need to be paid separately. Reference Numbers An alphanumeric field available as a cross reference to ensure the Sales Contract matches with the broker and/or trader\u2019s purchase contract number. Notes An option for notes to be included and printed on the contract. Contract dates and quantities The ability to keep track if the contract has been signed and returned. Can include Contract date, Sent date, and Date returned. This allows the ability to generate a report out of the system and preview what contracts have been sent and returned. Discounts, fees, and freight The Discount schedule previously chosen by generating a new Sales Contract will show in this field. If there are additional discount schedules, one can include on Fee schedule field. Terms of payment will default from customer. Delivery terms Market to market adjustment Market adjustments made through individual site or central site locations. If brought to a central site, the freight adjustment could be received from the issuing location back to the pricing location and brough together for one market price. Gains or losses would be calculated based off this market to market adjustment. Freight included in basis The ability to determine freight costs from the basis. Some merchandisers prefer to see freight separately. This is an option to set freight costs in the system with the commodity dollar amount posting to a freight expense account instead of being part of the margin. Freight per unit The ability to record what the freight rate was. This is for informational purposes and with the ability to print on the contract if preferred. Freight invoiceable A toggle switch with the ability to create an invoice based of freight weight (if toggled to yes). Addresses When a ticket is entered and applied to a contract, the addresses need to match. Ship from address: current location Ship to name: FOB address: destination contract. Hedge commodity For hedging purposes. The ability to identify if there was a commodity either being bought or sold that was not traded on an exchange. Within the contract entry, additional functionality includes: View: Scale tickets and load requests issued against a contract, along with load orders tied to a contract. Generate: Pricing confirmation. This can be printed. Fill: Ability to fill at market price or contract price. Market price: Takes quantity against current market. The system calculates gain/loss to create either a payable or receivable Contract price: Takes quantity against current contract price. There is no gain or losses. Can cancel or underfill the contract at any time. Sales Commodity Contracts for Load Requests Load request contracts can be viewed under Commodity Accounting > Outbound menu tab. A load request is a shipping order that states the specific ship date/time for a specific sales contract. Load orders: The individual shipments to be done Load requests: Shipments to be made Once loads have been shipped, the order quantity will show up based off load request, shipped quantity, ticket number and where it was shipped to. Those are used to request shipments. To create a new load request: Click New Choose specific contract number Choose delivery period Create request The newly created load requests automatically inputs the contract information (commodity, customer, customer account, contract number, and requested delivery date). The user will need to input the shipper in the Shipping carrier field. To create a new load order: Click Add Load The system will assign a number along with the shipping carrier that was previously selected. Input the Requested ship date Input Ordered Qty Choose Ship to address The ship to address needs to match what is on the contract. Click Save. This sets up a single load. You can remove a load or create multiple loads at one time with the Generate Load function. It depends on the user how many loads they would like to create. The load dates can be changed Outbound Scale Ticket Entry Commodity accounting > Outbound > Outbound scale tickets By clicking on the Outbound scale tickets window, all of the outbound scale tickets within the system are viewable. To create a new scale ticket: Click on New The Create scale ticket window will appear on the righthand side Ticket type: Outbound Commodity: enter commodity Branch: autogenerated Warehouse: autogenerated Customer account: choose customer Ticket date: autogenerated Delivery name: Autogenerated Address: will auto-populate with specific customer selected above. Click Create The new scale ticket will now appear in your main window. The user will be able to choose the specific load number previously set up to reflect on the shipped ticket. You do not have to use a load number. After entering in the outlined fields, click Save. Scale ticket split details: will rarely if ever use splits on a scale ticket Origin weights: most of the customers will use scale interface. Most of this information will be imported in the scale system. Designation weights: designation weights and grades are based off contract. The user can enter the contract\u2019s gross weight, tare weight and net weight, which will be reflected on the ticket record and with the ability to invoice based off that information. Grade Factors: can enter in any grade information. Transportation details: information to track truck and driver. This will feed into the TMS system for freight payment and tracking. Requirements state you must state what the previously hauled commodity is. This is a field identified on the Transportation details section. Direct Ship: This is a yes/no toggle switch. If flipped to yes, the Partner ticket number and Direct ship ticket number would become active and flagged. Direct ship indicates the grower is going to ship specific commodities stored onsite (ex: farm) to the receiving farm. It is a function to record commodities shipped from the users own inventory. This would set up the inbound scale ticket as well as a direct ship function so it doesn\u2019t update inventory. The ticket is now ready to be applied to a contract. Click Apply. The Outbound scale ticket application is now viewable and shows all of the outbound scale tickets, along with the sales contracts and storage agreements specific to the customer. Show all delivery periods. This is a yes/no toggle switch where you can view contracts. The default is to only show the current delivery period unless you wish to apply it to older contracts. But to apply against an upcoming period, you would need to turn toggle switch on. Spot Contract: if there is no contract available for this ticket or portion of it, the user can create a spot contract. The situation would be the purchaser would call the elevator and mention there was an over shipment. The elevator can at that point spot it out. If spotted out, the user would click the Spot Contract button where a new window will appear to create a spot contract. Once the selected contract shows the quantity to be allocated, the next steps include choosing the contract to apply it to. Click Post The contract will be updated in system and applied where it needs to be processed. Invoicing Commodity Accounting Menu > Invoice > Grain shipped not invoiced Outbound scale ticket destination weights and grades Outbound scale ticket destination weights and grades is a menu option where one can enter the destination weights, gross quantity per pound, and destination moisture, test weight, and additional grades for a specific contract. These results are inputted to calculate final payment. Grain shipped not invoiced A menu option showing all the loads shipped and yet to receive payment. These are separated by customer and by commodity. The user can select the number of loads they would like to create an invoice. The invoice process is referred to as a matching process. Majority of the shipments are made for commodity purposes, which means they do not need to send out invoices to request a payment. These invoices are after the fact and are known as a matching process. The goal is to match the payment sent when loads were sent. Under the Customer invoice amount field, they may not pay exact net amount due to weight or grade differences. Because the user will want the customer invoice and net amount to match, there is a future user option to adjust amount to match. For any dollar amounts differed on the commodity load, there will be functionality capturing the difference. Click Invoice There are two Invoice options: Pro forma invoice: this is in the rare situation where the user needs to send the invoice to the customer. This creates a document that looks like an invoice but doesn\u2019t update in the system as an invoice. It creates a document and then goes away. Invoice: this is the process of creating an invoice. The system generates the processes necessary to get the information back in F&O and creates a receivable on the customer account. After processing, a new Posting invoice window will appear with the invoice information: Parameters: printing specifications Overview: tickets being invoiced Setup: any payment format adjustments Line details: packing and delivery information Shipped not invoiced-Bulk A menu option which includes slight variations to be used with items that are not considered commodities (ex: ethanol). All Sales advances A menu option used on rail shipments for commodities. When railcars are loaded, it could take a couple of weeks to get to their destination. As soon as the railcars are loaded and released for shipment, the user can draft up to 90% of the commodity value for immediate payment. Once the shipments are recorded in system, a new invoice can be created. A Sales advance create window will pop up on right hand side. Sales advance description Customer account Commodity Currency Contract number: select contract you are going to advance it against. Unit number: unit number of the rail car Note: will appear on the printed documented If the shipment is selected to invoice, the system processes the shipment and calculates the profit. The system automatically inputs 90% for the advance percentage. If there were discounts or any other fees or charges, it would also calculate at 90%. Click Save. This locks it in system and the user can print a document showing the advance and the calculation took place. The Sales advance is created as a receivable. This is all the transactional outbound shipments for sales purposes. The Grain Inbound Processes can be found under Grain Inbound Processes","title":"Grain Outbound Processes"},{"location":"Grain_Outbound_Processes/#grain-outbound-processes","text":"","title":"Grain - Outbound Processes"},{"location":"Grain_Outbound_Processes/#overview","text":"An overview of the outbound grain process beginning with contracts and working through shipments and invoicing. Finance & Operations > Modules > Commodity Accounting From the commodity accounting menu, the outbound process consists of: Sales contracts Sales commodity contracts for load requests Load requests Outbound scale tickets Outbound scale ticket application Open contracts One also has the Invoicing option, which includes: Grain shipped not invoiced Outbound scale ticket destination weights and grades Shipped not invoiced \u2013 Bulk All sales advances","title":"Overview"},{"location":"Grain_Outbound_Processes/#sales-contracts","text":"","title":"Sales Contracts"},{"location":"Grain_Outbound_Processes/#creating-a-new-sales-contract","text":"There are two sections of Sales Contracts: - Line Detail - Header The following items are viewable in the Line Detail section. To enter a new sales contract (grain that is being shipped to another individual or company), click on Sales contracts. The new window will show a listing of all the sales contracts that currently exist. Click New located on the tab bar. The Create sales contract window will appear on the right-hand side and will default in the Branch one is located at. The Branch location can be changed. Additional items to be entered include: Contract Type: user defined Customer account: Automatically defaulted; can be changed Commodity: user defined Contract quantity: Amount of commodity available for the contract Load based: This is a toggle field set to yes / no. If set to no, the Number of loads will default to the Contract quantity. If set to yes: the contract is only satisfied by the number of loads. One would indicate the number of loads requested, which the system would calculate the load size. The Contract quantity is not significant to satisfy the contract. The Load size is user-defined with the Number of loads being reflective of the Load size. Discount schedule: you can choose discount schedule you would like in order to calculate the discounts that will be charged to you based off grain you deliver. Delivery Terms: user-defined. Majority of commodities are shipped on a Delivered basis. Grades to govern: user-defined. Defaults to Destination Weights to govern: user-defined. Defaults to Destination Delivery Period: Choose specific month and year Ticker: Pricing purposes Board Price: Becomes grayed out (un-usable) if Basis contract is used. Net Price: Becomes grayed out (un-usable) if Basis contract is used. Basis: Enter basis price if Basis contract is used. If Cash contract is used, it opens up board price and basis. Would need to enter both of those and the system will calculate Net price. Click Create After the contract is created, the Sales contract is available to view in the Sales contract header. The Delivery Period section shows the commodity scheduled for that delivery period. There can be multiple delivery periods along with the option to enter additional delivery periods and remove delivery periods.","title":"Creating a New Sales Contract"},{"location":"Grain_Outbound_Processes/#setting-the-price-on-a-basis-contract","text":"Basis contracts are required to have a price set. This is done by clicking on \u201cSet price\u201d under Delivery Periods. The system will open a Contract pricing slider where the user can enter a Price quantity for the contract. The user can price out the whole quantity or a portion of the quantity. The Net price will be generated with the entering of the Price quantity, along with the Board price and previously entered Basis. Click Create A new delivery period line is created with the set price contract.","title":"Setting the Price on a Basis Contract"},{"location":"Grain_Outbound_Processes/#alternate-delivery-pricing","text":"A function available with Sales Contract is the alternate delivery pricing. This functionality allows one to choose a different shipping address and a different price in (adjustment for shipping). Depending on when the ticket is entered and the chosen shipping address, the system will know what price to pull from.","title":"Alternate Delivery Pricing"},{"location":"Grain_Outbound_Processes/#contract-entry","text":"The Header section includes the following fields: Sales contract header Miscellaneous details The ability to identify the trader, broker, and broker commission rates. The system does not create a payable based off commission rate. This would need to be paid separately. Reference Numbers An alphanumeric field available as a cross reference to ensure the Sales Contract matches with the broker and/or trader\u2019s purchase contract number. Notes An option for notes to be included and printed on the contract. Contract dates and quantities The ability to keep track if the contract has been signed and returned. Can include Contract date, Sent date, and Date returned. This allows the ability to generate a report out of the system and preview what contracts have been sent and returned. Discounts, fees, and freight The Discount schedule previously chosen by generating a new Sales Contract will show in this field. If there are additional discount schedules, one can include on Fee schedule field. Terms of payment will default from customer. Delivery terms Market to market adjustment Market adjustments made through individual site or central site locations. If brought to a central site, the freight adjustment could be received from the issuing location back to the pricing location and brough together for one market price. Gains or losses would be calculated based off this market to market adjustment. Freight included in basis The ability to determine freight costs from the basis. Some merchandisers prefer to see freight separately. This is an option to set freight costs in the system with the commodity dollar amount posting to a freight expense account instead of being part of the margin. Freight per unit The ability to record what the freight rate was. This is for informational purposes and with the ability to print on the contract if preferred. Freight invoiceable A toggle switch with the ability to create an invoice based of freight weight (if toggled to yes). Addresses When a ticket is entered and applied to a contract, the addresses need to match. Ship from address: current location Ship to name: FOB address: destination contract. Hedge commodity For hedging purposes. The ability to identify if there was a commodity either being bought or sold that was not traded on an exchange. Within the contract entry, additional functionality includes: View: Scale tickets and load requests issued against a contract, along with load orders tied to a contract. Generate: Pricing confirmation. This can be printed. Fill: Ability to fill at market price or contract price. Market price: Takes quantity against current market. The system calculates gain/loss to create either a payable or receivable Contract price: Takes quantity against current contract price. There is no gain or losses. Can cancel or underfill the contract at any time.","title":"Contract Entry"},{"location":"Grain_Outbound_Processes/#sales-commodity-contracts-for-load-requests","text":"Load request contracts can be viewed under Commodity Accounting > Outbound menu tab. A load request is a shipping order that states the specific ship date/time for a specific sales contract. Load orders: The individual shipments to be done Load requests: Shipments to be made Once loads have been shipped, the order quantity will show up based off load request, shipped quantity, ticket number and where it was shipped to. Those are used to request shipments. To create a new load request: Click New Choose specific contract number Choose delivery period Create request The newly created load requests automatically inputs the contract information (commodity, customer, customer account, contract number, and requested delivery date). The user will need to input the shipper in the Shipping carrier field. To create a new load order: Click Add Load The system will assign a number along with the shipping carrier that was previously selected. Input the Requested ship date Input Ordered Qty Choose Ship to address The ship to address needs to match what is on the contract. Click Save. This sets up a single load. You can remove a load or create multiple loads at one time with the Generate Load function. It depends on the user how many loads they would like to create. The load dates can be changed","title":"Sales Commodity Contracts for Load Requests"},{"location":"Grain_Outbound_Processes/#outbound-scale-ticket-entry","text":"Commodity accounting > Outbound > Outbound scale tickets By clicking on the Outbound scale tickets window, all of the outbound scale tickets within the system are viewable. To create a new scale ticket: Click on New The Create scale ticket window will appear on the righthand side Ticket type: Outbound Commodity: enter commodity Branch: autogenerated Warehouse: autogenerated Customer account: choose customer Ticket date: autogenerated Delivery name: Autogenerated Address: will auto-populate with specific customer selected above. Click Create The new scale ticket will now appear in your main window. The user will be able to choose the specific load number previously set up to reflect on the shipped ticket. You do not have to use a load number. After entering in the outlined fields, click Save. Scale ticket split details: will rarely if ever use splits on a scale ticket Origin weights: most of the customers will use scale interface. Most of this information will be imported in the scale system. Designation weights: designation weights and grades are based off contract. The user can enter the contract\u2019s gross weight, tare weight and net weight, which will be reflected on the ticket record and with the ability to invoice based off that information. Grade Factors: can enter in any grade information. Transportation details: information to track truck and driver. This will feed into the TMS system for freight payment and tracking. Requirements state you must state what the previously hauled commodity is. This is a field identified on the Transportation details section. Direct Ship: This is a yes/no toggle switch. If flipped to yes, the Partner ticket number and Direct ship ticket number would become active and flagged. Direct ship indicates the grower is going to ship specific commodities stored onsite (ex: farm) to the receiving farm. It is a function to record commodities shipped from the users own inventory. This would set up the inbound scale ticket as well as a direct ship function so it doesn\u2019t update inventory. The ticket is now ready to be applied to a contract. Click Apply. The Outbound scale ticket application is now viewable and shows all of the outbound scale tickets, along with the sales contracts and storage agreements specific to the customer. Show all delivery periods. This is a yes/no toggle switch where you can view contracts. The default is to only show the current delivery period unless you wish to apply it to older contracts. But to apply against an upcoming period, you would need to turn toggle switch on. Spot Contract: if there is no contract available for this ticket or portion of it, the user can create a spot contract. The situation would be the purchaser would call the elevator and mention there was an over shipment. The elevator can at that point spot it out. If spotted out, the user would click the Spot Contract button where a new window will appear to create a spot contract. Once the selected contract shows the quantity to be allocated, the next steps include choosing the contract to apply it to. Click Post The contract will be updated in system and applied where it needs to be processed.","title":"Outbound Scale Ticket Entry"},{"location":"Grain_Outbound_Processes/#invoicing","text":"Commodity Accounting Menu > Invoice > Grain shipped not invoiced","title":"Invoicing"},{"location":"Grain_Outbound_Processes/#outbound-scale-ticket-destination-weights-and-grades","text":"Outbound scale ticket destination weights and grades is a menu option where one can enter the destination weights, gross quantity per pound, and destination moisture, test weight, and additional grades for a specific contract. These results are inputted to calculate final payment.","title":"Outbound scale ticket destination weights and grades"},{"location":"Grain_Outbound_Processes/#grain-shipped-not-invoiced","text":"A menu option showing all the loads shipped and yet to receive payment. These are separated by customer and by commodity. The user can select the number of loads they would like to create an invoice. The invoice process is referred to as a matching process. Majority of the shipments are made for commodity purposes, which means they do not need to send out invoices to request a payment. These invoices are after the fact and are known as a matching process. The goal is to match the payment sent when loads were sent. Under the Customer invoice amount field, they may not pay exact net amount due to weight or grade differences. Because the user will want the customer invoice and net amount to match, there is a future user option to adjust amount to match. For any dollar amounts differed on the commodity load, there will be functionality capturing the difference. Click Invoice There are two Invoice options: Pro forma invoice: this is in the rare situation where the user needs to send the invoice to the customer. This creates a document that looks like an invoice but doesn\u2019t update in the system as an invoice. It creates a document and then goes away. Invoice: this is the process of creating an invoice. The system generates the processes necessary to get the information back in F&O and creates a receivable on the customer account. After processing, a new Posting invoice window will appear with the invoice information: Parameters: printing specifications Overview: tickets being invoiced Setup: any payment format adjustments Line details: packing and delivery information","title":"Grain shipped not invoiced"},{"location":"Grain_Outbound_Processes/#shipped-not-invoiced-bulk","text":"A menu option which includes slight variations to be used with items that are not considered commodities (ex: ethanol).","title":"Shipped not invoiced-Bulk"},{"location":"Grain_Outbound_Processes/#all-sales-advances","text":"A menu option used on rail shipments for commodities. When railcars are loaded, it could take a couple of weeks to get to their destination. As soon as the railcars are loaded and released for shipment, the user can draft up to 90% of the commodity value for immediate payment. Once the shipments are recorded in system, a new invoice can be created. A Sales advance create window will pop up on right hand side. Sales advance description Customer account Commodity Currency Contract number: select contract you are going to advance it against. Unit number: unit number of the rail car Note: will appear on the printed documented If the shipment is selected to invoice, the system processes the shipment and calculates the profit. The system automatically inputs 90% for the advance percentage. If there were discounts or any other fees or charges, it would also calculate at 90%. Click Save. This locks it in system and the user can print a document showing the advance and the calculation took place. The Sales advance is created as a receivable. This is all the transactional outbound shipments for sales purposes. The Grain Inbound Processes can be found under Grain Inbound Processes","title":"All Sales advances"},{"location":"HowtoupdateLevridgeScale/","text":"How to Update Levridge Scale Prerequisites An older Version of Levridge Scale must be installed and configured Setup Download the new version installer exe file Right click and Run as Administrator Agree to terms and click Install When the install is complete, click Finish Open IIS On the LevScaleAPI and LevPrint Application Pools, right click > Advanced settings In the Identity field select Custom account > Set and enter username and password Open Services On the LevHardwareInterfaceService and LevScaleClient services , right click > Properties Click the Log On tab Enter account and password and click OK. If the account is part of a directory, click Browse. Then enter the username and click Check Names. Check the configuration of appsettings Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers In the LevScaleAPI and LevScaleClient folders, configure appsettings.json Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services In the AxToScaleIntegration and ScaleToAxIntegration folders configure appsettings.json Restart the PC","title":"How to Update Levridge Scale"},{"location":"HowtoupdateLevridgeScale/#how-to-update-levridge-scale","text":"","title":"How to Update Levridge Scale"},{"location":"HowtoupdateLevridgeScale/#prerequisites","text":"An older Version of Levridge Scale must be installed and configured","title":"Prerequisites"},{"location":"HowtoupdateLevridgeScale/#setup","text":"Download the new version installer exe file Right click and Run as Administrator Agree to terms and click Install When the install is complete, click Finish Open IIS On the LevScaleAPI and LevPrint Application Pools, right click > Advanced settings In the Identity field select Custom account > Set and enter username and password Open Services On the LevHardwareInterfaceService and LevScaleClient services , right click > Properties Click the Log On tab Enter account and password and click OK. If the account is part of a directory, click Browse. Then enter the username and click Check Names. Check the configuration of appsettings Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers In the LevScaleAPI and LevScaleClient folders, configure appsettings.json Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services In the AxToScaleIntegration and ScaleToAxIntegration folders configure appsettings.json Restart the PC","title":"Setup"},{"location":"InstanceConfig/","text":"InstanceConfig Settings InstanceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework. Example \"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfiguration\", \"LogRequestsAndResponses\": true, \"EnableAppInsightsAdaptiveSampling\": true, \"HttpClientTimeout\": 100, \"AcceptedApiRoles\":[ \"access_as_application\" ] } Definition InstanceConfig The node in the appsettings.json file does not actually need to be named \"InstanceConfig\". You can use a command line parameter to specify the node name (section name) that contains the InstanceConfig data. No matter the name, the instance config section must contain the following attributes: AzureTableConfiguration LogRequestsAndResponses EnableAppInsightsAdaptiveSampling HttpClientTimeout AcceptedApiRoles AzureAdSection AzureTableConfiguration Required The AzureTableConfiguration attribute contains a string that specifies the configuration node (section) that holds the Azure Table configuration used by the current instance of the Integration Framework. This must point to a node that is a AzureTableEntityConfiguration json object LogRequestsAndResponses Optional Default = false The LogRequestsAndResponses attribute contains a boolean that specifies whether or not to log the requests and responses of the controllers in the current instance of the Integration Framework. EnableAppInsightsAdaptiveSampling Optional Default = true The EnableAppInsightsAdaptiveSampling attribute contains a boolean that specifies whether or not to enable application insights adaptive sampling. If this is disabled all the messages logged to Application Insights. This should only be used during troubleshooting and testing because the cost for Application Insights is billed based on volume. The default state is \"true\" which means that adaptive sampling is enabled by default. See Sampling in Application Insights for more information. HttpClientTimeout Optional Default = 100 seconds The HttpClientTimeout attribute specifies the number of seconds to use for the timeout on all HTTP Client calls in the integration framework. The default is 100 seconds. In some cases this is not enough time under heavy load, particularly the Agsync to FinOps work order integration. To change this set the value to an integer value that represents the number of seconds you want for the timeout. AcceptedApiRoles Optional Default = Empty Array The AcceptedApiRoles attribute specifies what roles in the Active Directory Application Registration are accepted as adequate permissions to authorize an application to interact with secured APIs on this integration instance. AzureAdSection Optional Default = \"AzureAD\" The name of the section that contains the AzureAD configuration options used for AzureAD authentication.","title":"InstanceConfig Settings"},{"location":"InstanceConfig/#instanceconfig-settings","text":"InstanceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework.","title":"InstanceConfig Settings"},{"location":"InstanceConfig/#example","text":"\"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfiguration\", \"LogRequestsAndResponses\": true, \"EnableAppInsightsAdaptiveSampling\": true, \"HttpClientTimeout\": 100, \"AcceptedApiRoles\":[ \"access_as_application\" ] }","title":"Example"},{"location":"InstanceConfig/#definition","text":"","title":"Definition"},{"location":"InstanceConfig/#instanceconfig","text":"The node in the appsettings.json file does not actually need to be named \"InstanceConfig\". You can use a command line parameter to specify the node name (section name) that contains the InstanceConfig data. No matter the name, the instance config section must contain the following attributes: AzureTableConfiguration LogRequestsAndResponses EnableAppInsightsAdaptiveSampling HttpClientTimeout AcceptedApiRoles AzureAdSection","title":"InstanceConfig"},{"location":"InstanceConfig/#azuretableconfiguration","text":"Required The AzureTableConfiguration attribute contains a string that specifies the configuration node (section) that holds the Azure Table configuration used by the current instance of the Integration Framework. This must point to a node that is a AzureTableEntityConfiguration json object","title":"AzureTableConfiguration"},{"location":"InstanceConfig/#logrequestsandresponses","text":"Optional Default = false The LogRequestsAndResponses attribute contains a boolean that specifies whether or not to log the requests and responses of the controllers in the current instance of the Integration Framework.","title":"LogRequestsAndResponses"},{"location":"InstanceConfig/#enableappinsightsadaptivesampling","text":"Optional Default = true The EnableAppInsightsAdaptiveSampling attribute contains a boolean that specifies whether or not to enable application insights adaptive sampling. If this is disabled all the messages logged to Application Insights. This should only be used during troubleshooting and testing because the cost for Application Insights is billed based on volume. The default state is \"true\" which means that adaptive sampling is enabled by default. See Sampling in Application Insights for more information.","title":"EnableAppInsightsAdaptiveSampling"},{"location":"InstanceConfig/#httpclienttimeout","text":"Optional Default = 100 seconds The HttpClientTimeout attribute specifies the number of seconds to use for the timeout on all HTTP Client calls in the integration framework. The default is 100 seconds. In some cases this is not enough time under heavy load, particularly the Agsync to FinOps work order integration. To change this set the value to an integer value that represents the number of seconds you want for the timeout.","title":"HttpClientTimeout"},{"location":"InstanceConfig/#acceptedapiroles","text":"Optional Default = Empty Array The AcceptedApiRoles attribute specifies what roles in the Active Directory Application Registration are accepted as adequate permissions to authorize an application to interact with secured APIs on this integration instance.","title":"AcceptedApiRoles"},{"location":"InstanceConfig/#azureadsection","text":"Optional Default = \"AzureAD\" The name of the section that contains the AzureAD configuration options used for AzureAD authentication.","title":"AzureAdSection"},{"location":"IntegratingCustomFields/","text":"Introduction In many implementations a client will have specific needs that require custom fields to be added to existing entities or custom behavior for an existing field in an integration. This document shows how to create a custom field extension to have those custom fields integrated when the entity is being integrated. Overview In order to integrate custom fields you will need to create a Visual Studio solution with upto three projects: Custom Source Proxy Project Contains the proxy for the source datasource with the custom fields in the entities This project is only necessary if there are custom fields in the source. If your customizations only include custom behavior for existing fields then a custom source proxy will not be needed. Custom Destination Proxy Project Contains the proxy for the desitination datasource with the custom fields in the entities This project is only necessary if there are custom fields in the destination. If your customizations only include custom behavior for existing fields then a custom destination proxy will not be needed. Custom Mapping Project Contains the code need to map the integration for the custom fields between the source and destination entities Note: If there are no custom fields involved and you are only defining custom behavior for existing fields you will not need new proxies. You only need a proxy to define the metadata for custom fields. Please see Deploying Custom Field Mapping Assemblies for information on deploying the custom mapping assembly. Tutorial Create the Solution The first step is to create a Visual Studio solution for the custom mapping. In Visual Studio, create a new C# Class Library (.NET Core). You may want to give the solution a different name than the project. In our example, the customer is Comstock so we will name the solution \"ComstockCustomMapping\" and the project Levridge.Integration.IntegrationService.Mapping.Comstock. We recommend you use this naming convention for your custom mapping project: Levridge.Integration.IntegrationService.Mapping.[clientname]. Create the Source Proxy Project Create the Destination Proxy Project Add References to the Custom Mapping Project The Levridge packages are published to our DevOps Artifacts so you will need to add a Nuget source for those packages. This is done in Visual Studio from Tools/Options/NuGet Package Manager/Package Sources. The source is https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages-beta/nuget/v3/index.json If you are working the LevDevelopment branch. If you are working in the customer's repository you should use https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages/nuget/v3/index.json which is the released version of the packages. You will need to add the following Nuget references to your custom mapping project: Levridge.EntityFramework Levridge.Integration.IntegrationService.Abstractions Levridge.Integration.IntegrationService.Mapping Microsoft.Extensions.DependencyInjection System.ComponentModel.Composition Note: The Levridge packages are available from our Azure DevOps Artifacts repository. The URL for released packages is https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages/nuget/v3/index.json Add Source and Destination Datasource References to Custom Mapping Project You will need to reference the destination data source project in order to have access to any Field types and other types used during mapping. If your datasource is CRM you would include this reference: * Levridge.ODataDataSources.CRMODataDataSource If your datasource is F&O you would include this reference: * Levridge.DynamicsAxDataSource Update the references to be excluded from deployment These references will be needed for the build process, but we will want to use the libraries provided by the standard deployment and not deploy our own copy of the libraries with the custom mapping assemblies. To accomplish this, we let the msbuild system know to exclude these libraries from the runtime deployment by adding <ExcludeAssets>runtime</ExcludeAssets> to the <PackageReference> node for each package. You should have an <ItemGroup> node that looks somthing like this. <ItemGroup> <PackageReference Include=\"Levridge.EntityFramework\" Version=\"2.0.10\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.Integration.IntegrationService.Abstractions\" Version=\"1.0.0\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.Integration.IntegrationService.Mapping\" Version=\"1.0.0\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.ODataDataSources.CRMODataDataSource\" Version=\"2.1.15\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Microsoft.Extensions.DependencyInjection\" Version=\"3.0.2\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> </ItemGroup> Add a reference to the two datasource proxy projects Your custom mapping methods will need to access the source and data entities so you will need to add a reference to the two proxy projects you created in sections Create the Source Proxy Project and Create the Destination Proxy Project If you do not need a custom proxy project you should add a reference package to the correct Levridge nuget package. The F&O and CRM packages are: * Levridge.DynamicsAxDataSource * Levridge.ODataDataSources.DynamicsCRM Create An EntityMapBuilderExtension class We need to have a class that will contain the necessary mapping methods for the custom fields being added to the integration. Create a public class This can not be a static class because Microsoft MEF won't export a static class. Add the [Export] attribute to the class The Export attribute is in the System.ComponentModel.Composition that was added in the section Add References to the Custom Mapping Project Name the class We recommend using something like [client]CustomFieldsEntityMapping. The actual name is not important, orther than to be clear the purpose of the class. In our example we named the class ContosoCustomFieldsEntityMapping . Add a public static void method that takes a single IServiceCollection parameter. In our example we added the following method: public static void AddContosoCustomMaps(IServiceCollection services) Add a private static method that takes a single IEntityMapBuilder parameter and returns an IEntityMapBuilder and takes two generic parameters. In our example we added the following method: private static IEntityMapBuilder AddContosoCustomFieldsToMaps<TSource, TTarget>(IEntityMapBuilder builder) Add the following code to the public static method created in step 3 above: var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapping.AddContosoCustomFieldsToMaps (builder);` The second line should reference the current class and the method you created in step 4 above. Here is our complete method in the example: public static void AddLandusCustomMaps(IServiceCollection services) { var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapping.AddContosoCustomFieldsToMaps (builder); } Note: The namespaces AxEntities and CRMEntities should reference your custom proxies if you created them otherwise it should reference the packaged Levridge provided proxy Add the following code to the private static method created in step 4 above: if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapping)); The first block validates the parameter. The last line calls a method on a helper class to invoke all the mapping methods on the class we are now building. Here is our complete method in the example: private static IEntityMapBuilder AddContosoCustomFieldsToMaps (IEntityMapBuilder builder) { if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapping)); } Create mapping methods Create a private static method that a single IEntityMapBuilder parameter and returns an IEntityMapBuilder Name the method Map[SourceEntity]_[DestinationEntity]. In our example we added the following method: private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) This method will add the custom field mapping for CustomerV3 to lev_customer Add an [EntityMapMethod] Attribute to the map method Add mapping code in the map method The mapping code is split into two levels: - AddEntityMap The structure of the AddEntityMap is an extension method on IEntityMapBuilder that takes two generic parameters for the source and target entities and an Action method parameter used to configure the EntityMap by adding field maps for the entities. - AddFieldMap AddFieldMap is a method on EntityMap . There are several that takes two generic parameters for the source field type and target field type and an Action method parameter used to configure the EntityMap by adding field maps for the entities. Here is an example method that adds mapping for CustomerV3 to lev_customer: private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.lev_customer>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevInCareOf)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_incareof))); em.AddMapReferencedField(nameof(AxEntities.CustomerV3), nameof(AxEntities.CustomerV3.LevPrintName)); }); return builder; } Example Mapping using System; using Microsoft.Extensions.DependencyInjection; using Levridge.EntityFramework; using Levridge.ODataDataSources; using Levridge.Integration.IntegrationService.Abstractions; using AxEntities = ContosoCustomFields.Microsoft.Dynamics.DataEntities; using CRMEntities = ContosoCustomFields.ODataDataSources.DynamicsCRM; using System.ComponentModel.Composition; namespace Levridge.Integration.IntegrationService.Mapping.ContosoCustomFields { [Export] public class ContosoCustomFieldsEntityMapBuilderExtensions { public static void AddContosoCustomMaps(IServiceCollection services) { var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapBuilderExtensions.AddContosoCustomFieldsToMaps<AxEntities.CustomerV3, CRMEntities.lev_customer>(builder); } private static IEntityMapBuilder AddContosoCustomFieldsToMaps<TSource, TTarget>(IEntityMapBuilder builder) { if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapBuilderExtensions)); } [EntityMapMethod] private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.lev_customer>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevInCareOf)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_incareof))); em.AddMapReferencedField(nameof(AxEntities.CustomerV3), nameof(AxEntities.CustomerV3.LevPrintName)); }); return builder; } [EntityMapMethod] private static IEntityMapBuilder MapCustomerV3_account(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.account>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.account.name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); }); return builder; } [EntityMapMethod] private static IEntityMapBuilder MapInventSite_lev_companysite(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.InventSite, CRMEntities.lev_companysite>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.InventSite.LevRegionId)), new CRMODataField<String>(nameof(CRMEntities.lev_companysite.stn_region))); }); return builder; } } } Deploying the Custom Mapping Assemblies To deploy the custom assembly you simply copy the output of the mapping assembly to the same directory that contains the Levridge.Integration.Host assemblies. See Deploying Custom Field Mapping Assemblies for more information.","title":"Integrating Custom Fields"},{"location":"IntegratingCustomFields/#introduction","text":"In many implementations a client will have specific needs that require custom fields to be added to existing entities or custom behavior for an existing field in an integration. This document shows how to create a custom field extension to have those custom fields integrated when the entity is being integrated.","title":"Introduction"},{"location":"IntegratingCustomFields/#overview","text":"In order to integrate custom fields you will need to create a Visual Studio solution with upto three projects: Custom Source Proxy Project Contains the proxy for the source datasource with the custom fields in the entities This project is only necessary if there are custom fields in the source. If your customizations only include custom behavior for existing fields then a custom source proxy will not be needed. Custom Destination Proxy Project Contains the proxy for the desitination datasource with the custom fields in the entities This project is only necessary if there are custom fields in the destination. If your customizations only include custom behavior for existing fields then a custom destination proxy will not be needed. Custom Mapping Project Contains the code need to map the integration for the custom fields between the source and destination entities Note: If there are no custom fields involved and you are only defining custom behavior for existing fields you will not need new proxies. You only need a proxy to define the metadata for custom fields. Please see Deploying Custom Field Mapping Assemblies for information on deploying the custom mapping assembly.","title":"Overview"},{"location":"IntegratingCustomFields/#tutorial","text":"","title":"Tutorial"},{"location":"IntegratingCustomFields/#create-the-solution","text":"The first step is to create a Visual Studio solution for the custom mapping. In Visual Studio, create a new C# Class Library (.NET Core). You may want to give the solution a different name than the project. In our example, the customer is Comstock so we will name the solution \"ComstockCustomMapping\" and the project Levridge.Integration.IntegrationService.Mapping.Comstock. We recommend you use this naming convention for your custom mapping project: Levridge.Integration.IntegrationService.Mapping.[clientname].","title":"Create the Solution"},{"location":"IntegratingCustomFields/#create-the-source-proxy-project","text":"","title":"Create the Source Proxy Project"},{"location":"IntegratingCustomFields/#create-the-destination-proxy-project","text":"","title":"Create the Destination Proxy Project"},{"location":"IntegratingCustomFields/#add-references-to-the-custom-mapping-project","text":"The Levridge packages are published to our DevOps Artifacts so you will need to add a Nuget source for those packages. This is done in Visual Studio from Tools/Options/NuGet Package Manager/Package Sources. The source is https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages-beta/nuget/v3/index.json If you are working the LevDevelopment branch. If you are working in the customer's repository you should use https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages/nuget/v3/index.json which is the released version of the packages. You will need to add the following Nuget references to your custom mapping project: Levridge.EntityFramework Levridge.Integration.IntegrationService.Abstractions Levridge.Integration.IntegrationService.Mapping Microsoft.Extensions.DependencyInjection System.ComponentModel.Composition Note: The Levridge packages are available from our Azure DevOps Artifacts repository. The URL for released packages is https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages/nuget/v3/index.json","title":"Add References to the Custom Mapping Project"},{"location":"IntegratingCustomFields/#add-source-and-destination-datasource-references-to-custom-mapping-project","text":"You will need to reference the destination data source project in order to have access to any Field types and other types used during mapping. If your datasource is CRM you would include this reference: * Levridge.ODataDataSources.CRMODataDataSource If your datasource is F&O you would include this reference: * Levridge.DynamicsAxDataSource","title":"Add Source and Destination Datasource References to Custom Mapping Project"},{"location":"IntegratingCustomFields/#update-the-references-to-be-excluded-from-deployment","text":"These references will be needed for the build process, but we will want to use the libraries provided by the standard deployment and not deploy our own copy of the libraries with the custom mapping assemblies. To accomplish this, we let the msbuild system know to exclude these libraries from the runtime deployment by adding <ExcludeAssets>runtime</ExcludeAssets> to the <PackageReference> node for each package. You should have an <ItemGroup> node that looks somthing like this. <ItemGroup> <PackageReference Include=\"Levridge.EntityFramework\" Version=\"2.0.10\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.Integration.IntegrationService.Abstractions\" Version=\"1.0.0\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.Integration.IntegrationService.Mapping\" Version=\"1.0.0\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.ODataDataSources.CRMODataDataSource\" Version=\"2.1.15\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Microsoft.Extensions.DependencyInjection\" Version=\"3.0.2\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> </ItemGroup>","title":"Update the references to be excluded from deployment"},{"location":"IntegratingCustomFields/#add-a-reference-to-the-two-datasource-proxy-projects","text":"Your custom mapping methods will need to access the source and data entities so you will need to add a reference to the two proxy projects you created in sections Create the Source Proxy Project and Create the Destination Proxy Project If you do not need a custom proxy project you should add a reference package to the correct Levridge nuget package. The F&O and CRM packages are: * Levridge.DynamicsAxDataSource * Levridge.ODataDataSources.DynamicsCRM","title":"Add a reference to the two datasource proxy projects"},{"location":"IntegratingCustomFields/#create-an-entitymapbuilderextension-class","text":"We need to have a class that will contain the necessary mapping methods for the custom fields being added to the integration. Create a public class This can not be a static class because Microsoft MEF won't export a static class. Add the [Export] attribute to the class The Export attribute is in the System.ComponentModel.Composition that was added in the section Add References to the Custom Mapping Project Name the class We recommend using something like [client]CustomFieldsEntityMapping. The actual name is not important, orther than to be clear the purpose of the class. In our example we named the class ContosoCustomFieldsEntityMapping . Add a public static void method that takes a single IServiceCollection parameter. In our example we added the following method: public static void AddContosoCustomMaps(IServiceCollection services) Add a private static method that takes a single IEntityMapBuilder parameter and returns an IEntityMapBuilder and takes two generic parameters. In our example we added the following method: private static IEntityMapBuilder AddContosoCustomFieldsToMaps<TSource, TTarget>(IEntityMapBuilder builder) Add the following code to the public static method created in step 3 above: var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapping.AddContosoCustomFieldsToMaps (builder);` The second line should reference the current class and the method you created in step 4 above. Here is our complete method in the example: public static void AddLandusCustomMaps(IServiceCollection services) { var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapping.AddContosoCustomFieldsToMaps (builder); } Note: The namespaces AxEntities and CRMEntities should reference your custom proxies if you created them otherwise it should reference the packaged Levridge provided proxy Add the following code to the private static method created in step 4 above: if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapping)); The first block validates the parameter. The last line calls a method on a helper class to invoke all the mapping methods on the class we are now building. Here is our complete method in the example: private static IEntityMapBuilder AddContosoCustomFieldsToMaps (IEntityMapBuilder builder) { if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapping)); } Create mapping methods Create a private static method that a single IEntityMapBuilder parameter and returns an IEntityMapBuilder Name the method Map[SourceEntity]_[DestinationEntity]. In our example we added the following method: private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) This method will add the custom field mapping for CustomerV3 to lev_customer Add an [EntityMapMethod] Attribute to the map method Add mapping code in the map method The mapping code is split into two levels: - AddEntityMap The structure of the AddEntityMap is an extension method on IEntityMapBuilder that takes two generic parameters for the source and target entities and an Action method parameter used to configure the EntityMap by adding field maps for the entities. - AddFieldMap AddFieldMap is a method on EntityMap . There are several that takes two generic parameters for the source field type and target field type and an Action method parameter used to configure the EntityMap by adding field maps for the entities. Here is an example method that adds mapping for CustomerV3 to lev_customer: private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.lev_customer>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevInCareOf)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_incareof))); em.AddMapReferencedField(nameof(AxEntities.CustomerV3), nameof(AxEntities.CustomerV3.LevPrintName)); }); return builder; }","title":"Create An EntityMapBuilderExtension class"},{"location":"IntegratingCustomFields/#example-mapping","text":"using System; using Microsoft.Extensions.DependencyInjection; using Levridge.EntityFramework; using Levridge.ODataDataSources; using Levridge.Integration.IntegrationService.Abstractions; using AxEntities = ContosoCustomFields.Microsoft.Dynamics.DataEntities; using CRMEntities = ContosoCustomFields.ODataDataSources.DynamicsCRM; using System.ComponentModel.Composition; namespace Levridge.Integration.IntegrationService.Mapping.ContosoCustomFields { [Export] public class ContosoCustomFieldsEntityMapBuilderExtensions { public static void AddContosoCustomMaps(IServiceCollection services) { var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapBuilderExtensions.AddContosoCustomFieldsToMaps<AxEntities.CustomerV3, CRMEntities.lev_customer>(builder); } private static IEntityMapBuilder AddContosoCustomFieldsToMaps<TSource, TTarget>(IEntityMapBuilder builder) { if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapBuilderExtensions)); } [EntityMapMethod] private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.lev_customer>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevInCareOf)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_incareof))); em.AddMapReferencedField(nameof(AxEntities.CustomerV3), nameof(AxEntities.CustomerV3.LevPrintName)); }); return builder; } [EntityMapMethod] private static IEntityMapBuilder MapCustomerV3_account(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.account>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.account.name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); }); return builder; } [EntityMapMethod] private static IEntityMapBuilder MapInventSite_lev_companysite(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.InventSite, CRMEntities.lev_companysite>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.InventSite.LevRegionId)), new CRMODataField<String>(nameof(CRMEntities.lev_companysite.stn_region))); }); return builder; } } }","title":"Example Mapping"},{"location":"IntegratingCustomFields/#deploying-the-custom-mapping-assemblies","text":"To deploy the custom assembly you simply copy the output of the mapping assembly to the same directory that contains the Levridge.Integration.Host assemblies. See Deploying Custom Field Mapping Assemblies for more information.","title":"Deploying the Custom Mapping Assemblies"},{"location":"Integration%20Template/","text":"Title of Integration This should be a short, one paragraph description of the integration being documented. Overview A more detailed overview should included here. This overview should describe the integration and any unique details for this integration. API This section should include detailed documentation of the API. Configuration This section should include detailed documentation for configuring the integration. (Optional) Deployment This section should include any instructions necessary to deploy this integration. This section may not be needed if the deployment follows a standard deployment process that is documented elsewhere. In this case it would be helpful to direct the reader to that standard documentation.","title":"Title of Integration"},{"location":"Integration%20Template/#title-of-integration","text":"This should be a short, one paragraph description of the integration being documented.","title":"Title of Integration"},{"location":"Integration%20Template/#overview","text":"A more detailed overview should included here. This overview should describe the integration and any unique details for this integration.","title":"Overview"},{"location":"Integration%20Template/#api","text":"This section should include detailed documentation of the API.","title":"API"},{"location":"Integration%20Template/#configuration","text":"This section should include detailed documentation for configuring the integration.","title":"Configuration"},{"location":"Integration%20Template/#optional-deployment","text":"This section should include any instructions necessary to deploy this integration. This section may not be needed if the deployment follows a standard deployment process that is documented elsewhere. In this case it would be helpful to direct the reader to that standard documentation.","title":"(Optional) Deployment"},{"location":"Integration-Overview/","text":"Integration Introduction The Levridge integration framework provides integration between Dynamics 365 Finance and Dynamics 365 Customer Engagement and 3rd party applications. This document provides and overview of the integration framework and links to the documents that exist for the framework. Overview Levridge has created an integration framework to handle all the integrations between systems. This framework uses json entities to exchange information. The integration framework uses Microsoft Azure Service Bus to provide a Publish and Subscribe messaging pattern . Levridge has created an event framework in D365 Finance that will publish entity data to the service bus based on Creates, Deletes and Updates. Information/messages sent to the service bus can be subscribed to by 3rd party applications or by the Levridge integration framework and sent to 3rd party applications like AgSync. The data entities in D365 Finance and can be filtered so only certain records are sent. All integrations that use the framework follow the same pattern: A data source has an integration event The data source responds to the integration event by sending one or more entities to the service bus. The service bus publishes the message(s) to each subscription An instance of the integration framework receives the message(s) from a subscription The integration framework transforms the message if needed The integration framework sends the message to the target data source The Levridge Integration Framework is most commonly run in the cloud as an Azure App Serivce . It can also run as a windows service or as an IIS application. See this article to learn more about the deployment options. Integrations Currently we support the following integrations: D365 F&O to D365 CE D365 CE to D365 F&O Scale Agsync Kahler Surety oneWeigh Field Reveal Levridge CRM Remote Printing Service Environment Planning A standard D365 implementation is used when launching a Levridge environment plan. The D365 F&O System Requirements and what one needs to start a project are outlined in Environment Planning . Levridge Integration System Requirements Azure App Registrations One each for the Production and Test environments Azure App Registrations Azure Service Bus Namespace One each for the Production and Test environments Configure both using the Standard Pricing Tier Topics/Subscriptions will be determined based on integration within scope for the project Documentation Azure Service Bus Overview Azure Service Bus topics and subscriptions Azure App Service Plan One each for Production and Test environments Use a Standard tier for the Test environment Use a Premium V2 tier for the Production environment Additional sizing will be reviewed during the implemenation Azure App Service Plan overview Individual Azure App Services will be deployed to these App Service Plans Azure App Services Separate App Services will be deployed for each integrating application Once deployed and configured we will then deploy the Levridge Integration Framework to each Separate Levridge Integration Framework configuration will be required App Services pricing is included in the App Service Plan tier pricing (see App Service Plan overview above) Azure Storage Account Levridge Integrations utilize Azure Storage Accounts in multiple areas One each required for the Production and Test environments Use the General Purpose V2 account type Azure Storage Account overview Azure Key Vault One key vault is required. Can be used by both the Production and Test environments Azure Key Vault overview Event Framework Events - Other Applications Event Framework Overview Applications from Levridge or other Third-Party vendors may be used in conjunction with the Levridge product. The setups may be completed at System administration > Setup > Event framework > Event Framework Events. Agsync : Dispatching Software Package for shipping application equipment and trucks to deliver fertilizer and chemicals. There are 2 integrations including master data sharing from F&O to Ag Sync including customer accounts, operations and sites. Ag Sync will create work orders that connect with F&O through the sales order service for creation of work orders. Credit checking sharing is also synced between Ag Sync and F&O. Kahler : 3rd Party platform that acts as a controller for fertilizer blending. After a sales order/work order is ready for release, the service order is sent to Kahler with product and customer information that controls the blending of the product based on capacity of the trucks. Kahler then adds a packing slip to the F&O sales order/work order line with released data including delivery details. Thresholds are shared to perform invoicing of the product blending and delivery. Scale : Customers, products, vehicles, and other details in F&O are shared with the scale application. The details are used for the Scale Ticket, weights are captured and driver tickets or BOL are generated for shipping. Once printed the information is shared back to F&O and associated with sales order selected. OneWeigh: OneWeigh Documentation Bing: mapping details are shared for mileage and directions under Transportation Management Field Reveal : Data is received into CE. Recommendations and Fields are data sourced from Field Reveal and shared with CE.","title":"Overview"},{"location":"Integration-Overview/#integration-introduction","text":"The Levridge integration framework provides integration between Dynamics 365 Finance and Dynamics 365 Customer Engagement and 3rd party applications. This document provides and overview of the integration framework and links to the documents that exist for the framework.","title":"Integration Introduction"},{"location":"Integration-Overview/#overview","text":"Levridge has created an integration framework to handle all the integrations between systems. This framework uses json entities to exchange information. The integration framework uses Microsoft Azure Service Bus to provide a Publish and Subscribe messaging pattern . Levridge has created an event framework in D365 Finance that will publish entity data to the service bus based on Creates, Deletes and Updates. Information/messages sent to the service bus can be subscribed to by 3rd party applications or by the Levridge integration framework and sent to 3rd party applications like AgSync. The data entities in D365 Finance and can be filtered so only certain records are sent. All integrations that use the framework follow the same pattern: A data source has an integration event The data source responds to the integration event by sending one or more entities to the service bus. The service bus publishes the message(s) to each subscription An instance of the integration framework receives the message(s) from a subscription The integration framework transforms the message if needed The integration framework sends the message to the target data source The Levridge Integration Framework is most commonly run in the cloud as an Azure App Serivce . It can also run as a windows service or as an IIS application. See this article to learn more about the deployment options.","title":"Overview"},{"location":"Integration-Overview/#integrations","text":"Currently we support the following integrations: D365 F&O to D365 CE D365 CE to D365 F&O Scale Agsync Kahler Surety oneWeigh Field Reveal Levridge CRM Remote Printing Service","title":"Integrations"},{"location":"Integration-Overview/#environment-planning","text":"A standard D365 implementation is used when launching a Levridge environment plan. The D365 F&O System Requirements and what one needs to start a project are outlined in Environment Planning .","title":"Environment Planning"},{"location":"Integration-Overview/#levridge-integration-system-requirements","text":"Azure App Registrations One each for the Production and Test environments Azure App Registrations Azure Service Bus Namespace One each for the Production and Test environments Configure both using the Standard Pricing Tier Topics/Subscriptions will be determined based on integration within scope for the project Documentation Azure Service Bus Overview Azure Service Bus topics and subscriptions Azure App Service Plan One each for Production and Test environments Use a Standard tier for the Test environment Use a Premium V2 tier for the Production environment Additional sizing will be reviewed during the implemenation Azure App Service Plan overview Individual Azure App Services will be deployed to these App Service Plans Azure App Services Separate App Services will be deployed for each integrating application Once deployed and configured we will then deploy the Levridge Integration Framework to each Separate Levridge Integration Framework configuration will be required App Services pricing is included in the App Service Plan tier pricing (see App Service Plan overview above) Azure Storage Account Levridge Integrations utilize Azure Storage Accounts in multiple areas One each required for the Production and Test environments Use the General Purpose V2 account type Azure Storage Account overview Azure Key Vault One key vault is required. Can be used by both the Production and Test environments Azure Key Vault overview","title":"Levridge Integration System Requirements"},{"location":"Integration-Overview/#event-framework-events-other-applications","text":"Event Framework Overview Applications from Levridge or other Third-Party vendors may be used in conjunction with the Levridge product. The setups may be completed at System administration > Setup > Event framework > Event Framework Events. Agsync : Dispatching Software Package for shipping application equipment and trucks to deliver fertilizer and chemicals. There are 2 integrations including master data sharing from F&O to Ag Sync including customer accounts, operations and sites. Ag Sync will create work orders that connect with F&O through the sales order service for creation of work orders. Credit checking sharing is also synced between Ag Sync and F&O. Kahler : 3rd Party platform that acts as a controller for fertilizer blending. After a sales order/work order is ready for release, the service order is sent to Kahler with product and customer information that controls the blending of the product based on capacity of the trucks. Kahler then adds a packing slip to the F&O sales order/work order line with released data including delivery details. Thresholds are shared to perform invoicing of the product blending and delivery. Scale : Customers, products, vehicles, and other details in F&O are shared with the scale application. The details are used for the Scale Ticket, weights are captured and driver tickets or BOL are generated for shipping. Once printed the information is shared back to F&O and associated with sales order selected. OneWeigh: OneWeigh Documentation Bing: mapping details are shared for mileage and directions under Transportation Management Field Reveal : Data is received into CE. Recommendations and Fields are data sourced from Field Reveal and shared with CE.","title":"Event Framework Events - Other Applications"},{"location":"Kahler/","text":"Kahler Integration The Kahler integration is a bidirectional integration that consists of a Topic for Dispensing Work Orders that go from D365 F&O to Kahler and Dispensing Work Records that go from Kahler to D365 F&O with the goal of margin control and recognizing revenue across site locations. Overview Because this is a bidirectional integration there are two instances of the integration running to handle the entire integration. There is one integration instance for each direction. One aspect of Kahler that is different from other integrations is the D365 F&O to Kahler instance must run on premise because the Kahler system runs behind the firewall. This should be deployed as a service. Another aspect that is different is that each location should only get the messages from the topic that apply to that location. This is done with a filter on the service bus topic subscription. In order for the filter to work the Levridge Entity Event must be configured to expose the branch property on the message. Required Resources Security permissions to access sales orders, transfer orders, and transportation maangement system in D365 F&O Security permissions and access to Kahler's system Setup To integrate to and from Kahler and D365 F&O you will need to: Create an Azure Service bus topic for Dispensing Work Orders (D365 F&O to Kahler) Create an Azure Service bus topic for Dispensing Work Records (Kahler to D365 F&O) Create a subscription on the Dispensing Work Order topic for each Branch that has a Kahler mixer Create a filter on the subscription for each Branch Create a subscription on the Dispensing Work Record topic for integration back to F&O Configure Event Endpoint in F&O Configure Levridge Entity Events You will need to be sure to provide properties on the event to allow filtering by Branch Create an application ID for the integration framework to authenticate to D365 F&O Create an Azure Active Directory Application in D365 F&O Set up Azure Key Vault / Overview Deploy the Levridge Integration Framework as a service at each Branch that has a Kahler mixer Configuration for Kahler on Premise This configuration will need to be on premise with the Kahler mixer. The on-premise instance will handle the Dispensing Work Order from D365 F&O to Kahler and the Webhook that receives Dispensing Work Records from Kahler. The configuration of D365 F&O is required to release to Kahler. Within the release product itself, default warehouses must be defined to ensure that under Manage Inventory default warehouses are set up with a dispensing method to be able to ship to a Kahler. The dispensing method is a 1:1 ration (1 warehouse 1 dispensing method). This configuration produces a URL that is an identifier for each Kahler. Each Kahler instance has its own URL and that URL must be attached to the product to ensure it is sent to the correct web hub. In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with Dispensing Work Order service bus topic]\", \"ODataConfigName\": \"[section name with F&O data configuration]\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with Kahler data configuration]\", \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"Kahler\", \"Direction\": \"Target\" } Here is a sample template for the entire appsettings.json file used for the on-premise deployment of the integration from FinOps to Kahler: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"KahlerConroller\": \"Levridge.Integration.Host.KahlerController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"ApplicationInsights\": { \"InstrumentationKey\": \"08f05bc5-e901-4c19-8358-286bdcedf35e\" }, \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Order\", //[section name with Dispensing Work Order service bus topic] \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"Kahler End Point\", //[section name with Kahler data configuration], \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"Kahler\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Kahler End Point\": { \"UriString\": \"[URL to Local Kahler]\" }, \"Dispensing Work Order\": { \"ConnectionString\": \"[connection string to Dispensing Work Order Topic]\", \"TopicName\": \"[Dispensing Work Order Topic Name]\", \"SubscriptionName\": \"[Subscription Name for the Branch]\", \"RequiresSession\": true }, \"CDS\": { \"UriString\": \"[URL to CDS or Localhost]\", \"ActiveDirectoryResource\": \"[URL to CDS]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to CDS]/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"Levridge.Integration.Host.KahlerController\": { \"ConnectionString\": \"[connection string to Dispensing Work Record Topic]\", \"TopicName\": \"[Dispensing Work Record Topic Name]\", \"RequiresSession\": true } } Controllers This section contains a list of controllers that will be loaded by the current instance. In addition to the default controller that we always want to load, we want the system to load the Kahler controller. The names (on the left) are not significant and are used only for debugging. The values (on the right) are significant. It must be the name of the assembly that should be loaded for the controller. InstanceConfig InstanceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework. SourceConfig The source config will represent the data being send from D365 F&O. Currently, the Dispensing Work Order is the only entity sent from F&O. In the future the topic may also include master data that is sent to Kahler. The ODataConfigName is not currently being used but is a required value. So point it to the section that contains the connection information to D365 F&O. TargetConfig The target config will represent the data endpoint for the local Kahler mixer. The \"ODataConfigName\" should point to a section that contains the Kahler REST endpoint. Levridge.Integration.Host.KahlerController This section is used by the Kahler controller to be able to send messages to the proper topic to be handled by the integration framework and written to D365 F&O. Configuration for Kahler in Azure This instance can be a single instance running in the cloud. This instance will handle the Dispensing Work Record from Kahler to D365 F&O. In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with Dispensing Work Record service bus topic]\" \"ODataConfigName\": \"\", \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with F&O data configuration]\", \"CDSConfigName\": \"[section name with CDS configuration]\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" } Here is a template of the full appsettings.json file used for the Kahler integration from the Webhook to FinOps: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\" }, \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Record\", //[section name with Dispensing Work Record service bus topic] \"ODataConfigName\": \"\", \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"CDSConfigName\": \"CDS\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Dispensing Work Record\": { \"ConnectionString\": \"[connection string to Dispensing Work Record Topic]\", \"TopicName\": \"[Dispensing Work Record Topic Name]\", \"SubscriptionName\": \"[Subscription Name for Integration to D365 F&O]\", \"RequiresSession\": true } } Dispensing Method Configuration Release Products Grid Highlight line Manage Inventory Warehouse Tab Warehouse Items Dispensing Method field Select the warehouse that should be tied to the dispensing method Select the appropriate configure dispensing method Add Kahler specific URL If the URL is not setup properly for each product, the product could be sent to an incorrect Kahler location. This step is critical to ensure the setup and configurations are accurate. Sales Order Statuses Planned (generated sales order) Booked Released (order is sent to dispatcher work board) Scheduled (generates dispensing work record and assigns application site) Completed Once the order is in a scheduled status, it will generate a dispnsing work record which kicks off the integration to send the product to Kahler. Once Kahler completes the dispatching of product and the onsite work is completed, the work order status is updated to either completed, pending, or review. Data is populated in the work order completion tab in F&O. Work Order Completion Rolling stock ID (task completion equipment) Weather information Humidity Temperature Wind speed Wind direction Pests Acreage completed Start and end times Acmount of actual product applied Once the work is completed by the dispatcher, the work order status updated to the final completion stage (complete/verify). Picking List Within each order, there is a possibility of multiple picking lists. Picking lists annotate the amount of batches/truck loads left Kahler and the mix in each truck. Picking lists allow one to know how many loads are being used. There are two bill options: Bill what Kahler said was used Bill for what the machine stated was used Transportation Management System (TMS) has the ability to generate a freight bill after Kahler sends the picking lists to ensure the third party contractor delivering the product is paid. The steps below outline the process: Data from Kahler creates a picking list Load creation in TMS Generate freight bill invoiceable to the third party contractor Packing Order A packing slip is generated for the work order in an invoiceable status. Packing orders can take place either in the complete, pending, review status or in the complete, verify status. Generate Order Manually The below outlines the steps required to generate a manual order. Create a sales order. The information collected in the sales order includes: Who the grower is The inventory location the product is being picked up at Generate product to be shipped to Kahler Individual products Custom configuration BOM Select configuration BOM Product and supply Configure line Configure selected item (product type and amount) Click OK (BOM is generated) Select blending site Save Explode BOM back out Warehouse items tab Release for dispensing Generates dispensing ID Order is sent to Kahler Manually pack, slip, and post Manual Transfer Order Transfer orders allow product to be moved from one site to another. The below outlines the process: Inventory management Transfer order Populate \"From\" and \"To\" warehouses Add line Select product and amont of product to be transferred Save Ship Release for dispensing Transfer order is sent to Kahler to act on physical shipping of the product.","title":"Kahler"},{"location":"Kahler/#kahler-integration","text":"The Kahler integration is a bidirectional integration that consists of a Topic for Dispensing Work Orders that go from D365 F&O to Kahler and Dispensing Work Records that go from Kahler to D365 F&O with the goal of margin control and recognizing revenue across site locations.","title":"Kahler Integration"},{"location":"Kahler/#overview","text":"Because this is a bidirectional integration there are two instances of the integration running to handle the entire integration. There is one integration instance for each direction. One aspect of Kahler that is different from other integrations is the D365 F&O to Kahler instance must run on premise because the Kahler system runs behind the firewall. This should be deployed as a service. Another aspect that is different is that each location should only get the messages from the topic that apply to that location. This is done with a filter on the service bus topic subscription. In order for the filter to work the Levridge Entity Event must be configured to expose the branch property on the message.","title":"Overview"},{"location":"Kahler/#required-resources","text":"Security permissions to access sales orders, transfer orders, and transportation maangement system in D365 F&O Security permissions and access to Kahler's system","title":"Required Resources"},{"location":"Kahler/#setup","text":"To integrate to and from Kahler and D365 F&O you will need to: Create an Azure Service bus topic for Dispensing Work Orders (D365 F&O to Kahler) Create an Azure Service bus topic for Dispensing Work Records (Kahler to D365 F&O) Create a subscription on the Dispensing Work Order topic for each Branch that has a Kahler mixer Create a filter on the subscription for each Branch Create a subscription on the Dispensing Work Record topic for integration back to F&O Configure Event Endpoint in F&O Configure Levridge Entity Events You will need to be sure to provide properties on the event to allow filtering by Branch Create an application ID for the integration framework to authenticate to D365 F&O Create an Azure Active Directory Application in D365 F&O Set up Azure Key Vault / Overview Deploy the Levridge Integration Framework as a service at each Branch that has a Kahler mixer","title":"Setup"},{"location":"Kahler/#configuration-for-kahler-on-premise","text":"This configuration will need to be on premise with the Kahler mixer. The on-premise instance will handle the Dispensing Work Order from D365 F&O to Kahler and the Webhook that receives Dispensing Work Records from Kahler. The configuration of D365 F&O is required to release to Kahler. Within the release product itself, default warehouses must be defined to ensure that under Manage Inventory default warehouses are set up with a dispensing method to be able to ship to a Kahler. The dispensing method is a 1:1 ration (1 warehouse 1 dispensing method). This configuration produces a URL that is an identifier for each Kahler. Each Kahler instance has its own URL and that URL must be attached to the product to ensure it is sent to the correct web hub. In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with Dispensing Work Order service bus topic]\", \"ODataConfigName\": \"[section name with F&O data configuration]\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with Kahler data configuration]\", \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"Kahler\", \"Direction\": \"Target\" } Here is a sample template for the entire appsettings.json file used for the on-premise deployment of the integration from FinOps to Kahler: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"KahlerConroller\": \"Levridge.Integration.Host.KahlerController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"ApplicationInsights\": { \"InstrumentationKey\": \"08f05bc5-e901-4c19-8358-286bdcedf35e\" }, \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Order\", //[section name with Dispensing Work Order service bus topic] \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"Kahler End Point\", //[section name with Kahler data configuration], \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"Kahler\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Kahler End Point\": { \"UriString\": \"[URL to Local Kahler]\" }, \"Dispensing Work Order\": { \"ConnectionString\": \"[connection string to Dispensing Work Order Topic]\", \"TopicName\": \"[Dispensing Work Order Topic Name]\", \"SubscriptionName\": \"[Subscription Name for the Branch]\", \"RequiresSession\": true }, \"CDS\": { \"UriString\": \"[URL to CDS or Localhost]\", \"ActiveDirectoryResource\": \"[URL to CDS]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to CDS]/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"Levridge.Integration.Host.KahlerController\": { \"ConnectionString\": \"[connection string to Dispensing Work Record Topic]\", \"TopicName\": \"[Dispensing Work Record Topic Name]\", \"RequiresSession\": true } }","title":"Configuration for Kahler on Premise"},{"location":"Kahler/#controllers","text":"This section contains a list of controllers that will be loaded by the current instance. In addition to the default controller that we always want to load, we want the system to load the Kahler controller. The names (on the left) are not significant and are used only for debugging. The values (on the right) are significant. It must be the name of the assembly that should be loaded for the controller.","title":"Controllers"},{"location":"Kahler/#instanceconfig","text":"InstanceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework.","title":"InstanceConfig"},{"location":"Kahler/#sourceconfig","text":"The source config will represent the data being send from D365 F&O. Currently, the Dispensing Work Order is the only entity sent from F&O. In the future the topic may also include master data that is sent to Kahler. The ODataConfigName is not currently being used but is a required value. So point it to the section that contains the connection information to D365 F&O.","title":"SourceConfig"},{"location":"Kahler/#targetconfig","text":"The target config will represent the data endpoint for the local Kahler mixer. The \"ODataConfigName\" should point to a section that contains the Kahler REST endpoint.","title":"TargetConfig"},{"location":"Kahler/#levridgeintegrationhostkahlercontroller","text":"This section is used by the Kahler controller to be able to send messages to the proper topic to be handled by the integration framework and written to D365 F&O.","title":"Levridge.Integration.Host.KahlerController"},{"location":"Kahler/#configuration-for-kahler-in-azure","text":"This instance can be a single instance running in the cloud. This instance will handle the Dispensing Work Record from Kahler to D365 F&O. In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with Dispensing Work Record service bus topic]\" \"ODataConfigName\": \"\", \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with F&O data configuration]\", \"CDSConfigName\": \"[section name with CDS configuration]\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" } Here is a template of the full appsettings.json file used for the Kahler integration from the Webhook to FinOps: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\" }, \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Record\", //[section name with Dispensing Work Record service bus topic] \"ODataConfigName\": \"\", \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"CDSConfigName\": \"CDS\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Dispensing Work Record\": { \"ConnectionString\": \"[connection string to Dispensing Work Record Topic]\", \"TopicName\": \"[Dispensing Work Record Topic Name]\", \"SubscriptionName\": \"[Subscription Name for Integration to D365 F&O]\", \"RequiresSession\": true } }","title":"Configuration for Kahler in Azure"},{"location":"Kahler/#dispensing-method-configuration","text":"Release Products Grid Highlight line Manage Inventory Warehouse Tab Warehouse Items Dispensing Method field Select the warehouse that should be tied to the dispensing method Select the appropriate configure dispensing method Add Kahler specific URL If the URL is not setup properly for each product, the product could be sent to an incorrect Kahler location. This step is critical to ensure the setup and configurations are accurate.","title":"Dispensing Method Configuration"},{"location":"Kahler/#sales-order-statuses","text":"Planned (generated sales order) Booked Released (order is sent to dispatcher work board) Scheduled (generates dispensing work record and assigns application site) Completed Once the order is in a scheduled status, it will generate a dispnsing work record which kicks off the integration to send the product to Kahler. Once Kahler completes the dispatching of product and the onsite work is completed, the work order status is updated to either completed, pending, or review. Data is populated in the work order completion tab in F&O.","title":"Sales Order Statuses"},{"location":"Kahler/#work-order-completion","text":"Rolling stock ID (task completion equipment) Weather information Humidity Temperature Wind speed Wind direction Pests Acreage completed Start and end times Acmount of actual product applied Once the work is completed by the dispatcher, the work order status updated to the final completion stage (complete/verify).","title":"Work Order Completion"},{"location":"Kahler/#picking-list","text":"Within each order, there is a possibility of multiple picking lists. Picking lists annotate the amount of batches/truck loads left Kahler and the mix in each truck. Picking lists allow one to know how many loads are being used. There are two bill options: Bill what Kahler said was used Bill for what the machine stated was used Transportation Management System (TMS) has the ability to generate a freight bill after Kahler sends the picking lists to ensure the third party contractor delivering the product is paid. The steps below outline the process: Data from Kahler creates a picking list Load creation in TMS Generate freight bill invoiceable to the third party contractor","title":"Picking List"},{"location":"Kahler/#packing-order","text":"A packing slip is generated for the work order in an invoiceable status. Packing orders can take place either in the complete, pending, review status or in the complete, verify status.","title":"Packing Order"},{"location":"Kahler/#generate-order-manually","text":"The below outlines the steps required to generate a manual order. Create a sales order. The information collected in the sales order includes: Who the grower is The inventory location the product is being picked up at Generate product to be shipped to Kahler Individual products Custom configuration BOM Select configuration BOM Product and supply Configure line Configure selected item (product type and amount) Click OK (BOM is generated) Select blending site Save Explode BOM back out Warehouse items tab Release for dispensing Generates dispensing ID Order is sent to Kahler Manually pack, slip, and post","title":"Generate Order Manually"},{"location":"Kahler/#manual-transfer-order","text":"Transfer orders allow product to be moved from one site to another. The below outlines the process: Inventory management Transfer order Populate \"From\" and \"To\" warehouses Add line Select product and amont of product to be transferred Save Ship Release for dispensing Transfer order is sent to Kahler to act on physical shipping of the product.","title":"Manual Transfer Order"},{"location":"KeyVault/","text":"Azure Key Vault This should be a short, one paragraph description of the integration being documented. Overview A more detailed overview should included here. This overview should describe the integration and any unique details for this integration. API This section should include detailed documentation of the API. Configuration This section should include detailed documentation for configuring the integration. (Optional) Deployment This section should include any instructions necessary to deploy this integration. This section may not be needed if the deployment follows a standard deployment process that is documented elsewhere. In this case it would be helpful to direct the reader to that standard documentation.","title":"Azure Key Vault"},{"location":"KeyVault/#azure-key-vault","text":"This should be a short, one paragraph description of the integration being documented.","title":"Azure Key Vault"},{"location":"KeyVault/#overview","text":"A more detailed overview should included here. This overview should describe the integration and any unique details for this integration.","title":"Overview"},{"location":"KeyVault/#api","text":"This section should include detailed documentation of the API.","title":"API"},{"location":"KeyVault/#configuration","text":"This section should include detailed documentation for configuring the integration.","title":"Configuration"},{"location":"KeyVault/#optional-deployment","text":"This section should include any instructions necessary to deploy this integration. This section may not be needed if the deployment follows a standard deployment process that is documented elsewhere. In this case it would be helpful to direct the reader to that standard documentation.","title":"(Optional) Deployment"},{"location":"Levridge-CRM-Remote-Printing-Service/","text":"","title":"Levridge CRM Remote Printing Service"},{"location":"Licensing_Certifications/","text":"Licensing and Certifications Overview In agronomy, various licenses are required to handle regulated and/or restricted products because those products can be dangerous to humans or the environment. Countries, states and counties can all have different licensing requirements. Levridge Agronomy is able to track and maintain these licensing requirements. Certificate Types In Finance and Operations under Accounts receivable > Setup > License and certification setup certificate types with a description and mark the option for required renewal of that certificate where appropriate. For example, a pesticide may require an applicator license. Certificate types may be setup on products or on contact records. Certificates Compliance In Finance and Operations under Accounts receivable > Setup > License and certification > Certificates compliance establish the settings for each certificate type in a given country and state. These parameters tell the system how to react when the certificate type is utilized on a sales order or a proposal in a given country and state. There are options to enable warnings for the sales order entry or sales packing slip/invoicing processes. Optionally, the user can choose to go beyond a warning and choose to prevent postings for packing slip/invoices or agronomy work order dispatches. If the sales order or proposal is entered in CRM, the contact for compliance is required before the order or proposal can be sent for approval. Regulated Products Regional Lists To identify which products are regulated and require certifications, add the items to regulated product regional lists. In Finance and Operations go to Inventory management > Setup > Product compliance > Regulated products regional lists. In the Country/region field, select the country for the list that you want to update. Select the Reported check box. Click the Reported regulated products button. Click Add, and select the item number. Repeat this step for each item that you want to add. Establishing Licenses for Employees, Customers and Contacts Once certificate types and regulated products have been setup, employees, customer and contacts with the required certificates/licenses can be identified. For employees, in Finance and Operations go to Human resources > Workers > Employees. On a given employee under the Worker action pane at the top of the page, under Competencies click > Certificates. In the form that opens, enter the certificate type the employee has, a certification number, start and end date and the country, state and/or county the certificate is utilized in. To repeat this process for customers (the customer must be a person and not an organization) with certificates, go to Accounts receivable > All customers > select a customer and under the Customer action pane at the top of the page, under Set up > click Certificates and enter the same information. For contacts of customers with certificates, on the customer choose Contacts > View contacts. Select the contact and under the Competencies action pane at the top of the page > click Certificates and again enter the same information. After the certificate types, products, certificate compliance parameters and certificates are setup, when a sales order, proposal or work order are entered and a regulated product is selected for a line item the system uses what has been set up. The system retrieves the delivery address on the document to find the country, state and county for the document and compares them to certificates the customer, employee or contact on the document have. If a non-expired license is not found, a warning or error are thrown based on what has been setup in the certificates compliance form. Seed and Technology Agreements Compliance Seed manufacturers or suppliers own the patents to certain kinds of seed and those patents earns them royalties. To utilize or sell the seed, vendors and customers must have agreements with the seed companies. To identify a vendor with the agreement, in Finance and Operations under Product information management > select a released product which requires an agreement to sell and view the details of that product. Under the Purchase fast tab, in the Vendor field select a vendor for this product that has the required agreement and agreement title with the seed manufacturer. To setup a customer with an agreement go to Accounts receivable > All customers > select a customer and under Seed and technology agreements fast tab, enter the appropriate information regarding the agreement the customer has. Lastly, to establish how the system should react when a product requiring an agreement is utilized on a proposal, work order or sales order in Finance and Operations go to Accounts receivable > Setup > License and certification > Seed and technology agreements compliance. In this form, identify in a given country and state if warnings or error should be thrown when products requiring agreements are utilized and the vendor or customer does not have an agreement.","title":"Licensing and Certifications"},{"location":"Licensing_Certifications/#licensing-and-certifications","text":"","title":"Licensing and Certifications"},{"location":"Licensing_Certifications/#overview","text":"In agronomy, various licenses are required to handle regulated and/or restricted products because those products can be dangerous to humans or the environment. Countries, states and counties can all have different licensing requirements. Levridge Agronomy is able to track and maintain these licensing requirements.","title":"Overview"},{"location":"Licensing_Certifications/#certificate-types","text":"In Finance and Operations under Accounts receivable > Setup > License and certification setup certificate types with a description and mark the option for required renewal of that certificate where appropriate. For example, a pesticide may require an applicator license. Certificate types may be setup on products or on contact records.","title":"Certificate Types"},{"location":"Licensing_Certifications/#certificates-compliance","text":"In Finance and Operations under Accounts receivable > Setup > License and certification > Certificates compliance establish the settings for each certificate type in a given country and state. These parameters tell the system how to react when the certificate type is utilized on a sales order or a proposal in a given country and state. There are options to enable warnings for the sales order entry or sales packing slip/invoicing processes. Optionally, the user can choose to go beyond a warning and choose to prevent postings for packing slip/invoices or agronomy work order dispatches. If the sales order or proposal is entered in CRM, the contact for compliance is required before the order or proposal can be sent for approval.","title":"Certificates Compliance"},{"location":"Licensing_Certifications/#regulated-products-regional-lists","text":"To identify which products are regulated and require certifications, add the items to regulated product regional lists. In Finance and Operations go to Inventory management > Setup > Product compliance > Regulated products regional lists. In the Country/region field, select the country for the list that you want to update. Select the Reported check box. Click the Reported regulated products button. Click Add, and select the item number. Repeat this step for each item that you want to add.","title":"Regulated Products Regional Lists"},{"location":"Licensing_Certifications/#establishing-licenses-for-employees-customers-and-contacts","text":"Once certificate types and regulated products have been setup, employees, customer and contacts with the required certificates/licenses can be identified. For employees, in Finance and Operations go to Human resources > Workers > Employees. On a given employee under the Worker action pane at the top of the page, under Competencies click > Certificates. In the form that opens, enter the certificate type the employee has, a certification number, start and end date and the country, state and/or county the certificate is utilized in. To repeat this process for customers (the customer must be a person and not an organization) with certificates, go to Accounts receivable > All customers > select a customer and under the Customer action pane at the top of the page, under Set up > click Certificates and enter the same information. For contacts of customers with certificates, on the customer choose Contacts > View contacts. Select the contact and under the Competencies action pane at the top of the page > click Certificates and again enter the same information. After the certificate types, products, certificate compliance parameters and certificates are setup, when a sales order, proposal or work order are entered and a regulated product is selected for a line item the system uses what has been set up. The system retrieves the delivery address on the document to find the country, state and county for the document and compares them to certificates the customer, employee or contact on the document have. If a non-expired license is not found, a warning or error are thrown based on what has been setup in the certificates compliance form.","title":"Establishing Licenses for Employees, Customers and Contacts"},{"location":"Licensing_Certifications/#seed-and-technology-agreements-compliance","text":"Seed manufacturers or suppliers own the patents to certain kinds of seed and those patents earns them royalties. To utilize or sell the seed, vendors and customers must have agreements with the seed companies. To identify a vendor with the agreement, in Finance and Operations under Product information management > select a released product which requires an agreement to sell and view the details of that product. Under the Purchase fast tab, in the Vendor field select a vendor for this product that has the required agreement and agreement title with the seed manufacturer. To setup a customer with an agreement go to Accounts receivable > All customers > select a customer and under Seed and technology agreements fast tab, enter the appropriate information regarding the agreement the customer has. Lastly, to establish how the system should react when a product requiring an agreement is utilized on a proposal, work order or sales order in Finance and Operations go to Accounts receivable > Setup > License and certification > Seed and technology agreements compliance. In this form, identify in a given country and state if warnings or error should be thrown when products requiring agreements are utilized and the vendor or customer does not have an agreement.","title":"Seed and Technology Agreements Compliance"},{"location":"Logging/","text":"Logging Settings This document describes how to configure logging for the Levridge Integration Framework Overview The Levridge Integration Framework utilizes the standard ASP.NET Core logging capabilities. Our primary target for logging is Azure Application Insights however we can also log to the Windows Event Log. This can be usefull if the integration framework is running as a windows service and does not have highspeed internet access to send log data to Application Insights. Log Settings In the appsettings.json file there is a \"Logging\" section that defines the log settings for the various logging providers. A typical logging section may look like this. \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Debug\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Trace\" } }, \"LogLevel\": { \"Default\": \"Warning\" } }, Unless you are using Debug or Console logging the only setting you need to be concerned with is the ApplicationInsights object. In a typical production environment you will want this set to \"Information\" or \"Warning\" rather than trace. However, to troubleshoot issues you may need to set this to \"Trace\". Valid Log Levels Here are the valid log level settings: Setting Description Trace Logs that contain the most detailed messages. These messages may contain sensitive application data. These messages are disabled by default and should never be enabled in a production environment. Debug Logs that are used for interactive investigation during development. These logs should primarily contain information useful for debugging and have no long-term value. Information Logs that track the general flow of the application. These logs should have long-term value. Warning Logs that highlight an abnormal or unexpected event in the application flow, but do not otherwise cause the application execution to stop. Error Logs that highlight when the current flow of execution is stopped due to a failure. These should indicate a failure in the current activity, not an application-wide failure. Critical Logs that describe an unrecoverable application or system crash, or a catastrophic failure that requires immediate attention. None Not used for writing log messages. Specifies that a logging category should not write any messages. Levridge Guidance for using Log Levels In order to provide a consistent user experience when using the configuration to adjust the log levels we need to have a consistent practice accross all of our code for what information is logged at what level. Generally speaking we would like to have logging set to Information in production unless there is a need to troubleshoot a specific issue. At this level we should be able to see all errors and warnings along with usefull information for basic troubleshooting. Here is what Levridge is logging at the different levels: Trace Log variable states, parameters & request and response payloads as Trace items. Use trace to log verbose information and large payloads. These items may can cause performance issues during normal operation. Debug Log any information that inidates the basic flow of the code. Examples include something like \"Entering POST method\" or \"Enabling authentication.\" This is general information that helps someone follow the flow of the code and can be useful in determining what is happening when an error occures. Information Log specific state information. For example \"Recieved Order 1234\" or \"Enabling AzureAd authentication scheme.\" These messages provide specific instance and state information. For example, in the trace section we showed an example \"Enabling authenticaction\". The represents the current code that is executing but not any instance or state information. On the other hand, logging \"Enabling AzureAd authentication scheme\" tells us which type of authenticaion is being enabled. Warning Log abnormal situations that do not warrent stopping the application and do not leave the application in an unkown state. Error Log error conditions from which we can recover. Critical Log all exceptions as critical. Include as much state information as possible to help with troubleshooting the root cause of the exception. Application Insights Instrumentation Key Application Insights uses an Intrumentation Key to specify the Application Insights resource to use for logging. If the integration framework is deployed to Azure and Application Insights is enabled, the Instrumentation Key will be specified in the environment variables. However, if the Integration is deployed on premise an Instrumentation Key must be specified for the Application Insights logging provider to send the log data to the correct Application Insights resource. \"ApplicationInsights\": { \"InstrumentationKey\": \"[Application Insights Instrumentation Key]\" }, This section is at the top level and not in the Logging section. Here is an example of a partial appsettings.json file. \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"ApplicationInsights\": { \"InstrumentationKey\": \"1a2b3c4d-5e6f-4b24-9308-4dff05f1cd02\" },","title":"Logging Settings"},{"location":"Logging/#logging-settings","text":"This document describes how to configure logging for the Levridge Integration Framework","title":"Logging Settings"},{"location":"Logging/#overview","text":"The Levridge Integration Framework utilizes the standard ASP.NET Core logging capabilities. Our primary target for logging is Azure Application Insights however we can also log to the Windows Event Log. This can be usefull if the integration framework is running as a windows service and does not have highspeed internet access to send log data to Application Insights.","title":"Overview"},{"location":"Logging/#log-settings","text":"In the appsettings.json file there is a \"Logging\" section that defines the log settings for the various logging providers. A typical logging section may look like this. \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Debug\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Trace\" } }, \"LogLevel\": { \"Default\": \"Warning\" } }, Unless you are using Debug or Console logging the only setting you need to be concerned with is the ApplicationInsights object. In a typical production environment you will want this set to \"Information\" or \"Warning\" rather than trace. However, to troubleshoot issues you may need to set this to \"Trace\".","title":"Log Settings"},{"location":"Logging/#valid-log-levels","text":"Here are the valid log level settings: Setting Description Trace Logs that contain the most detailed messages. These messages may contain sensitive application data. These messages are disabled by default and should never be enabled in a production environment. Debug Logs that are used for interactive investigation during development. These logs should primarily contain information useful for debugging and have no long-term value. Information Logs that track the general flow of the application. These logs should have long-term value. Warning Logs that highlight an abnormal or unexpected event in the application flow, but do not otherwise cause the application execution to stop. Error Logs that highlight when the current flow of execution is stopped due to a failure. These should indicate a failure in the current activity, not an application-wide failure. Critical Logs that describe an unrecoverable application or system crash, or a catastrophic failure that requires immediate attention. None Not used for writing log messages. Specifies that a logging category should not write any messages.","title":"Valid Log Levels"},{"location":"Logging/#levridge-guidance-for-using-log-levels","text":"In order to provide a consistent user experience when using the configuration to adjust the log levels we need to have a consistent practice accross all of our code for what information is logged at what level. Generally speaking we would like to have logging set to Information in production unless there is a need to troubleshoot a specific issue. At this level we should be able to see all errors and warnings along with usefull information for basic troubleshooting. Here is what Levridge is logging at the different levels:","title":"Levridge Guidance for using Log Levels"},{"location":"Logging/#trace","text":"Log variable states, parameters & request and response payloads as Trace items. Use trace to log verbose information and large payloads. These items may can cause performance issues during normal operation.","title":"Trace"},{"location":"Logging/#debug","text":"Log any information that inidates the basic flow of the code. Examples include something like \"Entering POST method\" or \"Enabling authentication.\" This is general information that helps someone follow the flow of the code and can be useful in determining what is happening when an error occures.","title":"Debug"},{"location":"Logging/#information","text":"Log specific state information. For example \"Recieved Order 1234\" or \"Enabling AzureAd authentication scheme.\" These messages provide specific instance and state information. For example, in the trace section we showed an example \"Enabling authenticaction\". The represents the current code that is executing but not any instance or state information. On the other hand, logging \"Enabling AzureAd authentication scheme\" tells us which type of authenticaion is being enabled.","title":"Information"},{"location":"Logging/#warning","text":"Log abnormal situations that do not warrent stopping the application and do not leave the application in an unkown state.","title":"Warning"},{"location":"Logging/#error","text":"Log error conditions from which we can recover.","title":"Error"},{"location":"Logging/#critical","text":"Log all exceptions as critical. Include as much state information as possible to help with troubleshooting the root cause of the exception.","title":"Critical"},{"location":"Logging/#application-insights-instrumentation-key","text":"Application Insights uses an Intrumentation Key to specify the Application Insights resource to use for logging. If the integration framework is deployed to Azure and Application Insights is enabled, the Instrumentation Key will be specified in the environment variables. However, if the Integration is deployed on premise an Instrumentation Key must be specified for the Application Insights logging provider to send the log data to the correct Application Insights resource. \"ApplicationInsights\": { \"InstrumentationKey\": \"[Application Insights Instrumentation Key]\" }, This section is at the top level and not in the Logging section. Here is an example of a partial appsettings.json file. \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"ApplicationInsights\": { \"InstrumentationKey\": \"1a2b3c4d-5e6f-4b24-9308-4dff05f1cd02\" },","title":"Application Insights Instrumentation Key"},{"location":"ManagingSplits_SalesContracts_Prepayments/","text":"Managing Splits, Sales Contracts, and Prepayments Overview Within Levridge, when a sales order or invoice is created, the system automatically selects the sales contract according to the items and categories identified. It also selects a prepayment against it, eliminating the need to manually go in and figure out the process, creating fewer invoicing issues sent to growers. Target Audience: This functionality applies to individuals in Ag Retailers who manage splits, contracts, and prepayments on behalf of customers. Sales Orders Levridge syncs sales orders between CE and F&O. As sales orders are entered in CE and generated, the sales order is then created in F&O. The sales order in CE becomes read only once generated. As sales orders are entered in F&O, it will be shared with CE. Sales order header When a sales order is created, the ordering customer is selected along with a customer operation and optionally a customer site. The customer site if selected, will be used to default the split group, else the split group will default from the customer operation. Note that the split group may be updated within sales order entry as needed. The operation information will default to the sales order lines. A branch, line of business, growing season and sales period may also be entered as part of the sales order entry process. The sales period is required. If AR parameters use the sales period for pricing, the pricing on the sales order will be determined based on these dates. Branch and line of business may be used to filter or categorize sales orders for list pages and some reporting. Growing season entry on a sales order will help to determine volume pricing is used, else used as a filter for list pages and some reporting. Sales order line During sales order line entry, the operation will default, but may be updated by the user. Levridge displays only the list pricing during sales order entry as specific customer pricing is determined at time of delivery applying the sales agreements. On each line, the split group intended method for pricing may be entered. For example, a counter sale where the seed bag is damaged, could reference a flat price. Another example, during sales order entry, a specific sales agreement for pricing could be requested. Validation of license and certification may require a contact for certain products before it can be sent for approval. The contact information is entered in the header area. Supplementary items on the sales order line On a released item, a product may contain required or optional supplementary items. Levridge has added functionality to automatically address the use of required supplementary items including: A new field linking the supplementary item to the master item is created. Automatically adding the supplementary line to an order with the appropriate quantity based on the associated item. If the associated item is deleted or the quantity is changed, the supplementary item is also deleted, or the quantity is automatically changed on the existing supplementary line. The supplementary item\u2019s splits and taxes will also be recalculated. Added a supplementary item flag of \u2018Multiple Percentage\u2019 to calculate a percentage of the multiple as needed. New fields for the supplementary item that recognize if a minimum quantity is required and the value of the minimum quantity. Packing Slip Post When the sales order posts a packing slip in F&O, the pricing will be applied to each customer participating in the split group on each line. The system will initially look for intended method for pricing on the participating customer in the split group. The system then looks at valid sales agreements to apply the sales agreement pricing and any associated prepayments. If there are multiple sales agreements, the oldest will be used first. If there is a quantity remaining that is not covered by a sales agreement, any uncontracted prepayments will be applied. The uncontracted price date may be used to determine pricing. For any remaining quantities the pricing will based on the price date of the sales order. Price dates are determined by the AR Parameter to determine what date should be used to determine pricing. The split allocation line is defined from procedures above. If the sales order line includes a Bill of Materials (BOM) item, it will validate the \u2018Expand on Sales Order Allocation\u2019 parameter on the item. If the parameter is set to yes, each of the components of the BOM will be broken out on the split allocation line for pricing. If this parament is set to no, the pricing will be based on the BOM item. For example, as fertilizer is blended, there may be a sales agreement for component products supplied by the customer. Modifications to pricing may be made upon review for billing. All Sales Order Split Group Allocations This view has been created in AR>Order to review all the allocation lines from all sales orders. Delivered Not Billed AR>orders>shipped not invoiced split group allocations Standard FinOps allows delivery of products that will be ready for invoicing. The invoicing can be today or future billed. This is standard. There are new list pages that displays deliveries that need to be billed that are broken down per customer (based on splits) by allocation line. The item must be invoiced, so all parties will be billed. Unable to partially bill a product to one customer in a split. Product Functionality Create Split Groups in F&O The split group setup is located under Create Split Group in F&O . Sales Agreement Entry In Accounts Receivable > Orders > Sales agreements > Create a new Sales agreement under the \u201cSales Agreement\u201d tab by clicking the New button. On the new sales agreement, select the customer the agreement is for and the item(s) or a sales category(s) the agreement is for. The sales agreement can include any number of items or sales categories for that particular contract. Prepayment Entry In Accounts Receivable > Payments > Customer payment journal > Click the New button to create a new prepayment then click the \u201cEnter customer prepayments\u201d button. Enter the customer the prepayment is for. Enter in the amount of the prepayment. If the prepayment is being used on a sales agreement, the Sales agreement will show up in the \u201cSales agreement\u201d table. Mark the sales agreement the prepayment should be applied against. If there is no sales agreement/contract, you can still take a prepayment and enter it as an Uncontracted amount to ensure the funds are accounted for. A prepayment can have some portion of it applied against an agreement and some set aside as Uncontracted. Once the amounts and agreements have been selected, click \u201cSave in Journal\u201d, annotating the prepayment has been accepted. Click \u201cPost\u201d to process and post the prepayment. Sales Order Entry In Accounts Receivable > Orders > All sales orders > Click the New button to create a new sales order. Enter the customer Once selected, the customer\u2019s account information will auto-populate Choose any split group for that customer on your sales order The field will default to a split group that is 100% but you can select whichever one you would like Choose specific period Enter the items for the sales order and their quantities. Additional order lines can be created. Click Save. Click the Post packing slip button to indicate the product has been sent out to the customer. Once delivered, one is now able to view the sales order with a sales agreement and prepayment allocated towards it according to the items that match between the sales order and the sales agreement and/or prepayment.","title":"Managing Splits, Sales Contracts, and Prepayments"},{"location":"ManagingSplits_SalesContracts_Prepayments/#managing-splits-sales-contracts-and-prepayments","text":"","title":"Managing Splits, Sales Contracts, and Prepayments"},{"location":"ManagingSplits_SalesContracts_Prepayments/#overview","text":"Within Levridge, when a sales order or invoice is created, the system automatically selects the sales contract according to the items and categories identified. It also selects a prepayment against it, eliminating the need to manually go in and figure out the process, creating fewer invoicing issues sent to growers. Target Audience: This functionality applies to individuals in Ag Retailers who manage splits, contracts, and prepayments on behalf of customers.","title":"Overview"},{"location":"ManagingSplits_SalesContracts_Prepayments/#sales-orders","text":"Levridge syncs sales orders between CE and F&O. As sales orders are entered in CE and generated, the sales order is then created in F&O. The sales order in CE becomes read only once generated. As sales orders are entered in F&O, it will be shared with CE.","title":"Sales Orders"},{"location":"ManagingSplits_SalesContracts_Prepayments/#sales-order-header","text":"When a sales order is created, the ordering customer is selected along with a customer operation and optionally a customer site. The customer site if selected, will be used to default the split group, else the split group will default from the customer operation. Note that the split group may be updated within sales order entry as needed. The operation information will default to the sales order lines. A branch, line of business, growing season and sales period may also be entered as part of the sales order entry process. The sales period is required. If AR parameters use the sales period for pricing, the pricing on the sales order will be determined based on these dates. Branch and line of business may be used to filter or categorize sales orders for list pages and some reporting. Growing season entry on a sales order will help to determine volume pricing is used, else used as a filter for list pages and some reporting.","title":"Sales order header"},{"location":"ManagingSplits_SalesContracts_Prepayments/#sales-order-line","text":"During sales order line entry, the operation will default, but may be updated by the user. Levridge displays only the list pricing during sales order entry as specific customer pricing is determined at time of delivery applying the sales agreements. On each line, the split group intended method for pricing may be entered. For example, a counter sale where the seed bag is damaged, could reference a flat price. Another example, during sales order entry, a specific sales agreement for pricing could be requested. Validation of license and certification may require a contact for certain products before it can be sent for approval. The contact information is entered in the header area.","title":"Sales order line"},{"location":"ManagingSplits_SalesContracts_Prepayments/#supplementary-items-on-the-sales-order-line","text":"On a released item, a product may contain required or optional supplementary items. Levridge has added functionality to automatically address the use of required supplementary items including: A new field linking the supplementary item to the master item is created. Automatically adding the supplementary line to an order with the appropriate quantity based on the associated item. If the associated item is deleted or the quantity is changed, the supplementary item is also deleted, or the quantity is automatically changed on the existing supplementary line. The supplementary item\u2019s splits and taxes will also be recalculated. Added a supplementary item flag of \u2018Multiple Percentage\u2019 to calculate a percentage of the multiple as needed. New fields for the supplementary item that recognize if a minimum quantity is required and the value of the minimum quantity.","title":"Supplementary items on the sales order line"},{"location":"ManagingSplits_SalesContracts_Prepayments/#packing-slip-post","text":"When the sales order posts a packing slip in F&O, the pricing will be applied to each customer participating in the split group on each line. The system will initially look for intended method for pricing on the participating customer in the split group. The system then looks at valid sales agreements to apply the sales agreement pricing and any associated prepayments. If there are multiple sales agreements, the oldest will be used first. If there is a quantity remaining that is not covered by a sales agreement, any uncontracted prepayments will be applied. The uncontracted price date may be used to determine pricing. For any remaining quantities the pricing will based on the price date of the sales order. Price dates are determined by the AR Parameter to determine what date should be used to determine pricing. The split allocation line is defined from procedures above. If the sales order line includes a Bill of Materials (BOM) item, it will validate the \u2018Expand on Sales Order Allocation\u2019 parameter on the item. If the parameter is set to yes, each of the components of the BOM will be broken out on the split allocation line for pricing. If this parament is set to no, the pricing will be based on the BOM item. For example, as fertilizer is blended, there may be a sales agreement for component products supplied by the customer. Modifications to pricing may be made upon review for billing.","title":"Packing Slip Post"},{"location":"ManagingSplits_SalesContracts_Prepayments/#all-sales-order-split-group-allocations","text":"This view has been created in AR>Order to review all the allocation lines from all sales orders.","title":"All Sales Order Split Group Allocations"},{"location":"ManagingSplits_SalesContracts_Prepayments/#delivered-not-billed","text":"AR>orders>shipped not invoiced split group allocations Standard FinOps allows delivery of products that will be ready for invoicing. The invoicing can be today or future billed. This is standard. There are new list pages that displays deliveries that need to be billed that are broken down per customer (based on splits) by allocation line. The item must be invoiced, so all parties will be billed. Unable to partially bill a product to one customer in a split.","title":"Delivered Not Billed"},{"location":"ManagingSplits_SalesContracts_Prepayments/#product-functionality","text":"","title":"Product Functionality"},{"location":"ManagingSplits_SalesContracts_Prepayments/#create-split-groups-in-fo","text":"The split group setup is located under Create Split Group in F&O .","title":"Create Split Groups in F&amp;O"},{"location":"ManagingSplits_SalesContracts_Prepayments/#sales-agreement-entry","text":"In Accounts Receivable > Orders > Sales agreements > Create a new Sales agreement under the \u201cSales Agreement\u201d tab by clicking the New button. On the new sales agreement, select the customer the agreement is for and the item(s) or a sales category(s) the agreement is for. The sales agreement can include any number of items or sales categories for that particular contract.","title":"Sales Agreement Entry"},{"location":"ManagingSplits_SalesContracts_Prepayments/#prepayment-entry","text":"In Accounts Receivable > Payments > Customer payment journal > Click the New button to create a new prepayment then click the \u201cEnter customer prepayments\u201d button. Enter the customer the prepayment is for. Enter in the amount of the prepayment. If the prepayment is being used on a sales agreement, the Sales agreement will show up in the \u201cSales agreement\u201d table. Mark the sales agreement the prepayment should be applied against. If there is no sales agreement/contract, you can still take a prepayment and enter it as an Uncontracted amount to ensure the funds are accounted for. A prepayment can have some portion of it applied against an agreement and some set aside as Uncontracted. Once the amounts and agreements have been selected, click \u201cSave in Journal\u201d, annotating the prepayment has been accepted. Click \u201cPost\u201d to process and post the prepayment.","title":"Prepayment Entry"},{"location":"ManagingSplits_SalesContracts_Prepayments/#sales-order-entry","text":"In Accounts Receivable > Orders > All sales orders > Click the New button to create a new sales order. Enter the customer Once selected, the customer\u2019s account information will auto-populate Choose any split group for that customer on your sales order The field will default to a split group that is 100% but you can select whichever one you would like Choose specific period Enter the items for the sales order and their quantities. Additional order lines can be created. Click Save. Click the Post packing slip button to indicate the product has been sent out to the customer. Once delivered, one is now able to view the sales order with a sales agreement and prepayment allocated towards it according to the items that match between the sales order and the sales agreement and/or prepayment.","title":"Sales Order Entry"},{"location":"Managing_Fertilizer_Contracts_For_Ag_Retailers/","text":"Managing Fertilizer Contracts for Ag Retailers When fertilizer is contracted, a large quantity of product is being shipped and needs to be managed by the ag retailer, which is a big undertaking. Currently, most ag retailers are using an Access database to manage hundreds or thousands of lines of information without any ability to easily integrate that data to their financial system or pull reports of outstanding accounts or inventory levels. With Levridge, the purchase, inventory, and distribution of fertilizers is all managed within one system, giving real-time information and data to users across different departments. Levridge allows users to access and record information on contracts, terminals, quantities, descriptions, and release numbers all on one screen. This information then integrates directly to the back office for invoicing, tracking, and inventory management. Because Levridge is built on Dynamics 365, a Microsoft platform, it also integrates with Excel and allows user to export and import data on spreadsheets as well. This effectively eliminates all need for manual re-entry between systems or solutions. Once a contract for fertilizer has been confirmed, the ag retailer can track and manage all loads within that contract which includes the load location, distribution site, shipping carrier, and delivery terms. The purchase agreements remain in the system until the load is ready to be released. At that time, the individual line item then generates a purchase order which lists the details of the load and fulfills the order within the system.","title":"Managing Fertilizer Contracts For Ag Retailers"},{"location":"Managing_Fertilizer_Contracts_For_Ag_Retailers/#managing-fertilizer-contracts-for-ag-retailers","text":"When fertilizer is contracted, a large quantity of product is being shipped and needs to be managed by the ag retailer, which is a big undertaking. Currently, most ag retailers are using an Access database to manage hundreds or thousands of lines of information without any ability to easily integrate that data to their financial system or pull reports of outstanding accounts or inventory levels. With Levridge, the purchase, inventory, and distribution of fertilizers is all managed within one system, giving real-time information and data to users across different departments. Levridge allows users to access and record information on contracts, terminals, quantities, descriptions, and release numbers all on one screen. This information then integrates directly to the back office for invoicing, tracking, and inventory management. Because Levridge is built on Dynamics 365, a Microsoft platform, it also integrates with Excel and allows user to export and import data on spreadsheets as well. This effectively eliminates all need for manual re-entry between systems or solutions. Once a contract for fertilizer has been confirmed, the ag retailer can track and manage all loads within that contract which includes the load location, distribution site, shipping carrier, and delivery terms. The purchase agreements remain in the system until the load is ready to be released. At that time, the individual line item then generates a purchase order which lists the details of the load and fulfills the order within the system.","title":"Managing Fertilizer Contracts for Ag Retailers"},{"location":"ODataConfig/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"ODataConfig/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"ODataConfig/#overview","text":"","title":"Overview"},{"location":"ODataConfig/#main-point-1","text":"","title":"Main Point 1"},{"location":"ODataConfig/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"PreparingCDSForDeployment/","text":"Introduction The Levridge Integration Framework uses the CDS repository to store reference data. We need to provide deployment packages that include solutions, applications and data that can be used to deploy the CDS components to the customer. This document explains the steps necessary to package CDS for deployment to a customer environment. Overview The steps necessary to prepare the CDS components for deployment are: 1. Create the Solution 2. Create the application packages 3. Create the export schemas 4. Export the data 5. Check assets into source control Create Solution Create Application Packages Create Export Schemas Export Data Check-In Assets","title":"Introduction"},{"location":"PreparingCDSForDeployment/#introduction","text":"The Levridge Integration Framework uses the CDS repository to store reference data. We need to provide deployment packages that include solutions, applications and data that can be used to deploy the CDS components to the customer. This document explains the steps necessary to package CDS for deployment to a customer environment.","title":"Introduction"},{"location":"PreparingCDSForDeployment/#overview","text":"The steps necessary to prepare the CDS components for deployment are: 1. Create the Solution 2. Create the application packages 3. Create the export schemas 4. Export the data 5. Check assets into source control","title":"Overview"},{"location":"PreparingCDSForDeployment/#create-solution","text":"","title":"Create Solution"},{"location":"PreparingCDSForDeployment/#create-application-packages","text":"","title":"Create Application Packages"},{"location":"PreparingCDSForDeployment/#create-export-schemas","text":"","title":"Create Export Schemas"},{"location":"PreparingCDSForDeployment/#export-data","text":"","title":"Export Data"},{"location":"PreparingCDSForDeployment/#check-in-assets","text":"","title":"Check-In Assets"},{"location":"Prepayments/","text":"Prepayments Prepayments may be tracked against a sales agreement instead of an invoice. Levridge may hold the approval of a sales agreement until an appropriate prepayment has been met. For example, a user may accept a prepayment such as $10,000 toward fertilizer. This allows you to lock in the pricing as of the day of the prepayment. The prepayment resides in the AR account as an unapplied value. There are list pages that allow you to see the sales agreements that require a prepayment. The remaining balance of the prepayment will be displayed along with contact information for collection. Prepayments may be collected and entered as uncontracted (not specific to a sales agreement) or specified for a specific item or item category (such as chemical). Price date may be captured as of the uncontracted prepayment date to be used to capture pricing when the payment is applied to the transaction. During the ordering process, the system will automatically find the sales agreements and prepayments and apply to the order. Billing needs to review the information provided, making for a faster more efficient invoice processing. Please see below example of the Prepayment summary within the Payments view in AR: Remaining balances may be viewed in the Prepayment Lines menu choice in AR:","title":"Prepayments"},{"location":"Prepayments/#prepayments","text":"Prepayments may be tracked against a sales agreement instead of an invoice. Levridge may hold the approval of a sales agreement until an appropriate prepayment has been met. For example, a user may accept a prepayment such as $10,000 toward fertilizer. This allows you to lock in the pricing as of the day of the prepayment. The prepayment resides in the AR account as an unapplied value. There are list pages that allow you to see the sales agreements that require a prepayment. The remaining balance of the prepayment will be displayed along with contact information for collection. Prepayments may be collected and entered as uncontracted (not specific to a sales agreement) or specified for a specific item or item category (such as chemical). Price date may be captured as of the uncontracted prepayment date to be used to capture pricing when the payment is applied to the transaction. During the ordering process, the system will automatically find the sales agreements and prepayments and apply to the order. Billing needs to review the information provided, making for a faster more efficient invoice processing. Please see below example of the Prepayment summary within the Payments view in AR: Remaining balances may be viewed in the Prepayment Lines menu choice in AR:","title":"Prepayments"},{"location":"Pricing_Discounts/","text":"Pricing and Discounts The sales trade agreements have been expanded to include method and terms of payment, zone pricing (seed), and volume pricing. Method and Terms of Payment The method and terms of payment modification allows for different pricing to be used on sales orders. The sales trade agreement has the option to select this type of pricing. For example, a standard price of $10 may be updated to $8 when method of payment is cash. First three \u2013 can setup specific pricing. For example, John Deere Financial could provide special pricing in certain areas. Special pricing may also be based on the terms of payment. Zone Pricing Levridge now allows zone pricing based off the home address of a customer, not just the site location. This will permit pricing specific to the county of the home address of the customer for both selling to a customer and purchasing products such as seed. Zone pricing will allow for more precise pricing on sales orders and purchase orders and should make year-end reconciliation with the manufacturers more efficient. Customer Zone Sales Pricing enhancement includes: A new \u2018Vendor Zones\u2019 table is available to define the zones The \u2018zone\u2019 field is also added to all trade agreement journals \u2018Zone Pricing Address\u2019 is added to the customer setup > sales order defaults Sales forms will validate items with zone pricing, match to the customer zone and display the appropriate price. Site Zone Purchase Pricing enhancement includes: A new \u2018Site Zones\u2019 table is available under Procurement & Sourcing>Setup>Price Discounts>Site Zones Sites will use zone pricing for purchases from vendors with zones Zones are added to the trade agreement journals Zones are identified by manufacturer Purchase price trade agreements may be setup including item, zone and price. When the code is ran on a purchase order it will search for the sites address and match the county and state to the correct zone in the zone pricing table. The code will then search the purchase price trade agreement journal for the item and zone and put the price on the purchase order, purchase agreement, RFQ, and purchase requisition. The purchase price trade agreement journal will display the appropriate pricing on forms. Volume Pricing The sales trade agreements provide options for volume pricing where ranges are designated for different levels of pricing. For example, a quantity of 1-20 has certain pricing, 21-50 another price. Volume pricing takes one step farther. Volume pricing looks at the quantities on order and quantities within a date range, then through the pricing service, will assign the appropriate price. Credit Limits Receivables>Setup> AR Parameters Standard FinOps customer setup permits a credit limit type of None, Balance, Balance + packing slip or product receipt, or Balance + all. Levridge allows you to define what you want to include in the calculation for available credit. Currently FinOps looks at outstanding sales orders and accounts receivable amount due. Levridge allows this to be expanded to include sales agreements with either hard stops or warnings. This is an overall setting for the company. There are transactions that originate in CRM that are supported by an existing AX process. To provide a consistent user experience, the configuration selection for transactions that should be included in credit limit calculation should reflect these relationships. For example, if CRM Agronomy Contract is set to \u201cYes\u201d to include, then Sales agreements should be automatically set to \u201cYes\u201d to include. The Customer Balance List with credit limit report has also been modified to reflect a Balance that includes the balance due PLUS any pending transactions considered in calculating available credit.","title":"Pricing and Discounts"},{"location":"Pricing_Discounts/#pricing-and-discounts","text":"The sales trade agreements have been expanded to include method and terms of payment, zone pricing (seed), and volume pricing.","title":"Pricing and Discounts"},{"location":"Pricing_Discounts/#method-and-terms-of-payment","text":"The method and terms of payment modification allows for different pricing to be used on sales orders. The sales trade agreement has the option to select this type of pricing. For example, a standard price of $10 may be updated to $8 when method of payment is cash. First three \u2013 can setup specific pricing. For example, John Deere Financial could provide special pricing in certain areas. Special pricing may also be based on the terms of payment.","title":"Method and Terms of Payment"},{"location":"Pricing_Discounts/#zone-pricing","text":"Levridge now allows zone pricing based off the home address of a customer, not just the site location. This will permit pricing specific to the county of the home address of the customer for both selling to a customer and purchasing products such as seed. Zone pricing will allow for more precise pricing on sales orders and purchase orders and should make year-end reconciliation with the manufacturers more efficient.","title":"Zone Pricing"},{"location":"Pricing_Discounts/#customer-zone-sales-pricing-enhancement-includes","text":"A new \u2018Vendor Zones\u2019 table is available to define the zones The \u2018zone\u2019 field is also added to all trade agreement journals \u2018Zone Pricing Address\u2019 is added to the customer setup > sales order defaults Sales forms will validate items with zone pricing, match to the customer zone and display the appropriate price.","title":"Customer Zone Sales Pricing enhancement includes:"},{"location":"Pricing_Discounts/#site-zone-purchase-pricing-enhancement-includes","text":"A new \u2018Site Zones\u2019 table is available under Procurement & Sourcing>Setup>Price Discounts>Site Zones Sites will use zone pricing for purchases from vendors with zones Zones are added to the trade agreement journals Zones are identified by manufacturer Purchase price trade agreements may be setup including item, zone and price. When the code is ran on a purchase order it will search for the sites address and match the county and state to the correct zone in the zone pricing table. The code will then search the purchase price trade agreement journal for the item and zone and put the price on the purchase order, purchase agreement, RFQ, and purchase requisition. The purchase price trade agreement journal will display the appropriate pricing on forms.","title":"Site Zone Purchase Pricing enhancement includes:"},{"location":"Pricing_Discounts/#volume-pricing","text":"The sales trade agreements provide options for volume pricing where ranges are designated for different levels of pricing. For example, a quantity of 1-20 has certain pricing, 21-50 another price. Volume pricing takes one step farther. Volume pricing looks at the quantities on order and quantities within a date range, then through the pricing service, will assign the appropriate price.","title":"Volume Pricing"},{"location":"Pricing_Discounts/#credit-limits","text":"Receivables>Setup> AR Parameters Standard FinOps customer setup permits a credit limit type of None, Balance, Balance + packing slip or product receipt, or Balance + all. Levridge allows you to define what you want to include in the calculation for available credit. Currently FinOps looks at outstanding sales orders and accounts receivable amount due. Levridge allows this to be expanded to include sales agreements with either hard stops or warnings. This is an overall setting for the company. There are transactions that originate in CRM that are supported by an existing AX process. To provide a consistent user experience, the configuration selection for transactions that should be included in credit limit calculation should reflect these relationships. For example, if CRM Agronomy Contract is set to \u201cYes\u201d to include, then Sales agreements should be automatically set to \u201cYes\u201d to include. The Customer Balance List with credit limit report has also been modified to reflect a Balance that includes the balance due PLUS any pending transactions considered in calculating available credit.","title":"Credit Limits"},{"location":"Pricing_Service_Setup/","text":"Pricing Service Setup The configuration for the pricing service setup is as follows: { \"clientappid\": \"[Client AppID from AD]\", \"clientappsecret\": \"[secret from AD]\", \"tenant\": \"https://login.microsoftonline.com/5555a5b1-fbt8-465b-ad9d-21e21129e610/oauth2/token\", \"uristring\": \"https://[environment subdomain].cloudax.dynamics.com/api/services/LevPricingServices/PricingService/getPricing\", \"resource\": \"https://[environment subdomain].cloudax.dynamics.com\", \"username\": \"John.smith@email.com\", \"password\": \"plaintextpassword\" }","title":"Pricing Service Setup"},{"location":"Pricing_Service_Setup/#pricing-service-setup","text":"The configuration for the pricing service setup is as follows: { \"clientappid\": \"[Client AppID from AD]\", \"clientappsecret\": \"[secret from AD]\", \"tenant\": \"https://login.microsoftonline.com/5555a5b1-fbt8-465b-ad9d-21e21129e610/oauth2/token\", \"uristring\": \"https://[environment subdomain].cloudax.dynamics.com/api/services/LevPricingServices/PricingService/getPricing\", \"resource\": \"https://[environment subdomain].cloudax.dynamics.com\", \"username\": \"John.smith@email.com\", \"password\": \"plaintextpassword\" }","title":"Pricing Service Setup"},{"location":"PublishCatalog/","text":"Publish Catalog Brief introduction of the module, component or feature being documented. This document explains ... How to Publish a Catalog Go to Procurement and Sourcing > Catalogs > Procurement Catalogs. In the list, find and select the desired record. Click Publish Catalog.","title":"Publish Catalog"},{"location":"PublishCatalog/#publish-catalog","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Publish Catalog"},{"location":"PublishCatalog/#how-to-publish-a-catalog","text":"Go to Procurement and Sourcing > Catalogs > Procurement Catalogs. In the list, find and select the desired record. Click Publish Catalog.","title":"How to Publish a Catalog"},{"location":"Purchase_Agreements/","text":"Purchase Agreements Agriculture retailers will contract with vendors to purchase a quantity of inventory over a specific period. When the contract is approved the vendor will send a list of all the releases that will be delivered over the contracted time. For example, the purchase of a large quantity of fertilizer from Koch will need to be managed in releases to track all delivery and payment data. To simplify the management of these contracts and released purchase orders we will need to have the following functionality. Store release order information in a table that is on a purchase agreement. This information is displayed in a new screen \u2018Purchase Agreement Release\u2019. Each purchase agreement will store all the load numbers given to the ag retailer from the supplier for the duration of the agreement. Managing release loads becomes more efficient with access to a list of outstanding commitments. A user may highlight a line or load number from the below table and create a purchase order and direct delivery sales order.See vendor reference on top screen that represents the vendor load number. Review all purchase orders and all sales orders related to the purchase agreement Assign an estimated freight value for Fertilizer Daily Position Report (DPR) The above Purchase Agreement Release view may be filtered for use by a logistics expert. They may see lines that don\u2019t have delivery address or carrier assignments. This allows them to: Assign pickup address and delivery address Assign carriers Release and auto confirm a PO from a purchase agreement release line Upon release of the PO a TMS load number is created. A carrier is also assigned on the line for auto invoicing. After PO receiving, a user will review the loads, verify the data and post the receiving load. New functionality has been added to the process to: Link a prepayment to the purchase agreement that will be surfaced on subsequent released purchased orders. Levridge has enhanced TMS functionality to link a sales order to a release purchase order that will direct ship to the customer.","title":"Purchase Agreements"},{"location":"Purchase_Agreements/#purchase-agreements","text":"Agriculture retailers will contract with vendors to purchase a quantity of inventory over a specific period. When the contract is approved the vendor will send a list of all the releases that will be delivered over the contracted time. For example, the purchase of a large quantity of fertilizer from Koch will need to be managed in releases to track all delivery and payment data. To simplify the management of these contracts and released purchase orders we will need to have the following functionality. Store release order information in a table that is on a purchase agreement. This information is displayed in a new screen \u2018Purchase Agreement Release\u2019. Each purchase agreement will store all the load numbers given to the ag retailer from the supplier for the duration of the agreement. Managing release loads becomes more efficient with access to a list of outstanding commitments. A user may highlight a line or load number from the below table and create a purchase order and direct delivery sales order.See vendor reference on top screen that represents the vendor load number. Review all purchase orders and all sales orders related to the purchase agreement Assign an estimated freight value for Fertilizer Daily Position Report (DPR) The above Purchase Agreement Release view may be filtered for use by a logistics expert. They may see lines that don\u2019t have delivery address or carrier assignments. This allows them to: Assign pickup address and delivery address Assign carriers Release and auto confirm a PO from a purchase agreement release line Upon release of the PO a TMS load number is created. A carrier is also assigned on the line for auto invoicing. After PO receiving, a user will review the loads, verify the data and post the receiving load. New functionality has been added to the process to: Link a prepayment to the purchase agreement that will be surfaced on subsequent released purchased orders. Levridge has enhanced TMS functionality to link a sales order to a release purchase order that will direct ship to the customer.","title":"Purchase Agreements"},{"location":"PurchasingPolicyAssignment/","text":"Purchasing Policy Assignment Brief introduction of the module, component or feature being documented. This document explains ... How to Purchase Policy Assignments Close the page. Go to Procuremnet and Sourcing > Setup > Policies > Purchasing Policies. In the list, click the link in the selected row. In the list, click the link in the selected row. Click Cancel. In the list, find and select the desired record. In the list, click the link in the selected row. In the tree, select 'Landus\\Monsanto'. Click Add. Click OK. Click Save. Close the page.","title":"Purchasing Policy Assignment"},{"location":"PurchasingPolicyAssignment/#purchasing-policy-assignment","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Purchasing Policy Assignment"},{"location":"PurchasingPolicyAssignment/#how-to-purchase-policy-assignments","text":"Close the page. Go to Procuremnet and Sourcing > Setup > Policies > Purchasing Policies. In the list, click the link in the selected row. In the list, click the link in the selected row. Click Cancel. In the list, find and select the desired record. In the list, click the link in the selected row. In the tree, select 'Landus\\Monsanto'. Click Add. Click OK. Click Save. Close the page.","title":"How to Purchase Policy Assignments"},{"location":"RFQ/","text":"RFQ Brief introduction of the module, component or feature being documented. This document explains ... RFQ Go to Procurement and sourcing > Requests for quotations > All requests for quotations. Click New. In the Solicitation type field, enter or select a value. In the list, click the link in the selected row. In the Requesting department field, type a value. In the warehouse field, type a value. Click OK. In the list, mark the selected row. In the Item number field, type a value. In the Quantity field, enter a number. In the Lines or header field, select an option. In the list, mark the selected row. In the Vendor account field, enter or select a value. In the list, click the link in the selected row. Click Add. In the list, mark the selected row. In the Vendor account field, enter or select a value. Close the page. In the Vendor account field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Click Save. Click Send. In the list, mark the selected row. Click OK. Close the page. Close the page. Close the page. Close the page. Click Manage replies. Click Edit. Click Edit RFQ reply. In the list, mark the selected row. In the Unit price field, enter a number. Expand the Line details section. Click Submit. In the list, find and select the desired record. Click Edit. Click Edit RFQ reply. In the list, mark the selected row. In the Unit price field, enter a number. Click Submit. Close the page. Refresh the page. Click Compare replies. In the Show field, select an option. Select the mark check box. Click Accept. In the list, mark the selected row. Click OK. In the list, mark the selected row. Click OK. Close the page. Close the page. Refresh the page. Close the page. Close the page. Go to Procurement and sourving > Purchase orders > All purchase orders. In the list, find and select the desired record. In the list, click the link in the selected row.","title":"RFQ"},{"location":"RFQ/#rfq","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"RFQ"},{"location":"RFQ/#rfq_1","text":"Go to Procurement and sourcing > Requests for quotations > All requests for quotations. Click New. In the Solicitation type field, enter or select a value. In the list, click the link in the selected row. In the Requesting department field, type a value. In the warehouse field, type a value. Click OK. In the list, mark the selected row. In the Item number field, type a value. In the Quantity field, enter a number. In the Lines or header field, select an option. In the list, mark the selected row. In the Vendor account field, enter or select a value. In the list, click the link in the selected row. Click Add. In the list, mark the selected row. In the Vendor account field, enter or select a value. Close the page. In the Vendor account field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Click Save. Click Send. In the list, mark the selected row. Click OK. Close the page. Close the page. Close the page. Close the page. Click Manage replies. Click Edit. Click Edit RFQ reply. In the list, mark the selected row. In the Unit price field, enter a number. Expand the Line details section. Click Submit. In the list, find and select the desired record. Click Edit. Click Edit RFQ reply. In the list, mark the selected row. In the Unit price field, enter a number. Click Submit. Close the page. Refresh the page. Click Compare replies. In the Show field, select an option. Select the mark check box. Click Accept. In the list, mark the selected row. Click OK. In the list, mark the selected row. Click OK. Close the page. Close the page. Refresh the page. Close the page. Close the page. Go to Procurement and sourving > Purchase orders > All purchase orders. In the list, find and select the desired record. In the list, click the link in the selected row.","title":"RFQ"},{"location":"ReadMe%20%282%29/","text":"Introduction The Levridge integration framework provides integration between Dynamics365 Finance and Operations and Dynamics 365 Customer Engagement and 3rd party applications. This document provides and overview of the integration framework and links to the document that exists for the framework. Overview The Levridge Integration Framework is an entity syncronization framework. It provides a means to synchronize data at an entity level between multiple data sources. All integrations that use the framework follow the same pattern: 1. A data source has an integration event 2. The data source responds to the integration event by sending one or more entities to the service bus. 3. The service bus publishes the message(s) to each subscription 4. An instance of the integration framework receives the message(s) from a subscription 5. The integration framework transforms the message it if needed 6. The integration framework sends the message to the target data source Integrations Currently we support the following integrations: - D365 F&O to D365 CRM - D365 CRM to D365 F&O - Kahler - Agsync - oneWeigh - Field Reveal - Surety - Levridge Scale House D365 F&O to D365 CRM Setup To integrate from D365 F&O to D365 CRM you will need to: - configure Levridge Entity Events - Create an application ID for the integration framework to authenticate to D365 CRM - Create an application user in D365 CRM and assign the proper role(s) - Create an Azure Service bus topic - Create a subscription on the topic above Configuration In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with F&O data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" } D365 CRM to D365 F&O Setup To integrate from D365 CRM to D365 F&O you will need to: - Configure Azure Service Bus Endpoint in CRM - Configure Azure Service Bus plugin on the appropriate entities - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic - Create a subscription on the topic above Configuration In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with CRM data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with F&O data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" } Kahler The Kahler integration is a bidirectional integration that consists of a Topic for Dispensing Work Orders that go from D365 F&O to Kahler and Dispensing Work Records that go from Kahler to D365 F&O. This means there are two instances of the integration running to handle the entire integration. One aspect of Kahler that is different from other integrations is the D365 F&O to Kahler instance must run on premise because the Kahler system runs behind the firewall. This should be deployed as a service. Another aspect that is different is that each location should only get the messages from the topic that apply to that location. This is done with a filter on the service bus topic subscription. In order for the filter to work the Levridge Entity Event must be configured to expose the branch property on the message. Setup To integrate to and from Kahler and D365 F&O you will need to: - Configure Levridge Entity Events - You will need to be sure to provide properties on the event to allow filtering by Branch - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic for Dispensing Work Orders (D365 F&O to Kahler) - Create an Azure Service bus topic for Dispensing Work Records (Kahler to D365 F&O) - Create a subscription on the Dispensing Work Order topic for each Branch that has a Kahler mixer - Create a filter on the subscription for each Branch - Create a subscription on the Dispensing Work Record topic for integration back to F&O - Deploy the Levridge Integration Framework as a service at each Branch that has a Kahler mixer Configuration for Kahler on Premise This configuration will need to be on premise with the Kahler mixer. In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"KahlerConroller\": \"Levridge.Integration.Host.KahlerController\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Order\", //[section name with Dispensing Work Order service bus topic] \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"Kahler End Point\", //[section name with Kahler data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"Kahler\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": [URL to D365 F&O], \"ActiveDirectoryResource\": [URL to D365 F&O], \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": [Application ID used to register the application in AD], \"ActiveDirectoryClientAppSecret\": [Client Secret genrated for the Application ID in AD], \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Kahler End Point\": { \"UriString\": [URL to Local Kahler] }, \"Dispensing Work Order\": { \"ConnectionString\": [connection string to Dispensing Work Order Topic], \"TopicName\": [Dispensing Work Order Topic Name], \"SubscriptionName\": [Subscription Name for the Branch], \"RequiresSession\": true }, \"Levridge.Integration.Host.KahlerController\": { \"ConnectionString\": [connection string to Dispensing Work Record Topic], \"TopicName\": [Dispensing Work Record Topic Name], \"RequiresSession\": true } Controllers This section contains a list of controllers that will be loaded by the current instance. In addition to the default controller that we alwasy want to load, we want the system to load the Kahler controller. The names (on the left) are not significant and are used only for debugging. The values (on the right) are significant. It must be the name of the assembly that should be loaded for the controller. SourceConfig The source config will represent the data being send from D365 F&O. Currently, the Dispensing Work Order is the only entity sent from F&O. In the future the topic may also include master data that is sent to Kahler. The ODataConfigName is not currently being used but is a required value. So point it to the section that contains the connection information to D365 F&O. TargetConfig The target config will represent the data endpoint for the local Kahler mixer. The \"ODataConfigName\" should point to a section that contains the Kahler REST endpoint. Levridge.Integration.Host.KahlerController This section is used by the Kahler controller to be able to send messages to the proper topic to be handled by the integration framework and written to D365 F&O Configuration for Kahler in Azure This instance can be a single instance runing in the cloud. In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Record\", //[section name with Dispensing Work Record service bus topic] \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": [URL to D365 F&O], \"ActiveDirectoryResource\": [URL to D365 F&O], \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": [Application ID used to register the application in AD], \"ActiveDirectoryClientAppSecret\": [Client Secret genrated for the Application ID in AD], \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Dispensing Work Record\": { \"ConnectionString\": [connection string to Dispensing Work Record Topic], \"TopicName\": [Dispensing Work Record Topic Name], \"SubscriptionName\": [Subscription Name for Integration to D365 F&O], \"RequiresSession\": true } Agsync oneWeigh Field Reveal Surety Levridge Scale House","title":"Introduction"},{"location":"ReadMe%20%282%29/#introduction","text":"The Levridge integration framework provides integration between Dynamics365 Finance and Operations and Dynamics 365 Customer Engagement and 3rd party applications. This document provides and overview of the integration framework and links to the document that exists for the framework.","title":"Introduction"},{"location":"ReadMe%20%282%29/#overview","text":"The Levridge Integration Framework is an entity syncronization framework. It provides a means to synchronize data at an entity level between multiple data sources. All integrations that use the framework follow the same pattern: 1. A data source has an integration event 2. The data source responds to the integration event by sending one or more entities to the service bus. 3. The service bus publishes the message(s) to each subscription 4. An instance of the integration framework receives the message(s) from a subscription 5. The integration framework transforms the message it if needed 6. The integration framework sends the message to the target data source","title":"Overview"},{"location":"ReadMe%20%282%29/#integrations","text":"Currently we support the following integrations: - D365 F&O to D365 CRM - D365 CRM to D365 F&O - Kahler - Agsync - oneWeigh - Field Reveal - Surety - Levridge Scale House","title":"Integrations"},{"location":"ReadMe%20%282%29/#d365-fo-to-d365-crm","text":"","title":"D365 F&amp;O to D365 CRM"},{"location":"ReadMe%20%282%29/#setup","text":"To integrate from D365 F&O to D365 CRM you will need to: - configure Levridge Entity Events - Create an application ID for the integration framework to authenticate to D365 CRM - Create an application user in D365 CRM and assign the proper role(s) - Create an Azure Service bus topic - Create a subscription on the topic above","title":"Setup"},{"location":"ReadMe%20%282%29/#configuration","text":"In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with F&O data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" }","title":"Configuration"},{"location":"ReadMe%20%282%29/#d365-crm-to-d365-fo","text":"","title":"D365 CRM to D365 F&amp;O"},{"location":"ReadMe%20%282%29/#setup_1","text":"To integrate from D365 CRM to D365 F&O you will need to: - Configure Azure Service Bus Endpoint in CRM - Configure Azure Service Bus plugin on the appropriate entities - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic - Create a subscription on the topic above","title":"Setup"},{"location":"ReadMe%20%282%29/#configuration_1","text":"In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with CRM data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with F&O data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }","title":"Configuration"},{"location":"ReadMe%20%282%29/#kahler","text":"The Kahler integration is a bidirectional integration that consists of a Topic for Dispensing Work Orders that go from D365 F&O to Kahler and Dispensing Work Records that go from Kahler to D365 F&O. This means there are two instances of the integration running to handle the entire integration. One aspect of Kahler that is different from other integrations is the D365 F&O to Kahler instance must run on premise because the Kahler system runs behind the firewall. This should be deployed as a service. Another aspect that is different is that each location should only get the messages from the topic that apply to that location. This is done with a filter on the service bus topic subscription. In order for the filter to work the Levridge Entity Event must be configured to expose the branch property on the message.","title":"Kahler"},{"location":"ReadMe%20%282%29/#setup_2","text":"To integrate to and from Kahler and D365 F&O you will need to: - Configure Levridge Entity Events - You will need to be sure to provide properties on the event to allow filtering by Branch - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic for Dispensing Work Orders (D365 F&O to Kahler) - Create an Azure Service bus topic for Dispensing Work Records (Kahler to D365 F&O) - Create a subscription on the Dispensing Work Order topic for each Branch that has a Kahler mixer - Create a filter on the subscription for each Branch - Create a subscription on the Dispensing Work Record topic for integration back to F&O - Deploy the Levridge Integration Framework as a service at each Branch that has a Kahler mixer","title":"Setup"},{"location":"ReadMe%20%282%29/#configuration-for-kahler-on-premise","text":"This configuration will need to be on premise with the Kahler mixer. In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"KahlerConroller\": \"Levridge.Integration.Host.KahlerController\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Order\", //[section name with Dispensing Work Order service bus topic] \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"Kahler End Point\", //[section name with Kahler data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"Kahler\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": [URL to D365 F&O], \"ActiveDirectoryResource\": [URL to D365 F&O], \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": [Application ID used to register the application in AD], \"ActiveDirectoryClientAppSecret\": [Client Secret genrated for the Application ID in AD], \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Kahler End Point\": { \"UriString\": [URL to Local Kahler] }, \"Dispensing Work Order\": { \"ConnectionString\": [connection string to Dispensing Work Order Topic], \"TopicName\": [Dispensing Work Order Topic Name], \"SubscriptionName\": [Subscription Name for the Branch], \"RequiresSession\": true }, \"Levridge.Integration.Host.KahlerController\": { \"ConnectionString\": [connection string to Dispensing Work Record Topic], \"TopicName\": [Dispensing Work Record Topic Name], \"RequiresSession\": true }","title":"Configuration for Kahler on Premise"},{"location":"ReadMe%20%282%29/#controllers","text":"This section contains a list of controllers that will be loaded by the current instance. In addition to the default controller that we alwasy want to load, we want the system to load the Kahler controller. The names (on the left) are not significant and are used only for debugging. The values (on the right) are significant. It must be the name of the assembly that should be loaded for the controller.","title":"Controllers"},{"location":"ReadMe%20%282%29/#sourceconfig","text":"The source config will represent the data being send from D365 F&O. Currently, the Dispensing Work Order is the only entity sent from F&O. In the future the topic may also include master data that is sent to Kahler. The ODataConfigName is not currently being used but is a required value. So point it to the section that contains the connection information to D365 F&O.","title":"SourceConfig"},{"location":"ReadMe%20%282%29/#targetconfig","text":"The target config will represent the data endpoint for the local Kahler mixer. The \"ODataConfigName\" should point to a section that contains the Kahler REST endpoint.","title":"TargetConfig"},{"location":"ReadMe%20%282%29/#levridgeintegrationhostkahlercontroller","text":"This section is used by the Kahler controller to be able to send messages to the proper topic to be handled by the integration framework and written to D365 F&O","title":"Levridge.Integration.Host.KahlerController"},{"location":"ReadMe%20%282%29/#configuration-for-kahler-in-azure","text":"This instance can be a single instance runing in the cloud. In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Record\", //[section name with Dispensing Work Record service bus topic] \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": [URL to D365 F&O], \"ActiveDirectoryResource\": [URL to D365 F&O], \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": [Application ID used to register the application in AD], \"ActiveDirectoryClientAppSecret\": [Client Secret genrated for the Application ID in AD], \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Dispensing Work Record\": { \"ConnectionString\": [connection string to Dispensing Work Record Topic], \"TopicName\": [Dispensing Work Record Topic Name], \"SubscriptionName\": [Subscription Name for Integration to D365 F&O], \"RequiresSession\": true }","title":"Configuration for Kahler in Azure"},{"location":"ReadMe%20%282%29/#agsync","text":"","title":"Agsync"},{"location":"ReadMe%20%282%29/#oneweigh","text":"","title":"oneWeigh"},{"location":"ReadMe%20%282%29/#field-reveal","text":"","title":"Field Reveal"},{"location":"ReadMe%20%282%29/#surety","text":"","title":"Surety"},{"location":"ReadMe%20%282%29/#levridge-scale-house","text":"","title":"Levridge Scale House"},{"location":"Recommendation-Integration/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"Recommendation-Integration/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Recommendation-Integration/#overview","text":"","title":"Overview"},{"location":"Recommendation-Integration/#main-point-1","text":"","title":"Main Point 1"},{"location":"Recommendation-Integration/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"Rolling_Stock_Management/","text":"Rolling Stock Management Overview The rolling stock module addresses the gap between the fixed assets and operational equipment management dashboarder module. Rolling stock is fixed assets on wheels such as trucks, application equipment, etc. With rolling stock you can track what the equipment is, where it is located, when it was last serviced, when the license or insurance is due, what the equipment\u2019s weight is, with or without product, and lastly, who is the equipment assigned to. The tracking will assist with the recognition of revenue and expenses, tracking for maintenance and location of the equipment assets. Fleet tracking captures information from the scale application, work order, and third-party dispatching application. Fixed Assets \u2013 geared towards managing assets that we find on a balance sheet typically managed by the accounting staff. Rolling Stock \u2013 geared towards operational management of large volumes of equipment typically managed by the operational staff. Fixed Asset to Rolling Stock Integration This integration allows an accountant to go ahead and start the setup of a fixed asset and then copy some of those elements of that setup over into a pending status piece of rolling equipment that then the operations team can pickup and add additional details and maintain those records separately from the fixed assets. Setup of a Fixed Asset Fixed assets > Fixed assets > Fixed assets Create new fixed asset (+New) Assign Fixed asset group Input number \u2013 in most environments you would have a number sequence that would automatically assign your fixed assets, but you can also manually input this number as well. Input name Input Make Input Model Input Model year Input Serial number \u2013 this is mapped to a vehicle vin number. Input Asset condition \u2013 this is mapped over. Typically, this field would be used if you bought something new or used or want to list condition. Note: The accountant or the person that manages fixed assets could input any additional information that they would like to store for that fixed asset. Rolling Stock Flag - when turned to yes this is what copies the data from the fixed asset over to the rolling stock module. Save Note: Once you have saved the fixed asset, if you scroll to the reference and notes section, the Copied to Rs list is populated with the date you created the new rolling stock item based off the date a copied from the fixed asset record. Rolling Stock Module Rolling stock > Equipment > Pending equipment Open the rolling stock record you would like to make updates to Update status Active \u2013 allows the equipment to be used transactionally and will also show this piece of equipment in a financial dimension Inactive Pending Retired Input Equipment type Capture License plate number (if appliable) Input Issuing state Input Issuing county Input License expiration date Input notes (if applicable) Input Equipment color Input Cab configuration Input door number Input Drivetrain Designate Owning branch \u2013 what location is accountable for this piece of equipment Input Vehicle tare weight Input Tare unit of measure Input Licensed weight \u2013 this weight is the basis for license fees Input Licensed weight unit of measure Input License fee Input Capacity Input unit of measure for capacity Input Mileage Input Mileage updated Designate if GPS is enabled Assign financial dimension Save Linking Fixed Asset Number to Rolling Rock Sometimes what may occur is a piece of equipment is brought in and may be leased or may be bought later, so it is not listed as a fixed asset yet. We do have the ability to take a piece of rolling stock and link it to a fixed asset number. Rolling Stock > Equipment > All equipment Select applicable equipment References and notes > Fixed asset reference > Fixed asset number Note: You can go back and link the equipment even though the fixed asset was not already created. Select fixed asset number that should be linked to equipment Note: When a fixed asset is created through the procurement process, the Vendor number and Purchase order fields would be populated in the references and notes section for that piece of equipment. Equipment Parameters We can configure our rolling stock so that disposal of the fixed asset would automate the disposal and status change of the linked rolling stock. Rolling stock > Setup > Equipment parameters General tab Designate Automatic disposal Yes No Designate Disposal status Designate Disposal reason code Note: This is an optional configuration, and the status and reason codes would be defined/created for that specific organization\u2019s need. Tracking Temporary Transfers or Equipment Loans Loaning Equipment Out Create new loan of equipment (+New) Input Rolling stock ID Input Borrowing branch \u2013 where it is being loaned to Add any applicable notes to record \u2013 i.e. expected date of return Note: You will be able to view who the record was created by and the date and time it was recorded. This record will show in the list of things that are in process Check Equipment Back In Select line of equipment that is being returned Click on Equipment returned in header Add comment to the Complete loan form Input date that equipment was returned Click OK","title":"Rolling Stock Management"},{"location":"Rolling_Stock_Management/#rolling-stock-management","text":"","title":"Rolling Stock Management"},{"location":"Rolling_Stock_Management/#overview","text":"The rolling stock module addresses the gap between the fixed assets and operational equipment management dashboarder module. Rolling stock is fixed assets on wheels such as trucks, application equipment, etc. With rolling stock you can track what the equipment is, where it is located, when it was last serviced, when the license or insurance is due, what the equipment\u2019s weight is, with or without product, and lastly, who is the equipment assigned to. The tracking will assist with the recognition of revenue and expenses, tracking for maintenance and location of the equipment assets. Fleet tracking captures information from the scale application, work order, and third-party dispatching application. Fixed Assets \u2013 geared towards managing assets that we find on a balance sheet typically managed by the accounting staff. Rolling Stock \u2013 geared towards operational management of large volumes of equipment typically managed by the operational staff.","title":"Overview"},{"location":"Rolling_Stock_Management/#fixed-asset-to-rolling-stock-integration","text":"This integration allows an accountant to go ahead and start the setup of a fixed asset and then copy some of those elements of that setup over into a pending status piece of rolling equipment that then the operations team can pickup and add additional details and maintain those records separately from the fixed assets.","title":"Fixed Asset to Rolling Stock Integration"},{"location":"Rolling_Stock_Management/#setup-of-a-fixed-asset","text":"Fixed assets > Fixed assets > Fixed assets Create new fixed asset (+New) Assign Fixed asset group Input number \u2013 in most environments you would have a number sequence that would automatically assign your fixed assets, but you can also manually input this number as well. Input name Input Make Input Model Input Model year Input Serial number \u2013 this is mapped to a vehicle vin number. Input Asset condition \u2013 this is mapped over. Typically, this field would be used if you bought something new or used or want to list condition. Note: The accountant or the person that manages fixed assets could input any additional information that they would like to store for that fixed asset. Rolling Stock Flag - when turned to yes this is what copies the data from the fixed asset over to the rolling stock module. Save Note: Once you have saved the fixed asset, if you scroll to the reference and notes section, the Copied to Rs list is populated with the date you created the new rolling stock item based off the date a copied from the fixed asset record.","title":"Setup of a Fixed Asset"},{"location":"Rolling_Stock_Management/#rolling-stock-module","text":"Rolling stock > Equipment > Pending equipment Open the rolling stock record you would like to make updates to Update status Active \u2013 allows the equipment to be used transactionally and will also show this piece of equipment in a financial dimension Inactive Pending Retired Input Equipment type Capture License plate number (if appliable) Input Issuing state Input Issuing county Input License expiration date Input notes (if applicable) Input Equipment color Input Cab configuration Input door number Input Drivetrain Designate Owning branch \u2013 what location is accountable for this piece of equipment Input Vehicle tare weight Input Tare unit of measure Input Licensed weight \u2013 this weight is the basis for license fees Input Licensed weight unit of measure Input License fee Input Capacity Input unit of measure for capacity Input Mileage Input Mileage updated Designate if GPS is enabled Assign financial dimension Save","title":"Rolling Stock Module"},{"location":"Rolling_Stock_Management/#linking-fixed-asset-number-to-rolling-rock","text":"Sometimes what may occur is a piece of equipment is brought in and may be leased or may be bought later, so it is not listed as a fixed asset yet. We do have the ability to take a piece of rolling stock and link it to a fixed asset number. Rolling Stock > Equipment > All equipment Select applicable equipment References and notes > Fixed asset reference > Fixed asset number Note: You can go back and link the equipment even though the fixed asset was not already created. Select fixed asset number that should be linked to equipment Note: When a fixed asset is created through the procurement process, the Vendor number and Purchase order fields would be populated in the references and notes section for that piece of equipment.","title":"Linking Fixed Asset Number to Rolling Rock"},{"location":"Rolling_Stock_Management/#equipment-parameters","text":"We can configure our rolling stock so that disposal of the fixed asset would automate the disposal and status change of the linked rolling stock. Rolling stock > Setup > Equipment parameters General tab Designate Automatic disposal Yes No Designate Disposal status Designate Disposal reason code Note: This is an optional configuration, and the status and reason codes would be defined/created for that specific organization\u2019s need.","title":"Equipment Parameters"},{"location":"Rolling_Stock_Management/#tracking-temporary-transfers-or-equipment-loans","text":"","title":"Tracking Temporary Transfers or Equipment Loans"},{"location":"Rolling_Stock_Management/#loaning-equipment-out","text":"Create new loan of equipment (+New) Input Rolling stock ID Input Borrowing branch \u2013 where it is being loaned to Add any applicable notes to record \u2013 i.e. expected date of return Note: You will be able to view who the record was created by and the date and time it was recorded. This record will show in the list of things that are in process","title":"Loaning Equipment Out"},{"location":"Rolling_Stock_Management/#check-equipment-back-in","text":"Select line of equipment that is being returned Click on Equipment returned in header Add comment to the Complete loan form Input date that equipment was returned Click OK","title":"Check Equipment Back In"},{"location":"Scale-Functionality/","text":"Scale Functionality Overview Levridge Scale allows you to improve efficiency and accuracy by automatically capturing weight and quality attributes during scale ticket creation when weighing trucks containing bulk products. Scale tickets and bill of ladings can easily be issued to drivers as well as synchronized real-time to Levridge Commodity accounting built in Microsoft Dynamics 365 Finance and Supply Chain Management. Scale tickets can also be exported to other ERP systems. Levridge Scale provides a modern and easy to understand interface, allowing users to create scale tickets quickly and accurately. Scale Application Configuration How to Install Levridge Scale How to Update Levridge Scale ScaleHead Hardware Setup for Rice Lake 920i and Rice Lake 1280 Scale Appsettings Configuration Scale Implementation Activities Scale Application FAQ Scale Ticket Types Different types of scale tickets can be entered into the Scale app depending upon what type of transaction needs to be recorded. The type of scale tickets that can be entered include: Inbound Grain Outbound Grain Agronomy Sales Transfer Weight Only Customer Account Select the correct Customer Account from the list. Note: Customers appearing in the list are configured by setting them up in Setup > Application Configuration > Customer Short List. See Scale Customer Short List for more details. You can also search for any customer using the Search field. Driver On If the driver is in the truck when it is being weighed the Driver On toggle should be set to Yes. If the Driver On toggle is not visible, it can be turned on by going to SETUP > Application Configuration > Settings > Is Driver On Weight The weight from the scale can be recorded by selecting the Capture button. You can also manually enter the Weigh-In and Weight-Out values. Gross Quantity The gross quantity is calculated by taking the net weight and dividing it by the Factor entered in SETUP > Application Configuration > Gross Quantity Settings. For example, when weighing Corn by the bushel, if a Factor of 56 has been entered and 53,300 has been captured as the Net Weight the Gross Quantity would be: 955.36 bushels. Trucks in Yard This contains the list of scale tickets that have been saved, but not yet complete or printed as either the truck is emptying its contents or is being filled and still needs to have its Weigh-Out amount captured on the scale ticket. Grade Factors Grade factor values used to determine quality discounts and premiums can be manually entered in the Scale Application or brought in with integrations to grain analyzers, such as the GAC 2500. If the Scale Application is integrated to one or more grain analyzer, the grade factor information taken from a sample will display in the Open Grade Factor Results and can be matched with the correct corresponding scale ticket. Grade factors can be printed on Grade tickets as well as the Scale ticket. If grade factors are entered and maintained in Levridge they can be integrated with the Scale Application. Scale Ticket History The Scale Ticket History window displays today and yesterday\u2019s printed scale tickets. If you do not see a scale ticket in the history window that you expect it may be that the truck is still in the yard and that the ticket has not yet been printed. Application Configuration This is where the settings to change Site, Print, Etc. are located.","title":"Scale Functionality"},{"location":"Scale-Functionality/#scale-functionality","text":"","title":"Scale Functionality"},{"location":"Scale-Functionality/#overview","text":"Levridge Scale allows you to improve efficiency and accuracy by automatically capturing weight and quality attributes during scale ticket creation when weighing trucks containing bulk products. Scale tickets and bill of ladings can easily be issued to drivers as well as synchronized real-time to Levridge Commodity accounting built in Microsoft Dynamics 365 Finance and Supply Chain Management. Scale tickets can also be exported to other ERP systems. Levridge Scale provides a modern and easy to understand interface, allowing users to create scale tickets quickly and accurately. Scale Application Configuration How to Install Levridge Scale How to Update Levridge Scale ScaleHead Hardware Setup for Rice Lake 920i and Rice Lake 1280 Scale Appsettings Configuration Scale Implementation Activities Scale Application FAQ","title":"Overview"},{"location":"Scale-Functionality/#scale-ticket-types","text":"Different types of scale tickets can be entered into the Scale app depending upon what type of transaction needs to be recorded. The type of scale tickets that can be entered include: Inbound Grain Outbound Grain Agronomy Sales Transfer Weight Only","title":"Scale Ticket Types"},{"location":"Scale-Functionality/#customer-account","text":"Select the correct Customer Account from the list. Note: Customers appearing in the list are configured by setting them up in Setup > Application Configuration > Customer Short List. See Scale Customer Short List for more details. You can also search for any customer using the Search field.","title":"Customer Account"},{"location":"Scale-Functionality/#driver-on","text":"If the driver is in the truck when it is being weighed the Driver On toggle should be set to Yes. If the Driver On toggle is not visible, it can be turned on by going to SETUP > Application Configuration > Settings > Is Driver On","title":"Driver On"},{"location":"Scale-Functionality/#weight","text":"The weight from the scale can be recorded by selecting the Capture button. You can also manually enter the Weigh-In and Weight-Out values.","title":"Weight"},{"location":"Scale-Functionality/#gross-quantity","text":"The gross quantity is calculated by taking the net weight and dividing it by the Factor entered in SETUP > Application Configuration > Gross Quantity Settings. For example, when weighing Corn by the bushel, if a Factor of 56 has been entered and 53,300 has been captured as the Net Weight the Gross Quantity would be: 955.36 bushels.","title":"Gross Quantity"},{"location":"Scale-Functionality/#trucks-in-yard","text":"This contains the list of scale tickets that have been saved, but not yet complete or printed as either the truck is emptying its contents or is being filled and still needs to have its Weigh-Out amount captured on the scale ticket.","title":"Trucks in Yard"},{"location":"Scale-Functionality/#grade-factors","text":"Grade factor values used to determine quality discounts and premiums can be manually entered in the Scale Application or brought in with integrations to grain analyzers, such as the GAC 2500. If the Scale Application is integrated to one or more grain analyzer, the grade factor information taken from a sample will display in the Open Grade Factor Results and can be matched with the correct corresponding scale ticket. Grade factors can be printed on Grade tickets as well as the Scale ticket. If grade factors are entered and maintained in Levridge they can be integrated with the Scale Application.","title":"Grade Factors"},{"location":"Scale-Functionality/#scale-ticket-history","text":"The Scale Ticket History window displays today and yesterday\u2019s printed scale tickets. If you do not see a scale ticket in the history window that you expect it may be that the truck is still in the yard and that the ticket has not yet been printed.","title":"Scale Ticket History"},{"location":"Scale-Functionality/#application-configuration","text":"This is where the settings to change Site, Print, Etc. are located.","title":"Application Configuration"},{"location":"Scale-Overview/","text":"Scale Overview Scale Functionality Scale Application Configuration How to Install Levridge Scale How to Update Levridge Scale ScaleHead Hardware Setup for Rice Lake 920i and Rice Lake 1280 Scale Appsettings Configuration Scale Implementation Activities Scale Application FAQ","title":"Scale"},{"location":"Scale-Overview/#scale","text":"","title":"Scale"},{"location":"Scale-Overview/#overview","text":"Scale Functionality Scale Application Configuration How to Install Levridge Scale How to Update Levridge Scale ScaleHead Hardware Setup for Rice Lake 920i and Rice Lake 1280 Scale Appsettings Configuration Scale Implementation Activities Scale Application FAQ","title":"Overview"},{"location":"ScaleHeadHardwareSetup/","text":"Scale Hardware Setup Rice Lake 920i Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = 1 Hostname = <ip address of scalehead> Port = 10001 TypeId = TcpIPClientStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService Rice Lake 1280 Configure the 1280 Access the Scale UI in a browser. http://* :3000 In the Menu go to Configuration > Communications Select Ethernet, TCP Client 2 Remote Address = < ip address of Levridge Scale PC > Remote Port Number = 10001 Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = 1 Hostname = <ip address of scalehead> Port = 10001 TypeId = TcpIPCStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService Serial Connection Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = COM1 Speed = 9600 DataBits = 8 StopBits = 1 Parity = N FlowControl = 0 TypeId = SerialStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService","title":"Scale Hardware Setup"},{"location":"ScaleHeadHardwareSetup/#scale-hardware-setup","text":"","title":"Scale Hardware Setup"},{"location":"ScaleHeadHardwareSetup/#rice-lake-920i","text":"Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = 1 Hostname = <ip address of scalehead> Port = 10001 TypeId = TcpIPClientStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService","title":"Rice Lake 920i"},{"location":"ScaleHeadHardwareSetup/#rice-lake-1280","text":"Configure the 1280 Access the Scale UI in a browser. http://* :3000 In the Menu go to Configuration > Communications Select Ethernet, TCP Client 2 Remote Address = < ip address of Levridge Scale PC > Remote Port Number = 10001 Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = 1 Hostname = <ip address of scalehead> Port = 10001 TypeId = TcpIPCStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService","title":"Rice Lake 1280"},{"location":"ScaleHeadHardwareSetup/#serial-connection","text":"Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = COM1 Speed = 9600 DataBits = 8 StopBits = 1 Parity = N FlowControl = 0 TypeId = SerialStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService","title":"Serial Connection"},{"location":"ScaleImplementationActivities/","text":"Scale Implementation Activities Overview The following is an overview of the implementation activities necessary for getting started with scale. Full Implementation - Includes Integration to FinOps At the scale: Install the scale application Setup Azure service bus Configure the Azure service bus to connect to FinOps Setup event endpoint in FinOps Configure the appsettings.json files for the scale application Connect hardware to the application Configure the scale application settings Customer short list Gross quantity settings Printer settings Equipment mgmt Main settings page In FinOps Set up the event framework events for integrating to the scale Configure data that will be sent back-and-forth to the scale (requires input from client on how they want to use the scale) Products Carrier services Use in scale flag Net weight Units of measure Create estimated ticket flag Use TMS parameters Scale operators from the workers table Rolling stock Equipment types and container weights (if using estimated tickets) Grade factors Grade factor sequencing Growing seasons Hazardous materials Freight carriers Customers Customer split groups Customer operations and sites Units of measure Inventory sites Pits Bins Setup number sequences Setup scale parameters under AR > Setup > Ag > Ag parameters All scale tickets Agronomy scale Configure batch processes for generating orders from tickets (sales orders, transfer orders, etc.) Configure TMS (requires input from the client on how they want to configure) Delivery terms Shipping carriers Grower and company Carrier services TMS parameters under TMS > Setup > TMS parameters > General > Agronomy scale Default settings for grower and company carriers Rating and routing Synch initial data to the scale prior to running","title":"Scale Implementation Activities"},{"location":"ScaleImplementationActivities/#scale-implementation-activities","text":"","title":"Scale Implementation Activities"},{"location":"ScaleImplementationActivities/#overview","text":"The following is an overview of the implementation activities necessary for getting started with scale.","title":"Overview"},{"location":"ScaleImplementationActivities/#full-implementation-includes-integration-to-finops","text":"At the scale: Install the scale application Setup Azure service bus Configure the Azure service bus to connect to FinOps Setup event endpoint in FinOps Configure the appsettings.json files for the scale application Connect hardware to the application Configure the scale application settings Customer short list Gross quantity settings Printer settings Equipment mgmt Main settings page","title":"Full Implementation - Includes Integration to FinOps"},{"location":"ScaleImplementationActivities/#in-finops","text":"Set up the event framework events for integrating to the scale Configure data that will be sent back-and-forth to the scale (requires input from client on how they want to use the scale) Products Carrier services Use in scale flag Net weight Units of measure Create estimated ticket flag Use TMS parameters Scale operators from the workers table Rolling stock Equipment types and container weights (if using estimated tickets) Grade factors Grade factor sequencing Growing seasons Hazardous materials Freight carriers Customers Customer split groups Customer operations and sites Units of measure Inventory sites Pits Bins Setup number sequences Setup scale parameters under AR > Setup > Ag > Ag parameters All scale tickets Agronomy scale Configure batch processes for generating orders from tickets (sales orders, transfer orders, etc.) Configure TMS (requires input from the client on how they want to configure) Delivery terms Shipping carriers Grower and company Carrier services TMS parameters under TMS > Setup > TMS parameters > General > Agronomy scale Default settings for grower and company carriers Rating and routing Synch initial data to the scale prior to running","title":"In FinOps"},{"location":"ServiceBusConfiguration/","text":"ServiceBusConfiguration The ServiceBusConfiguration object is used to configure a connection to a service bus queue or topic. Example \"prodagsyncmasterdata\": { \"ConnectionString\": \"Endpoint=[Customer Servicebus Connection String]\", \"TopicName\": \"[Customer Servicebus Topic]\", \"SubscriptionName\": \"[Customer Servicebus Topic Subscription]\", \"MaxConcurrentCount\":10, \"PrefetchCount\": 5 }, Definition ConnectionString TopicName SubscriptionName MaxConcurrentCount The maximum number of messages that will be allowed to be processed simultaneously. PrefetchCount","title":"ServiceBusConfiguration"},{"location":"ServiceBusConfiguration/#servicebusconfiguration","text":"The ServiceBusConfiguration object is used to configure a connection to a service bus queue or topic.","title":"ServiceBusConfiguration"},{"location":"ServiceBusConfiguration/#example","text":"\"prodagsyncmasterdata\": { \"ConnectionString\": \"Endpoint=[Customer Servicebus Connection String]\", \"TopicName\": \"[Customer Servicebus Topic]\", \"SubscriptionName\": \"[Customer Servicebus Topic Subscription]\", \"MaxConcurrentCount\":10, \"PrefetchCount\": 5 },","title":"Example"},{"location":"ServiceBusConfiguration/#definition","text":"","title":"Definition"},{"location":"ServiceBusConfiguration/#connectionstring","text":"","title":"ConnectionString"},{"location":"ServiceBusConfiguration/#topicname","text":"","title":"TopicName"},{"location":"ServiceBusConfiguration/#subscriptionname","text":"","title":"SubscriptionName"},{"location":"ServiceBusConfiguration/#maxconcurrentcount","text":"The maximum number of messages that will be allowed to be processed simultaneously.","title":"MaxConcurrentCount"},{"location":"ServiceBusConfiguration/#prefetchcount","text":"","title":"PrefetchCount"},{"location":"SetupCostVariances/","text":"Setup Cost Variances Brief introduction of the module, component or feature being documented. This document explains ... How to Setup Cost Variances Close the page. Go to Cost Management > Ledger Integration Policies Setup > Posting. Click the Standard cost variance tab. In the Select field, select an option.","title":"Setup Cost Variances"},{"location":"SetupCostVariances/#setup-cost-variances","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Setup Cost Variances"},{"location":"SetupCostVariances/#how-to-setup-cost-variances","text":"Close the page. Go to Cost Management > Ledger Integration Policies Setup > Posting. Click the Standard cost variance tab. In the Select field, select an option.","title":"How to Setup Cost Variances"},{"location":"SetupStandardCost/","text":"Setup a Standard Cost Brief introduction of the module, component or feature being documented. This document explains ... How to Setup a Standard Cost Use the Quick Filter to find records. For example, filter on the Item number field with a value of 'harness'. Click Item price. Click New. In the list, mark the selected row. In the Version field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Site field, type a value. In the Price field, enter a number. Click Save. Click the Active prices tab. Click the Pending prices tab. On the Action Pane, click Options. Close the page. Refresh the page. Click Item price. Click Activate pending price(s). Click the Active prices tab.","title":"Setup a Standard Cost"},{"location":"SetupStandardCost/#setup-a-standard-cost","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Setup a Standard Cost"},{"location":"SetupStandardCost/#how-to-setup-a-standard-cost","text":"Use the Quick Filter to find records. For example, filter on the Item number field with a value of 'harness'. Click Item price. Click New. In the list, mark the selected row. In the Version field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Site field, type a value. In the Price field, enter a number. Click Save. Click the Active prices tab. Click the Pending prices tab. On the Action Pane, click Options. Close the page. Refresh the page. Click Item price. Click Activate pending price(s). Click the Active prices tab.","title":"How to Setup a Standard Cost"},{"location":"SourceConfig/","text":"SourceConfig Settings SourceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction. Example \"SourceConfig\": { \"ServiceBusConfigName\": \"Levridge.Integration.Host.SuretyController\", \"ODataConfigName\": \"DynamicsCRM\", \"SystemName\": \"Surety\", \"Direction\": \"Source\" } Definition SourceConfig The node in the appsettings.json file does not actually need to be named \"SourceConfig\". You can use a command line parameter to specify the node name (section name) that contains the SourceConfig data. No matter the name, the source config section must contain the following attributes: - ServiceBusConfigName - ODataConfigName - CDSConfigName - SystemName - Direction ServiceBusConfigName The ServiceBusConfigName attribute contains a string that specifies the json object (configuration section) that holds the service bus configuration used by the Source of the Integration Interaction. This must point to a node that is a ServiceBusConfig json object ODataConfigName The ODataConfigName attribute contains a string that specifies the json object (configuration section) that holds the data configuration used by the Source of the Integration Interaction. This must point to a node that is a ODataConfig json object CDSConfigName The CDSConfigName attribute contains a string that specifies the json object (configuration section) that holds the CDS configuration used by the Source of the Integration Interaction. This must point to a node that is a CDSConfig json object SystemName The SystemName attribute holds a string value that represents the source system name. It must be one of the names recognized by the SystemName enumeration . Direction The direction is either Soruce or Target. This must be specified since the SourceConfig Node can have any name so the direction of the configuration may not be clear from the name.","title":"SourceConfig Settings"},{"location":"SourceConfig/#sourceconfig-settings","text":"SourceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction.","title":"SourceConfig Settings"},{"location":"SourceConfig/#example","text":"\"SourceConfig\": { \"ServiceBusConfigName\": \"Levridge.Integration.Host.SuretyController\", \"ODataConfigName\": \"DynamicsCRM\", \"SystemName\": \"Surety\", \"Direction\": \"Source\" }","title":"Example"},{"location":"SourceConfig/#definition","text":"","title":"Definition"},{"location":"SourceConfig/#sourceconfig","text":"The node in the appsettings.json file does not actually need to be named \"SourceConfig\". You can use a command line parameter to specify the node name (section name) that contains the SourceConfig data. No matter the name, the source config section must contain the following attributes: - ServiceBusConfigName - ODataConfigName - CDSConfigName - SystemName - Direction","title":"SourceConfig"},{"location":"SourceConfig/#servicebusconfigname","text":"The ServiceBusConfigName attribute contains a string that specifies the json object (configuration section) that holds the service bus configuration used by the Source of the Integration Interaction. This must point to a node that is a ServiceBusConfig json object","title":"ServiceBusConfigName"},{"location":"SourceConfig/#odataconfigname","text":"The ODataConfigName attribute contains a string that specifies the json object (configuration section) that holds the data configuration used by the Source of the Integration Interaction. This must point to a node that is a ODataConfig json object","title":"ODataConfigName"},{"location":"SourceConfig/#cdsconfigname","text":"The CDSConfigName attribute contains a string that specifies the json object (configuration section) that holds the CDS configuration used by the Source of the Integration Interaction. This must point to a node that is a CDSConfig json object","title":"CDSConfigName"},{"location":"SourceConfig/#systemname","text":"The SystemName attribute holds a string value that represents the source system name. It must be one of the names recognized by the SystemName enumeration .","title":"SystemName"},{"location":"SourceConfig/#direction","text":"The direction is either Soruce or Target. This must be specified since the SourceConfig Node can have any name so the direction of the configuration may not be clear from the name.","title":"Direction"},{"location":"Surety/","text":"Surety","title":"Surety"},{"location":"Surety/#surety","text":"","title":"Surety"},{"location":"SystemName/","text":"SystemName SystemName is an enumerated value that is used in the Source and Target configurations to configure which integrations get loaded into the current integration framework instance. The valid values are: None : No integrations will be loaded DynamicsAX : The integrations for Dynamics 365 Finance and Operations will be loaded as either the Source or the Target depending on which config node it appears. DynamicsCRM : The integrations for Dynamics 365 Customer Engagement will be loaded as either the Source or the Target depending on which config node it appears. ScaleHouse : The integrations for the Levridge Scale Application will be loaded as either the Source or the Target depending on which config node it appears. OneWeigh : The integrations for OneWeigh will be loaded as either the Source or the Target depending on which config node it appears. AgSync : The integrations for Agsync will be loaded as either the Source or the Target depending on which config node it appears. Recommendation : The integrations for Recommendations will be loaded as the Source. This is not a valid value for the Target configuration. Field : The integrations for Fields will be loaded as the Source. This is not a valid value for the Target configuration. Surety : The integrations for Surety will be loaded as the Source. This is not a valid value for the Target configuration. Kahler : The integrations for Kahler will be loaded as either the Source or the Target depending on which config node it appears.","title":"SystemName"},{"location":"SystemName/#systemname","text":"SystemName is an enumerated value that is used in the Source and Target configurations to configure which integrations get loaded into the current integration framework instance. The valid values are: None : No integrations will be loaded DynamicsAX : The integrations for Dynamics 365 Finance and Operations will be loaded as either the Source or the Target depending on which config node it appears. DynamicsCRM : The integrations for Dynamics 365 Customer Engagement will be loaded as either the Source or the Target depending on which config node it appears. ScaleHouse : The integrations for the Levridge Scale Application will be loaded as either the Source or the Target depending on which config node it appears. OneWeigh : The integrations for OneWeigh will be loaded as either the Source or the Target depending on which config node it appears. AgSync : The integrations for Agsync will be loaded as either the Source or the Target depending on which config node it appears. Recommendation : The integrations for Recommendations will be loaded as the Source. This is not a valid value for the Target configuration. Field : The integrations for Fields will be loaded as the Source. This is not a valid value for the Target configuration. Surety : The integrations for Surety will be loaded as the Source. This is not a valid value for the Target configuration. Kahler : The integrations for Kahler will be loaded as either the Source or the Target depending on which config node it appears.","title":"SystemName"},{"location":"TMS/","text":"Transportation Management System Overview An overview of the inbound grain process beginning with contracts and working through settlements. The in-bound process will be used for anyone buying in a commodity. Finance & Operations > Modules > Commodity Accounting From the commodity accounting menu, the outbound process consists of: Contracts Offers Purchase contracts Storage agreements Contract expiration Open contracts Delivery Settlement Contracts Offers Commodity Accounting > Inbound > Contract > Offers The Offers My view shows a list of open offers. Open offers can be filtered by Branch, Commodity and Executed offers. Executed Offers is a yes/no toggle button if flipped to \u201cYes\u201d will show the contracts that have been filled with a purchase contract issued to the contract. To create a new offer, click New. A Create offer window will appear on the right-hand side. The Create offer fields include: Branch Offer date Offer type Notification - Before offer can be executed, the user needs to contact whoever created the offer and ask if they want the contract to be executed. Market offer - If the current market or bid at this location reaches offer level, the contract is executed automatically. Customer Commodity Contract type Delivery period Offer quantity Ticket default: Automatically defaults. The input is reflective of selected Delivery period. Board price Basis Net price Expiration date FOB location Notes Click Create. A review of the contract is then generated. Click Save. Created offers can be removed. Purchase Contracts The Create purchase contract is generated by clicking New and opening an offer. A Create offer window will appear on the right-hand side. This is the same Create purchase contract window shown in the Create Contracts section. Click Create. The system will show the created Purchase contract. The Line view includes General and Delivery and pricing information. The General view outlines the line detail part of the contract capturing the contract information currently in the system. The Customer operation field is a farm field type development. The Delivery and pricing information view show the delivery information. The Header view shows additional detail: General contract information Includes Direct Ship information Contract dates and quantities Once tickets are applied to the contract, the system begins tracking what has been delivered. Part of a commodity can also be canceled. Sent date: The ability to track whether the contract has been signed Date returned: The date when the contract was returned Contract expires: The date when the contract expires. There is a contract expiration program track and get rid of contracts that have expired. Discounts, fees and freight The \u201cUse discount schedule in place at time of delivery\u201d is a yes/no toggle button with the option to have commodity and branch set up with a default discount schedule. In the setup page, there is a setup flag to use a discount schedule which would default to every contract or scale ticket. Fee schedule: Storage charges or assessments. Market to market adjustment: if the user is bringing contracts to market and you want to bring them back to market at one location, you can use a basis or freight adjustment to add/subtract to price to get the right calculation of bringing contracts to market. Freight included in basis: information of basis level of how much was freight. Addresses Multiple addresses to use on contract. These addresses can be overwritten Ship from name Ship to name: Defaults to branch previously entered in FOB name: Where ownership changes Miscellaneous details Can identify who in your company created contract. If a Broker was used, this can be identified along with the Broker commission rate. The commission rate is not processed and is just for informational purposes. It does not create a payable. Hedge commodity The commodity will default in. Additional hedge commodities can be entered. Can get long/short to run by hedge commodity. Pricing of a Contract Commodity > Inbound > Contract > Purchase contracts The Delivery and Pricing view is available under the \u201cLine\u201d My view. To set a price, highlight the delivery period. Click on Set price. The Contract pricing window will appear on the right-hand side. The user can change the Price quantity, Board price, and Basis to match what should be on the contract. The Net price is calculated from Board Price, subtracted Basis, and gave Net price. Click Create. A new delivery period line is created. Throughout system, you will see same contract number, but it will have two delivery period lines showing up. Within the contract entry, additional functionality includes: View: Scale tickets and load requests issued against a contract, along with load orders tied to a contract. Generate: Pricing confirmation. This can be printed. Fill: Ability to fill at market price or contract price. Market price: Takes quantity against current market. The system calculates gain/loss to create either a payable or receivable Contract price: Takes quantity against current contract price. There is no gain or losses. Delivery Process on In-bound Grain Commodity accounting > Inbound > Delivery Delivery Process on in-bound grain includes: Inbound scale tickets Delivery sheets Inbound scale ticket application Unit trains Inbound Scale Tickets Commodity accounting > Inbound > Delivery > Inbound scale tickets Most of the inbound scale tickets will be imported in from scale a scale interface. But you do have the ability to add new scale tickets or edit existing scale tickets that have been imported. To create a new scale ticket, click on New. A Create scale ticket window will appear on the right-hand side. Ticket type Commodity Branch Warehouse Customer account Name Ticket date: this is a user field and can be overridden Customer operation: There can be multiple operations for a customer. Must choose one. A customer operation is required. Customer site: This field is not required but can choose for tracking purposes. Split Group: Will default in with the customer operation. This can be overridden. Click Create. The below image shows a newly created inbound scale ticket. Additional information and categories one can enter attached to a scale ticket. Scale ticket split details: If there were multiple splits, the system would preview the split they would be receiving. Weights: The system calculates net weight. This is a toggle on/off button (defaults Driver to on). The user can select scale operation and grader if they want the information recorded on the ticket. Date/Time: Can be viewed on the printed ticket. Notes: There are two types of notes: External and Internal. External will print on scale ticket. Grade factors: Grade factors are set up in the system and assigned to the commodity. The sequence they show up in the table is user defined. There is the ability for the moisture and test weight depending on equipment person has but can import moisture and test weight (TW). User can enter other discount factors as well. Those are used to defer back to the discount schedules that are attached to any contract or storage agreement user has and calculate any premium or charges that are due based off those discounts. Transportation Details: This is not a required entry but can be provided. It is a way to identify the driver delivering the commodity for informational purposes and when the truck comes back empty. The Unit number is primary used in rail shipments can add and group this ticket with others. Sometimes previously hauled commodity is a required field so that there wasn\u2019t hazardous material hauled prior to commodity. The next step is to Post to Inventory so all commodity received will show up in inventory to track and update DPR for inventory amounts. DPR: daily position report. After the ticket is posted, it is locked in and ready to be used in other parts of the system. This concludes the inbound scale ticket option. Inbound scale ticket application process The Inbound scale ticket application process takes scale tickets received and provides the user the option to determine how the scale tickets will be used. The contract number can be changed. Inbound scale ticket auto-apply: The user can set up a sequence in the system to auto apply on each contract. e.g. If you have it set up to sequence if you want your first application contract, second agreement storage agreement. The system will automatically apply your scale ticket or a portion of it to an existing purchase contract or to an existing storage agreement based on the sequences set up on your auto-apply functionality. Inbound scale ticket un-apply Ability to unassign scale tickets from contracts Can select a scale ticket not previously assigned to a contract (if let\u2019s say it was un-applied as mentioned above) the user can click on the scale ticket and allocate it to a purchase contract or a storage agreement. Or you can do the full amount or part of a contract. This is what the inbound scale ticket application program will do to get commodities moved to the specific obligations a customer may have. Delivery Sheets Delivery Sheets is a way to group multiple tickets together for same commodity and same customer. You can also use delivery sheet to calculate average grades. It is a delivery sheet to group tickets together and process them as a group instead of individually. The system automatically assigns Delivery Sheet number. If you want to see completed sheets, you can click on the Show Completed toggle button (Yes/No). You can also show the Voided delivery sheets as well (toggle button). To create a new delivery sheet, click New. The Create delivery sheet window will appear on the right-hand side of the window. Branch: Defaults to last branch used Date: Defaults to current date Customer account: Enter account name or number Commodity: Choose commodity Customer operation: Choose the customer operation Customer Site: Choose customer site Split group: The system assigns a split group, but this can be overridden Estimated start date: not required fields. Some customers use a planning process. Estimated delivery quantity: \u201cabove\u201d helps with planning purposes. Click Create. A new delivery sheet will be created and open in the main window. Under the Delivery sheet ownership splits section: All tickets applied to the delivery sheet will be assigned to the one account. You can have multiple accounts with different percentages applied and as the ability to complete splits. Can choose default disposition. Each time the user applies a ticket to the delivery sheet, it will be applied to that specific contract. The user can choose what they intend to do with the storage agreement. There is the option of the tickets to be applied when added to the delivery sheet. Delivery sheet completion details: Details the splits and dispositions of the delivery sheet After these sections are reviewed and filled out, the user can complete the delivery sheet. This finishes the process and lock down the calculations. The user cannot settle any of the tickets delivered until it is completed. The tickets will not show up as available to settle until the complete function has been done. Unit Trains If unit trains are received within a facility, this is a simple program to create a Unit train number, which is an alphanumeric field. After creating a number, click save. These numbers are now available within the system to be used and attached to a scale ticket. Settlement Commodity accounting > Inbound > Settlement Settlement requests Settlement payments Discounts, fees and charging invoicing Settle options with grower Warehouse receipts Settlement sheet reprint Settlement Requests Commodity accounting > Inbound > Settlement > Settlement requests Settlement request window shows all settlement requests with a status of either opened, invoiced, or paid. To create new settlement request, click New. Select a customer, commodity, and branch. The disposition is a drop-down field asking the location of the contracts (Stored, Price later, Priced contract). After choosing, click Next. If chosen Priced Contract, the system shows all the scale tickets that have been applied to a priced contract that have not been settled yet. These are available to be settled. After choosing the contracts to be settled, click Next. The system provides a Preliminary summary with the contract number, delivery period, end price, settled quantity, and settled amount (gross dollar amount). Discounts, fees and charges would be summarized as well in the bottom quadrant. Click Next. The system will take the user to the Remittance screen. This screen summarizes the remittance portion. The Deferred payment function is utilized frequently. This is the option to lock in a commodity price and selling the commodity in a future date. The Requested payment date can change to reflect the future date. The Deferred charge code and Deferred Terms code are utilized along with the deferred payment option. The user can choose to have a premium on the deferred payment. Add/Split Payments is another function with the ability to issue additional checks. Click Next. The system is now ready to issue the check(s). The Settlement request summary provides a summary of the Settlement Request. Click Finish. From there, the user can go to Settlement Payment. Settlement and Payment Process Settlement and Payment Process is a two-step process: Confirm Confirm and Pay After the user selects one of the above options (self-explanatory), the system will validate the settlement and post in journal. Discount, fees, and charges invoicing. Functionality not completed as of October 2020. Warehouse receipt This is a legal tender document. If the document is listed as a negotiable warehouse receipt, it is a legal tender. A non-negotiable document does not have the same legal tender but has same protection level. To issue a new warehouse receipt, Click New. The Create warehouse receipt will appear on the right-hand side in a new window. After completing the warehouse receipt, the user would choose a Storage agreement. Click Save. A warehouse receipt will then be issued. This is another form of storage for the grower. Settle options with grower Functionality not completed as of October 2020. Settle sheet reprint This is the option to be able to reprint a settlement sheet. The Grain Outbound Processes can be found under Grain Outbound Processes","title":"Transportation Management System"},{"location":"TMS/#transportation-management-system","text":"","title":"Transportation Management System"},{"location":"TMS/#overview","text":"An overview of the inbound grain process beginning with contracts and working through settlements. The in-bound process will be used for anyone buying in a commodity. Finance & Operations > Modules > Commodity Accounting From the commodity accounting menu, the outbound process consists of: Contracts Offers Purchase contracts Storage agreements Contract expiration Open contracts Delivery Settlement","title":"Overview"},{"location":"TMS/#contracts","text":"","title":"Contracts"},{"location":"TMS/#offers","text":"Commodity Accounting > Inbound > Contract > Offers The Offers My view shows a list of open offers. Open offers can be filtered by Branch, Commodity and Executed offers. Executed Offers is a yes/no toggle button if flipped to \u201cYes\u201d will show the contracts that have been filled with a purchase contract issued to the contract. To create a new offer, click New. A Create offer window will appear on the right-hand side. The Create offer fields include: Branch Offer date Offer type Notification - Before offer can be executed, the user needs to contact whoever created the offer and ask if they want the contract to be executed. Market offer - If the current market or bid at this location reaches offer level, the contract is executed automatically. Customer Commodity Contract type Delivery period Offer quantity Ticket default: Automatically defaults. The input is reflective of selected Delivery period. Board price Basis Net price Expiration date FOB location Notes Click Create. A review of the contract is then generated. Click Save. Created offers can be removed.","title":"Offers"},{"location":"TMS/#purchase-contracts","text":"The Create purchase contract is generated by clicking New and opening an offer. A Create offer window will appear on the right-hand side. This is the same Create purchase contract window shown in the Create Contracts section. Click Create. The system will show the created Purchase contract. The Line view includes General and Delivery and pricing information. The General view outlines the line detail part of the contract capturing the contract information currently in the system. The Customer operation field is a farm field type development. The Delivery and pricing information view show the delivery information. The Header view shows additional detail: General contract information Includes Direct Ship information Contract dates and quantities Once tickets are applied to the contract, the system begins tracking what has been delivered. Part of a commodity can also be canceled. Sent date: The ability to track whether the contract has been signed Date returned: The date when the contract was returned Contract expires: The date when the contract expires. There is a contract expiration program track and get rid of contracts that have expired. Discounts, fees and freight The \u201cUse discount schedule in place at time of delivery\u201d is a yes/no toggle button with the option to have commodity and branch set up with a default discount schedule. In the setup page, there is a setup flag to use a discount schedule which would default to every contract or scale ticket. Fee schedule: Storage charges or assessments. Market to market adjustment: if the user is bringing contracts to market and you want to bring them back to market at one location, you can use a basis or freight adjustment to add/subtract to price to get the right calculation of bringing contracts to market. Freight included in basis: information of basis level of how much was freight. Addresses Multiple addresses to use on contract. These addresses can be overwritten Ship from name Ship to name: Defaults to branch previously entered in FOB name: Where ownership changes Miscellaneous details Can identify who in your company created contract. If a Broker was used, this can be identified along with the Broker commission rate. The commission rate is not processed and is just for informational purposes. It does not create a payable. Hedge commodity The commodity will default in. Additional hedge commodities can be entered. Can get long/short to run by hedge commodity.","title":"Purchase Contracts"},{"location":"TMS/#pricing-of-a-contract","text":"Commodity > Inbound > Contract > Purchase contracts The Delivery and Pricing view is available under the \u201cLine\u201d My view. To set a price, highlight the delivery period. Click on Set price. The Contract pricing window will appear on the right-hand side. The user can change the Price quantity, Board price, and Basis to match what should be on the contract. The Net price is calculated from Board Price, subtracted Basis, and gave Net price. Click Create. A new delivery period line is created. Throughout system, you will see same contract number, but it will have two delivery period lines showing up. Within the contract entry, additional functionality includes: View: Scale tickets and load requests issued against a contract, along with load orders tied to a contract. Generate: Pricing confirmation. This can be printed. Fill: Ability to fill at market price or contract price. Market price: Takes quantity against current market. The system calculates gain/loss to create either a payable or receivable Contract price: Takes quantity against current contract price. There is no gain or losses.","title":"Pricing of a Contract"},{"location":"TMS/#delivery-process-on-in-bound-grain","text":"Commodity accounting > Inbound > Delivery Delivery Process on in-bound grain includes: Inbound scale tickets Delivery sheets Inbound scale ticket application Unit trains","title":"Delivery Process on In-bound Grain"},{"location":"TMS/#inbound-scale-tickets","text":"Commodity accounting > Inbound > Delivery > Inbound scale tickets Most of the inbound scale tickets will be imported in from scale a scale interface. But you do have the ability to add new scale tickets or edit existing scale tickets that have been imported. To create a new scale ticket, click on New. A Create scale ticket window will appear on the right-hand side. Ticket type Commodity Branch Warehouse Customer account Name Ticket date: this is a user field and can be overridden Customer operation: There can be multiple operations for a customer. Must choose one. A customer operation is required. Customer site: This field is not required but can choose for tracking purposes. Split Group: Will default in with the customer operation. This can be overridden. Click Create. The below image shows a newly created inbound scale ticket. Additional information and categories one can enter attached to a scale ticket. Scale ticket split details: If there were multiple splits, the system would preview the split they would be receiving. Weights: The system calculates net weight. This is a toggle on/off button (defaults Driver to on). The user can select scale operation and grader if they want the information recorded on the ticket. Date/Time: Can be viewed on the printed ticket. Notes: There are two types of notes: External and Internal. External will print on scale ticket. Grade factors: Grade factors are set up in the system and assigned to the commodity. The sequence they show up in the table is user defined. There is the ability for the moisture and test weight depending on equipment person has but can import moisture and test weight (TW). User can enter other discount factors as well. Those are used to defer back to the discount schedules that are attached to any contract or storage agreement user has and calculate any premium or charges that are due based off those discounts. Transportation Details: This is not a required entry but can be provided. It is a way to identify the driver delivering the commodity for informational purposes and when the truck comes back empty. The Unit number is primary used in rail shipments can add and group this ticket with others. Sometimes previously hauled commodity is a required field so that there wasn\u2019t hazardous material hauled prior to commodity. The next step is to Post to Inventory so all commodity received will show up in inventory to track and update DPR for inventory amounts. DPR: daily position report. After the ticket is posted, it is locked in and ready to be used in other parts of the system. This concludes the inbound scale ticket option.","title":"Inbound Scale Tickets"},{"location":"TMS/#inbound-scale-ticket-application-process","text":"The Inbound scale ticket application process takes scale tickets received and provides the user the option to determine how the scale tickets will be used. The contract number can be changed. Inbound scale ticket auto-apply: The user can set up a sequence in the system to auto apply on each contract. e.g. If you have it set up to sequence if you want your first application contract, second agreement storage agreement. The system will automatically apply your scale ticket or a portion of it to an existing purchase contract or to an existing storage agreement based on the sequences set up on your auto-apply functionality. Inbound scale ticket un-apply Ability to unassign scale tickets from contracts Can select a scale ticket not previously assigned to a contract (if let\u2019s say it was un-applied as mentioned above) the user can click on the scale ticket and allocate it to a purchase contract or a storage agreement. Or you can do the full amount or part of a contract. This is what the inbound scale ticket application program will do to get commodities moved to the specific obligations a customer may have.","title":"Inbound scale ticket application process"},{"location":"TMS/#delivery-sheets","text":"Delivery Sheets is a way to group multiple tickets together for same commodity and same customer. You can also use delivery sheet to calculate average grades. It is a delivery sheet to group tickets together and process them as a group instead of individually. The system automatically assigns Delivery Sheet number. If you want to see completed sheets, you can click on the Show Completed toggle button (Yes/No). You can also show the Voided delivery sheets as well (toggle button). To create a new delivery sheet, click New. The Create delivery sheet window will appear on the right-hand side of the window. Branch: Defaults to last branch used Date: Defaults to current date Customer account: Enter account name or number Commodity: Choose commodity Customer operation: Choose the customer operation Customer Site: Choose customer site Split group: The system assigns a split group, but this can be overridden Estimated start date: not required fields. Some customers use a planning process. Estimated delivery quantity: \u201cabove\u201d helps with planning purposes. Click Create. A new delivery sheet will be created and open in the main window. Under the Delivery sheet ownership splits section: All tickets applied to the delivery sheet will be assigned to the one account. You can have multiple accounts with different percentages applied and as the ability to complete splits. Can choose default disposition. Each time the user applies a ticket to the delivery sheet, it will be applied to that specific contract. The user can choose what they intend to do with the storage agreement. There is the option of the tickets to be applied when added to the delivery sheet. Delivery sheet completion details: Details the splits and dispositions of the delivery sheet After these sections are reviewed and filled out, the user can complete the delivery sheet. This finishes the process and lock down the calculations. The user cannot settle any of the tickets delivered until it is completed. The tickets will not show up as available to settle until the complete function has been done.","title":"Delivery Sheets"},{"location":"TMS/#unit-trains","text":"If unit trains are received within a facility, this is a simple program to create a Unit train number, which is an alphanumeric field. After creating a number, click save. These numbers are now available within the system to be used and attached to a scale ticket.","title":"Unit Trains"},{"location":"TMS/#settlement","text":"Commodity accounting > Inbound > Settlement Settlement requests Settlement payments Discounts, fees and charging invoicing Settle options with grower Warehouse receipts Settlement sheet reprint","title":"Settlement"},{"location":"TMS/#settlement-requests","text":"Commodity accounting > Inbound > Settlement > Settlement requests Settlement request window shows all settlement requests with a status of either opened, invoiced, or paid. To create new settlement request, click New. Select a customer, commodity, and branch. The disposition is a drop-down field asking the location of the contracts (Stored, Price later, Priced contract). After choosing, click Next. If chosen Priced Contract, the system shows all the scale tickets that have been applied to a priced contract that have not been settled yet. These are available to be settled. After choosing the contracts to be settled, click Next. The system provides a Preliminary summary with the contract number, delivery period, end price, settled quantity, and settled amount (gross dollar amount). Discounts, fees and charges would be summarized as well in the bottom quadrant. Click Next. The system will take the user to the Remittance screen. This screen summarizes the remittance portion. The Deferred payment function is utilized frequently. This is the option to lock in a commodity price and selling the commodity in a future date. The Requested payment date can change to reflect the future date. The Deferred charge code and Deferred Terms code are utilized along with the deferred payment option. The user can choose to have a premium on the deferred payment. Add/Split Payments is another function with the ability to issue additional checks. Click Next. The system is now ready to issue the check(s). The Settlement request summary provides a summary of the Settlement Request. Click Finish. From there, the user can go to Settlement Payment.","title":"Settlement Requests"},{"location":"TMS/#settlement-and-payment-process","text":"Settlement and Payment Process is a two-step process: Confirm Confirm and Pay After the user selects one of the above options (self-explanatory), the system will validate the settlement and post in journal.","title":"Settlement and Payment Process"},{"location":"TMS/#discount-fees-and-charges-invoicing","text":"Functionality not completed as of October 2020.","title":"Discount, fees, and charges invoicing."},{"location":"TMS/#warehouse-receipt","text":"This is a legal tender document. If the document is listed as a negotiable warehouse receipt, it is a legal tender. A non-negotiable document does not have the same legal tender but has same protection level. To issue a new warehouse receipt, Click New. The Create warehouse receipt will appear on the right-hand side in a new window. After completing the warehouse receipt, the user would choose a Storage agreement. Click Save. A warehouse receipt will then be issued. This is another form of storage for the grower.","title":"Warehouse receipt"},{"location":"TMS/#settle-options-with-grower","text":"Functionality not completed as of October 2020.","title":"Settle options with grower"},{"location":"TMS/#settle-sheet-reprint","text":"This is the option to be able to reprint a settlement sheet. The Grain Outbound Processes can be found under Grain Outbound Processes","title":"Settle sheet reprint"},{"location":"TargetConfig/","text":"Target Config Settings TargetConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction. Example \"TargetConfig\": { \"ODataConfigName\": \"DynamicsCRM\", \"CDSConfigName\": \"CDS\", \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" } Definition TargetConfig The node in the appsettings.json file does not actually need to be named \"TargetConfig\". You can use a command line parameter to specify the node name (section name) that contains the TargetConfig data. No matter the name, the source config section must contain the following attributes: - ODataConfigName - CDSConfigName - SystemName - Direction ODataConfigName The ODataConfigName attribute contains a string that specifies the json object (configuration section) that holds the data configuration used by the Source of the Integration Interaction. This must point to a node that is a ODataConfig json object CDSConfigName The CDSConfigName attribute contains a string that specifies the json object (configuration section) that holds the CDS configuration used by the Target of the Integration Interaction. This must point to a node that is a CDSConfig json object SystemName The SystemName attribute holds a string value that represents the source system name. It must be one of the names recognized by the SystemName enumeration . Direction The direction is either Soruce or Target. This must be specified since the TargetConfig Node can have any name so the direction of the configuration may not be clear from the name.","title":"Target Config Settings"},{"location":"TargetConfig/#target-config-settings","text":"TargetConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction.","title":"Target Config Settings"},{"location":"TargetConfig/#example","text":"\"TargetConfig\": { \"ODataConfigName\": \"DynamicsCRM\", \"CDSConfigName\": \"CDS\", \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" }","title":"Example"},{"location":"TargetConfig/#definition","text":"","title":"Definition"},{"location":"TargetConfig/#targetconfig","text":"The node in the appsettings.json file does not actually need to be named \"TargetConfig\". You can use a command line parameter to specify the node name (section name) that contains the TargetConfig data. No matter the name, the source config section must contain the following attributes: - ODataConfigName - CDSConfigName - SystemName - Direction","title":"TargetConfig"},{"location":"TargetConfig/#odataconfigname","text":"The ODataConfigName attribute contains a string that specifies the json object (configuration section) that holds the data configuration used by the Source of the Integration Interaction. This must point to a node that is a ODataConfig json object","title":"ODataConfigName"},{"location":"TargetConfig/#cdsconfigname","text":"The CDSConfigName attribute contains a string that specifies the json object (configuration section) that holds the CDS configuration used by the Target of the Integration Interaction. This must point to a node that is a CDSConfig json object","title":"CDSConfigName"},{"location":"TargetConfig/#systemname","text":"The SystemName attribute holds a string value that represents the source system name. It must be one of the names recognized by the SystemName enumeration .","title":"SystemName"},{"location":"TargetConfig/#direction","text":"The direction is either Soruce or Target. This must be specified since the TargetConfig Node can have any name so the direction of the configuration may not be clear from the name.","title":"Direction"},{"location":"Template/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"Template/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Template/#overview","text":"","title":"Overview"},{"location":"Template/#main-point-1","text":"","title":"Main Point 1"},{"location":"Template/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"TradeAgreementsPriceGroup/","text":"Trade Agreements Price Group Brief introduction of the module, component or feature being documented. This document explains ... Trade Agreements Price Group Go to Inventory Management > Setup > Price/Discount > Customer Price/Discount Groups. Click New. In the Price Groups field, type a value. In the Name field, type a value. On the Action Pane, click Trade Agreements. Click Save. On the Action Pane, click Trade Agreements. Click View Sales Prices. Close the page. One the Action Pane, click Trade Agreements. Click View Trade Agreements (sales). Close the page. On the Action Pane, click Trade Agreements. Close the page. Go to Product Information Management > Products > Released Products. In the list, click the link in the select row. Close the page. Go to Accounts Receivable > Customers > All customers. In the list, find and select the desired record. In the list, click the link in the selected row. Click Edit. In the Price field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. Click Save. Close the page. Go to Inventory Management > Setup > Price/Discount > Customer Price/Discount Groups. In the list, find and select the desired record. On the Action Pane, click Trade Agreements. Click Create Trade Agreements. Click New. In the Name field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Click Lines. In the list, mark the selected row. In the Party code type field, select an option. In the Account selection field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Item relation field, enter or select a value. Close the page. In the Item relation field, type a value. In the Site field, type a value. In the Warehouse field, type a value. In the Amount in currency field, enter a number. Click Post. Click OK. Refresh the page. Close the page. On the Action Pane, click Trade Agreements. Click View sales prices. Close the page. Close the page. Go to Accounts receivable > Orders > All sales orders. In the list, find and select the desired record. Click New.","title":"Trade Agreements Price Group"},{"location":"TradeAgreementsPriceGroup/#trade-agreements-price-group","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Trade Agreements Price Group"},{"location":"TradeAgreementsPriceGroup/#trade-agreements-price-group_1","text":"Go to Inventory Management > Setup > Price/Discount > Customer Price/Discount Groups. Click New. In the Price Groups field, type a value. In the Name field, type a value. On the Action Pane, click Trade Agreements. Click Save. On the Action Pane, click Trade Agreements. Click View Sales Prices. Close the page. One the Action Pane, click Trade Agreements. Click View Trade Agreements (sales). Close the page. On the Action Pane, click Trade Agreements. Close the page. Go to Product Information Management > Products > Released Products. In the list, click the link in the select row. Close the page. Go to Accounts Receivable > Customers > All customers. In the list, find and select the desired record. In the list, click the link in the selected row. Click Edit. In the Price field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. Click Save. Close the page. Go to Inventory Management > Setup > Price/Discount > Customer Price/Discount Groups. In the list, find and select the desired record. On the Action Pane, click Trade Agreements. Click Create Trade Agreements. Click New. In the Name field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Click Lines. In the list, mark the selected row. In the Party code type field, select an option. In the Account selection field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Item relation field, enter or select a value. Close the page. In the Item relation field, type a value. In the Site field, type a value. In the Warehouse field, type a value. In the Amount in currency field, enter a number. Click Post. Click OK. Refresh the page. Close the page. On the Action Pane, click Trade Agreements. Click View sales prices. Close the page. Close the page. Go to Accounts receivable > Orders > All sales orders. In the list, find and select the desired record. Click New.","title":"Trade Agreements Price Group"},{"location":"Unit-Testing-Entity-Mappings/","text":"Introduction This library provides the base classes and utility classes to help you bild unit tests for the integration framework. It contains classes in the following categories: * Mapping Unit Test Helper Classes * Service Bus Helper and Mock classes * Integration Test Helper Classes Mapping Unit Test Helper Classes EntityMapBuilderExtensionsTestHelper The EntityMapBuilderExtensionsTestHelper class contains static methods you can use to obtain an EntityMapProvider<> for a particular scenario and methods to execute A2B and B2A synchronization using the EntityMapProvider<> obtained. To create a unit test that can test a mapping scenario, reference this library in your test project. Then create a unit test using the following steps: Call GetEntityMapProvider (Type entityMapBuilderType, string methodName) passing the source target template parameter types as defined on the mapping method along with the class that contains the mapping method and the name of the mapping method that you want to test. For example, to test the mapping for AxEntities.ScaleTicketGradeFactor and ScaleHouseEntities.ScaleTicketGradeFactor make the following call: var mapProvider = EntityMapBuilderExtensionsTestHelper.GetEntityMapProvider<AxEntities.ScaleTicketGradeFactor, ScaleHouseEntities.ScaleTicketGradeFactor>(typeof(AxToScaleEntityMapBuilderExtensions), \"MapAXScaleTicketGradeFactor_ScaleHouseScaleTicketGradeFactor\"); Instantiate and populate the entities you want to use for mapping. I prefer to use the [MemberData] attribute to provide multiple instances for testing. See this article for example on providing data for unit tests. Use the EntityMapProvider<> to perform the mapping by calling one of the transform methods on The EntityMapBuilderExtensionsTestHelper class. For example, to test the B2A mapping for the previous example use the following code: AXentity = EntityMapBuilderExtensionsTestHelper.TransformB2A(mapProvider, ScaleEntity, AXentity); Assert - check the mapped values In order to test the expected values you should have an instance of the target object with the expected values and then get the transformed object from the target entity and compare the two. You can pass in an object with the expected values using the MemberData method. Example: // Get target object var targetObject = AXentity.GetEntityAsDotNetType<AxEntities.ScaleTicketGradeFactor>(); // Assert Assert.NotNull(targetObject); Assert.Equal(expectedResult.GradeFactorId, targetObject.GradeFactorId); Assert.Equal(expectedResult.GradeFactorValue, targetObject.GradeFactorValue); Assert.Equal(expectedResult.TicketNumber, targetObject.TicketNumber); Assert.Equal(expectedResult.LineNumber, targetObject.LineNumber); Using MemberData to Provide Unit Test Data If you want to use the MemberData method for building data to use in your unit tests (you can refer to this article for an over view) here are some ideas. 1. Create Methods to Instantiate and Populate the Source and Expected Target Objects I would recommend creating a private static method on your test class that recieves parameters that can be used to initialize the class with the desired values. If you need several parameters you can put them in an object array or Key Value pair or even a dictionary. Example: private static AxEntities.ScaleTicketGradeFactor GetAxTicketGradeFactorObject(int line, string id, string value, string ticketNumber) { return new AxEntities.ScaleTicketGradeFactor() { LineNumber = line, GradeFactorId = id, GradeFactorValue = decimal.Parse(value), TicketNumber = ticketNumber }; } 2. Create Methods to Instantiate and Populate the Source and Target Entities Once you have a populated source object you can use it to instantiate and initialize a source Entity. Example: private static Entity GetAxTicketGradeFactorEntity(AxEntities.ScaleTicketGradeFactor scaleTicketGradeFactor = null) { var axScaleTicketGradeFactor = scaleTicketGradeFactor ?? new AxEntities.ScaleTicketGradeFactor(); Entity entity = DynamicsAxEntities.Instance.GetScaleTicketGradeFactorEntity(); entity.CreateAndPopulateEntityFields(typeof(JSONField<>), axScaleTicketGradeFactor); return entity; } As you can see, if an object is provided, it is used to initialize the Entity. Otherwise a default object is used. 3. Implement the MemberData Method As described in this article for an over view) the MemberData method must return IEnumerable<object[]> . You can craete a method that uses the methods described in the previous steps to create source & target entities along with a target expected object. Then you can define that method using the [MemberData] attribute. Here is an example MemberData method: public static IEnumerable<object[]> GetSynchronizeA2BGradeFactorData() { return new List<object[]> { new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(1, \"A\", \"8\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(1, \"A\", \"8\", \"0000169\") }, new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(2, \"AB\", \"0.3\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(2, \"AB\", \"0.3\", \"0000169\") }, new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(3, \"AS\", \"31.3\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(3, \"AS\", \"31.3\", \"0000169\") } }; } Example Unit Test Here is an example unit test that tests Ticket Grade Factor entities from the ScaleHouse application to F&O. [Theory] [MemberData(nameof(GetSynchronizeB2AGradeFactorData))] public void MapScaleTicketGradeFactor_SynchronizeB2AGradeFactor_CorrectMapping( Entity AXentity, // AX ticket grade factor Entity ScaleEntity, // Scale house ticket grade factor AxEntities.ScaleTicketGradeFactor expectedResult) { // Arrange var mapProvider = EntityMapBuilderExtensionsTestHelper.GetEntityMapProvider<AxEntities.ScaleTicketGradeFactor, ScaleHouseEntities.ScaleTicketGradeFactor> (typeof(AxToScaleEntityMapBuilderExtensions), \"MapAXScaleTicketGradeFactor_ScaleHouseScaleTicketGradeFactor\"); //Act // Transform AXentity = EntityMapBuilderExtensionsTestHelper.TransformB2A(mapProvider, ScaleEntity, AXentity); // Get target object var targetObject = AXentity.GetEntityAsDotNetType<AxEntities.ScaleTicketGradeFactor>(); // Assert Assert.NotNull(targetObject); Assert.Equal(expectedResult.GradeFactorId, targetObject.GradeFactorId); Assert.Equal(expectedResult.GradeFactorValue, targetObject.GradeFactorValue); Assert.Equal(expectedResult.TicketNumber, targetObject.TicketNumber); Assert.Equal(expectedResult.LineNumber, targetObject.LineNumber); }","title":"Introduction"},{"location":"Unit-Testing-Entity-Mappings/#introduction","text":"This library provides the base classes and utility classes to help you bild unit tests for the integration framework. It contains classes in the following categories: * Mapping Unit Test Helper Classes * Service Bus Helper and Mock classes * Integration Test Helper Classes","title":"Introduction"},{"location":"Unit-Testing-Entity-Mappings/#mapping-unit-test-helper-classes","text":"","title":"Mapping Unit Test Helper Classes"},{"location":"Unit-Testing-Entity-Mappings/#entitymapbuilderextensionstesthelper","text":"The EntityMapBuilderExtensionsTestHelper class contains static methods you can use to obtain an EntityMapProvider<> for a particular scenario and methods to execute A2B and B2A synchronization using the EntityMapProvider<> obtained. To create a unit test that can test a mapping scenario, reference this library in your test project. Then create a unit test using the following steps: Call GetEntityMapProvider (Type entityMapBuilderType, string methodName) passing the source target template parameter types as defined on the mapping method along with the class that contains the mapping method and the name of the mapping method that you want to test. For example, to test the mapping for AxEntities.ScaleTicketGradeFactor and ScaleHouseEntities.ScaleTicketGradeFactor make the following call: var mapProvider = EntityMapBuilderExtensionsTestHelper.GetEntityMapProvider<AxEntities.ScaleTicketGradeFactor, ScaleHouseEntities.ScaleTicketGradeFactor>(typeof(AxToScaleEntityMapBuilderExtensions), \"MapAXScaleTicketGradeFactor_ScaleHouseScaleTicketGradeFactor\"); Instantiate and populate the entities you want to use for mapping. I prefer to use the [MemberData] attribute to provide multiple instances for testing. See this article for example on providing data for unit tests. Use the EntityMapProvider<> to perform the mapping by calling one of the transform methods on The EntityMapBuilderExtensionsTestHelper class. For example, to test the B2A mapping for the previous example use the following code: AXentity = EntityMapBuilderExtensionsTestHelper.TransformB2A(mapProvider, ScaleEntity, AXentity); Assert - check the mapped values In order to test the expected values you should have an instance of the target object with the expected values and then get the transformed object from the target entity and compare the two. You can pass in an object with the expected values using the MemberData method. Example: // Get target object var targetObject = AXentity.GetEntityAsDotNetType<AxEntities.ScaleTicketGradeFactor>(); // Assert Assert.NotNull(targetObject); Assert.Equal(expectedResult.GradeFactorId, targetObject.GradeFactorId); Assert.Equal(expectedResult.GradeFactorValue, targetObject.GradeFactorValue); Assert.Equal(expectedResult.TicketNumber, targetObject.TicketNumber); Assert.Equal(expectedResult.LineNumber, targetObject.LineNumber);","title":"EntityMapBuilderExtensionsTestHelper"},{"location":"Unit-Testing-Entity-Mappings/#using-memberdata-to-provide-unit-test-data","text":"If you want to use the MemberData method for building data to use in your unit tests (you can refer to this article for an over view) here are some ideas.","title":"Using MemberData to Provide Unit Test Data"},{"location":"Unit-Testing-Entity-Mappings/#1-create-methods-to-instantiate-and-populate-the-source-and-expected-target-objects","text":"I would recommend creating a private static method on your test class that recieves parameters that can be used to initialize the class with the desired values. If you need several parameters you can put them in an object array or Key Value pair or even a dictionary. Example: private static AxEntities.ScaleTicketGradeFactor GetAxTicketGradeFactorObject(int line, string id, string value, string ticketNumber) { return new AxEntities.ScaleTicketGradeFactor() { LineNumber = line, GradeFactorId = id, GradeFactorValue = decimal.Parse(value), TicketNumber = ticketNumber }; }","title":"1. Create Methods to Instantiate and Populate the Source and Expected Target Objects"},{"location":"Unit-Testing-Entity-Mappings/#2-create-methods-to-instantiate-and-populate-the-source-and-target-entities","text":"Once you have a populated source object you can use it to instantiate and initialize a source Entity. Example: private static Entity GetAxTicketGradeFactorEntity(AxEntities.ScaleTicketGradeFactor scaleTicketGradeFactor = null) { var axScaleTicketGradeFactor = scaleTicketGradeFactor ?? new AxEntities.ScaleTicketGradeFactor(); Entity entity = DynamicsAxEntities.Instance.GetScaleTicketGradeFactorEntity(); entity.CreateAndPopulateEntityFields(typeof(JSONField<>), axScaleTicketGradeFactor); return entity; } As you can see, if an object is provided, it is used to initialize the Entity. Otherwise a default object is used.","title":"2. Create Methods to Instantiate and Populate the Source and Target Entities"},{"location":"Unit-Testing-Entity-Mappings/#3-implement-the-memberdata-method","text":"As described in this article for an over view) the MemberData method must return IEnumerable<object[]> . You can craete a method that uses the methods described in the previous steps to create source & target entities along with a target expected object. Then you can define that method using the [MemberData] attribute. Here is an example MemberData method: public static IEnumerable<object[]> GetSynchronizeA2BGradeFactorData() { return new List<object[]> { new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(1, \"A\", \"8\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(1, \"A\", \"8\", \"0000169\") }, new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(2, \"AB\", \"0.3\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(2, \"AB\", \"0.3\", \"0000169\") }, new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(3, \"AS\", \"31.3\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(3, \"AS\", \"31.3\", \"0000169\") } }; }","title":"3. Implement the MemberData Method"},{"location":"Unit-Testing-Entity-Mappings/#example-unit-test","text":"Here is an example unit test that tests Ticket Grade Factor entities from the ScaleHouse application to F&O. [Theory] [MemberData(nameof(GetSynchronizeB2AGradeFactorData))] public void MapScaleTicketGradeFactor_SynchronizeB2AGradeFactor_CorrectMapping( Entity AXentity, // AX ticket grade factor Entity ScaleEntity, // Scale house ticket grade factor AxEntities.ScaleTicketGradeFactor expectedResult) { // Arrange var mapProvider = EntityMapBuilderExtensionsTestHelper.GetEntityMapProvider<AxEntities.ScaleTicketGradeFactor, ScaleHouseEntities.ScaleTicketGradeFactor> (typeof(AxToScaleEntityMapBuilderExtensions), \"MapAXScaleTicketGradeFactor_ScaleHouseScaleTicketGradeFactor\"); //Act // Transform AXentity = EntityMapBuilderExtensionsTestHelper.TransformB2A(mapProvider, ScaleEntity, AXentity); // Get target object var targetObject = AXentity.GetEntityAsDotNetType<AxEntities.ScaleTicketGradeFactor>(); // Assert Assert.NotNull(targetObject); Assert.Equal(expectedResult.GradeFactorId, targetObject.GradeFactorId); Assert.Equal(expectedResult.GradeFactorValue, targetObject.GradeFactorValue); Assert.Equal(expectedResult.TicketNumber, targetObject.TicketNumber); Assert.Equal(expectedResult.LineNumber, targetObject.LineNumber); }","title":"Example Unit Test"},{"location":"Unit_of_Measure_Setup/","text":"Unit of Measure Setup The unit of measure integration between F&O and CE does not currently include conversions. It only makes sure that each UOM in F&O has a corresponding UOM in CE and that the UOM is placed in the correct Unit Group. The Primary UOM for a unit group can not be changed after the Unit group is created. Because the integration will randomly assign the default UOM when it creates a unit group, it is important to always create the Unit group manually prior to running the integration. The following fields should be set in CE to their matching values (Including capitalization) from F&O for every Unit Class that will be integrated to CE. Once the integration of UOM is run, outstanding UOM records should be placed into their correct Unit Group and have the correct base UOM.","title":"Unit of Measure Setup"},{"location":"Unit_of_Measure_Setup/#unit-of-measure-setup","text":"The unit of measure integration between F&O and CE does not currently include conversions. It only makes sure that each UOM in F&O has a corresponding UOM in CE and that the UOM is placed in the correct Unit Group. The Primary UOM for a unit group can not be changed after the Unit group is created. Because the integration will randomly assign the default UOM when it creates a unit group, it is important to always create the Unit group manually prior to running the integration. The following fields should be set in CE to their matching values (Including capitalization) from F&O for every Unit Class that will be integrated to CE. Once the integration of UOM is run, outstanding UOM records should be placed into their correct Unit Group and have the correct base UOM.","title":"Unit of Measure Setup"},{"location":"UploadStandardCostPricing/","text":"Upload Standard Cost Pricing Overview INSERT How to Upload Standard Cost Pricing Go to Cost Management > Predetermined cost policies setup > Costing Versions. In the list, find and select the desired record. Click Price Click Item Price. Click the Active Prices tab. Click the Pending Prices tab. Click New. In the list, mark the selected row. In the item number field, type a value. In the Site field, type a value. In the Price field, enter a number. Click Save. Click Open in Microsoft Office. Click Pending item prices (100). Click Download. Click Open in Microsoft Office. Click Pending Item Prices. Click Download. Refresh the page. In the list, mark or unmark all rows. Click Activate pending price(s). Click the Active prices tab. Close the page. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the item number field with a value of 'harness'. On the Action Pane, click Manage Inventory. On the Action pane, click Manage Costs. Click Item price. In the list, find and select the desired record.","title":"Upload Standard Cost Pricing"},{"location":"UploadStandardCostPricing/#upload-standard-cost-pricing","text":"","title":"Upload Standard Cost Pricing"},{"location":"UploadStandardCostPricing/#overview","text":"INSERT","title":"Overview"},{"location":"UploadStandardCostPricing/#how-to-upload-standard-cost-pricing","text":"Go to Cost Management > Predetermined cost policies setup > Costing Versions. In the list, find and select the desired record. Click Price Click Item Price. Click the Active Prices tab. Click the Pending Prices tab. Click New. In the list, mark the selected row. In the item number field, type a value. In the Site field, type a value. In the Price field, enter a number. Click Save. Click Open in Microsoft Office. Click Pending item prices (100). Click Download. Click Open in Microsoft Office. Click Pending Item Prices. Click Download. Refresh the page. In the list, mark or unmark all rows. Click Activate pending price(s). Click the Active prices tab. Close the page. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the item number field with a value of 'harness'. On the Action Pane, click Manage Inventory. On the Action pane, click Manage Costs. Click Item price. In the list, find and select the desired record.","title":"How to Upload Standard Cost Pricing"},{"location":"UuidCompositeRequest/","text":"UuidCompositeRequest The UuidCompositeRequest object is used by the AgsyncUUID controller to make a request for UUID values based on SyncId values passed in the request. JSON Defintion JSON Example { \"accountId\": \"ABC\", \"accountName\": \"Levridge - Barnesville\", \"growerId\": \"CUS-100442\", \"growerName\": \"Captain Cook Farms\", \"farmId\": \"COP100263\", \"farmeName\": \"Captain Cook Farms\", \"fieldId\": \"CST-400312\", \"fieldName\": \"CC Veggie Field NE\" } JSON Schema { \"$schema\": \"http://json-schema.org/draft-07/schema\", \"$id\": \"http://example.com/example.json\", \"type\": \"object\", \"readOnly\": false, \"writeOnly\": false, \"minProperties\": 0, \"title\": \"UuidCompositeRequest\", \"description\": \"This schema comprises the entire JSON document for a Composite Request\", \"additionalProperties\": true, \"required\": [ \"accountId\" ], \"properties\": { \"accountId\": { \"$id\": \"#/properties/accountId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountId Schema\", \"description\": \"The Sync Id for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"SCG1\" ] }, \"accountName\": { \"$id\": \"#/properties/accountName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountName Schema\", \"description\": \"This is an optional name for the account\", \"default\": \"\", \"examples\": [ \"Alexandria\" ] }, \"growerId\": { \"$id\": \"#/properties/growerId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerId Schema\", \"description\": \"The Sync Id for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"CUS-100347\" ] }, \"growerName\": { \"$id\": \"#/properties/growerName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerName Schema\", \"description\": \"This is an optional name for the Grower\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"farmId\": { \"$id\": \"#/properties/farmId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmId Schema\", \"description\": \"The Sync Id for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"COP100208\" ] }, \"farmeName\": { \"$id\": \"#/properties/farmeName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmeName Schema\", \"description\": \"This is an optional name for the Farm\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"fieldId\": { \"$id\": \"#/properties/fieldId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldId Schema\", \"description\": \"The Sync Id for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"CST-000026\" ] }, \"fieldName\": { \"$id\": \"#/properties/fieldName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldName Schema\", \"description\": \"This is an optional name for the Field\", \"default\": \"\", \"examples\": [ \"NW 40\" ] } } }","title":"UuidCompositeRequest"},{"location":"UuidCompositeRequest/#uuidcompositerequest","text":"The UuidCompositeRequest object is used by the AgsyncUUID controller to make a request for UUID values based on SyncId values passed in the request.","title":"UuidCompositeRequest"},{"location":"UuidCompositeRequest/#json-defintion","text":"","title":"JSON Defintion"},{"location":"UuidCompositeRequest/#json-example","text":"{ \"accountId\": \"ABC\", \"accountName\": \"Levridge - Barnesville\", \"growerId\": \"CUS-100442\", \"growerName\": \"Captain Cook Farms\", \"farmId\": \"COP100263\", \"farmeName\": \"Captain Cook Farms\", \"fieldId\": \"CST-400312\", \"fieldName\": \"CC Veggie Field NE\" }","title":"JSON Example"},{"location":"UuidCompositeRequest/#json-schema","text":"{ \"$schema\": \"http://json-schema.org/draft-07/schema\", \"$id\": \"http://example.com/example.json\", \"type\": \"object\", \"readOnly\": false, \"writeOnly\": false, \"minProperties\": 0, \"title\": \"UuidCompositeRequest\", \"description\": \"This schema comprises the entire JSON document for a Composite Request\", \"additionalProperties\": true, \"required\": [ \"accountId\" ], \"properties\": { \"accountId\": { \"$id\": \"#/properties/accountId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountId Schema\", \"description\": \"The Sync Id for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"SCG1\" ] }, \"accountName\": { \"$id\": \"#/properties/accountName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountName Schema\", \"description\": \"This is an optional name for the account\", \"default\": \"\", \"examples\": [ \"Alexandria\" ] }, \"growerId\": { \"$id\": \"#/properties/growerId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerId Schema\", \"description\": \"The Sync Id for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"CUS-100347\" ] }, \"growerName\": { \"$id\": \"#/properties/growerName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerName Schema\", \"description\": \"This is an optional name for the Grower\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"farmId\": { \"$id\": \"#/properties/farmId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmId Schema\", \"description\": \"The Sync Id for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"COP100208\" ] }, \"farmeName\": { \"$id\": \"#/properties/farmeName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmeName Schema\", \"description\": \"This is an optional name for the Farm\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"fieldId\": { \"$id\": \"#/properties/fieldId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldId Schema\", \"description\": \"The Sync Id for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"CST-000026\" ] }, \"fieldName\": { \"$id\": \"#/properties/fieldName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldName Schema\", \"description\": \"This is an optional name for the Field\", \"default\": \"\", \"examples\": [ \"NW 40\" ] } } }","title":"JSON Schema"},{"location":"UuidCompositeResponse/","text":"UuidCompositResponse The UuidCompositResponse object is used by the AgsyncUUID controller to return UUID values based on SyncId values passed in the request. JSON Defintion JSON Example { \"accountId\": \"BAR\", \"accountUuid\": \"336a8049-853c-4992-8382-e77e8868e208\", \"accountGuid\": \"000ad538-0000-0000-0000-000000000000\", \"accountName\": null, \"growerId\": \"CUS-100442\", \"growerUuid\": \"63ffb30a-aaf6-4cbe-83b7-95765aa2c5e4\", \"growerGuid\": \"000ceb06-0000-0000-0000-000000000000\", \"growerName\": null, \"farmId\": \"COP100263\", \"farmUuid\": \"d4334cd1-1a1f-4484-94d6-246645e07196\", \"farmGuid\": \"000ceb07-0000-0000-0000-000000000000\", \"farmName\": null, \"fieldId\": \"CST-400312\", \"fieldUuid\": \"9e0f0647-c21a-495a-92a2-9d0aaaf2bc8f\", \"fieldGuid\": \"001a5c8a-0000-0000-0000-000000000000\", \"fieldName\": null } JSON Schema { \"$schema\": \"http://json-schema.org/draft-07/schema\", \"$id\": \"http://example.com/example.json\", \"type\": \"object\", \"readOnly\": false, \"writeOnly\": false, \"minProperties\": 0, \"title\": \"The UuidCompositeResponse Schema\", \"description\": \"The root schema comprises the entire JSON document for Composite Response\", \"additionalProperties\": true, \"required\": [], \"properties\": { \"accountId\": { \"$id\": \"#/properties/accountId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountId Schema\", \"description\": \"The Sync Id for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"SCG1\" ] }, \"accountUuid\": { \"$id\": \"#/properties/accountUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountUuid Schema\", \"description\": \"The UUID for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"e0485a5d-f6c1-4a0e-824a-1abffbcfaa9\" ] }, \"accountGuid\": { \"$id\": \"#/properties/accountGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountGuid Schema\", \"description\": \"The GUID for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"000c33a4-0000-0000-0000-000000000000\" ] }, \"accountName\": { \"$id\": \"#/properties/accountName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountName Schema\", \"description\": \"This is an optional name for the account\", \"default\": \"\", \"examples\": [ \"Alexandria\" ] }, \"growerId\": { \"$id\": \"#/properties/growerId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerId Schema\", \"description\": \"The Sync Id for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"CUS-100347\" ] }, \"growerUuid\": { \"$id\": \"#/properties/growerUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerUuid Schema\", \"description\": \"The UUID for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"ad5ee735-c783-45d3-9b7a-5e7b089b1fbf\" ] }, \"growerGuid\": { \"$id\": \"#/properties/growerGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerGuid Schema\", \"description\": \"The GUID for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"000cd991-0000-0000-0000-000000000000\" ] }, \"growerName\": { \"$id\": \"#/properties/growerName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerName Schema\", \"description\": \"This is an optional name for the grower\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"farmId\": { \"$id\": \"#/properties/farmId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmId Schema\", \"description\": \"The Sync Id for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"COP100208\" ] }, \"farmUuid\": { \"$id\": \"#/properties/farmUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmUuid Schema\", \"description\": \"The UUID for the Grower (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"1f7b3ecc-e2eb-4724-b9ec-f0b756d21566\" ] }, \"farmGuid\": { \"$id\": \"#/properties/farmGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmGuid Schema\", \"description\": \"The GUID for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"000cd992-0000-0000-0000-000000000000\" ] }, \"farmeName\": { \"$id\": \"#/properties/farmeName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmeName Schema\", \"description\": \"This is an optional name for the farm\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"fieldId\": { \"$id\": \"#/properties/fieldId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldId Schema\", \"description\": \"The Sync Id for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"CST-000026\" ] }, \"fieldUuid\": { \"$id\": \"#/properties/fieldUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldUuid Schema\", \"description\": \"The UUID for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"2ac15a5a-2c8a-4f65-b5fe-3706637937ec\" ] }, \"fieldGuid\": { \"$id\": \"#/properties/fieldGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldGuid Schema\", \"description\": \"The GUID for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"001a4769-0000-0000-0000-000000000000\" ] }, \"fieldName\": { \"$id\": \"#/properties/fieldName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldName Schema\", \"description\": \"This is an optional name for the field\", \"default\": \"\", \"examples\": [ \"NW 40\" ] } } }","title":"UuidCompositResponse"},{"location":"UuidCompositeResponse/#uuidcompositresponse","text":"The UuidCompositResponse object is used by the AgsyncUUID controller to return UUID values based on SyncId values passed in the request.","title":"UuidCompositResponse"},{"location":"UuidCompositeResponse/#json-defintion","text":"","title":"JSON Defintion"},{"location":"UuidCompositeResponse/#json-example","text":"{ \"accountId\": \"BAR\", \"accountUuid\": \"336a8049-853c-4992-8382-e77e8868e208\", \"accountGuid\": \"000ad538-0000-0000-0000-000000000000\", \"accountName\": null, \"growerId\": \"CUS-100442\", \"growerUuid\": \"63ffb30a-aaf6-4cbe-83b7-95765aa2c5e4\", \"growerGuid\": \"000ceb06-0000-0000-0000-000000000000\", \"growerName\": null, \"farmId\": \"COP100263\", \"farmUuid\": \"d4334cd1-1a1f-4484-94d6-246645e07196\", \"farmGuid\": \"000ceb07-0000-0000-0000-000000000000\", \"farmName\": null, \"fieldId\": \"CST-400312\", \"fieldUuid\": \"9e0f0647-c21a-495a-92a2-9d0aaaf2bc8f\", \"fieldGuid\": \"001a5c8a-0000-0000-0000-000000000000\", \"fieldName\": null }","title":"JSON Example"},{"location":"UuidCompositeResponse/#json-schema","text":"{ \"$schema\": \"http://json-schema.org/draft-07/schema\", \"$id\": \"http://example.com/example.json\", \"type\": \"object\", \"readOnly\": false, \"writeOnly\": false, \"minProperties\": 0, \"title\": \"The UuidCompositeResponse Schema\", \"description\": \"The root schema comprises the entire JSON document for Composite Response\", \"additionalProperties\": true, \"required\": [], \"properties\": { \"accountId\": { \"$id\": \"#/properties/accountId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountId Schema\", \"description\": \"The Sync Id for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"SCG1\" ] }, \"accountUuid\": { \"$id\": \"#/properties/accountUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountUuid Schema\", \"description\": \"The UUID for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"e0485a5d-f6c1-4a0e-824a-1abffbcfaa9\" ] }, \"accountGuid\": { \"$id\": \"#/properties/accountGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountGuid Schema\", \"description\": \"The GUID for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"000c33a4-0000-0000-0000-000000000000\" ] }, \"accountName\": { \"$id\": \"#/properties/accountName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountName Schema\", \"description\": \"This is an optional name for the account\", \"default\": \"\", \"examples\": [ \"Alexandria\" ] }, \"growerId\": { \"$id\": \"#/properties/growerId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerId Schema\", \"description\": \"The Sync Id for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"CUS-100347\" ] }, \"growerUuid\": { \"$id\": \"#/properties/growerUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerUuid Schema\", \"description\": \"The UUID for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"ad5ee735-c783-45d3-9b7a-5e7b089b1fbf\" ] }, \"growerGuid\": { \"$id\": \"#/properties/growerGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerGuid Schema\", \"description\": \"The GUID for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"000cd991-0000-0000-0000-000000000000\" ] }, \"growerName\": { \"$id\": \"#/properties/growerName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerName Schema\", \"description\": \"This is an optional name for the grower\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"farmId\": { \"$id\": \"#/properties/farmId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmId Schema\", \"description\": \"The Sync Id for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"COP100208\" ] }, \"farmUuid\": { \"$id\": \"#/properties/farmUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmUuid Schema\", \"description\": \"The UUID for the Grower (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"1f7b3ecc-e2eb-4724-b9ec-f0b756d21566\" ] }, \"farmGuid\": { \"$id\": \"#/properties/farmGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmGuid Schema\", \"description\": \"The GUID for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"000cd992-0000-0000-0000-000000000000\" ] }, \"farmeName\": { \"$id\": \"#/properties/farmeName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmeName Schema\", \"description\": \"This is an optional name for the farm\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"fieldId\": { \"$id\": \"#/properties/fieldId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldId Schema\", \"description\": \"The Sync Id for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"CST-000026\" ] }, \"fieldUuid\": { \"$id\": \"#/properties/fieldUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldUuid Schema\", \"description\": \"The UUID for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"2ac15a5a-2c8a-4f65-b5fe-3706637937ec\" ] }, \"fieldGuid\": { \"$id\": \"#/properties/fieldGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldGuid Schema\", \"description\": \"The GUID for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"001a4769-0000-0000-0000-000000000000\" ] }, \"fieldName\": { \"$id\": \"#/properties/fieldName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldName Schema\", \"description\": \"This is an optional name for the field\", \"default\": \"\", \"examples\": [ \"NW 40\" ] } } }","title":"JSON Schema"},{"location":"VFD/","text":"Veterinary Feed Initiatives (VFD) Overview Veterinary Feed Directives (VFDs) are prescriptions for antibiotics written by veterinarians for livestock. The antibiotics specified in VFDs are dispensed in certain dosages for a herd and are placed/hosted with the feed given to livestock. VFDs and the antibiotics with them are governed and restricted differently by the various states and countries. Levridge supports the legal tracking, creation and consumption of Veterinary Feed Directives (VFD) within host feed items. Prior to creating VFDs perform these initial system setup steps: Create a VFD drug group Feed and livestock > Setup > Veterinary feed directive (VFD) drug groups Click New Enter a VFD group and description Click Save Note - An inclusive restricted product regional list needs to be created for each country before an exclusive list is created. Product information management > Setup > Product compliance > Restricted products regional lists Click New Select a country, state, list ID and description. In the Restricted list type field select Exclusive and save. Create a restricted product which will host the active ingredient listed in the VFD Product information management > Products > Released products Select an item In the Manage inventory action pane click Restricted products Click New Enter data and select the product regional list created earlier. Save the new record. Click Restricted VFD groups Click New Select the VFD group created earlier and save Close the Restricted VFD groups form In the released products form, go to the Active ingredient fast tab and enter an Active ingredient Enter a rate like 4000 mg per 1 lb Indicate what actions should happen when delivering and invoicing sales orders containing host items that have Active ingredients/antibiotics and there is not a valid VFD or if the customer's VFDs have been consumed Feed and livestock > Setup > Veterinary feed directive (VFD) compliance In the compliance form, mark the desired settings for enabling warnings and/or preventing postings for deliverying and invoicing orders To begin entering and consuming VFDs: Create a VFD Accounts receivable > Customers > All customers > Select the customer with a VFD > Agriculture > Veterinary feed directives Click New In the VFD drug group field, select the drug group set up earlier Enter the customer operation the VFD is written for Enter values for the prescription name, issued and expiration dates, dosage quantity and unit, number of head and head quantity. If desired, to determine the rate of consumption of the active ingredient: In the Dosage calculator section of the VFD form, enter values for the rate, base weight and herd average weight and click the Calculate dosage button. If desired, to quickly create a sales order for this VFD: Click the Create sales order button in this VFD form and in the dialog that opens fields will be defaulted from the VFD. In the Items section of the dialog, click the ellipses button (three dots) and click Find items. The Items grid will be populated with all the possible host products for the active ingredient/antibiotic in the VFD. In the grid on the line for the desired host product, enter the quantity of the host product to consume. Click OK and a new sales order will be created. To consume the VFD Accounts receivable > Orders > All sales orders Click New and enter values including the customer operation the VFD is written for On the sales order line, create a new line and select the restricted product created earlier that is a host for the active ingredient in the VFD Enter a quantity for the selected item. Once the quantity is entered, the VFD created for the current customer operation will be defaulted onto the sales line. When the sales order is delivered, the VFD will be consumed according to the quantity on the sales line and the rate of active ingredient specified on the item. If an active, valid VFD does not exist for the customer operation, a warning or error will be presented based on the settings specified earlier.","title":"Veterinary Feed Initiatives (VFD)"},{"location":"VFD/#veterinary-feed-initiatives-vfd","text":"","title":"Veterinary Feed Initiatives (VFD)"},{"location":"VFD/#overview","text":"Veterinary Feed Directives (VFDs) are prescriptions for antibiotics written by veterinarians for livestock. The antibiotics specified in VFDs are dispensed in certain dosages for a herd and are placed/hosted with the feed given to livestock. VFDs and the antibiotics with them are governed and restricted differently by the various states and countries. Levridge supports the legal tracking, creation and consumption of Veterinary Feed Directives (VFD) within host feed items. Prior to creating VFDs perform these initial system setup steps: Create a VFD drug group Feed and livestock > Setup > Veterinary feed directive (VFD) drug groups Click New Enter a VFD group and description Click Save Note - An inclusive restricted product regional list needs to be created for each country before an exclusive list is created. Product information management > Setup > Product compliance > Restricted products regional lists Click New Select a country, state, list ID and description. In the Restricted list type field select Exclusive and save. Create a restricted product which will host the active ingredient listed in the VFD Product information management > Products > Released products Select an item In the Manage inventory action pane click Restricted products Click New Enter data and select the product regional list created earlier. Save the new record. Click Restricted VFD groups Click New Select the VFD group created earlier and save Close the Restricted VFD groups form In the released products form, go to the Active ingredient fast tab and enter an Active ingredient Enter a rate like 4000 mg per 1 lb Indicate what actions should happen when delivering and invoicing sales orders containing host items that have Active ingredients/antibiotics and there is not a valid VFD or if the customer's VFDs have been consumed Feed and livestock > Setup > Veterinary feed directive (VFD) compliance In the compliance form, mark the desired settings for enabling warnings and/or preventing postings for deliverying and invoicing orders","title":"Overview"},{"location":"VFD/#to-begin-entering-and-consuming-vfds","text":"Create a VFD Accounts receivable > Customers > All customers > Select the customer with a VFD > Agriculture > Veterinary feed directives Click New In the VFD drug group field, select the drug group set up earlier Enter the customer operation the VFD is written for Enter values for the prescription name, issued and expiration dates, dosage quantity and unit, number of head and head quantity. If desired, to determine the rate of consumption of the active ingredient: In the Dosage calculator section of the VFD form, enter values for the rate, base weight and herd average weight and click the Calculate dosage button. If desired, to quickly create a sales order for this VFD: Click the Create sales order button in this VFD form and in the dialog that opens fields will be defaulted from the VFD. In the Items section of the dialog, click the ellipses button (three dots) and click Find items. The Items grid will be populated with all the possible host products for the active ingredient/antibiotic in the VFD. In the grid on the line for the desired host product, enter the quantity of the host product to consume. Click OK and a new sales order will be created.","title":"To begin entering and consuming VFDs:"},{"location":"VFD/#to-consume-the-vfd","text":"Accounts receivable > Orders > All sales orders Click New and enter values including the customer operation the VFD is written for On the sales order line, create a new line and select the restricted product created earlier that is a host for the active ingredient in the VFD Enter a quantity for the selected item. Once the quantity is entered, the VFD created for the current customer operation will be defaulted onto the sales line. When the sales order is delivered, the VFD will be consumed according to the quantity on the sales line and the rate of active ingredient specified on the item. If an active, valid VFD does not exist for the customer operation, a warning or error will be presented based on the settings specified earlier.","title":"To consume the VFD"},{"location":"Vendor_Purchasing_Rebates/","text":"Vendor Purchasing Rebates Levridge has expanded vendor rebate to include the option to evaluate the line breaks retroactively and base the rebate on the total lifetime value. Vendor Rebate Group A link has been added to the vendor for access to the vendor rebate table. This will allow the user to select the vendor rebate groups that need to be associated with that vendor. The vendor rebate group now includes a \u2018Vendor Selection\u2019 option that shows all vendors assigned to the selected vendor item rebate group. Vendors may be added or removed from the group. Item Rebate Group A link has been added to the item release for access to the item rebate table. This will allow the user to select the item rebate groups that need to be associated with that item. The item rebate group now includes an \u2018Item Selection\u2019 option to show all products assigned to the selected vendor item rebate group. Products may be added or removed from the group. Product dimensions may also be displayed. Rebate Agreement The rebate agreement defines parameters that trigger the cumulation of rebates. The agreement parameters include: Switch to allow retroactive rebate based on a lifetime of cumulative purchases. Upon creation of a vendor rebate agreement, the default expiry date of never has been changed to one year following the start date. The user has the option to update the expiry date. Rebate Process Once the rebate agreements are setup up properly, every time a Purchase order is invoiced, the rebate will show up in the accrual account as well as in the Rebate claims screen. A rebate claims screen will provide details of rebates processed. Processing from the claims will create a credit on the vendors account that can be left as a credit or settled against an invoice.","title":"Vendor Purchasing Rebates"},{"location":"Vendor_Purchasing_Rebates/#vendor-purchasing-rebates","text":"Levridge has expanded vendor rebate to include the option to evaluate the line breaks retroactively and base the rebate on the total lifetime value.","title":"Vendor Purchasing Rebates"},{"location":"Vendor_Purchasing_Rebates/#vendor-rebate-group","text":"A link has been added to the vendor for access to the vendor rebate table. This will allow the user to select the vendor rebate groups that need to be associated with that vendor. The vendor rebate group now includes a \u2018Vendor Selection\u2019 option that shows all vendors assigned to the selected vendor item rebate group. Vendors may be added or removed from the group.","title":"Vendor Rebate Group"},{"location":"Vendor_Purchasing_Rebates/#item-rebate-group","text":"A link has been added to the item release for access to the item rebate table. This will allow the user to select the item rebate groups that need to be associated with that item. The item rebate group now includes an \u2018Item Selection\u2019 option to show all products assigned to the selected vendor item rebate group. Products may be added or removed from the group. Product dimensions may also be displayed.","title":"Item Rebate Group"},{"location":"Vendor_Purchasing_Rebates/#rebate-agreement","text":"The rebate agreement defines parameters that trigger the cumulation of rebates. The agreement parameters include: Switch to allow retroactive rebate based on a lifetime of cumulative purchases. Upon creation of a vendor rebate agreement, the default expiry date of never has been changed to one year following the start date. The user has the option to update the expiry date.","title":"Rebate Agreement"},{"location":"Vendor_Purchasing_Rebates/#rebate-process","text":"Once the rebate agreements are setup up properly, every time a Purchase order is invoiced, the rebate will show up in the accrual account as well as in the Rebate claims screen. A rebate claims screen will provide details of rebates processed. Processing from the claims will create a credit on the vendors account that can be left as a credit or settled against an invoice.","title":"Rebate Process"},{"location":"VeterinaryFeedDirectives/","text":"Veterinary Feed Directives (VFD) Overview Veterinary Feed Directives (VFDs) are prescriptions for antibiotics written by veterinarians for livestock. The antibiotics specified in VFDs are dispensed in certain dosages for a herd and are placed/hosted with the feed given to livestock. VFDs and the antibiotics with them are governed and restricted differently by the various states and countries. Levridge supports the legal tracking, creation and consumption of Veterinary Feed Directives (VFD) within host feed items. Initial System Setup Steps Prior to creating VFDs perform these initial system setup steps: Create a VFD drug group Feed and livestock > Setup > Veterinary feed directive (VFD) drug groups Click New Enter a VFD group and description Click Save Create a restricted product regional list Note - An inclusive restricted product regional list needs to be created for each country before an exclusive list is created. Product information management > Setup > Product compliance > Restricted products regional lists Click New Select a country, state, list ID and description. In the Restricted list type field select Exclusive and save. Create a restricted product which will host the active ingredient listed in the VFD Product information management > Products > Released products Select an item In the Manage inventory action pane click Restricted products Click New Enter data and select the product regional list created earlier. Save the new record. Click Restricted VFD groups Click New Select the VFD group created earlier and save Close the Restricted VFD groups form In the released products form, go to the Active ingredient fast tab and enter an Active ingredient Enter a rate like 4000 mg per 1 lb Indicate what actions should happen when delivering and invoicing sales orders containing host items that have Active ingredients/antibiotics and there is not a valid VFD or if the customer's VFDs have been consumed Feed and livestock > Setup > Veterinary feed directive (VFD) compliance In the compliance form, mark the desired settings for enabling warnings and/or preventing postings for deliverying and invoicing orders To begin entering and consuming VFDs: Create a VFD Accounts receivable > Customers > All customers > Select the customer with a VFD > Agriculture > Veterinary feed directives Click New In the VFD drug group field, select the drug group set up earlier Enter the customer operation the VFD is written for Enter values for the prescription name, issued and expiration dates, dosage quantity and unit, number of head and head quantity. If desired, to determine the rate of consumption of the active ingredient: In the Dosage calculator section of the VFD form, enter values for the rate, base weight and herd average weight and click the Calculate dosage button. If desired, to quickly create a sales order for this VFD: Click the Create sales order button in this VFD form and in the dialog that opens fields will be defaulted from the VFD. In the Items section of the dialog, click the ellipses button (three dots) and click Find items. The Items grid will be populated with all the possible host products for the active ingredient/antibiotic in the VFD. In the grid on the line for the desired host product, enter the quantity of the host product to consume. Click OK and a new sales order will be created. To consume the VFD Accounts receivable > Orders > All sales orders Click New and enter values including the customer operation the VFD is written for On the sales order line, create a new line and select the restricted product created earlier that is a host for the active ingredient in the VFD Enter a quantity for the selected item. Once the quantity is entered, the VFD created for the current customer operation will be defaulted onto the sales line. When the sales order is delivered, the VFD will be consumed according to the quantity on the sales line and the rate of active ingredient specified on the item. If an active, valid VFD does not exist for the customer operation, a warning or error will be presented based on the settings specified earlier.","title":"Veterinary Feed Directives (VFD)"},{"location":"VeterinaryFeedDirectives/#veterinary-feed-directives-vfd","text":"","title":"Veterinary Feed Directives (VFD)"},{"location":"VeterinaryFeedDirectives/#overview","text":"Veterinary Feed Directives (VFDs) are prescriptions for antibiotics written by veterinarians for livestock. The antibiotics specified in VFDs are dispensed in certain dosages for a herd and are placed/hosted with the feed given to livestock. VFDs and the antibiotics with them are governed and restricted differently by the various states and countries. Levridge supports the legal tracking, creation and consumption of Veterinary Feed Directives (VFD) within host feed items.","title":"Overview"},{"location":"VeterinaryFeedDirectives/#initial-system-setup-steps","text":"Prior to creating VFDs perform these initial system setup steps: Create a VFD drug group Feed and livestock > Setup > Veterinary feed directive (VFD) drug groups Click New Enter a VFD group and description Click Save Create a restricted product regional list Note - An inclusive restricted product regional list needs to be created for each country before an exclusive list is created. Product information management > Setup > Product compliance > Restricted products regional lists Click New Select a country, state, list ID and description. In the Restricted list type field select Exclusive and save. Create a restricted product which will host the active ingredient listed in the VFD Product information management > Products > Released products Select an item In the Manage inventory action pane click Restricted products Click New Enter data and select the product regional list created earlier. Save the new record. Click Restricted VFD groups Click New Select the VFD group created earlier and save Close the Restricted VFD groups form In the released products form, go to the Active ingredient fast tab and enter an Active ingredient Enter a rate like 4000 mg per 1 lb Indicate what actions should happen when delivering and invoicing sales orders containing host items that have Active ingredients/antibiotics and there is not a valid VFD or if the customer's VFDs have been consumed Feed and livestock > Setup > Veterinary feed directive (VFD) compliance In the compliance form, mark the desired settings for enabling warnings and/or preventing postings for deliverying and invoicing orders","title":"Initial System Setup Steps"},{"location":"VeterinaryFeedDirectives/#to-begin-entering-and-consuming-vfds","text":"Create a VFD Accounts receivable > Customers > All customers > Select the customer with a VFD > Agriculture > Veterinary feed directives Click New In the VFD drug group field, select the drug group set up earlier Enter the customer operation the VFD is written for Enter values for the prescription name, issued and expiration dates, dosage quantity and unit, number of head and head quantity. If desired, to determine the rate of consumption of the active ingredient: In the Dosage calculator section of the VFD form, enter values for the rate, base weight and herd average weight and click the Calculate dosage button. If desired, to quickly create a sales order for this VFD: Click the Create sales order button in this VFD form and in the dialog that opens fields will be defaulted from the VFD. In the Items section of the dialog, click the ellipses button (three dots) and click Find items. The Items grid will be populated with all the possible host products for the active ingredient/antibiotic in the VFD. In the grid on the line for the desired host product, enter the quantity of the host product to consume. Click OK and a new sales order will be created.","title":"To begin entering and consuming VFDs:"},{"location":"VeterinaryFeedDirectives/#to-consume-the-vfd","text":"Accounts receivable > Orders > All sales orders Click New and enter values including the customer operation the VFD is written for On the sales order line, create a new line and select the restricted product created earlier that is a host for the active ingredient in the VFD Enter a quantity for the selected item. Once the quantity is entered, the VFD created for the current customer operation will be defaulted onto the sales line. When the sales order is delivered, the VFD will be consumed according to the quantity on the sales line and the rate of active ingredient specified on the item. If an active, valid VFD does not exist for the customer operation, a warning or error will be presented based on the settings specified earlier.","title":"To consume the VFD"},{"location":"about/","text":"","title":"About"},{"location":"agsyncConfigObject/","text":"Agsync Settings Agsync is an object in the appsettings.json file used by the Levridge Integration Framework. To define the configuration for the integration of Agsync Workorders to FinOps. Example \"agsync\": { \"MustUseWktProcessor\": true, \"ConnectionString\": \"Endpoint=[Customer Servicebus Connection String]\", \"TopicName\": \"[Customer Servicebus Topic]\", \"SubscriptionName\": \"[Customer Servicebus Topic Subscription]\", \"PrefetchCount\": 5, \"RequiresSession\": [true/false], \"RedirectUri\": \"[Agsync Integration Base URL]/api/AgsyncAuth\", \"TokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"AuthorizeUrl\": \"https://auth.agsync.com/core/connect/authorize\", \"baseUri\": \"https://fields.agsync.com/api/\", \"rejectUri\": \"https://orders.agsync.com/api/orders/\", \"ClientId\": \"[Agsync assigned client ID]\", \"ClientPass\": \"[Agsync assigned client password]\", \"VaultURL\": \"[Integration Framework Key Vault URL]\", \"AgSyncTokenKey\": \"[Vault Key Used for Access Token]\" \"WktUrl\": \"[Agsync Integration Base URL]/api/WktProcessor\", \"ProcessStatuses\": \"Plan,Released,Canceled,Scheduled,Rejected,Completed,Accepted\", \"MustUseCustomerSite\": true } Definition MustUseWktProcessor The MustUseWktProcessor attribute contains a bollean that specifies whether or not to process the WKT sent in the workorder from Agsync to FinOps. ConnectionString TopicName SubscriptionName PrefetchCount RequiresSession RedirectUri TokenUrl AuthorizeUrl baseUri rejectUri ClientId ClientPass VaultURL AgSyncTokenKey ProcessStatuses Not Required Place a comma delimited list of statuses that should be processed by the controller. It is important to make sure the capitalization is correct (Title Case) because it does an exact match. Deafult: \"Planned,Released,Canceled,Scheduled,Rejected,Completed,Accepted\" MustUseCustomerSite Not Required Set this value to true to require a valid customer site on work orders. Set this value to false to ignore the customer site on work orders. Default: true","title":"Agsync Settings"},{"location":"agsyncConfigObject/#agsync-settings","text":"Agsync is an object in the appsettings.json file used by the Levridge Integration Framework. To define the configuration for the integration of Agsync Workorders to FinOps.","title":"Agsync Settings"},{"location":"agsyncConfigObject/#example","text":"\"agsync\": { \"MustUseWktProcessor\": true, \"ConnectionString\": \"Endpoint=[Customer Servicebus Connection String]\", \"TopicName\": \"[Customer Servicebus Topic]\", \"SubscriptionName\": \"[Customer Servicebus Topic Subscription]\", \"PrefetchCount\": 5, \"RequiresSession\": [true/false], \"RedirectUri\": \"[Agsync Integration Base URL]/api/AgsyncAuth\", \"TokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"AuthorizeUrl\": \"https://auth.agsync.com/core/connect/authorize\", \"baseUri\": \"https://fields.agsync.com/api/\", \"rejectUri\": \"https://orders.agsync.com/api/orders/\", \"ClientId\": \"[Agsync assigned client ID]\", \"ClientPass\": \"[Agsync assigned client password]\", \"VaultURL\": \"[Integration Framework Key Vault URL]\", \"AgSyncTokenKey\": \"[Vault Key Used for Access Token]\" \"WktUrl\": \"[Agsync Integration Base URL]/api/WktProcessor\", \"ProcessStatuses\": \"Plan,Released,Canceled,Scheduled,Rejected,Completed,Accepted\", \"MustUseCustomerSite\": true }","title":"Example"},{"location":"agsyncConfigObject/#definition","text":"","title":"Definition"},{"location":"agsyncConfigObject/#mustusewktprocessor","text":"The MustUseWktProcessor attribute contains a bollean that specifies whether or not to process the WKT sent in the workorder from Agsync to FinOps.","title":"MustUseWktProcessor"},{"location":"agsyncConfigObject/#connectionstring","text":"","title":"ConnectionString"},{"location":"agsyncConfigObject/#topicname","text":"","title":"TopicName"},{"location":"agsyncConfigObject/#subscriptionname","text":"","title":"SubscriptionName"},{"location":"agsyncConfigObject/#prefetchcount","text":"","title":"PrefetchCount"},{"location":"agsyncConfigObject/#requiressession","text":"","title":"RequiresSession"},{"location":"agsyncConfigObject/#redirecturi","text":"","title":"RedirectUri"},{"location":"agsyncConfigObject/#tokenurl","text":"","title":"TokenUrl"},{"location":"agsyncConfigObject/#authorizeurl","text":"","title":"AuthorizeUrl"},{"location":"agsyncConfigObject/#baseuri","text":"","title":"baseUri"},{"location":"agsyncConfigObject/#rejecturi","text":"","title":"rejectUri"},{"location":"agsyncConfigObject/#clientid","text":"","title":"ClientId"},{"location":"agsyncConfigObject/#clientpass","text":"","title":"ClientPass"},{"location":"agsyncConfigObject/#vaulturl","text":"","title":"VaultURL"},{"location":"agsyncConfigObject/#agsynctokenkey","text":"","title":"AgSyncTokenKey"},{"location":"agsyncConfigObject/#processstatuses","text":"Not Required Place a comma delimited list of statuses that should be processed by the controller. It is important to make sure the capitalization is correct (Title Case) because it does an exact match. Deafult: \"Planned,Released,Canceled,Scheduled,Rejected,Completed,Accepted\"","title":"ProcessStatuses"},{"location":"agsyncConfigObject/#mustusecustomersite","text":"Not Required Set this value to true to require a valid customer site on work orders. Set this value to false to ignore the customer site on work orders. Default: true","title":"MustUseCustomerSite"},{"location":"appsettings.json/","text":"appsettings.json The appsettings.json is a configuration file that is used in standard Microsoft Configuration for ASP.NET Core to provide application settings. This document explains the various json objects used in the appsettings.json file. Overview AzureAd The AzureAd section provides the necesary information for authentication. see AzureAd Settings Controllers The controllers section provides a list of json objects that define which controllers to load for the current Levridge Integration Framework instance. See Controllers Settings Logging The Levridge Integration Framework utilizes the standard ASP.NET Core logging capabilities. The Logging section defines the logging settings for the various logging providers being used. See Logging Settings InstanceConfig The InstanceConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework. See InstanceConfig Settings SourceConfig The SourceConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction. See SourceConfig Settings TargetConfig The TargetConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Target of an integration interaction. See TargetConfig Settings","title":"appsettings.json"},{"location":"appsettings.json/#appsettingsjson","text":"The appsettings.json is a configuration file that is used in standard Microsoft Configuration for ASP.NET Core to provide application settings. This document explains the various json objects used in the appsettings.json file.","title":"appsettings.json"},{"location":"appsettings.json/#overview","text":"","title":"Overview"},{"location":"appsettings.json/#azuread","text":"The AzureAd section provides the necesary information for authentication. see AzureAd Settings","title":"AzureAd"},{"location":"appsettings.json/#controllers","text":"The controllers section provides a list of json objects that define which controllers to load for the current Levridge Integration Framework instance. See Controllers Settings","title":"Controllers"},{"location":"appsettings.json/#logging","text":"The Levridge Integration Framework utilizes the standard ASP.NET Core logging capabilities. The Logging section defines the logging settings for the various logging providers being used. See Logging Settings","title":"Logging"},{"location":"appsettings.json/#instanceconfig","text":"The InstanceConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework. See InstanceConfig Settings","title":"InstanceConfig"},{"location":"appsettings.json/#sourceconfig","text":"The SourceConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction. See SourceConfig Settings","title":"SourceConfig"},{"location":"appsettings.json/#targetconfig","text":"The TargetConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Target of an integration interaction. See TargetConfig Settings","title":"TargetConfig"},{"location":"command-line-arguments/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"command-line-arguments/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"command-line-arguments/#overview","text":"","title":"Overview"},{"location":"command-line-arguments/#main-point-1","text":"","title":"Main Point 1"},{"location":"command-line-arguments/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"equity-management-implementation-activities/","text":"Equity Management Implementation Activities Overview The following is an overview of the implementation activities necessary for getting started with processing equity. Initial Implementation Activities In FinOps, update released products with a patronage unit In FinOps, setup equity vendor journals In FinOps, setup equity vendor payments including checks In FinOps, setup any patronage payment distributions on customers From FinOps, push via the Levridge integration customers, contacts, item categories, units of measure, branches and addresses to CE In CE, setup patronage specific information: a. Stock classes Sources Periods Patronage split lines Into CE, import stock subscriptions Into CE, import stock subscrptions Into CE, import any equity credits from other systems (if applicable) In CE, create patronage categories a. Setup per unit and revenue allocations Setup 199A allocations In CE, setup requirements equity In CE, setup equity revolvements Year-End Activities In FinOps, export out patronage sales In CE, import imported transactions (these are what was exported from FinOps or other systems) In CE, run patronage detail to create eligible transactions a. Verify results (this takes most of the time) i. Eligible transactions were created properly ii. Split look as expected In CE, run patronage category allocations a. Verify results (this takes most of the time) i. Payments ii. Equity credits In CE, run equity revolvements a. Verify results i. Payment details ii. Equity credits updated accordingly In CE, run retirement equity summaries In CE, create payment summaries a. Verify results In CE, export payment summaries In FinOps, import payment summaries which become vendor journals In FinOps, post vendor journals In FinOps, pay equity vendor invoices Calendar Year-End Activities In CE, create non-patronage distributions for 1099 PATR In CE, create 1099 PATR credits In CE, create 1099 PATR records a. Verify results In CE, build 1099 PATR electronic file a. Verify results In CE, print copy B and copy C of the 1099 PATR records","title":"Equity Management Implementation Activities"},{"location":"equity-management-implementation-activities/#equity-management-implementation-activities","text":"","title":"Equity Management Implementation Activities"},{"location":"equity-management-implementation-activities/#overview","text":"The following is an overview of the implementation activities necessary for getting started with processing equity.","title":"Overview"},{"location":"equity-management-implementation-activities/#initial-implementation-activities","text":"In FinOps, update released products with a patronage unit In FinOps, setup equity vendor journals In FinOps, setup equity vendor payments including checks In FinOps, setup any patronage payment distributions on customers From FinOps, push via the Levridge integration customers, contacts, item categories, units of measure, branches and addresses to CE In CE, setup patronage specific information: a. Stock classes Sources Periods Patronage split lines Into CE, import stock subscriptions Into CE, import stock subscrptions Into CE, import any equity credits from other systems (if applicable) In CE, create patronage categories a. Setup per unit and revenue allocations Setup 199A allocations In CE, setup requirements equity In CE, setup equity revolvements","title":"Initial Implementation Activities"},{"location":"equity-management-implementation-activities/#year-end-activities","text":"In FinOps, export out patronage sales In CE, import imported transactions (these are what was exported from FinOps or other systems) In CE, run patronage detail to create eligible transactions a. Verify results (this takes most of the time) i. Eligible transactions were created properly ii. Split look as expected In CE, run patronage category allocations a. Verify results (this takes most of the time) i. Payments ii. Equity credits In CE, run equity revolvements a. Verify results i. Payment details ii. Equity credits updated accordingly In CE, run retirement equity summaries In CE, create payment summaries a. Verify results In CE, export payment summaries In FinOps, import payment summaries which become vendor journals In FinOps, post vendor journals In FinOps, pay equity vendor invoices","title":"Year-End Activities"},{"location":"equity-management-implementation-activities/#calendar-year-end-activities","text":"In CE, create non-patronage distributions for 1099 PATR In CE, create 1099 PATR credits In CE, create 1099 PATR records a. Verify results In CE, build 1099 PATR electronic file a. Verify results In CE, print copy B and copy C of the 1099 PATR records","title":"Calendar Year-End Activities"},{"location":"equity-management-overview/","text":"Equity Management Overview Equity Management Process Equity Management Implementation Activities","title":"Equity Management"},{"location":"equity-management-overview/#equity-management","text":"","title":"Equity Management"},{"location":"equity-management-overview/#overview","text":"Equity Management Process Equity Management Implementation Activities","title":"Overview"},{"location":"equity-management/","text":"Equity Management Overview Equity Management is the management of cooperative shares, member equity, and member dividends (the more common type is patronage). These are dividends or distributions that a co-operative pays to its members or investors. Most co-ops call these patronage dividends. Patronage dividends are given based on a proportion of profit that the business makes. Once this amount is determined, management calculates the dividend according to how much each member has used the co-op's services. It is typically an annual process of generating dividends and equity balances. Managing this process has been streamlined and simplified within the Levridge solution. In a few simple steps, you can accurately set up splits, distributions, equity, reports, and cut checks. Implementation Activities The Equity Management Implementation Activities provides an overview of the implementation activities necessary for getting started with processing equity management. Base Type Functionality The equity management solutions is operated on Dynamics 365 Customer Engagement (CE) functionality, with an integration from F&O. There is certain functionality that is reliant on the integration between F&O and CE Patronage to get the data into the system, one of those being \u201cProducts\u201d under the Setup navigation area. All the products listed are integrated over from F&O. D365 CE Setup Functionality Products The Product form includes multiple views. This is accomplished by clicking on a certain product line. The two main factors related to Patronage are: Eligible for Patronage: This field is set to either yes or no. Patronage unit: The goal is to know how Patronage is paid out on a product. Products can be sold in different types of unit, for example: ounce, pound, ton, vs. bushel, bag, individually. The default sales unit can be different than the Patronage itself. For example, a product sold in pounds but paid in tons. The Item Category, Relationship to the Product, and Products under Site Navigator are reliant on the integration between F&O and CE Patronage. They are areas integrated from F&O. An important item to note is outlining what item category relates to which Patronage category. The Patronage category is the determining factor of what items will be calculated and what items will be pulled in at different rates based. Stock Classes This section allows a cooperative to set up stock classes. Some cooperatives will have many stock classes, some will have none. Periods Periods include calendar and fiscal periods. These are not integrated from F&O and set up on CE Patronage. Fiscal period: 1099PATR reporting is run on calendar year, requiring the fiscal period to include a year calendar. Split due date: A Patronage Split is how a grower would like their patronage eligible transactions to be split to another grower. The Split due date is the date the annual member letters must be returned by. This used when cooperatives send their annual letters to their members and the date they request the letter to be returned. Minimum Spend: This is the minimum spend amount within a period to receive patronage. There is currently no functionality around this field and more for informational purposes. Minimum Voting Activity: There is currently no functionality around this field and more for informational purposes. Sources Sources is where the transactional data comes from including previous years. You could have multiple sources if you have had mergers or acquisitions with other cooperatives. They include rules and regulations from mergers and acquisitions with other cooperatives. With those cooperatives comes different rules and regulations, and this is where cooperatives can identify where those transactions come from, different payout rates, and what rules should apply. If a cooperative has not undergone a merger or acquisition, there will more than likely be only one source information. Primary retirement age: This field is used to set up the retirement age that members will get paid out. This annotates what age the member is eligible to receive Patronage. Secondary retirement age: This field is used as a secondary option to pay out Patronage. This is the age where Patronage pay outs are mandatory. There is currently no functionality around this field and more for informational purposes. Default stock class: There is currently no functionality around this field and more for informational purposes. Minimum payout threshold: Can enter the minimum amount the company will pay patronage on. This is informational and can be used building the payment summary export if included in the query that is built. Minimum Dividend percentage: Can enter the minimum percentage to receive dividends. This is informational and can be included when building queries. ERP System: This field is to track where the ERP system information comes from. There is currently no functionality around this field and more for informational purposes. 1099PATR Filing Entity: This field annotates if a member is filing a 1099PATR. If set to yes, the source is available to create 1099-PATR records for and you can populate the information on the Filing Details tab. The Filings Details tab outlines the information required on a 1099PATR electronic filing report. Address, Phone number, Tax ID number, Name, Contact Imported Transaction An Imported Transaction includes the Transaction Details, outlining the Invoice Number, Branch, Source, and the ability to mark whether it is an eligible transaction. The \u201cCreate Patronage Detail\u201d process needs to be run to create eligible transactions utilizing the patronage splits defined on the account record. There is the traceability functionality under \u201cEligible Transactions\u201d where you can view where the transactions came from and how they are being processed and utilized throughout the system. Customer Information Account Form Account Information: The fields are integrated over from F&O. Patronage Contact: is who would be receiving the retirement benefits. Estate Contact: in the case if a member dies and want to identify who we should be working out on behalf of their estate. No functional relevance as what is calculated. Purely who we should talk to if there are questions on payouts. Membership: These fields are integrated over from F&O and include: Membership Type, Tax ID Number, Tax ID Type. Patronage Split Lines: Patronage Split Lines are stored in the Patronage CE and used to calculate the eligible transactions which patronage can be calculated from. Patronage Summary: Displays the equity and payment summary for the account. Summarized by period, payout type, distribution type, and source Stock Summary: Displays the total stock subscriptions by stock class for the account. Reports There are several reporting statements available per account, to include: allocation and payment by account. Stocks Stock Subscriptions outline how many shares one has in a certain stock along with payment date, amount, and certificate number. Stock transfers and adjustments can be completed within the system. There are two stock types: Account type: A transfer of stock to another account. There is the option for an approval process under this type. Stock class type: Changing stocks into another type of stock. Adjustments: if there was a data entry error or, one can make adjustments. This field is highly auditable with several restrictions D365 Finance and Operations Equity Management Customers The Customer Account information includes a Membership tab for informational data. It does not drive functionality. It includes the following fields: Membership Type, Patron, Membership Date, Member ID, and Legal Classification Legal classification is utilized with 1099PATR reporting Released Product Details includes the Patronage unit where fields on the product need to be set up. The unit conversions come from the Patronage unit field and needs to be set up through F&O to be able to calculate the right unit when you switch over to D365 CE. Payment Details By clicking on \u201cProcess patronage\u201d, one can pull invoices within a specific date range, reading the invoice lines not creating. Converting the invoiced units to patronage units if the patronage unit is different on the released items. It also pulls in charge codes or discounts. Charge codes can be set up to either increase in price or decrease in price depending on how your rules are set up. When a sales order is generated, the F&O will break up the sales order into split allocations, creating an invoice to the customers financially responsible for what was delivered. From the information generated, one can export the data into an Excel file or CSV file to import into CE. This is done by \"Imported Transactions\" under the standard import functionality. You can then filter the list and \"Create Patronage Detail\". This takes the information you have from your patronage splits and whether this item is chargeable and nonchargeable and creates your eligible transactions. The data needs to be in the right format to be imported into CE and can be imported from any system, not just F&O. Eligible Transactions Patronage processing is generated once all eligible transactions have been created. One does not need to bring in imported transactions if they do not use splits or are already split out, they can import right into Eligible Transactions. These are the records that will be used when calculating the equity credit and payments through Patronage Category allocations. Equity Management Categories Equity management categories are set up based on what is being paid out and based on sources. If a cooperative has had mergers or acquisitions, or importing categories from previous years, there will likely be a variety of categories Patronage has been processed under. The categories can be calculated by revenue or by units. Direct products are not associated directly to a patronage category instead they choose the item categories of those products. Based on that relationship between item category and product that is what is determined which eligible transactions to pull in when it runs that calculation. An item category can only belong to one patronage category. All the eligible transactions are siphoned into the Patronage Category Allocation. Eligible transactions need to be listed as a sale or purchase. The Percent of Revenue is the total percent of revenue and dictates the Cash Percentage, creating a payment detail. The remaining of that would create an Equity Credit paid out later. These calculations can apply to certain branches. If a Patronage Category is calculated by Units, instead of reference how much is purchased, you are referencing quantity. It is classified as a rate if based on units. The Cash percentage would create a payment detail record with the rest going to an equity credit. Which the traceability you can view were created from that process. If the Patronage Category is calculated by units, Section199A Allocations can be set up which appear on the 1099PATR Deductions will be generated based on units purchased and the payout rate under a Specific Section1 allocation. This feeds into the 1099PATR processing. Once the allocation is run, one can no longer generate a new transaction. It becomes inactive. The other section that is created from this allocation is an equity credit. Equity Equity Credits If an equity is not paid out in the current calendar year, it moves into an equity credit value that would later determine what would be paid out This is created from the Patronage Calculation. These credits are run every year based on the items purchased or sold within that year to see how much would be paid out in the current year along with future years. An equity credit can be adjusted. Equity Revolvements Equity Revolvements are used to determine what to pay out on existing equity credits from prior years. Here is where you annotate what percentage to pay out for a certain source, class, distribution type, or period. Based on that criteria, payment detail records are created. You can set up a Payment Schedule for the credits to be paid out in multiple years. Retirement Equity This can be a manual or run process. The equity summary shows how much equity is available to be paid out and is a tracking mechanism to view whether one qualifies for a payout and if they request one. If a payout is requested, one can create payment details and send over to the system being utilized to for payouts. This process is traceable. Annual Allocations The 1099 information is located under the Annual Allocations navigation. It includes: Deductions Non-Patronage Distribution 1099 Credits 1099 PATR ##### 1099 PATR The 1099 PATR is a form a cooperative files for each person whom: The cooperative has paid at least $10 in patronage dividends and other distributions described in IRS tax section 6044(b). The cooperative withheld any federal income tax under the backup withholding rules regardless of the amount of the payment. When a cooperative collects new information for a 1099 year, they would create a new 1099 PATR form. Under 1099 PATR, click \u201cBuild 1099 PATR\u201d A dialog box will open asking to select the following: 1099 Year (a calendar year) Source (where you want the information to be coming from) This is the information collected previously under Source. Click Generate. This generates the records requested and pulls in the details required for the form. Additional items that make up a 1099 PATR form include: General Account Information 1099 Credit This includes a variety of credit types available. Deductions Records created from Patronage categories Non-Patronage Distributions Includes all the source data that made up the record. This is necessary for auditing purposes Payments Equity Credits Related The 1099 PATR form is used for electronic filing. The cooperative can print either 1099 PATR-B or 1099 PATR-C versions of the 1099 PATR to provide to their members for tax purposes. The 1099 PATR form is also available online and can be accessed through a portal for members to download. Equity Management Power BI Dashboards There are several dashboards available for Patronage through Power BI. These are powerful reporting tools to analyze and view key Patronage data and summaries. They are located: Customer Info navigation tab > Customers > Customer Info > Add Dashboards > Patronage Dashboard The following dashboards are already pre-loaded: 1099A Deductions Allocation Summary Eligible Transactions Equity Credit Equity Revolvements Patronage Dashboard Payment Details and Summary The Equity Management Category Process creates an individual payment detail record for each eligible transaction. There is a summarize payment option that if you use the Advanced Find functionality received with CE, you can put in any sort of query you want to show payment details and from there can \"Generate Payment Summary\". This would summarize all the records. Once you have that summary detail, you can export it to an Excel file. This is the data you would bring into your financial system. Once the data is exported, you can go into F&O under Accounts Payable and import the data. This will create a vendor invoice for each record. Once you have the vendor invoices, you can create a journal specific to equity management. There are designations for specific invoice journals for equity management. The equity management journal is different from a standard invoice journal due to bringing in and identifying the customer account. A core function in F&O is when those transactions are processed and imported from CE, F&O can pay out on a different account (a financial split vs payment split). Once in F&O, the customer can decide where they would like the distribution to be sent to and the allocated percentage. There are variety of payment journals one can choose from. When journals are set up to pay out, ensure equity payment is specified along with the check and device format. There are up to five options to choose from. There is the ability for multiple check formats and the ability to include additional information on check stubs. This is located under Payment Proposal.","title":"Equity Management"},{"location":"equity-management/#equity-management","text":"","title":"Equity Management"},{"location":"equity-management/#overview","text":"Equity Management is the management of cooperative shares, member equity, and member dividends (the more common type is patronage). These are dividends or distributions that a co-operative pays to its members or investors. Most co-ops call these patronage dividends. Patronage dividends are given based on a proportion of profit that the business makes. Once this amount is determined, management calculates the dividend according to how much each member has used the co-op's services. It is typically an annual process of generating dividends and equity balances. Managing this process has been streamlined and simplified within the Levridge solution. In a few simple steps, you can accurately set up splits, distributions, equity, reports, and cut checks.","title":"Overview"},{"location":"equity-management/#implementation-activities","text":"The Equity Management Implementation Activities provides an overview of the implementation activities necessary for getting started with processing equity management.","title":"Implementation Activities"},{"location":"equity-management/#base-type-functionality","text":"The equity management solutions is operated on Dynamics 365 Customer Engagement (CE) functionality, with an integration from F&O. There is certain functionality that is reliant on the integration between F&O and CE Patronage to get the data into the system, one of those being \u201cProducts\u201d under the Setup navigation area. All the products listed are integrated over from F&O.","title":"Base Type Functionality"},{"location":"equity-management/#d365-ce-setup-functionality","text":"","title":"D365 CE Setup Functionality"},{"location":"equity-management/#products","text":"The Product form includes multiple views. This is accomplished by clicking on a certain product line. The two main factors related to Patronage are: Eligible for Patronage: This field is set to either yes or no. Patronage unit: The goal is to know how Patronage is paid out on a product. Products can be sold in different types of unit, for example: ounce, pound, ton, vs. bushel, bag, individually. The default sales unit can be different than the Patronage itself. For example, a product sold in pounds but paid in tons. The Item Category, Relationship to the Product, and Products under Site Navigator are reliant on the integration between F&O and CE Patronage. They are areas integrated from F&O. An important item to note is outlining what item category relates to which Patronage category. The Patronage category is the determining factor of what items will be calculated and what items will be pulled in at different rates based.","title":"Products"},{"location":"equity-management/#stock-classes","text":"This section allows a cooperative to set up stock classes. Some cooperatives will have many stock classes, some will have none.","title":"Stock Classes"},{"location":"equity-management/#periods","text":"Periods include calendar and fiscal periods. These are not integrated from F&O and set up on CE Patronage. Fiscal period: 1099PATR reporting is run on calendar year, requiring the fiscal period to include a year calendar. Split due date: A Patronage Split is how a grower would like their patronage eligible transactions to be split to another grower. The Split due date is the date the annual member letters must be returned by. This used when cooperatives send their annual letters to their members and the date they request the letter to be returned. Minimum Spend: This is the minimum spend amount within a period to receive patronage. There is currently no functionality around this field and more for informational purposes. Minimum Voting Activity: There is currently no functionality around this field and more for informational purposes.","title":"Periods"},{"location":"equity-management/#sources","text":"Sources is where the transactional data comes from including previous years. You could have multiple sources if you have had mergers or acquisitions with other cooperatives. They include rules and regulations from mergers and acquisitions with other cooperatives. With those cooperatives comes different rules and regulations, and this is where cooperatives can identify where those transactions come from, different payout rates, and what rules should apply. If a cooperative has not undergone a merger or acquisition, there will more than likely be only one source information. Primary retirement age: This field is used to set up the retirement age that members will get paid out. This annotates what age the member is eligible to receive Patronage. Secondary retirement age: This field is used as a secondary option to pay out Patronage. This is the age where Patronage pay outs are mandatory. There is currently no functionality around this field and more for informational purposes. Default stock class: There is currently no functionality around this field and more for informational purposes. Minimum payout threshold: Can enter the minimum amount the company will pay patronage on. This is informational and can be used building the payment summary export if included in the query that is built. Minimum Dividend percentage: Can enter the minimum percentage to receive dividends. This is informational and can be included when building queries. ERP System: This field is to track where the ERP system information comes from. There is currently no functionality around this field and more for informational purposes. 1099PATR Filing Entity: This field annotates if a member is filing a 1099PATR. If set to yes, the source is available to create 1099-PATR records for and you can populate the information on the Filing Details tab. The Filings Details tab outlines the information required on a 1099PATR electronic filing report. Address, Phone number, Tax ID number, Name, Contact","title":"Sources"},{"location":"equity-management/#imported-transaction","text":"An Imported Transaction includes the Transaction Details, outlining the Invoice Number, Branch, Source, and the ability to mark whether it is an eligible transaction. The \u201cCreate Patronage Detail\u201d process needs to be run to create eligible transactions utilizing the patronage splits defined on the account record. There is the traceability functionality under \u201cEligible Transactions\u201d where you can view where the transactions came from and how they are being processed and utilized throughout the system.","title":"Imported Transaction"},{"location":"equity-management/#customer-information","text":"","title":"Customer Information"},{"location":"equity-management/#account-form","text":"Account Information: The fields are integrated over from F&O. Patronage Contact: is who would be receiving the retirement benefits. Estate Contact: in the case if a member dies and want to identify who we should be working out on behalf of their estate. No functional relevance as what is calculated. Purely who we should talk to if there are questions on payouts. Membership: These fields are integrated over from F&O and include: Membership Type, Tax ID Number, Tax ID Type. Patronage Split Lines: Patronage Split Lines are stored in the Patronage CE and used to calculate the eligible transactions which patronage can be calculated from. Patronage Summary: Displays the equity and payment summary for the account. Summarized by period, payout type, distribution type, and source Stock Summary: Displays the total stock subscriptions by stock class for the account.","title":"Account Form"},{"location":"equity-management/#reports","text":"There are several reporting statements available per account, to include: allocation and payment by account.","title":"Reports"},{"location":"equity-management/#stocks","text":"Stock Subscriptions outline how many shares one has in a certain stock along with payment date, amount, and certificate number. Stock transfers and adjustments can be completed within the system. There are two stock types: Account type: A transfer of stock to another account. There is the option for an approval process under this type. Stock class type: Changing stocks into another type of stock. Adjustments: if there was a data entry error or, one can make adjustments. This field is highly auditable with several restrictions","title":"Stocks"},{"location":"equity-management/#d365-finance-and-operations-equity-management","text":"","title":"D365 Finance and Operations Equity Management"},{"location":"equity-management/#customers","text":"The Customer Account information includes a Membership tab for informational data. It does not drive functionality. It includes the following fields: Membership Type, Patron, Membership Date, Member ID, and Legal Classification Legal classification is utilized with 1099PATR reporting Released Product Details includes the Patronage unit where fields on the product need to be set up. The unit conversions come from the Patronage unit field and needs to be set up through F&O to be able to calculate the right unit when you switch over to D365 CE.","title":"Customers"},{"location":"equity-management/#payment-details","text":"By clicking on \u201cProcess patronage\u201d, one can pull invoices within a specific date range, reading the invoice lines not creating. Converting the invoiced units to patronage units if the patronage unit is different on the released items. It also pulls in charge codes or discounts. Charge codes can be set up to either increase in price or decrease in price depending on how your rules are set up. When a sales order is generated, the F&O will break up the sales order into split allocations, creating an invoice to the customers financially responsible for what was delivered. From the information generated, one can export the data into an Excel file or CSV file to import into CE. This is done by \"Imported Transactions\" under the standard import functionality. You can then filter the list and \"Create Patronage Detail\". This takes the information you have from your patronage splits and whether this item is chargeable and nonchargeable and creates your eligible transactions. The data needs to be in the right format to be imported into CE and can be imported from any system, not just F&O.","title":"Payment Details"},{"location":"equity-management/#eligible-transactions","text":"Patronage processing is generated once all eligible transactions have been created. One does not need to bring in imported transactions if they do not use splits or are already split out, they can import right into Eligible Transactions. These are the records that will be used when calculating the equity credit and payments through Patronage Category allocations.","title":"Eligible Transactions"},{"location":"equity-management/#equity-management-categories","text":"Equity management categories are set up based on what is being paid out and based on sources. If a cooperative has had mergers or acquisitions, or importing categories from previous years, there will likely be a variety of categories Patronage has been processed under. The categories can be calculated by revenue or by units. Direct products are not associated directly to a patronage category instead they choose the item categories of those products. Based on that relationship between item category and product that is what is determined which eligible transactions to pull in when it runs that calculation. An item category can only belong to one patronage category. All the eligible transactions are siphoned into the Patronage Category Allocation. Eligible transactions need to be listed as a sale or purchase. The Percent of Revenue is the total percent of revenue and dictates the Cash Percentage, creating a payment detail. The remaining of that would create an Equity Credit paid out later. These calculations can apply to certain branches. If a Patronage Category is calculated by Units, instead of reference how much is purchased, you are referencing quantity. It is classified as a rate if based on units. The Cash percentage would create a payment detail record with the rest going to an equity credit. Which the traceability you can view were created from that process. If the Patronage Category is calculated by units, Section199A Allocations can be set up which appear on the 1099PATR Deductions will be generated based on units purchased and the payout rate under a Specific Section1 allocation. This feeds into the 1099PATR processing. Once the allocation is run, one can no longer generate a new transaction. It becomes inactive. The other section that is created from this allocation is an equity credit.","title":"Equity Management Categories"},{"location":"equity-management/#equity","text":"","title":"Equity"},{"location":"equity-management/#equity-credits","text":"If an equity is not paid out in the current calendar year, it moves into an equity credit value that would later determine what would be paid out This is created from the Patronage Calculation. These credits are run every year based on the items purchased or sold within that year to see how much would be paid out in the current year along with future years. An equity credit can be adjusted.","title":"Equity Credits"},{"location":"equity-management/#equity-revolvements","text":"Equity Revolvements are used to determine what to pay out on existing equity credits from prior years. Here is where you annotate what percentage to pay out for a certain source, class, distribution type, or period. Based on that criteria, payment detail records are created. You can set up a Payment Schedule for the credits to be paid out in multiple years.","title":"Equity Revolvements"},{"location":"equity-management/#retirement-equity","text":"This can be a manual or run process. The equity summary shows how much equity is available to be paid out and is a tracking mechanism to view whether one qualifies for a payout and if they request one. If a payout is requested, one can create payment details and send over to the system being utilized to for payouts. This process is traceable.","title":"Retirement Equity"},{"location":"equity-management/#annual-allocations","text":"The 1099 information is located under the Annual Allocations navigation. It includes: Deductions Non-Patronage Distribution 1099 Credits 1099 PATR ##### 1099 PATR The 1099 PATR is a form a cooperative files for each person whom: The cooperative has paid at least $10 in patronage dividends and other distributions described in IRS tax section 6044(b). The cooperative withheld any federal income tax under the backup withholding rules regardless of the amount of the payment. When a cooperative collects new information for a 1099 year, they would create a new 1099 PATR form. Under 1099 PATR, click \u201cBuild 1099 PATR\u201d A dialog box will open asking to select the following: 1099 Year (a calendar year) Source (where you want the information to be coming from) This is the information collected previously under Source. Click Generate. This generates the records requested and pulls in the details required for the form. Additional items that make up a 1099 PATR form include: General Account Information 1099 Credit This includes a variety of credit types available. Deductions Records created from Patronage categories Non-Patronage Distributions Includes all the source data that made up the record. This is necessary for auditing purposes Payments Equity Credits Related The 1099 PATR form is used for electronic filing. The cooperative can print either 1099 PATR-B or 1099 PATR-C versions of the 1099 PATR to provide to their members for tax purposes. The 1099 PATR form is also available online and can be accessed through a portal for members to download.","title":"Annual Allocations"},{"location":"equity-management/#equity-management-power-bi-dashboards","text":"There are several dashboards available for Patronage through Power BI. These are powerful reporting tools to analyze and view key Patronage data and summaries. They are located: Customer Info navigation tab > Customers > Customer Info > Add Dashboards > Patronage Dashboard The following dashboards are already pre-loaded: 1099A Deductions Allocation Summary Eligible Transactions Equity Credit Equity Revolvements Patronage Dashboard","title":"Equity Management Power BI Dashboards"},{"location":"equity-management/#payment-details-and-summary","text":"The Equity Management Category Process creates an individual payment detail record for each eligible transaction. There is a summarize payment option that if you use the Advanced Find functionality received with CE, you can put in any sort of query you want to show payment details and from there can \"Generate Payment Summary\". This would summarize all the records. Once you have that summary detail, you can export it to an Excel file. This is the data you would bring into your financial system. Once the data is exported, you can go into F&O under Accounts Payable and import the data. This will create a vendor invoice for each record. Once you have the vendor invoices, you can create a journal specific to equity management. There are designations for specific invoice journals for equity management. The equity management journal is different from a standard invoice journal due to bringing in and identifying the customer account. A core function in F&O is when those transactions are processed and imported from CE, F&O can pay out on a different account (a financial split vs payment split). Once in F&O, the customer can decide where they would like the distribution to be sent to and the allocated percentage. There are variety of payment journals one can choose from. When journals are set up to pay out, ensure equity payment is specified along with the check and device format. There are up to five options to choose from. There is the ability for multiple check formats and the ability to include additional information on check stubs. This is located under Payment Proposal.","title":"Payment Details and Summary"},{"location":"event_framework/","text":"Event Framework Overview The Event Framework enables the integration of data entities with other systems by sending entity data to an Azure Service Bus endpoint. The first time an Event Framework event is processed, all data is sent to the service bus endpoint. On subsequent runs, only entities that have changed are sent. If the same entity is contained in two different events; each event will operate independently, sending all changes to their respective endpoints. Event Framework events are intended to run daily as a batch service. Setup Event Framework Parameters System administration > Setup > Event framework > Event framework parameters Set the Environment name The Environment name is attached to Event framework messages sent from this system. This allows administrators to determine from which system an entity originated in the event of a failure. Enable the Event framework Set the Enabled switch to yes. Event framework messages will not be sent from this system when this switch is set to No. Create an Event Framework Endpoint System administration > Setup > Event framework > Event Framework endpoint definitions Click New Enter a name and description. Enter your Azure service bus endpoint connection string. If your endpoint requires sessions, set the switch to Yes. Enter the name of your topic or queue. Set the endpoint type to Topic or Queue. Set the Enabled switch to Yes. Create an Event Framework Event System administration > Setup > Event framework > Event framework events Click New. Enter a name and description. Choose your endpoint. If you wish to log a message to the Event Framework event log for successful and failed Event framework messages, set the Log success switch to Yes. The Last execution box contains the last execution date time. Set the Enabled switch to Yes. If this switch is No, the event will not be processed. Add an Entity to the Event Expand the Event tables Fast Tab. Click New. Select your entity in the Source table column. Change tracking type indicates whether all the entity\u2019s data sources are tracked for changes. Check the Propagate delete box to send a message when an instance of this entity is deleted. Entities are processed in ascending Line number order. Two entities with the same line number may be processed in either order. Add Event User Properties For every configured entity, you may add user properties to the Event framework message. The properties contain the value of the chosen entity field and are informational only. This is useful for filters applied to the Azure service bus subscription because the value of the property is added directly to the properties collection on the message rather than contains somewhere within the body. Adding an Entity Filter This filter restricts the Event framework messages that leave the system by applying a range to the query used to select the changed entities. Select the entity you wish to filter. Click Filter. Select range criteria and click OK. This will restrict the Event framework so that it only sends customers whose first name is \u201cJohn\u201d. Click Reset to remove all modifications to the query. Propagating Deleted Entities If you wish to send delete messages when a configured entity is deleted, you must check the Propagate delete box for that entity. The Event Framework will then store the last Event Framework message for that entity whenever one is processed. When the entity is deleted it will resend that stored message with an action of Delete. If an entity is created and deleted before the event is processed, an Event Framework message will not be generated for that entity. Advanced Options Refresh Entity List Whenever a data source is added or removed from a data entity it is necessary to refresh the entity list. This menu item is usually found in the Data management workspace and is provided here for convenience. Rebuild entity list Under certain conditions the Refresh entity list does not adequately refresh the entity metadata. The Rebuild entity list will first delete the entity from the entity table before calling the normal Refresh entity list functionality. Use this option with caution. Because rebuilding the entity list first deletes the entity metadata, change tracking information for that entity will be lost. Run now Click Run now to process the event immediately or schedule it to run in batch. Set the Simulate initial data load switch to Yes to process the event without sending and Event framework messages to the Azure Service Bus. This may be used to set the change tracking version to the current version. SQL Server Change Tracking The Event Framework uses SQL Server change tracking to determine which entities have changed. For more information see Enable change tracking for entities and About Change Tracking (SQL Server) . Entity Filtering Filters applied to the entity will prevent the Event Framework message for that entity from being sent. Filters applied to the Azure Service Bus subscription will prevent the Event Framework message from being received.","title":"Event Framework"},{"location":"event_framework/#event-framework","text":"","title":"Event Framework"},{"location":"event_framework/#overview","text":"The Event Framework enables the integration of data entities with other systems by sending entity data to an Azure Service Bus endpoint. The first time an Event Framework event is processed, all data is sent to the service bus endpoint. On subsequent runs, only entities that have changed are sent. If the same entity is contained in two different events; each event will operate independently, sending all changes to their respective endpoints. Event Framework events are intended to run daily as a batch service.","title":"Overview"},{"location":"event_framework/#setup-event-framework-parameters","text":"System administration > Setup > Event framework > Event framework parameters","title":"Setup Event Framework Parameters"},{"location":"event_framework/#set-the-environment-name","text":"The Environment name is attached to Event framework messages sent from this system. This allows administrators to determine from which system an entity originated in the event of a failure.","title":"Set the Environment name"},{"location":"event_framework/#enable-the-event-framework","text":"Set the Enabled switch to yes. Event framework messages will not be sent from this system when this switch is set to No.","title":"Enable the Event framework"},{"location":"event_framework/#create-an-event-framework-endpoint","text":"System administration > Setup > Event framework > Event Framework endpoint definitions Click New Enter a name and description. Enter your Azure service bus endpoint connection string. If your endpoint requires sessions, set the switch to Yes. Enter the name of your topic or queue. Set the endpoint type to Topic or Queue. Set the Enabled switch to Yes.","title":"Create an Event Framework Endpoint"},{"location":"event_framework/#create-an-event-framework-event","text":"System administration > Setup > Event framework > Event framework events Click New. Enter a name and description. Choose your endpoint. If you wish to log a message to the Event Framework event log for successful and failed Event framework messages, set the Log success switch to Yes. The Last execution box contains the last execution date time. Set the Enabled switch to Yes. If this switch is No, the event will not be processed.","title":"Create an Event Framework Event"},{"location":"event_framework/#add-an-entity-to-the-event","text":"Expand the Event tables Fast Tab. Click New. Select your entity in the Source table column. Change tracking type indicates whether all the entity\u2019s data sources are tracked for changes. Check the Propagate delete box to send a message when an instance of this entity is deleted. Entities are processed in ascending Line number order. Two entities with the same line number may be processed in either order.","title":"Add an Entity to the Event"},{"location":"event_framework/#add-event-user-properties","text":"For every configured entity, you may add user properties to the Event framework message. The properties contain the value of the chosen entity field and are informational only. This is useful for filters applied to the Azure service bus subscription because the value of the property is added directly to the properties collection on the message rather than contains somewhere within the body.","title":"Add Event User Properties"},{"location":"event_framework/#adding-an-entity-filter","text":"This filter restricts the Event framework messages that leave the system by applying a range to the query used to select the changed entities. Select the entity you wish to filter. Click Filter. Select range criteria and click OK. This will restrict the Event framework so that it only sends customers whose first name is \u201cJohn\u201d. Click Reset to remove all modifications to the query.","title":"Adding an Entity Filter"},{"location":"event_framework/#propagating-deleted-entities","text":"If you wish to send delete messages when a configured entity is deleted, you must check the Propagate delete box for that entity. The Event Framework will then store the last Event Framework message for that entity whenever one is processed. When the entity is deleted it will resend that stored message with an action of Delete. If an entity is created and deleted before the event is processed, an Event Framework message will not be generated for that entity.","title":"Propagating Deleted Entities"},{"location":"event_framework/#advanced-options","text":"","title":"Advanced Options"},{"location":"event_framework/#refresh-entity-list","text":"Whenever a data source is added or removed from a data entity it is necessary to refresh the entity list. This menu item is usually found in the Data management workspace and is provided here for convenience.","title":"Refresh Entity List"},{"location":"event_framework/#rebuild-entity-list","text":"Under certain conditions the Refresh entity list does not adequately refresh the entity metadata. The Rebuild entity list will first delete the entity from the entity table before calling the normal Refresh entity list functionality. Use this option with caution. Because rebuilding the entity list first deletes the entity metadata, change tracking information for that entity will be lost.","title":"Rebuild entity list"},{"location":"event_framework/#run-now","text":"Click Run now to process the event immediately or schedule it to run in batch. Set the Simulate initial data load switch to Yes to process the event without sending and Event framework messages to the Azure Service Bus. This may be used to set the change tracking version to the current version.","title":"Run now"},{"location":"event_framework/#sql-server-change-tracking","text":"The Event Framework uses SQL Server change tracking to determine which entities have changed. For more information see Enable change tracking for entities and About Change Tracking (SQL Server) .","title":"SQL Server Change Tracking"},{"location":"event_framework/#entity-filtering","text":"Filters applied to the entity will prevent the Event Framework message for that entity from being sent. Filters applied to the Azure Service Bus subscription will prevent the Event Framework message from being received.","title":"Entity Filtering"},{"location":"hostsettings.json/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"hostsettings.json/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"hostsettings.json/#overview","text":"","title":"Overview"},{"location":"hostsettings.json/#main-point-1","text":"","title":"Main Point 1"},{"location":"hostsettings.json/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"how-to-install-levridge-scale/","text":"How to Install Levridge Scale Prerequisites Windows user account needs to have local admin rights and a password PC needs to have an internet connection Disable any security add-ons (Bitdefender, etc.) Whenever prompted to use a browser, use Chrome Install SqlExpress using the 'Basic' installation SQL is located in the Master Scale App Install folder It was downloaded from https://go.microsoft.com/fwlink/?linkid=866658 The SQLEXPRESS connection string will default to Server=localhost\\SQLEXPRESS;Database=master;Trusted_Connection=True; If IIS is not enabled, enable IIS through Control panel>Programs and Features>Turn Windows feature on or off>Internet Information Services. Check the root box for Internet Information Services and let is select the defaults. Ensure everything under IIS>World Wide Web Services>Application Development Features is checked. If you receive an error, when downloading IIS you may need to make a change in the registry: Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\WindowsUpdate\\AU Set \"UseWUServer\" to 0 Install Levridge Scale Run the Levridge Scale House Install.exe Right click and Run as Administrator Agree to terms and click Install When the installer displays \"Installation Successfully Completed\", click Close Configure Settings reference the 2. Levridge Scale Appsettings document 1. Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers 2. In the API and Client folders, configure appsettings.json 3. Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services 4. In AxToScaleIntegration and HardwareInterface folders, configure appsettings.json Log into Services Open IIS In Application Pools, right click DefaultAppPool and click Stop On the left under Sites, rick click Default Web Site>Manager Website>Stop On the left select Application Pools, on the right do the follow steps for BOTH LevScaleAPI and LevPrint Right click>Advanced settings In the Identity field select Custom account>Set and enter username and password. Use the username and password. Open (Windows) Services There should be 4 new services installed: LevAxToScaleService LevHardwareService LevPrinterService LevScaleClient Set the Startup Type to \"Automatic (Delayed Start)\" On the LevHardwareService and LevScaleClient services, change the Log on for EACH service: Right click on the service>Properties Select the Log On tab Select account and password Click Apply and OK Restart the machine. When it restarts, the services will start automatically and the database will be created. Access Levridge Scale In a web browser, go to http://localhost to access Levridge Scale Sync data from F&O In F&O, Create an Event Frameowrk endpoint definition for scale Service Bus endpoint: Endpoint:=sb://example.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx= Enter the Topic name Endpoint type: Topic Session Required: Yes Enabled: Yes Create an Event Framework event and sync all scale entities, referenced in Scale Integration","title":"How to install levridge scale"},{"location":"how-to-install-levridge-scale/#how-to-install-levridge-scale","text":"","title":"How to Install Levridge Scale"},{"location":"how-to-install-levridge-scale/#prerequisites","text":"Windows user account needs to have local admin rights and a password PC needs to have an internet connection Disable any security add-ons (Bitdefender, etc.) Whenever prompted to use a browser, use Chrome Install SqlExpress using the 'Basic' installation SQL is located in the Master Scale App Install folder It was downloaded from https://go.microsoft.com/fwlink/?linkid=866658 The SQLEXPRESS connection string will default to Server=localhost\\SQLEXPRESS;Database=master;Trusted_Connection=True; If IIS is not enabled, enable IIS through Control panel>Programs and Features>Turn Windows feature on or off>Internet Information Services. Check the root box for Internet Information Services and let is select the defaults. Ensure everything under IIS>World Wide Web Services>Application Development Features is checked. If you receive an error, when downloading IIS you may need to make a change in the registry: Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\WindowsUpdate\\AU Set \"UseWUServer\" to 0","title":"Prerequisites"},{"location":"how-to-install-levridge-scale/#install-levridge-scale","text":"Run the Levridge Scale House Install.exe Right click and Run as Administrator Agree to terms and click Install When the installer displays \"Installation Successfully Completed\", click Close","title":"Install Levridge Scale"},{"location":"how-to-install-levridge-scale/#configure-settings","text":"reference the 2. Levridge Scale Appsettings document 1. Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers 2. In the API and Client folders, configure appsettings.json 3. Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services 4. In AxToScaleIntegration and HardwareInterface folders, configure appsettings.json","title":"Configure Settings"},{"location":"how-to-install-levridge-scale/#log-into-services","text":"Open IIS In Application Pools, right click DefaultAppPool and click Stop On the left under Sites, rick click Default Web Site>Manager Website>Stop On the left select Application Pools, on the right do the follow steps for BOTH LevScaleAPI and LevPrint Right click>Advanced settings In the Identity field select Custom account>Set and enter username and password. Use the username and password. Open (Windows) Services There should be 4 new services installed: LevAxToScaleService LevHardwareService LevPrinterService LevScaleClient Set the Startup Type to \"Automatic (Delayed Start)\" On the LevHardwareService and LevScaleClient services, change the Log on for EACH service: Right click on the service>Properties Select the Log On tab Select account and password Click Apply and OK Restart the machine. When it restarts, the services will start automatically and the database will be created.","title":"Log into Services"},{"location":"how-to-install-levridge-scale/#access-levridge-scale","text":"In a web browser, go to http://localhost to access Levridge Scale","title":"Access Levridge Scale"},{"location":"how-to-install-levridge-scale/#sync-data-from-fo","text":"In F&O, Create an Event Frameowrk endpoint definition for scale Service Bus endpoint: Endpoint:=sb://example.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx= Enter the Topic name Endpoint type: Topic Session Required: Yes Enabled: Yes Create an Event Framework event and sync all scale entities, referenced in Scale Integration","title":"Sync data from F&amp;O"},{"location":"oneWeigh/","text":"oneWeigh","title":"oneWeigh"},{"location":"oneWeigh/#oneweigh","text":"","title":"oneWeigh"},{"location":"print-service/","text":"Print Service Installing Print Service Application To first install print service application, open Visual Studio. In Visual Studio, the print service is checked-in at \"$/Levridge/CRM/Main/PrintService\". Double click this and map it to a path on your machine. In Visual Studio, click Build > Build Solution. Activate the service as detailed below in PowerShell: Right click on the windows icon and select \"Windows PowerShell (Admin)\" Enter the following command once. Be sure to substitute the local path! New-Service-Name\"PrintService\"-\"{Your Local path to project}\\PrintService\\bin\\Debug\\PrintService.exe-k netsvcs\" Locating Printer Network Name If a printer is a network device, its name will be more difficult to locate. Use these steps to find the name that the Print Service application will use to print: Go to control panel and locate the setting titled \"Devices and Printers\" (Note: Not all setting are in this screenshot. This view is set to \"Small icons\") Navigate to the list of print options on your computer and select the device of your choice. The full network name that is required for the code is listed once you select the printer. (Highlighted in yellow below) Using Print Service Application After initial setup, use one of the following two options to start the Application. PowerShell Following the first setup, you can enter the following command into PowerShell instead. Start-Service-Name\"PrintService\" Services App. Use Windows+R to select \"services.msc\" to open Services Management Console. Right click on PrintService and select \"start\" Setting Up a New Printer To set up a new printer, new parameters will need to be setup. To add the parameters, open the app.config file in the project and add the following: ServiceBusConnectionString ServiceBusTopicSubscription ServiceBusTopic PrinterName SiteID Two parameters will also need to be updated. These two need to be changed for the printer that is being printed to. The Site ID is the customer site code from CRM. For debugging the Service, we can use the Windows Event Viewer. Go to Administrative tools in the Control Panel and Open Event Viewer. Additional Information and Documentation In CRM on the sales ordered details header, there is an Auto Print Field. Set to Yes and click save. The sales order will then print.","title":"Print Service"},{"location":"print-service/#print-service","text":"","title":"Print Service"},{"location":"print-service/#installing-print-service-application","text":"To first install print service application, open Visual Studio. In Visual Studio, the print service is checked-in at \"$/Levridge/CRM/Main/PrintService\". Double click this and map it to a path on your machine. In Visual Studio, click Build > Build Solution. Activate the service as detailed below in PowerShell: Right click on the windows icon and select \"Windows PowerShell (Admin)\" Enter the following command once. Be sure to substitute the local path! New-Service-Name\"PrintService\"-\"{Your Local path to project}\\PrintService\\bin\\Debug\\PrintService.exe-k netsvcs\"","title":"Installing Print Service Application"},{"location":"print-service/#locating-printer-network-name","text":"If a printer is a network device, its name will be more difficult to locate. Use these steps to find the name that the Print Service application will use to print: Go to control panel and locate the setting titled \"Devices and Printers\" (Note: Not all setting are in this screenshot. This view is set to \"Small icons\") Navigate to the list of print options on your computer and select the device of your choice. The full network name that is required for the code is listed once you select the printer. (Highlighted in yellow below)","title":"Locating Printer Network Name"},{"location":"print-service/#using-print-service-application","text":"After initial setup, use one of the following two options to start the Application. PowerShell Following the first setup, you can enter the following command into PowerShell instead. Start-Service-Name\"PrintService\" Services App. Use Windows+R to select \"services.msc\" to open Services Management Console. Right click on PrintService and select \"start\"","title":"Using Print Service Application"},{"location":"print-service/#setting-up-a-new-printer","text":"To set up a new printer, new parameters will need to be setup. To add the parameters, open the app.config file in the project and add the following: ServiceBusConnectionString ServiceBusTopicSubscription ServiceBusTopic PrinterName SiteID Two parameters will also need to be updated. These two need to be changed for the printer that is being printed to. The Site ID is the customer site code from CRM. For debugging the Service, we can use the Windows Event Viewer. Go to Administrative tools in the Control Panel and Open Event Viewer.","title":"Setting Up a New Printer"},{"location":"print-service/#additional-information-and-documentation","text":"In CRM on the sales ordered details header, there is an Auto Print Field. Set to Yes and click save. The sales order will then print.","title":"Additional Information and Documentation"},{"location":"scale-application-configuration/","text":"Scale Application Configuration Overview The Levridge Scale application is structured as a browser-based application that can be operated as a server or as a desktop depending on the specification requirements of the customer. Windows Server When using the Scale application on Windows server the following servers will be installed and used. LevScale API: This server will handle all integration framework communications to Scale. O-Data is used in the integration framework. LevScalePrint: This server communicates with the client printer service and is used to render all Scale reports, such as Scale Tickets. Windows Desktop On a Windows Desktop environment, four services will be installed and used with the Scale application. LevPrinterService: This can be installed on any computer within the customer\u2019s intranet and allows the scale tickets to be printed. LevHardwareService: This service is used when connecting to hardware such as a scale head. LevridgeAxToScaleService: This works along with the LevridgeScaleToAxService and contains the integration framework which handles the bidirectional integration with Dynamics 365 F&O. When using multiple Levridge Scale servers along with one Enterprise system, only one LevridgeAxToScaleService is needed and can be set up as a cloud service. For LevridgeScaleToAxService, one is needed for each desktop or Levridge Scale instance. The integration framework uses the LevScaleAPI server to write into the LevScale. LevScaleClient: This is operating a straight web server without the reverse proxy capability. Workstation Management Define the association of the various equipment. In most applications, only one workstation will need to be created. When creating a workstation, assign a Workstation Name and then select the Equipment i.e. a scale head and a grain analyzer. The Equipment is set up in Equipment Management. Equipment Management Define the equipment such as scales and analyzers that will be used with the Scale application. Equipment can be marked as Inactive if it is not yet fully configured or no longer in use. Map Equipment Grades Map grade factors to a commodity for the given Equipment, such as a grain analyzer. This allows the system to parse the grain analyzer\u2019s output and assign grades to a commodity for use on a scale ticket. Settings Under Application Configuration>Settings Site: Choose a site from the drop down to assign site ID to the scale app Number Prefix: Enter in the number ID of the Site in FO Scale: Leave as default value of 1 Company Name: Enter company name Company Location/Address: Enter in correct company address Company Carrier: Use this to Select the transport that is set up in F&O to trasnport Transfer Tickets: Company Name Logo: Click on this to choose a picture file: Sizing IS being updated for logo Printer Server: Address of the Printer Server, Default value is http://localhost:8081 Printer Service: Address of the Printer Service, Default value is: http://localhost:4343/printerservice Report File Location: Location of where PDF versions of tickets are stored. Default value is C:\\Temp\\Reports . Will have to create this file folder on your local machine. Organization: DataAreaID of F&O, enter in 100 IsDriverOn: If this is toggled on, all ticket types will default to having the flag on unless manually changed by the scale operator. If set to no, \"Driver-on\" flag will not be displayed on the ticket window. Enable Spot Pricing: Further Development of Grain Functionality required. Field does not need to be filled in for agronomy. Enable Disposition: Further Development of Grain Functionality required. Field does not need to be filled in for agronomy. Scale Unit: Use drop down list to select LB Max Weight: Enter in the max weight of the scale head. Incr. Wt: This is what increments the scale head will display weights, i.e. 20 lbs. Printer Settings Under Application Configuration>Printer Settings. This window is used to choose the correct printers for each of your scale heads at a location, and to choose a corresponding menu color to know which scale head you are working with in your window. The printer settings you choose in this window will then default in when you choose that scale on the Application start page. Note: This setup is required. The printer selection can be changed to any printer on the Start page, but default printer setup is required to be able to print scale tickets. To Set up the Printer Settings for a Scale: Choose the scale you want to set up from the drop down on the top of the page. Choose your printers for both your Tickets and BOL. Using the printer Type can change between a full page printout vs. a receipt printout. Choose the number of copies that you want to print with each completed ticket. Choose a background Color for that specific scale-head to make sure the correct scale is being used to complete and print tickets. Click save to complete these changes. Customer Short List Under Application Configuration>Customer Short list Shows a list of all customers in the scale database in alphabetical order. Checking the Box next to a customer will put that customer into the drop-down list on all the scale ticket types in order to reduce load times because not all customers will be loading in the customer account drop-down. To add a customer to the short list manually, check the box next to their name, and click submit on the bottom left corner of the page. Gross Quantity Settings Under Application Configuration>Gross Quantity Settings Manually set up in scale to show the gross quantity conversions of certain products, i.e. lbs to gallons. To create a new gross quantity for a product: 1. Click create new on the top left of the page under INDEX 2. Choose the item ID for the correct item you want to add a quantity to 3. In Factor, enter the correct number. If you were to say a gallon of product is equal to 8 pounds, you would enter 8. The conversion is lbs/Unit of measure. The units of measure come from your FO system. 4. Choose your Commodity Unit of Measure. 5. Click Create. To edit a previously created Gross quantity, click Edit next to the GQ that you want to change and when you have finished editing it, click the blue \"Edit\" button to save it. To delete a previously created GQ, click delete next to the GQ. Confirm the delete by clicking the red \"Delete\" button. Standalone Configuration If using Levridge Scale as a standalone system (not integrating with D365 Finance and Operations) this screen is used to define data such as customers, commodities, grade factors etc.","title":"Scale Application Configuration"},{"location":"scale-application-configuration/#scale-application-configuration","text":"","title":"Scale Application Configuration"},{"location":"scale-application-configuration/#overview","text":"The Levridge Scale application is structured as a browser-based application that can be operated as a server or as a desktop depending on the specification requirements of the customer.","title":"Overview"},{"location":"scale-application-configuration/#windows-server","text":"When using the Scale application on Windows server the following servers will be installed and used. LevScale API: This server will handle all integration framework communications to Scale. O-Data is used in the integration framework. LevScalePrint: This server communicates with the client printer service and is used to render all Scale reports, such as Scale Tickets.","title":"Windows Server"},{"location":"scale-application-configuration/#windows-desktop","text":"On a Windows Desktop environment, four services will be installed and used with the Scale application. LevPrinterService: This can be installed on any computer within the customer\u2019s intranet and allows the scale tickets to be printed. LevHardwareService: This service is used when connecting to hardware such as a scale head. LevridgeAxToScaleService: This works along with the LevridgeScaleToAxService and contains the integration framework which handles the bidirectional integration with Dynamics 365 F&O. When using multiple Levridge Scale servers along with one Enterprise system, only one LevridgeAxToScaleService is needed and can be set up as a cloud service. For LevridgeScaleToAxService, one is needed for each desktop or Levridge Scale instance. The integration framework uses the LevScaleAPI server to write into the LevScale. LevScaleClient: This is operating a straight web server without the reverse proxy capability.","title":"Windows Desktop"},{"location":"scale-application-configuration/#workstation-management","text":"Define the association of the various equipment. In most applications, only one workstation will need to be created. When creating a workstation, assign a Workstation Name and then select the Equipment i.e. a scale head and a grain analyzer. The Equipment is set up in Equipment Management.","title":"Workstation Management"},{"location":"scale-application-configuration/#equipment-management","text":"Define the equipment such as scales and analyzers that will be used with the Scale application. Equipment can be marked as Inactive if it is not yet fully configured or no longer in use.","title":"Equipment Management"},{"location":"scale-application-configuration/#map-equipment-grades","text":"Map grade factors to a commodity for the given Equipment, such as a grain analyzer. This allows the system to parse the grain analyzer\u2019s output and assign grades to a commodity for use on a scale ticket.","title":"Map Equipment Grades"},{"location":"scale-application-configuration/#settings","text":"Under Application Configuration>Settings Site: Choose a site from the drop down to assign site ID to the scale app Number Prefix: Enter in the number ID of the Site in FO Scale: Leave as default value of 1 Company Name: Enter company name Company Location/Address: Enter in correct company address Company Carrier: Use this to Select the transport that is set up in F&O to trasnport Transfer Tickets: Company Name Logo: Click on this to choose a picture file: Sizing IS being updated for logo Printer Server: Address of the Printer Server, Default value is http://localhost:8081 Printer Service: Address of the Printer Service, Default value is: http://localhost:4343/printerservice Report File Location: Location of where PDF versions of tickets are stored. Default value is C:\\Temp\\Reports . Will have to create this file folder on your local machine. Organization: DataAreaID of F&O, enter in 100 IsDriverOn: If this is toggled on, all ticket types will default to having the flag on unless manually changed by the scale operator. If set to no, \"Driver-on\" flag will not be displayed on the ticket window. Enable Spot Pricing: Further Development of Grain Functionality required. Field does not need to be filled in for agronomy. Enable Disposition: Further Development of Grain Functionality required. Field does not need to be filled in for agronomy. Scale Unit: Use drop down list to select LB Max Weight: Enter in the max weight of the scale head. Incr. Wt: This is what increments the scale head will display weights, i.e. 20 lbs.","title":"Settings"},{"location":"scale-application-configuration/#printer-settings","text":"Under Application Configuration>Printer Settings. This window is used to choose the correct printers for each of your scale heads at a location, and to choose a corresponding menu color to know which scale head you are working with in your window. The printer settings you choose in this window will then default in when you choose that scale on the Application start page. Note: This setup is required. The printer selection can be changed to any printer on the Start page, but default printer setup is required to be able to print scale tickets.","title":"Printer Settings"},{"location":"scale-application-configuration/#to-set-up-the-printer-settings-for-a-scale","text":"Choose the scale you want to set up from the drop down on the top of the page. Choose your printers for both your Tickets and BOL. Using the printer Type can change between a full page printout vs. a receipt printout. Choose the number of copies that you want to print with each completed ticket. Choose a background Color for that specific scale-head to make sure the correct scale is being used to complete and print tickets. Click save to complete these changes.","title":"To Set up the Printer Settings for a Scale:"},{"location":"scale-application-configuration/#customer-short-list","text":"Under Application Configuration>Customer Short list Shows a list of all customers in the scale database in alphabetical order. Checking the Box next to a customer will put that customer into the drop-down list on all the scale ticket types in order to reduce load times because not all customers will be loading in the customer account drop-down. To add a customer to the short list manually, check the box next to their name, and click submit on the bottom left corner of the page.","title":"Customer Short List"},{"location":"scale-application-configuration/#gross-quantity-settings","text":"Under Application Configuration>Gross Quantity Settings Manually set up in scale to show the gross quantity conversions of certain products, i.e. lbs to gallons. To create a new gross quantity for a product: 1. Click create new on the top left of the page under INDEX 2. Choose the item ID for the correct item you want to add a quantity to 3. In Factor, enter the correct number. If you were to say a gallon of product is equal to 8 pounds, you would enter 8. The conversion is lbs/Unit of measure. The units of measure come from your FO system. 4. Choose your Commodity Unit of Measure. 5. Click Create. To edit a previously created Gross quantity, click Edit next to the GQ that you want to change and when you have finished editing it, click the blue \"Edit\" button to save it. To delete a previously created GQ, click delete next to the GQ. Confirm the delete by clicking the red \"Delete\" button.","title":"Gross Quantity Settings"},{"location":"scale-application-configuration/#standalone-configuration","text":"If using Levridge Scale as a standalone system (not integrating with D365 Finance and Operations) this screen is used to define data such as customers, commodities, grade factors etc.","title":"Standalone Configuration"},{"location":"scale-application-faq/","text":"Scale Application FAQ Q: What hardware does Levridge Scale integrate with? A: Levridge Scale currently supports the Rice Lake 920i and 1280 scales as well as the Cardinal 225D and Fairbanks FB2550 scales. In addition, Levridge Scale interfaces with the GAC 2500 grain analyzer. We are continuing to build out our library of supported hardware to include additional moisture and protein analyzers as well as message boards and RFID readers. Q: Is Levridge Scale NTEP certified? A: Yes \u2013 Levridge Scale is NTEP certified. Q: Can Levridge Scale support both metric and imperial systems of measurement? A: Yes, Levridge Scale supports both kilograms and pounds. Those weights can be converted to other units of measure such as bushels, tons, tonnes and hundred weight. Q: Does Levridge Scale work offline? A: Yes, the Levridge Scale can work offline. Once the application is back online, information will transmit to and from Levridge Scale. Q: Do you need to purchase Microsoft Dynamics 365 Finance or Supply Chain Management to use Levridge Scale? A: No. Levridge Scale is purchased separately from Dynamics 365. However, Levridge Scale does integrate with Levridge Commodity accounting built in Dynamics 365 Finance and Supply Chain. Q: What information from Levridge Scale integrates with Dynamics 365? A: Scale ticket information such as weights, quantities, and quality grade factors are integrated with Levridge Commodity Accounting where they can be matched to or generate sales orders or payables. Q: Does information from Levridge Commodity Accounting integrate with Levridge Scale? A: Yes, master data such as Customers, Split Groups, Items, Quality Grade Factors can all be integrated to Levridge Scale from Levridge Commodity Accounting built in Dynamics 365 Finance and Supply Chain. Q: Can Levridge Scale integration with other ERP systems? A: Yes. Using AgXML, scale tickets can be exported from the Scale app and brought into an external ERP system. Q: What languages are supported with Levridge Scale? A: Levridge Scale currently supports US English only.","title":"Scale Application FAQ"},{"location":"scale-application-faq/#scale-application-faq","text":"Q: What hardware does Levridge Scale integrate with? A: Levridge Scale currently supports the Rice Lake 920i and 1280 scales as well as the Cardinal 225D and Fairbanks FB2550 scales. In addition, Levridge Scale interfaces with the GAC 2500 grain analyzer. We are continuing to build out our library of supported hardware to include additional moisture and protein analyzers as well as message boards and RFID readers. Q: Is Levridge Scale NTEP certified? A: Yes \u2013 Levridge Scale is NTEP certified. Q: Can Levridge Scale support both metric and imperial systems of measurement? A: Yes, Levridge Scale supports both kilograms and pounds. Those weights can be converted to other units of measure such as bushels, tons, tonnes and hundred weight. Q: Does Levridge Scale work offline? A: Yes, the Levridge Scale can work offline. Once the application is back online, information will transmit to and from Levridge Scale. Q: Do you need to purchase Microsoft Dynamics 365 Finance or Supply Chain Management to use Levridge Scale? A: No. Levridge Scale is purchased separately from Dynamics 365. However, Levridge Scale does integrate with Levridge Commodity accounting built in Dynamics 365 Finance and Supply Chain. Q: What information from Levridge Scale integrates with Dynamics 365? A: Scale ticket information such as weights, quantities, and quality grade factors are integrated with Levridge Commodity Accounting where they can be matched to or generate sales orders or payables. Q: Does information from Levridge Commodity Accounting integrate with Levridge Scale? A: Yes, master data such as Customers, Split Groups, Items, Quality Grade Factors can all be integrated to Levridge Scale from Levridge Commodity Accounting built in Dynamics 365 Finance and Supply Chain. Q: Can Levridge Scale integration with other ERP systems? A: Yes. Using AgXML, scale tickets can be exported from the Scale app and brought into an external ERP system. Q: What languages are supported with Levridge Scale? A: Levridge Scale currently supports US English only.","title":"Scale Application FAQ"},{"location":"scale-appsettings-configuration/","text":"Scale Appsettings Configuration Configure Appsettings Files Configure the appsettings.json file in the following default locations: C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers\\LevScaleClient C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers\\LevScaleAPI C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services\\AxToScaleIntegration C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services\\HardwareInterface LevScaleClient { \"GeneratedDb\": \"C:\\\\LevridgeScaleHouse\\\\sql\", \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\" }, \"WipProcessInterval\": 10000, \"WipCleanupInterval\": 86400000, \"Logging\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Warning\" } }, \"ServiceBusSettings\": { \"ServiceBusConnectionString\": //Enter the endpoint for the service bus for integration from Levridge Scale to F&O \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"scaletofo\" }, \"WebAPI\": { \"Port\": 80, \"URL\": \"http://localhost:8080\", }, \"Printer\": { \"DataSource\": \"Server=.;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\", \"ReportPath\": \"./\" }, \"ScaleInterface\": { \"UriString\": \"http://localhost:44323/\", \"TLSVersion\": \"\" }, \"LogLocationCleanup\": { /// <summary> /// The location of the log folder. /// </summary> /// <remarks>The default value is 'C:\\Temp'.</remarks> \"LogFolder\": \"C:\\\\Temp\", /// <summary> /// The time to wait (in minutes) before clearing old logs from the reporting location. /// </summary> /// <remarks>The default is 1,440 mintues (24 hours).</remarks> \"RecheckInterval\": 2880, /// <summary> /// Log files may be deleted that are older than this many mintues.. /// </summary> /// <remarks>The default is 2,880 minutes (24 hours).</remarks> \"RemoveAfter\": 2880, /// <summary> /// The file filter used when clearing old report files. /// </summary> /// <remarks>The default is \"*\".</remarks> \"FileFilter\": \"*.txt\", /// <summary> /// The file search options. /// </summary> /// <remarks>The default is <see cref=\"SearchOption.TopDirectoryOnly\"/></remarks> \"FileSearchOptions\": \"TopDirectoryOnly\" }, \"Log4Net\": { \"xml\": \"log4net.xml\" }, \"DynamicsAX\": { //Enter the connection details for F&O \"UriString\": \"https://landusuat.sandbox.operations.dynamics.com/\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53-9376bxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b393xxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1cJLcxxxx=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"https://landusuat.sandbox.operations.dynamics.com/data/\", \"DataAreaId\": \"100\" } } LevScaleAPI { \"AllowedHosts\": \"*\", \"GeneratedDb\": \"C:\\\\LevridgeScaleHouse\\\\sql\", \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\" }, \"WipProcessInterval\": 10000, \"WipCleanupInterval\": 86400000, \"Logging\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Warning\" } }, \"ServiceBusSettings\": { \"ServiceBusConnectionString\": //Enter the endpoint for the service bus for integration from Levridge Scale to F&O \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"scaletofo\" }, \"WebAPI\": { \"Port\": 80, \"URL\": \"http://localhost:8080\", }, \"Printer\": { \"DataSource\": \"Server=.;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\", \"ReportPath\": \"./\" }, \"ScaleInterface\": { \"UriString\": \"http://localhost:44323/\", \"TLSVersion\": \"\" }, \"Log4Net\": { \"xml\": \"log4net.xml\" } } AxToScaleIntegration { \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Debug\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Console\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Debug\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"ApplicationInsights\": { \"InstrumentationKey\": \"\" }, \"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfigurationAX\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"AxToScale\", \"ODataConfigName\": \"DynamicsAX\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"ScaleOData\", \"SystemName\": \"ScaleHouse\", \"Direction\": \"Target\" }, //Enter the connection details for F&O \"DynamicsAX\": { \"UriString\": \"https://landusuat.sandbox.operations.dynamics.com/\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53xxxxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b39381xxxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1xxxxxI=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"https://landusuat.sandbox.operations.dynamics.com/data/\", \"DataAreaId\": \"100\" }, //Enter the Active Directory details for F&O. Leave the default values for UriString and ODataEntityPath \"ScaleOData\": { \"UriString\": \"http://localhost:8080/odata\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53-9376xxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b3xxxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1cJLcxxxxx=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"http://localhost:8080/odata\" }, \"AxToScale\": { \"ConnectionString\": //Enter the endpoint for the service bus for integration from F&O to Levridge Scale \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"axtoscale\", //Enter the Subscription name for the service bus \"SubscriptionName\": \"000\", \"PrefetchCount\": 40, \"MaxConcurrentCount\": 20 } } HardwareInterface { \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;\" }, \"Logging\": { \"LogLevel\": { \"Default\": \"Warning\" } }, \"AllowedHosts\": \"*\", \"Hardware\": { \"HubUrl\": \"http://localhost:80/scalehub\", \"WorkstationName\" : \"Ws1\" } }","title":"Scale Appsettings Configuration"},{"location":"scale-appsettings-configuration/#scale-appsettings-configuration","text":"","title":"Scale Appsettings Configuration"},{"location":"scale-appsettings-configuration/#configure-appsettings-files","text":"Configure the appsettings.json file in the following default locations: C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers\\LevScaleClient C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers\\LevScaleAPI C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services\\AxToScaleIntegration C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services\\HardwareInterface","title":"Configure Appsettings Files"},{"location":"scale-appsettings-configuration/#levscaleclient","text":"{ \"GeneratedDb\": \"C:\\\\LevridgeScaleHouse\\\\sql\", \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\" }, \"WipProcessInterval\": 10000, \"WipCleanupInterval\": 86400000, \"Logging\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Warning\" } }, \"ServiceBusSettings\": { \"ServiceBusConnectionString\": //Enter the endpoint for the service bus for integration from Levridge Scale to F&O \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"scaletofo\" }, \"WebAPI\": { \"Port\": 80, \"URL\": \"http://localhost:8080\", }, \"Printer\": { \"DataSource\": \"Server=.;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\", \"ReportPath\": \"./\" }, \"ScaleInterface\": { \"UriString\": \"http://localhost:44323/\", \"TLSVersion\": \"\" }, \"LogLocationCleanup\": { /// <summary> /// The location of the log folder. /// </summary> /// <remarks>The default value is 'C:\\Temp'.</remarks> \"LogFolder\": \"C:\\\\Temp\", /// <summary> /// The time to wait (in minutes) before clearing old logs from the reporting location. /// </summary> /// <remarks>The default is 1,440 mintues (24 hours).</remarks> \"RecheckInterval\": 2880, /// <summary> /// Log files may be deleted that are older than this many mintues.. /// </summary> /// <remarks>The default is 2,880 minutes (24 hours).</remarks> \"RemoveAfter\": 2880, /// <summary> /// The file filter used when clearing old report files. /// </summary> /// <remarks>The default is \"*\".</remarks> \"FileFilter\": \"*.txt\", /// <summary> /// The file search options. /// </summary> /// <remarks>The default is <see cref=\"SearchOption.TopDirectoryOnly\"/></remarks> \"FileSearchOptions\": \"TopDirectoryOnly\" }, \"Log4Net\": { \"xml\": \"log4net.xml\" }, \"DynamicsAX\": { //Enter the connection details for F&O \"UriString\": \"https://landusuat.sandbox.operations.dynamics.com/\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53-9376bxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b393xxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1cJLcxxxx=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"https://landusuat.sandbox.operations.dynamics.com/data/\", \"DataAreaId\": \"100\" } }","title":"LevScaleClient"},{"location":"scale-appsettings-configuration/#levscaleapi","text":"{ \"AllowedHosts\": \"*\", \"GeneratedDb\": \"C:\\\\LevridgeScaleHouse\\\\sql\", \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\" }, \"WipProcessInterval\": 10000, \"WipCleanupInterval\": 86400000, \"Logging\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Warning\" } }, \"ServiceBusSettings\": { \"ServiceBusConnectionString\": //Enter the endpoint for the service bus for integration from Levridge Scale to F&O \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"scaletofo\" }, \"WebAPI\": { \"Port\": 80, \"URL\": \"http://localhost:8080\", }, \"Printer\": { \"DataSource\": \"Server=.;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\", \"ReportPath\": \"./\" }, \"ScaleInterface\": { \"UriString\": \"http://localhost:44323/\", \"TLSVersion\": \"\" }, \"Log4Net\": { \"xml\": \"log4net.xml\" } }","title":"LevScaleAPI"},{"location":"scale-appsettings-configuration/#axtoscaleintegration","text":"{ \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Debug\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Console\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Debug\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"ApplicationInsights\": { \"InstrumentationKey\": \"\" }, \"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfigurationAX\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"AxToScale\", \"ODataConfigName\": \"DynamicsAX\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"ScaleOData\", \"SystemName\": \"ScaleHouse\", \"Direction\": \"Target\" }, //Enter the connection details for F&O \"DynamicsAX\": { \"UriString\": \"https://landusuat.sandbox.operations.dynamics.com/\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53xxxxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b39381xxxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1xxxxxI=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"https://landusuat.sandbox.operations.dynamics.com/data/\", \"DataAreaId\": \"100\" }, //Enter the Active Directory details for F&O. Leave the default values for UriString and ODataEntityPath \"ScaleOData\": { \"UriString\": \"http://localhost:8080/odata\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53-9376xxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b3xxxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1cJLcxxxxx=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"http://localhost:8080/odata\" }, \"AxToScale\": { \"ConnectionString\": //Enter the endpoint for the service bus for integration from F&O to Levridge Scale \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"axtoscale\", //Enter the Subscription name for the service bus \"SubscriptionName\": \"000\", \"PrefetchCount\": 40, \"MaxConcurrentCount\": 20 } }","title":"AxToScaleIntegration"},{"location":"scale-appsettings-configuration/#hardwareinterface","text":"{ \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;\" }, \"Logging\": { \"LogLevel\": { \"Default\": \"Warning\" } }, \"AllowedHosts\": \"*\", \"Hardware\": { \"HubUrl\": \"http://localhost:80/scalehub\", \"WorkstationName\" : \"Ws1\" } }","title":"HardwareInterface"},{"location":"scale-integration/","text":"Levridge Scale Integration Azure service bus explorer for Integration Down: F&O to scale Up: Scale to F&O Appsettings.json - configuration file, edit file to switch between up and down Integration F&O to scale Here is the Integration List which lists the entities needed when integrating F&O to scale through System administration > Setup > Event Framework > Event framework events. 1. System administration > Setup > Event framework > Event framework events 2. Run azure service bus Down 3. Run IntegrationConsole.cmd Integration scale to F&O Run azure service bus Up Run IntegrationConsole.cmd When Print is clicked on the scale app, the ticket will then sync to F&O. Scale Entities for Integration Agronomy Release LevUnitOfMeasureEntity HcmWorkerEntity LevScaleReleaseProductsEntity LevHazardousMaterialsTableEntity CustCustomerV3Entity LevSplitGroupEntity LevSplitGroupLinesEntity LevAccountToOperationRelationshipEntity LevCustomerOperationEntity LevCustomerSiteEntity LevRollingStockV2Entity LevFreightCarrierEntity LevInventSiteEntity LevWarehouseEntity LevScaleOperatorEntity LevScaleHouseSalesOrderEntity LevScaleHouseScaleTicketEntity: Add a filter for: Table Scale tickets; Field Ticket type; Criteria Transfer origin","title":"Scale"},{"location":"scale-integration/#levridge-scale-integration","text":"","title":"Levridge Scale Integration"},{"location":"scale-integration/#azure-service-bus-explorer-for-integration","text":"Down: F&O to scale Up: Scale to F&O Appsettings.json - configuration file, edit file to switch between up and down","title":"Azure service bus explorer for Integration"},{"location":"scale-integration/#integration-fo-to-scale","text":"Here is the Integration List which lists the entities needed when integrating F&O to scale through System administration > Setup > Event Framework > Event framework events. 1. System administration > Setup > Event framework > Event framework events 2. Run azure service bus Down 3. Run IntegrationConsole.cmd","title":"Integration F&amp;O to scale"},{"location":"scale-integration/#integration-scale-to-fo","text":"Run azure service bus Up Run IntegrationConsole.cmd When Print is clicked on the scale app, the ticket will then sync to F&O.","title":"Integration scale to F&amp;O"},{"location":"scale-integration/#scale-entities-for-integration","text":"","title":"Scale Entities for Integration"},{"location":"scale-integration/#agronomy-release","text":"LevUnitOfMeasureEntity HcmWorkerEntity LevScaleReleaseProductsEntity LevHazardousMaterialsTableEntity CustCustomerV3Entity LevSplitGroupEntity LevSplitGroupLinesEntity LevAccountToOperationRelationshipEntity LevCustomerOperationEntity LevCustomerSiteEntity LevRollingStockV2Entity LevFreightCarrierEntity LevInventSiteEntity LevWarehouseEntity LevScaleOperatorEntity LevScaleHouseSalesOrderEntity LevScaleHouseScaleTicketEntity: Add a filter for: Table Scale tickets; Field Ticket type; Criteria Transfer origin","title":"Agronomy Release"},{"location":"web.config/","text":"Web.config File Overview The web.config file only applies to Integration Framework instances that are hosted as a web application. Typically these are hosted in Azure but can also be hosted on-premise in IIS. Although Microsoft documentation claims that the web.config file has been replaced , Azure App Services still use it as the means to start the application service. It should not contain any application configuration settings. The web.config file is an XML file that contains a element. Web.Config Elements \\ \\ This is the main element that contains the other elements \\ \\<\\location> This element contains the relative path for the web server \\ \\<\\system.webserver> Contains the handlers and aspNetCore elements \\ \\<\\handlers> Defines the element for the web server. \\<aspNetCore\\> Defines the path to the web server assembly and standard output logging information. Set stdoutLogEnable to \"true\" to write standard out logging to files in the relative location pointed to by the stdoutLogFile attribute. To specify command-line attributes add them to the processPath attribuute on the aspNetCore element. For example, to specify the name for the InstanceConfig node change the processPath to look like this: processPath=\".\\Levridge.Integration.Host.exe -i=MyInstanceConfig\" Sample <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <location path=\".\" inheritInChildApplications=\"false\"> <system.webServer> <handlers> <add name=\"aspNetCore\" path=\"*\" verb=\"*\" modules=\"AspNetCoreModuleV2\" resourceType=\"Unspecified\" /> </handlers> <aspNetCore processPath=\".\\Levridge.Integration.Host.exe\" stdoutLogEnabled=\"false\" stdoutLogFile=\".\\logs\\stdout\" /> </system.webServer> </location> </configuration>","title":"Web.config File"},{"location":"web.config/#webconfig-file","text":"","title":"Web.config File"},{"location":"web.config/#overview","text":"The web.config file only applies to Integration Framework instances that are hosted as a web application. Typically these are hosted in Azure but can also be hosted on-premise in IIS. Although Microsoft documentation claims that the web.config file has been replaced , Azure App Services still use it as the means to start the application service. It should not contain any application configuration settings. The web.config file is an XML file that contains a element.","title":"Overview"},{"location":"web.config/#webconfig-elements","text":"","title":"Web.Config Elements"},{"location":"web.config/#_1","text":"This is the main element that contains the other elements","title":"\\\\"},{"location":"web.config/#location","text":"This element contains the relative path for the web server","title":"\\\\&lt;\\location&gt;"},{"location":"web.config/#systemwebserver","text":"Contains the handlers and aspNetCore elements","title":"\\\\&lt;\\system.webserver&gt;"},{"location":"web.config/#handlers","text":"Defines the element for the web server.","title":"\\\\&lt;\\handlers&gt;"},{"location":"web.config/#aspnetcore","text":"Defines the path to the web server assembly and standard output logging information. Set stdoutLogEnable to \"true\" to write standard out logging to files in the relative location pointed to by the stdoutLogFile attribute. To specify command-line attributes add them to the processPath attribuute on the aspNetCore element. For example, to specify the name for the InstanceConfig node change the processPath to look like this: processPath=\".\\Levridge.Integration.Host.exe -i=MyInstanceConfig\"","title":"\\&lt;aspNetCore\\>"},{"location":"web.config/#sample","text":"<?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <location path=\".\" inheritInChildApplications=\"false\"> <system.webServer> <handlers> <add name=\"aspNetCore\" path=\"*\" verb=\"*\" modules=\"AspNetCoreModuleV2\" resourceType=\"Unspecified\" /> </handlers> <aspNetCore processPath=\".\\Levridge.Integration.Host.exe\" stdoutLogEnabled=\"false\" stdoutLogFile=\".\\logs\\stdout\" /> </system.webServer> </location> </configuration>","title":"Sample"}]}