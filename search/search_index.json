{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction The Levridge integration framework provides integration between Dynamics365 Finance and Operations and Dynamics 365 Customer Engagement and 3rd party applications. This document provides and overview of the integration framework and links to the document that exists for the framework. Overview The Levridge Integration Framework is an entity syncronization framework. It provides a means to synchronize data at an entity level between multiple data sources. All integrations that use the framework follow the same pattern: 1. A data source has an integration event 2. The data source responds to the integration event by sending one or more entities to the service bus. 3. The service bus publishes the message(s) to each subscription 4. An instance of the integration framework receives the message(s) from a subscription 5. The integration framework transforms the message it if needed 6. The integration framework sends the message to the target data source Integrations Currently we support the following integrations: D365 F&O to D365 CRM D365 CRM to D365 F&O Levridge Scale House Agsync Kahler Surety oneWeigh Field Reveal Levridge CRM Remote Printing Service","title":"Home"},{"location":"#introduction","text":"The Levridge integration framework provides integration between Dynamics365 Finance and Operations and Dynamics 365 Customer Engagement and 3rd party applications. This document provides and overview of the integration framework and links to the document that exists for the framework.","title":"Introduction"},{"location":"#overview","text":"The Levridge Integration Framework is an entity syncronization framework. It provides a means to synchronize data at an entity level between multiple data sources. All integrations that use the framework follow the same pattern: 1. A data source has an integration event 2. The data source responds to the integration event by sending one or more entities to the service bus. 3. The service bus publishes the message(s) to each subscription 4. An instance of the integration framework receives the message(s) from a subscription 5. The integration framework transforms the message it if needed 6. The integration framework sends the message to the target data source","title":"Overview"},{"location":"#integrations","text":"Currently we support the following integrations: D365 F&O to D365 CRM D365 CRM to D365 F&O Levridge Scale House Agsync Kahler Surety oneWeigh Field Reveal Levridge CRM Remote Printing Service","title":"Integrations"},{"location":"AddAddressForDeliveryAndInvoice/","text":"Add Address for Delivery and Invoice Brief introduction of the module, component or feature being documented. This document explains ... Add Address for Delivery and Invoice Go to Accounts receivable > Customers > All customers. In the list, find and select the desired record. In the list, click the link in the selected row. In the list, click the link in the selected row. In the list, click the link in the selected row. In the list, click the link in the selected row. Click Add. In the Name or description field, type a value. In the Purpose field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. In the list, select row 7. Click Select. In the Zip/Postal code field, type a value. In the Street field, type a value. Click OK.","title":"Add Address for Delivery and Invoice"},{"location":"AddAddressForDeliveryAndInvoice/#add-address-for-delivery-and-invoice","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Add Address for Delivery and Invoice"},{"location":"AddAddressForDeliveryAndInvoice/#add-address-for-delivery-and-invoice_1","text":"Go to Accounts receivable > Customers > All customers. In the list, find and select the desired record. In the list, click the link in the selected row. In the list, click the link in the selected row. In the list, click the link in the selected row. In the list, click the link in the selected row. Click Add. In the Name or description field, type a value. In the Purpose field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. In the list, select row 7. Click Select. In the Zip/Postal code field, type a value. In the Street field, type a value. Click OK.","title":"Add Address for Delivery and Invoice"},{"location":"AdjustFIFOInventoryValue/","text":"Adjust FIFO Inventory Value Brief introduction of the module, component or feature being documented. This document explains ... How to Adjust FIFO Inventory Value Close the page. Go to Inventory Management > Periodic tasks > Closing and Adjustment. Click Adjustment. Click On-hand. Click Select. Expand the Records to include section. Click Filter. In the list, find and select the desired record. In the list, find and select the desired record. In the Criteria field, type a value. Click OK. Click OK. In the list, mark the selected row. In the Unit cost field, enter a number. Click Post. Click OK. Click Details. Click Voucher. Close the page. Click Details. Click Adjustments report. Click Cancel. Click Details. Click Settlements. Click to follow the link in the Item number field. Click to follow the link in the Item number field. On the Action pane, click Manage Inventory. Click On-hand inventory. Refresh the page. Click Transactions. Close the page. Go to Inventory management > Inquiries and reports > On-hand list. Apply the following filters: Enter a filter value of \"\" on the \"Item number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Site\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Warehouse\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Serial number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Batch number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Search name\" field using the \"begins with\" filter operator Click Intercompany on-hand. Click the On-hand tab.","title":"Adjust FIFO Inventory Value"},{"location":"AdjustFIFOInventoryValue/#adjust-fifo-inventory-value","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Adjust FIFO Inventory Value"},{"location":"AdjustFIFOInventoryValue/#how-to-adjust-fifo-inventory-value","text":"Close the page. Go to Inventory Management > Periodic tasks > Closing and Adjustment. Click Adjustment. Click On-hand. Click Select. Expand the Records to include section. Click Filter. In the list, find and select the desired record. In the list, find and select the desired record. In the Criteria field, type a value. Click OK. Click OK. In the list, mark the selected row. In the Unit cost field, enter a number. Click Post. Click OK. Click Details. Click Voucher. Close the page. Click Details. Click Adjustments report. Click Cancel. Click Details. Click Settlements. Click to follow the link in the Item number field. Click to follow the link in the Item number field. On the Action pane, click Manage Inventory. Click On-hand inventory. Refresh the page. Click Transactions. Close the page. Go to Inventory management > Inquiries and reports > On-hand list. Apply the following filters: Enter a filter value of \"\" on the \"Item number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Site\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Warehouse\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Serial number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Batch number\" field using the \"begins with\" filter operator; Enter a filter value of \"\" on the \"Search name\" field using the \"begins with\" filter operator Click Intercompany on-hand. Click the On-hand tab.","title":"How to Adjust FIFO Inventory Value"},{"location":"AgSyncEndpoint/","text":"AgSyncEndpoint Settings AgSyncEndpoint is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the integration between FinOps and Agsync master data. Example \"AgSyncEndpoint\": { \"MustUseWktProcessor\": true, \"UuidSource\": \"Agsync\", \"BaseFieldUri\": \"https://fields.agsync.com/api/\", \"BaseOrderUri\": \"https://orders.agsync.com/api/\", \"tokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"ClientId\": \"[Agsync assigned client ID]\", \"ClientPass\": \"[Agsync assigned client password]\", \"VaultURL\": \"https://levridgeagsynckeyvault.vault.azure.net/\", \"AgSyncTokenKey\": \"AgsyncAccessToken\", \"RedirectUri\": \"[Agsync Integration Base URL]/api/AgsyncAuth\", \"IntegrationId\": \"[Agsync assigned integration Id]\" } Definition UuidSource BaseFieldUri BaseOrderUri tokenUrl ClientId ClientPass VaultURL AgSyncTokenKey RedirectUri IntegrationId","title":"AgSyncEndpoint Settings"},{"location":"AgSyncEndpoint/#agsyncendpoint-settings","text":"AgSyncEndpoint is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the integration between FinOps and Agsync master data.","title":"AgSyncEndpoint Settings"},{"location":"AgSyncEndpoint/#example","text":"\"AgSyncEndpoint\": { \"MustUseWktProcessor\": true, \"UuidSource\": \"Agsync\", \"BaseFieldUri\": \"https://fields.agsync.com/api/\", \"BaseOrderUri\": \"https://orders.agsync.com/api/\", \"tokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"ClientId\": \"[Agsync assigned client ID]\", \"ClientPass\": \"[Agsync assigned client password]\", \"VaultURL\": \"https://levridgeagsynckeyvault.vault.azure.net/\", \"AgSyncTokenKey\": \"AgsyncAccessToken\", \"RedirectUri\": \"[Agsync Integration Base URL]/api/AgsyncAuth\", \"IntegrationId\": \"[Agsync assigned integration Id]\" }","title":"Example"},{"location":"AgSyncEndpoint/#definition","text":"","title":"Definition"},{"location":"AgSyncEndpoint/#uuidsource","text":"","title":"UuidSource"},{"location":"AgSyncEndpoint/#basefielduri","text":"","title":"BaseFieldUri"},{"location":"AgSyncEndpoint/#baseorderuri","text":"","title":"BaseOrderUri"},{"location":"AgSyncEndpoint/#tokenurl","text":"","title":"tokenUrl"},{"location":"AgSyncEndpoint/#clientid","text":"","title":"ClientId"},{"location":"AgSyncEndpoint/#clientpass","text":"","title":"ClientPass"},{"location":"AgSyncEndpoint/#vaulturl","text":"","title":"VaultURL"},{"location":"AgSyncEndpoint/#agsynctokenkey","text":"","title":"AgSyncTokenKey"},{"location":"AgSyncEndpoint/#redirecturi","text":"","title":"RedirectUri"},{"location":"AgSyncEndpoint/#integrationid","text":"","title":"IntegrationId"},{"location":"Agronomy/","text":"Agronomy The CRM End-to-End Scenarios and Processes provides an overview of the following information: 1. Planned to Sales Agreement \u2013 sales tool within CRM used to price product and transition growers into contracts. 2. Fertilizer Calculator \u2013 utility that allows a salesman to determine and calculate fertilizer requirements such as what product best fits the need of the customer and how much of that product is needed to fulfill the order (some work is still needed and is anticipated to be ready in Fall of 2020). 3. Sales Order Process \u2013 integration of all Levridge pieces, specifically split billing, and its close integration with sales orders in FinOps.","title":"Levridge Agronomy"},{"location":"Agronomy/#agronomy","text":"The CRM End-to-End Scenarios and Processes provides an overview of the following information: 1. Planned to Sales Agreement \u2013 sales tool within CRM used to price product and transition growers into contracts. 2. Fertilizer Calculator \u2013 utility that allows a salesman to determine and calculate fertilizer requirements such as what product best fits the need of the customer and how much of that product is needed to fulfill the order (some work is still needed and is anticipated to be ready in Fall of 2020). 3. Sales Order Process \u2013 integration of all Levridge pieces, specifically split billing, and its close integration with sales orders in FinOps.","title":"Agronomy"},{"location":"Agsync/","text":"Agsync The scale integration is a bidirectional integration that consists of a Topic for Master Data that goes from D365 F&O to Agsync and Service Calls for Work Orders that go from Agsync to D365 F&O. The Work Order integration utilize a background service running in the same application as the Webhook controller so there is no need for two integration application instances. There are a few uniqe aspects to the Agsync integration that is different from other integrations: - The Workorder integration service runs in the same app service as the controller and the Master Data integration service - The Workorder integration service does all the transformation directly rather than using an EntityMapper - The Workorder integration service makes a direct service call to D365 F&O rather than using a data source - We are using CDS to provide lookup services for mapping entity identifiers between systems. - We utilize a filter on the event in F&O to send only the customers that need to sent from F&O to Agsync. Integration Description Standard Master Data Integration The standard master data integration configuration is shown below. External UUID Master Data Integration There is an alternate configuration that may be required when integrating with Field Reveal when Field Reveal is the master source for customer fields. In this scenario Field Reveal will provide the UUIDs it generates so we can provide those values to Agsync when we create the corresponding records in Agsync. This scenario is complicated and should be avoided if possible. The reason it is necessary is because when Field Reveal creates a work order in Agsync directly it uses an old Agsync API that uses a UUID as the Sync ID. Field Reveal generates the UUID and needs to provide those to Levridge so they can be used when creating the master record in Agsync. In this scenario, it is imperative that the Customer and Customer Operation is not sent from F&O until they have been updated in Field Reveal and a Field created in Field Reveal. Once a record is created in Agsync the UUID for it can not be modified. The order of creation is as follows: 1. Customer and Customer Operatoin are created in FinOps. 2. Grower and Farm are created in Field Reveal and SyncIds are added in Field Reveal. 3. Field is created in Field Reveal. 1. This will cause a Field record to be sent from Field Reveal to the Levridge Field controller . 2. The Field data will be placed on a service bus topic that has two subscriptions 1. One subscription will be serviced by the FieldToCDS integration service 1. This will use the UUID information to create a lookup record in CDS 2. The other subscription will be serviced by the FieldToAX integration service 1. This will create the Customer Site in FinOps 3. When the record is created in FinOps it will trigger the event that sends the data to Agsync 1. The creation of the Customer Site entity causes the event to be evaluated 2. The filter that checks to make sure a Customer has an operation that has a site that corresponds to a field passes 4. The Customer, Operation and Site are all sent to the FinOpsToAgsync service bus topic 5. The AxToAgsync integration service receives the message and looks up the UUIDs from CDS then sends the records to Agsync for creation 6. Agsync creates the records and sends back a GUID. 7. The AxToAgsync integration updates CDS with the GUID values. This communication diagram depicts this interaction: Work Order Integration Controllers Agsync Auth Controller The AgsyncAuth controller is used to generate a token needed to integrate with Agsync. Agsync Auth Test Controller The AgsyncAuthTest controller is used to ... Agsync Order Changed Controller The AgsyncOrderChanged controller is used by Agsync to send work orders as they are created or updated. This controller will bundle the work order into a message and place it in the message topic. Agsync Sync Accounts Controller The AgsyncSyncAccounts controller is used to query Agsync for master data and write the information into CDS. This is done during go-live to populate the lookup data in CDS. Agsync UUID Controller The AgsyncUUID controller provides UUIDs based on Sync Ids passed to the controller. This is used by Field Reveal to obtain the UUID from the Sync ID entered into Field Reveal. Setup To integrate from D365 F&O to Agsync you will need to: Create an Azure Service bus topic Create a subscription on the topic above Configure Event Endpoint in F&O configure Levridge Entity Events Create Filter on Entity Event to only send agronomy customers Get Client ID and CLient password from Agsync Get Customer Specific Integration ID from Agsync Client Redirect URL is [Azure Webapp base URL]/api/AgsyncAuth Setup Azure Keyvault Create an application ID for the integration framework to authenticate to D365 CRM Create an application user in D365 CRM and assign the proper role(s) Configuration In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with service bus topic and subscription for Agsync Master Data]\", \"ODataConfigName\": \"[section name with F&O data configuration]\", \"SystemName\": \"DynamicsAx\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with Agsync endpoint configuration]\", \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"AgSync\", \"Direction\": \"Target\", } You must also include the controller entry to have the controller loaded: \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" } You must also configure two objects for Agsync integration: AgSyncEndpoint agsync Here is a sample template for the entire appsettings.json file used for the integration from FinOps to Agsync: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"SourceConfig\": { \"ServiceBusConfigName\": \"AgsyncMasterDataServiceBus\", \"ODataConfigName\": \"DynamicsAX\", \"SystemName\": \"DynamicsAx\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"AgSyncEndpoint\", \"SystemName\": \"AgSync\", \"Direction\": \"Target\", \"CDSConfigName\": \"CDS\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"CDS\": { \"UriString\": \"[URL to CDS or Localhost]\", \"ActiveDirectoryResource\": \"[URL to CDS]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to CDS]/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"AgSyncEndpoint\": { \"MustUseWktProcessor\": true, \"baseUri\": \"https://fields.agsync.com/api/\", \"tokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"ClientId\": \"[client ID assigned by Agsync]\", // customer specific \"ClientPass\": \"[Client Secret assigned by Agsync]\", // customer specific \"ValutURL\": \"[URL to customer Azure Key Vault]\", \"AgSyncTokenKey\": \"AgsyncAccessToken\", \"RedirectUri\": \"[URL to AgsyncAuth controller]\", // customer specific \"IntegrationId\": \"CustomerIntegrationID\" // customer specific }, \"agsync\": { // used by Webhook \"MustUseWktProcessor\": true, \"ConnectionString\": \"[connection string to Agsync master data topic]\", \"TopicName\": \"[Agsync master data topic]\", \"RequiresSession\": true, \"RedirectUri\": \"[URL to AgsyncAuth controller]\", \"TokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"AuthorizeUrl\": \"https://auth.agsync.com/core/connect/authorize\", \"baseUri\": \"https://fields.agsync.com/api/\", \"ClientId\": \"[client ID assigned by Agsync]\", \"ClientPass\": \"[Client Secret assigned by Agsync]\", \"ValutURL\": \"[URL to customer Azure Key Vault]\", \"AgSyncTokenKey\": \"AgsyncAccessToken\" }, \"AgsyncMasterDataServiceBus\": { \"ConnectionString\": \"[connection string to Agsync master data topic]\", \"TopicName\": \"[Agsync master data topic]\", \"SubscriptionName\": \"[Agsync master data subscription name]\", \"RequiresSession\": true } }","title":"Agsync"},{"location":"Agsync/#agsync","text":"The scale integration is a bidirectional integration that consists of a Topic for Master Data that goes from D365 F&O to Agsync and Service Calls for Work Orders that go from Agsync to D365 F&O. The Work Order integration utilize a background service running in the same application as the Webhook controller so there is no need for two integration application instances. There are a few uniqe aspects to the Agsync integration that is different from other integrations: - The Workorder integration service runs in the same app service as the controller and the Master Data integration service - The Workorder integration service does all the transformation directly rather than using an EntityMapper - The Workorder integration service makes a direct service call to D365 F&O rather than using a data source - We are using CDS to provide lookup services for mapping entity identifiers between systems. - We utilize a filter on the event in F&O to send only the customers that need to sent from F&O to Agsync.","title":"Agsync"},{"location":"Agsync/#integration-description","text":"","title":"Integration Description"},{"location":"Agsync/#standard-master-data-integration","text":"The standard master data integration configuration is shown below.","title":"Standard Master Data Integration"},{"location":"Agsync/#external-uuid-master-data-integration","text":"There is an alternate configuration that may be required when integrating with Field Reveal when Field Reveal is the master source for customer fields. In this scenario Field Reveal will provide the UUIDs it generates so we can provide those values to Agsync when we create the corresponding records in Agsync. This scenario is complicated and should be avoided if possible. The reason it is necessary is because when Field Reveal creates a work order in Agsync directly it uses an old Agsync API that uses a UUID as the Sync ID. Field Reveal generates the UUID and needs to provide those to Levridge so they can be used when creating the master record in Agsync. In this scenario, it is imperative that the Customer and Customer Operation is not sent from F&O until they have been updated in Field Reveal and a Field created in Field Reveal. Once a record is created in Agsync the UUID for it can not be modified. The order of creation is as follows: 1. Customer and Customer Operatoin are created in FinOps. 2. Grower and Farm are created in Field Reveal and SyncIds are added in Field Reveal. 3. Field is created in Field Reveal. 1. This will cause a Field record to be sent from Field Reveal to the Levridge Field controller . 2. The Field data will be placed on a service bus topic that has two subscriptions 1. One subscription will be serviced by the FieldToCDS integration service 1. This will use the UUID information to create a lookup record in CDS 2. The other subscription will be serviced by the FieldToAX integration service 1. This will create the Customer Site in FinOps 3. When the record is created in FinOps it will trigger the event that sends the data to Agsync 1. The creation of the Customer Site entity causes the event to be evaluated 2. The filter that checks to make sure a Customer has an operation that has a site that corresponds to a field passes 4. The Customer, Operation and Site are all sent to the FinOpsToAgsync service bus topic 5. The AxToAgsync integration service receives the message and looks up the UUIDs from CDS then sends the records to Agsync for creation 6. Agsync creates the records and sends back a GUID. 7. The AxToAgsync integration updates CDS with the GUID values. This communication diagram depicts this interaction:","title":"External UUID Master Data Integration"},{"location":"Agsync/#work-order-integration","text":"","title":"Work Order Integration"},{"location":"Agsync/#controllers","text":"","title":"Controllers"},{"location":"Agsync/#agsync-auth-controller","text":"The AgsyncAuth controller is used to generate a token needed to integrate with Agsync.","title":"Agsync Auth Controller"},{"location":"Agsync/#agsync-auth-test-controller","text":"The AgsyncAuthTest controller is used to ...","title":"Agsync Auth Test Controller"},{"location":"Agsync/#agsync-order-changed-controller","text":"The AgsyncOrderChanged controller is used by Agsync to send work orders as they are created or updated. This controller will bundle the work order into a message and place it in the message topic.","title":"Agsync Order Changed Controller"},{"location":"Agsync/#agsync-sync-accounts-controller","text":"The AgsyncSyncAccounts controller is used to query Agsync for master data and write the information into CDS. This is done during go-live to populate the lookup data in CDS.","title":"Agsync Sync Accounts Controller"},{"location":"Agsync/#agsync-uuid-controller","text":"The AgsyncUUID controller provides UUIDs based on Sync Ids passed to the controller. This is used by Field Reveal to obtain the UUID from the Sync ID entered into Field Reveal.","title":"Agsync UUID Controller"},{"location":"Agsync/#setup","text":"To integrate from D365 F&O to Agsync you will need to: Create an Azure Service bus topic Create a subscription on the topic above Configure Event Endpoint in F&O configure Levridge Entity Events Create Filter on Entity Event to only send agronomy customers Get Client ID and CLient password from Agsync Get Customer Specific Integration ID from Agsync Client Redirect URL is [Azure Webapp base URL]/api/AgsyncAuth Setup Azure Keyvault Create an application ID for the integration framework to authenticate to D365 CRM Create an application user in D365 CRM and assign the proper role(s)","title":"Setup"},{"location":"Agsync/#configuration","text":"In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with service bus topic and subscription for Agsync Master Data]\", \"ODataConfigName\": \"[section name with F&O data configuration]\", \"SystemName\": \"DynamicsAx\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with Agsync endpoint configuration]\", \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"AgSync\", \"Direction\": \"Target\", } You must also include the controller entry to have the controller loaded: \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" } You must also configure two objects for Agsync integration: AgSyncEndpoint agsync Here is a sample template for the entire appsettings.json file used for the integration from FinOps to Agsync: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"SourceConfig\": { \"ServiceBusConfigName\": \"AgsyncMasterDataServiceBus\", \"ODataConfigName\": \"DynamicsAX\", \"SystemName\": \"DynamicsAx\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"AgSyncEndpoint\", \"SystemName\": \"AgSync\", \"Direction\": \"Target\", \"CDSConfigName\": \"CDS\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"CDS\": { \"UriString\": \"[URL to CDS or Localhost]\", \"ActiveDirectoryResource\": \"[URL to CDS]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to CDS]/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"AgSyncEndpoint\": { \"MustUseWktProcessor\": true, \"baseUri\": \"https://fields.agsync.com/api/\", \"tokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"ClientId\": \"[client ID assigned by Agsync]\", // customer specific \"ClientPass\": \"[Client Secret assigned by Agsync]\", // customer specific \"ValutURL\": \"[URL to customer Azure Key Vault]\", \"AgSyncTokenKey\": \"AgsyncAccessToken\", \"RedirectUri\": \"[URL to AgsyncAuth controller]\", // customer specific \"IntegrationId\": \"CustomerIntegrationID\" // customer specific }, \"agsync\": { // used by Webhook \"MustUseWktProcessor\": true, \"ConnectionString\": \"[connection string to Agsync master data topic]\", \"TopicName\": \"[Agsync master data topic]\", \"RequiresSession\": true, \"RedirectUri\": \"[URL to AgsyncAuth controller]\", \"TokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"AuthorizeUrl\": \"https://auth.agsync.com/core/connect/authorize\", \"baseUri\": \"https://fields.agsync.com/api/\", \"ClientId\": \"[client ID assigned by Agsync]\", \"ClientPass\": \"[Client Secret assigned by Agsync]\", \"ValutURL\": \"[URL to customer Azure Key Vault]\", \"AgSyncTokenKey\": \"AgsyncAccessToken\" }, \"AgsyncMasterDataServiceBus\": { \"ConnectionString\": \"[connection string to Agsync master data topic]\", \"TopicName\": \"[Agsync master data topic]\", \"SubscriptionName\": \"[Agsync master data subscription name]\", \"RequiresSession\": true } }","title":"Configuration"},{"location":"AgsyncUUID/","text":"AgsyncUUID Controller The AgsyncUUID controller returns Agsync UUID values based on SyncIds provided to the controller. Overview The AgsyncUUID controller has one GET method and two POST methods. GET Method The GET method in the form of [BaseURL]/api/AgsyncUUID/[recordType]/[id]. The valid record types are: - Account - Grower - Farm - Field POST Methods The two POST methods both take a UuidCompositeRequest and return UuidCompositeResponse as a response. One URL accepts a record type (one of the valid strings above) in the form of [BaseURL]/api/AgsyncUUID/[recordType] with a UuidCompositeRequest in the body. This action will populate the UuidCompositeResponse in a hierarchical manner. For example, if the record type is \"Account\" only the account values will be returned. If the record type is \"Grower\" then the grower and account values will be returned. If the record type is \"Field\" then all record values will be returned. The second POST does not take a record type. It will simply take a UuidCompositeRequest in the body and will populate the values for any non-empty ID. For example, if the UuidCompositeRequest.AccountId and the UuidCompositeRequest.FieldId have values their respective identifying values will be returned in the UuidCompositeResponse . If there are any errors, they will always be reported in the UuidCompositResponse.FieldName value.","title":"AgsyncUUID Controller"},{"location":"AgsyncUUID/#agsyncuuid-controller","text":"The AgsyncUUID controller returns Agsync UUID values based on SyncIds provided to the controller.","title":"AgsyncUUID Controller"},{"location":"AgsyncUUID/#overview","text":"The AgsyncUUID controller has one GET method and two POST methods.","title":"Overview"},{"location":"AgsyncUUID/#get-method","text":"The GET method in the form of [BaseURL]/api/AgsyncUUID/[recordType]/[id]. The valid record types are: - Account - Grower - Farm - Field","title":"GET Method"},{"location":"AgsyncUUID/#post-methods","text":"The two POST methods both take a UuidCompositeRequest and return UuidCompositeResponse as a response. One URL accepts a record type (one of the valid strings above) in the form of [BaseURL]/api/AgsyncUUID/[recordType] with a UuidCompositeRequest in the body. This action will populate the UuidCompositeResponse in a hierarchical manner. For example, if the record type is \"Account\" only the account values will be returned. If the record type is \"Grower\" then the grower and account values will be returned. If the record type is \"Field\" then all record values will be returned. The second POST does not take a record type. It will simply take a UuidCompositeRequest in the body and will populate the values for any non-empty ID. For example, if the UuidCompositeRequest.AccountId and the UuidCompositeRequest.FieldId have values their respective identifying values will be returned in the UuidCompositeResponse . If there are any errors, they will always be reported in the UuidCompositResponse.FieldName value.","title":"POST Methods"},{"location":"ApplicationConfiguration/","text":"Application Configuration The Levridge Integration Framework utilizes standard Microsoft Configuration for ASP.NET Core to mange configuration settings. This document explains what configuration settings are managed and the definition, location and valid options for each setting. Overview There are five sources that are utilized for configuration data. Those sources are: web.config file command-line arguments hostsettings.json file Environment variables appsettings.json file Azure Key Vault","title":"Application Settings Configuration"},{"location":"ApplicationConfiguration/#application-configuration","text":"The Levridge Integration Framework utilizes standard Microsoft Configuration for ASP.NET Core to mange configuration settings. This document explains what configuration settings are managed and the definition, location and valid options for each setting.","title":"Application Configuration"},{"location":"ApplicationConfiguration/#overview","text":"There are five sources that are utilized for configuration data. Those sources are: web.config file command-line arguments hostsettings.json file Environment variables appsettings.json file Azure Key Vault","title":"Overview"},{"location":"AssignItemToProcurementCategory/","text":"Assign an Item to a Procurement Category Brief introduction of the module, component or feature being documented. This document explains ... How to Assign an Item to a Procurement Category Go to Product Information Management > Products > Released Products. In the list, find and select the desired record. Click Product categories. Click Edit. In the Category field, enter or select a value. In the tree, select 'ALL (New Category)\\Farm Supplies (New Category)'. Click OK. Click Save. In the Category field, enter or select a value. In the tree, select 'ALL (New Category)\\Natural Gas (New Category)'. Click OK. Click Save. Close the page. Close the page. Go to Procurement and Sourcing > Procurement Categories. In the tree, expand 'Landus\\Corporate'. In the tree, select 'Landus\\Corporate\\Equipment lease'. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. Click OK. Click Save. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the Item number field with a value of '110.1' Click Product Categories.","title":"Assign Item to a Procurement Category"},{"location":"AssignItemToProcurementCategory/#assign-an-item-to-a-procurement-category","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Assign an Item to a Procurement Category"},{"location":"AssignItemToProcurementCategory/#how-to-assign-an-item-to-a-procurement-category","text":"Go to Product Information Management > Products > Released Products. In the list, find and select the desired record. Click Product categories. Click Edit. In the Category field, enter or select a value. In the tree, select 'ALL (New Category)\\Farm Supplies (New Category)'. Click OK. Click Save. In the Category field, enter or select a value. In the tree, select 'ALL (New Category)\\Natural Gas (New Category)'. Click OK. Click Save. Close the page. Close the page. Go to Procurement and Sourcing > Procurement Categories. In the tree, expand 'Landus\\Corporate'. In the tree, select 'Landus\\Corporate\\Equipment lease'. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. Click OK. Click Save. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the Item number field with a value of '110.1' Click Product Categories.","title":"How to Assign an Item to a Procurement Category"},{"location":"AssignPostingProfiletoProcurementCategory/","text":"Assign Posting Profile to Procurement Category Brief introduction of the module, component or feature being documented. This document explains ... How to Assign a Posting Profile to a Procurement Category Go to Inventory Management > Setup > Posting > Posting. Click the Purchase Order tab. In the Select field, select an option. Click New. In the list, mark the selected row. In the Item code field, select an option. In the Category Relation field, enter or select a value. In the tree, expand 'Landus (New category)\\Corporate (Corporate)'. In the tree, select 'Landus (New category)\\Corporate (Corporate)\\Office Supplies (New category)'. Click OK. In the list, find and select the desired record. In the Category relation field, enter or select a value. In the tree, select 'Landus (New Category)\\Animal Nutrition (Animal Nutrition)'. Click OK. In the Main account field, specify the desired values. Click Save. In the list, find and select the desired record. Close the page.","title":"Assign Posting Profile to Procuremnet Category"},{"location":"AssignPostingProfiletoProcurementCategory/#assign-posting-profile-to-procurement-category","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Assign Posting Profile to Procurement Category"},{"location":"AssignPostingProfiletoProcurementCategory/#how-to-assign-a-posting-profile-to-a-procurement-category","text":"Go to Inventory Management > Setup > Posting > Posting. Click the Purchase Order tab. In the Select field, select an option. Click New. In the list, mark the selected row. In the Item code field, select an option. In the Category Relation field, enter or select a value. In the tree, expand 'Landus (New category)\\Corporate (Corporate)'. In the tree, select 'Landus (New category)\\Corporate (Corporate)\\Office Supplies (New category)'. Click OK. In the list, find and select the desired record. In the Category relation field, enter or select a value. In the tree, select 'Landus (New Category)\\Animal Nutrition (Animal Nutrition)'. Click OK. In the Main account field, specify the desired values. Click Save. In the list, find and select the desired record. Close the page.","title":"How to Assign a Posting Profile to a Procurement Category"},{"location":"AzureAd/","text":"AzureAd Settings Optional Example \"AzureAd\": { \"Instance\": \"https://login.microsoftonline.com/\", \"Domain\": \"stoneridgesoftware.com\", \"TenantId\": \"[Tenant ID GUID]\", \"ClientId\": \"[Client ID GUID]\", \"CallbackPath\": \"/signin-oidc\", \"SignedOutCallbackPath \": \"/signout-callback-oidc\" } Definition AzureAd Instance Required No Default value The azure cloud instance to use for authentication. Most of the time this value should be \"https://login.microsoftonline.com/\" for the Azure public cloud. There may be a use for country specific instances such as \"https://login.microsoftonline.de/\" for Azure AD Germany. Domain Required No Default value The domain of the AD tenant used for authentication. This may be your domain (i.e. stoneridgesoftware.com) or it may be sub-domain of onmicrosoft. (i.e. contoso.onmicrosoft.com) TenantId Required No Default value The TenantId (aka audience) that will be used for authentication. The following values are valid: \"TenantId\" as a GUID obtained from the Azure portal to sign in users in your organization \"organizations\" to sign in users in any work or school account \"common\" to sign in users with any work or school account or Microsoft personal account \"consumers\" to sign in users with a Microsoft personal account only ClientId Required No Default value The Client ID (aka application ID) assigned in the Azure Portal. This client ID is obtained by enabling Authentication and Authorization in the Azure Portal. Once Authentication is enabled you can obtain the ClientId from the Authentication / Authorization section of the app service. Select Azure Active Directory and then select the Azure AD App. CallbackPath Optional Default = false SignedOutCallbackPath Optional Default = false","title":"AzureAd Settings"},{"location":"AzureAd/#azuread-settings","text":"Optional","title":"AzureAd Settings"},{"location":"AzureAd/#example","text":"\"AzureAd\": { \"Instance\": \"https://login.microsoftonline.com/\", \"Domain\": \"stoneridgesoftware.com\", \"TenantId\": \"[Tenant ID GUID]\", \"ClientId\": \"[Client ID GUID]\", \"CallbackPath\": \"/signin-oidc\", \"SignedOutCallbackPath \": \"/signout-callback-oidc\" }","title":"Example"},{"location":"AzureAd/#definition","text":"","title":"Definition"},{"location":"AzureAd/#azuread","text":"","title":"AzureAd"},{"location":"AzureAd/#instance","text":"Required No Default value The azure cloud instance to use for authentication. Most of the time this value should be \"https://login.microsoftonline.com/\" for the Azure public cloud. There may be a use for country specific instances such as \"https://login.microsoftonline.de/\" for Azure AD Germany.","title":"Instance"},{"location":"AzureAd/#domain","text":"Required No Default value The domain of the AD tenant used for authentication. This may be your domain (i.e. stoneridgesoftware.com) or it may be sub-domain of onmicrosoft. (i.e. contoso.onmicrosoft.com)","title":"Domain"},{"location":"AzureAd/#tenantid","text":"Required No Default value The TenantId (aka audience) that will be used for authentication. The following values are valid: \"TenantId\" as a GUID obtained from the Azure portal to sign in users in your organization \"organizations\" to sign in users in any work or school account \"common\" to sign in users with any work or school account or Microsoft personal account \"consumers\" to sign in users with a Microsoft personal account only","title":"TenantId"},{"location":"AzureAd/#clientid","text":"Required No Default value The Client ID (aka application ID) assigned in the Azure Portal. This client ID is obtained by enabling Authentication and Authorization in the Azure Portal. Once Authentication is enabled you can obtain the ClientId from the Authentication / Authorization section of the app service. Select Azure Active Directory and then select the Azure AD App.","title":"ClientId"},{"location":"AzureAd/#callbackpath","text":"Optional Default = false","title":"CallbackPath"},{"location":"AzureAd/#signedoutcallbackpath","text":"Optional Default = false","title":"SignedOutCallbackPath"},{"location":"AzureKeyVault/","text":"Introduction Azure Key Vault Overview","title":"Introduction"},{"location":"AzureKeyVault/#introduction","text":"Azure Key Vault Overview","title":"Introduction"},{"location":"AzureTableEntityConfiguration/","text":"AzureTableEntityConfiguration Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"AzureTableEntityConfiguration"},{"location":"AzureTableEntityConfiguration/#azuretableentityconfiguration","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"AzureTableEntityConfiguration"},{"location":"AzureTableEntityConfiguration/#overview","text":"","title":"Overview"},{"location":"AzureTableEntityConfiguration/#main-point-1","text":"","title":"Main Point 1"},{"location":"AzureTableEntityConfiguration/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"BasicCustomerPriceSetup/","text":"Basic Customer Price Setup Brief introduction of the module, component or feature being documented. This document explains ... Basic Customer Price Setup Go to Product information management > Products > Released products. In the list, click the link in the selected row. Click Edit. In the Price field, enter a number. Click Save. Close the page. Go to Accounts receivable > Orders > All sales orders. In the list, find and select the desired record. In the list, click the link in the selected row. Click Remove. Click Yes. Click Add line. In the Item number field, type a value. In the Site field, type a value. In the Warehouse field, type a value.","title":"Basic Customer Price Setup"},{"location":"BasicCustomerPriceSetup/#basic-customer-price-setup","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Basic Customer Price Setup"},{"location":"BasicCustomerPriceSetup/#basic-customer-price-setup_1","text":"Go to Product information management > Products > Released products. In the list, click the link in the selected row. Click Edit. In the Price field, enter a number. Click Save. Close the page. Go to Accounts receivable > Orders > All sales orders. In the list, find and select the desired record. In the list, click the link in the selected row. Click Remove. Click Yes. Click Add line. In the Item number field, type a value. In the Site field, type a value. In the Warehouse field, type a value.","title":"Basic Customer Price Setup"},{"location":"BasicVendorPriceWithPriceUpdate/","text":"Basic Vendor Price with Price Update Brief introduction of the module, component or feature being documented. This document explains ... Basic Vendor Price with Price Update Go to Product Information Management > Products > Released Products. In the list, click the link in the selected row. Click Edit. Select Yes in the Latest pruchase price field. In the Price field, enter a number. Click Save. Close the page. Go to Procurement and Sourcing > Puchase Orders > All purchase orders. In the list, find and select the desired record. In the list, click the link in the selected row. Click Remove. Click Yes. Click Add line. In the Item number field, type a value. In the list, mark the selected row. In the unit price field, enter a number. Click Save. On the Action Pane, click Purchase. Click Confirm. On the Action Pane, click Receive. Click Product Receipt. In the list, mark the selected row. Open Product receipt column filter. Sort A to Z In the Product receipt field, type a value. Click OK. On the Action Pane, click Invoice. Click Invoice. In the Number field, type a value. Click Post. Click Update match status. Click Post. Close the page. Close the page. Go to Product Information Management > Products > Released Products. In the list, click the link in the selected row.","title":"Basic Vendor Price with Price Update"},{"location":"BasicVendorPriceWithPriceUpdate/#basic-vendor-price-with-price-update","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Basic Vendor Price with Price Update"},{"location":"BasicVendorPriceWithPriceUpdate/#basic-vendor-price-with-price-update_1","text":"Go to Product Information Management > Products > Released Products. In the list, click the link in the selected row. Click Edit. Select Yes in the Latest pruchase price field. In the Price field, enter a number. Click Save. Close the page. Go to Procurement and Sourcing > Puchase Orders > All purchase orders. In the list, find and select the desired record. In the list, click the link in the selected row. Click Remove. Click Yes. Click Add line. In the Item number field, type a value. In the list, mark the selected row. In the unit price field, enter a number. Click Save. On the Action Pane, click Purchase. Click Confirm. On the Action Pane, click Receive. Click Product Receipt. In the list, mark the selected row. Open Product receipt column filter. Sort A to Z In the Product receipt field, type a value. Click OK. On the Action Pane, click Invoice. Click Invoice. In the Number field, type a value. Click Post. Click Update match status. Click Post. Close the page. Close the page. Go to Product Information Management > Products > Released Products. In the list, click the link in the selected row.","title":"Basic Vendor Price with Price Update"},{"location":"BasicVendorPurchasePrice/","text":"Basic Vendor Purchase Price Brief introduction of the module, component or feature being documented. This document explains ... Basic Vendor Purchase Price Go to Product information management > Products > Released products. In the list, click the link in the selected row. Click Edit. In the Price field, enter a number. Click Save. Close the page. Go to Procurement and sourcing > Purchase orders > All purchase orders. Click New. In the Vendor account field, type a value. In the Warehouse field, type a value. Click OK. In the Item number field, type a value.","title":"Basic Vendor Purchase Price"},{"location":"BasicVendorPurchasePrice/#basic-vendor-purchase-price","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Basic Vendor Purchase Price"},{"location":"BasicVendorPurchasePrice/#basic-vendor-purchase-price_1","text":"Go to Product information management > Products > Released products. In the list, click the link in the selected row. Click Edit. In the Price field, enter a number. Click Save. Close the page. Go to Procurement and sourcing > Purchase orders > All purchase orders. Click New. In the Vendor account field, type a value. In the Warehouse field, type a value. Click OK. In the Item number field, type a value.","title":"Basic Vendor Purchase Price"},{"location":"CDSConfig/","text":"","title":"CDSConfig"},{"location":"CRM-End-To-End-Scenarios/","text":"CRM End-to-End Scenarios Overview Planned to Sales Agreement - sales tool within CRM used to price product and transition growers into contracts. Fertilizer Calculator - utility that allows a salesman to determine and calculate fertilizer requirements such as what product best fits the need of the customer and how much of that product is needed to fulfill the order (some work is still needed and is anticipated to be ready in Fall of 2020). Sales Order Process - integration of all Levridge pieces, specifically split billing, and its close integration with sales orders in FinOps. Process #1: Planned to Sales Agreement There are three separate methods of kicking off a planned sales agreement within CRM: batch plans, regular plan, and proposals. Batch Plans Batch Plans tab Generate New Populate required fields Name \u2013 this field will auto populate when you save Proposal Type - there are three proposal types: Customer, Field and Prospect. The batch plan will auto populate to the Customer Type. Account Customer Operation Split Group Sales Period \u2013 we need this so we can accurately price Save Programs Tab Farmable acreage field is required Preconfigured set of products in many cases an agronomist recommends the same products at the same rate so instead of calculating these rates each time, you can set up a program, so it automatically calculates product and rate. Add products utilizing the tabs across the top of the batch plan, (seed, fertilizer, chemical, etc.) After adding your products, you can either Generate a proposal Generate a sales agreement Proposal Types There are three different proposal types within a batch plan: Customer, Prospect, and Field. Customer - simplest proposal type and is the most used proposal type for a batch plan Prospect - individual the salesman is pursuing that is not a current client and we want a way to generate a price for product and a contact for the potential client Generate contact Sales period Farmable Acreage approximation Navigate to the seed, fertilizer, or chemical tab(s) to add product Create proposal Open proposal Proposal lines tab Run report Print Proposal Give to potential client Field - least common proposal type used Only benefit of the field is if we go through and make individual plans in a lot of cases, we will use the same product on all of them You can add products once to all appliable fields Creating a Regular Plan Plan to sales agreement Plans Generate new plan record Populate applicable fields Account Customer Operation Customer site \u2013 physical piece of land that you are putting the product on Split group Description - multiple plans for a field may be created so a detailed description is important Desired Crop Growing Season \u2013 what year this product will be applied to the field Utilize the tabs (Programs and Recommendations, seed, fertilizer, or chemical) to add applicable product(s) Program and recommendations Programs \u2013 ability to add existing or new programs Recommendations \u2013 attachment to precision mapping tools Seed (Unit) Seed calculator \u2013 helps do the math to easily populate the quantity field Add product line(s) for all required seed Fertilizer Timing \u2013 when to apply product Product Rate Unit/Rate This calculation not only helps get product pricing but also helps us know when the grower needs specific products applied Chemical Timing \u2013 when to apply product Product Rate Unit/Rate This calculation not only helps get product pricing but also helps us know when the grower needs specific products applied Plan is complete and proposal can be generated New Proposal Plan to sales agreement Proposals Generate new proposal Populate applicable fields Description Account Customer operation Split group Growing season Sales period Manager \u2013 the client will have a workflow that sets who the Manager is so it is auto generated, this is a customization Associated plans Add existing plans Select all associated plans created for this specific grower Add Create lines This function goes through each plan taking all product information and the split groups behind them and generates individual product lines for them and creates pricing for them Item category terms Allows you to set different payment methods by product Select item category (product) Select payment method Save Proposal lines Often discounts/incentives are provided to get the producer to agree to the proposal price Launch line you would like to discount Charge codes Add new proposal line change Select charge code \u2013 charge codes are user defined data that are defined in FinOps/AX and are integrated over to CE/CRM Value \u2013 dollar amount to be deducted off total product price Save Refresh Proposal line will be updated to reflect new net unit price after charge code has been applied Unit price \u2013 you can manually override this field to decrease price as well Calculate prices Add product lines from proposal lines tab In some instances, a customer will decide to add products after you have generated the proposal. Using the add new proposal line within the proposal lines tab will allow you to add last minute products to the proposal and recalculate price. 1. (+) New proposal line 2. Select product 3. Quantity 4. Save 5. Calculate prices 6. Line will be added to the proposal lines tab and price will be updated for that product from data from FinOps/AX. Submit for Approval Once your proposal is priced and complete, it is ready to be submitted for approval. The submit for approval function/button ensures that margin on products are maintained throughout the sales process. Submit for approval Looks for any charge code or line item changes that were made and compares them to the defined thresholds that have been set If any changes rise above threshold set, it will stop the process, lock down proposal and send to the Manager that the proposal needs approval before moving forward to contract/ agreement Seed Patented traits owned by specific manufacturer that you must have a license from that manufacturer before you can purchase and use product The system will look and see if grower has a valid agreement to buy this product and there is configuration in FinOps/AX to either warn/stop continued process With seed you will typically use the \u201cwarn\u201d function instead of fully stopping the process Restricted use pesticides Based on Federal/State laws, before restricted use products can be picked up, we must ensure that the applicator has a valid license to apply these products. This license number needs to be physically listed on the invoice. This will warn the process that this item needs to be taken care of. At this point in the process we may not know who is applying the product, so it is important to check back in until the license number has been documented. Generate sales agreement After the sales agreement is generated, it is sent across to FinOps/AX At this point, the process within CE/CRM is complete The final step in the sales process would be to pull up the third-party integration (ex. Hello Sign) to capture a digital signature Process #2 Fertilizer Calculator The Fertilizer Calculator is a tool used to generate blends of fertility products. Planning Tools Fertilizer Calculator Generate New Populate applicable fields Customer Customer Operation Batch Size \u2013 blender capacity so when generated it relays how many batches will need to occur to fulfill the order Fertilizer State Dry Liquid Save Blend Lines will populate with nutrient and product Input either input value (lbs.) or ratio (percentage) Click Calculate to populate output Quantity needed Total blend amount Number of batches needed Blend Percent Generate sales order and release report to blender facilities to begin blending product (this function/button is not currently available but will be once it is fully developed and tested). Process #3 Sales Order Process The sales order is comprised of two pieces: the sales order and the work order. Both are tightly integrated within FinOps. The purpose of the sales order is to give users that only have access to CE/CRM the ability to enter orders for delivery and perform some of the functions that are usually completed in FinOps/AX. Generating New Sales Order in CE/CRM Sales order tab Generate new Populate applicable sales order fields Account Customer operation - if the customer only has 1 operation it will default, otherwise, it will filter down to their operations Split group - who will be paying for the product Delivery address - delivery address is a requirement for many of the actions in FinOps Inventory site - where inventory is coming from Branch - who is responsible for the customer or in charge of handling the billing Sales period - sales period is used to price the products against Ship date - not required and will default if not manually populated Save Enter Sales Order Lines Add product 2 Pick quantity Save After saving the estimated price, which is pulled from CRM/CE, will be populated. This may not be the price that is actually paid but is a stored list price that adjustments can be made to. Submit for Approval Checks for any products that need an applicators license Checks for any seed tech licenses that may be required Credit check (based off the credit settings within FinOps, it will either warn/deny generating sales order) Generate Sales Order Once your submission has been approved, you will need to generate a sales order in FinOps/AX You will receive a pop-up notifying you the sales order was created successfully in FinOps/AX Once order is acted upon in FinOps, you can go into the line details within CE/CRM and it will give more information on the split group allocations (quantities, dates shipped, etc) so the person in CE/CRM has access to some of that detail Work Order The work order is a type of sales order where the Ag Retailer will be performing a service. A work order requires more detail than a basic sales order. 1. Orders 2. Work Orders 3. Generate New 4. Populate applicable fields - Account - Customer Operation - Customer Site - Auto Print \u2013 printer logic exists to automatically print a report remotely would be needed when a hard copy is necessary for the remote location to send with the driver - Sales Site \u2013 party who is responsible for the sale of the product - Application Site \u2013 party performing task - Application Operation \u2013 type of work being done (synced with AgSync) - Application Date \u2013 anticipated application date of the product - Application Window \u2013 for chemical product this is important because depending on stage of the crop, it could cause harm if applied outside of a specific timeframe - Crop \u2013 crop product will be applied to - Order Status - Planned \u2013 occurring in the future - Booked \u2013 occurring in the future - Released \u2013 moved to queue to get done and application date is set - Scheduled \u2013 it will happen today or tomorrow and has been assigned to an applicator - In-Progress \u2013 product was administered partially and due to some unforeseen event, the job was not completed and requires further attention - Completed Pending Review \u2013 application is complete - Archived - Rejected - Work Order ID \u2013 generated number out of AgSync. - Dispensing Order Number \u2013 only comes into effect if there is a blender/Kahler integration. This number is created when the picking list / mixed ticket is dispatched out to the warehouse. - Ordering Notes - Notes that are specific to the field (ex. Approach on NW Corner) - Notes that are specific to application (ex. Spray when wind is coming from NW to ensure surrounding susceptible fields are not sprayed) - Application Notes \u2013 notes or observation that equipment operator made while in the field 5. Save Enter Work Order Lines Work Order Lines tab Add new line Populate applicable fields Sales Sites Customer Product Pests \u2013 when spraying chemicals some states require documentation that states purpose of application Application Site Quantity Submit for Approval \u2013 if this is an integrated order from AgSync or from some third-party dispatch, the submit for approval function/button would be gone but if you generate in CRM you would see submit for approval If you open a work order line, you will be able to view the Work Order Completion Tab which provides more information on the application and applicator. Application Worker Application License Rolling Stock - equipment that was used to perform application Weather data Required by law to be tracked Wind Speed Wind Direction Temperature Humidity Completion date Start/End Times","title":"CRM End-to-End Scenarios"},{"location":"CRM-End-To-End-Scenarios/#crm-end-to-end-scenarios","text":"","title":"CRM End-to-End Scenarios"},{"location":"CRM-End-To-End-Scenarios/#overview","text":"Planned to Sales Agreement - sales tool within CRM used to price product and transition growers into contracts. Fertilizer Calculator - utility that allows a salesman to determine and calculate fertilizer requirements such as what product best fits the need of the customer and how much of that product is needed to fulfill the order (some work is still needed and is anticipated to be ready in Fall of 2020). Sales Order Process - integration of all Levridge pieces, specifically split billing, and its close integration with sales orders in FinOps.","title":"Overview"},{"location":"CRM-End-To-End-Scenarios/#process-1-planned-to-sales-agreement","text":"There are three separate methods of kicking off a planned sales agreement within CRM: batch plans, regular plan, and proposals.","title":"Process #1: Planned to Sales Agreement"},{"location":"CRM-End-To-End-Scenarios/#batch-plans","text":"Batch Plans tab Generate New Populate required fields Name \u2013 this field will auto populate when you save Proposal Type - there are three proposal types: Customer, Field and Prospect. The batch plan will auto populate to the Customer Type. Account Customer Operation Split Group Sales Period \u2013 we need this so we can accurately price Save Programs Tab Farmable acreage field is required Preconfigured set of products in many cases an agronomist recommends the same products at the same rate so instead of calculating these rates each time, you can set up a program, so it automatically calculates product and rate. Add products utilizing the tabs across the top of the batch plan, (seed, fertilizer, chemical, etc.) After adding your products, you can either Generate a proposal Generate a sales agreement","title":"Batch Plans"},{"location":"CRM-End-To-End-Scenarios/#proposal-types","text":"There are three different proposal types within a batch plan: Customer, Prospect, and Field. Customer - simplest proposal type and is the most used proposal type for a batch plan Prospect - individual the salesman is pursuing that is not a current client and we want a way to generate a price for product and a contact for the potential client Generate contact Sales period Farmable Acreage approximation Navigate to the seed, fertilizer, or chemical tab(s) to add product Create proposal Open proposal Proposal lines tab Run report Print Proposal Give to potential client Field - least common proposal type used Only benefit of the field is if we go through and make individual plans in a lot of cases, we will use the same product on all of them You can add products once to all appliable fields","title":"Proposal Types"},{"location":"CRM-End-To-End-Scenarios/#creating-a-regular-plan","text":"Plan to sales agreement Plans Generate new plan record Populate applicable fields Account Customer Operation Customer site \u2013 physical piece of land that you are putting the product on Split group Description - multiple plans for a field may be created so a detailed description is important Desired Crop Growing Season \u2013 what year this product will be applied to the field Utilize the tabs (Programs and Recommendations, seed, fertilizer, or chemical) to add applicable product(s) Program and recommendations Programs \u2013 ability to add existing or new programs Recommendations \u2013 attachment to precision mapping tools Seed (Unit) Seed calculator \u2013 helps do the math to easily populate the quantity field Add product line(s) for all required seed Fertilizer Timing \u2013 when to apply product Product Rate Unit/Rate This calculation not only helps get product pricing but also helps us know when the grower needs specific products applied Chemical Timing \u2013 when to apply product Product Rate Unit/Rate This calculation not only helps get product pricing but also helps us know when the grower needs specific products applied Plan is complete and proposal can be generated","title":"Creating a Regular Plan"},{"location":"CRM-End-To-End-Scenarios/#new-proposal","text":"Plan to sales agreement Proposals Generate new proposal Populate applicable fields Description Account Customer operation Split group Growing season Sales period Manager \u2013 the client will have a workflow that sets who the Manager is so it is auto generated, this is a customization Associated plans Add existing plans Select all associated plans created for this specific grower Add Create lines This function goes through each plan taking all product information and the split groups behind them and generates individual product lines for them and creates pricing for them Item category terms Allows you to set different payment methods by product Select item category (product) Select payment method Save Proposal lines Often discounts/incentives are provided to get the producer to agree to the proposal price Launch line you would like to discount Charge codes Add new proposal line change Select charge code \u2013 charge codes are user defined data that are defined in FinOps/AX and are integrated over to CE/CRM Value \u2013 dollar amount to be deducted off total product price Save Refresh Proposal line will be updated to reflect new net unit price after charge code has been applied Unit price \u2013 you can manually override this field to decrease price as well Calculate prices","title":"New Proposal"},{"location":"CRM-End-To-End-Scenarios/#add-product-lines-from-proposal-lines-tab","text":"In some instances, a customer will decide to add products after you have generated the proposal. Using the add new proposal line within the proposal lines tab will allow you to add last minute products to the proposal and recalculate price. 1. (+) New proposal line 2. Select product 3. Quantity 4. Save 5. Calculate prices 6. Line will be added to the proposal lines tab and price will be updated for that product from data from FinOps/AX.","title":"Add product lines from proposal lines tab"},{"location":"CRM-End-To-End-Scenarios/#submit-for-approval","text":"Once your proposal is priced and complete, it is ready to be submitted for approval. The submit for approval function/button ensures that margin on products are maintained throughout the sales process. Submit for approval Looks for any charge code or line item changes that were made and compares them to the defined thresholds that have been set If any changes rise above threshold set, it will stop the process, lock down proposal and send to the Manager that the proposal needs approval before moving forward to contract/ agreement Seed Patented traits owned by specific manufacturer that you must have a license from that manufacturer before you can purchase and use product The system will look and see if grower has a valid agreement to buy this product and there is configuration in FinOps/AX to either warn/stop continued process With seed you will typically use the \u201cwarn\u201d function instead of fully stopping the process Restricted use pesticides Based on Federal/State laws, before restricted use products can be picked up, we must ensure that the applicator has a valid license to apply these products. This license number needs to be physically listed on the invoice. This will warn the process that this item needs to be taken care of. At this point in the process we may not know who is applying the product, so it is important to check back in until the license number has been documented. Generate sales agreement After the sales agreement is generated, it is sent across to FinOps/AX At this point, the process within CE/CRM is complete The final step in the sales process would be to pull up the third-party integration (ex. Hello Sign) to capture a digital signature","title":"Submit for Approval"},{"location":"CRM-End-To-End-Scenarios/#process-2-fertilizer-calculator","text":"The Fertilizer Calculator is a tool used to generate blends of fertility products. Planning Tools Fertilizer Calculator Generate New Populate applicable fields Customer Customer Operation Batch Size \u2013 blender capacity so when generated it relays how many batches will need to occur to fulfill the order Fertilizer State Dry Liquid Save Blend Lines will populate with nutrient and product Input either input value (lbs.) or ratio (percentage) Click Calculate to populate output Quantity needed Total blend amount Number of batches needed Blend Percent Generate sales order and release report to blender facilities to begin blending product (this function/button is not currently available but will be once it is fully developed and tested).","title":"Process #2 Fertilizer Calculator"},{"location":"CRM-End-To-End-Scenarios/#process-3-sales-order-process","text":"The sales order is comprised of two pieces: the sales order and the work order. Both are tightly integrated within FinOps. The purpose of the sales order is to give users that only have access to CE/CRM the ability to enter orders for delivery and perform some of the functions that are usually completed in FinOps/AX.","title":"Process #3 Sales Order Process"},{"location":"CRM-End-To-End-Scenarios/#generating-new-sales-order-in-cecrm","text":"Sales order tab Generate new Populate applicable sales order fields Account Customer operation - if the customer only has 1 operation it will default, otherwise, it will filter down to their operations Split group - who will be paying for the product Delivery address - delivery address is a requirement for many of the actions in FinOps Inventory site - where inventory is coming from Branch - who is responsible for the customer or in charge of handling the billing Sales period - sales period is used to price the products against Ship date - not required and will default if not manually populated Save","title":"Generating New Sales Order in CE/CRM"},{"location":"CRM-End-To-End-Scenarios/#enter-sales-order-lines","text":"Add product 2 Pick quantity Save After saving the estimated price, which is pulled from CRM/CE, will be populated. This may not be the price that is actually paid but is a stored list price that adjustments can be made to. Submit for Approval Checks for any products that need an applicators license Checks for any seed tech licenses that may be required Credit check (based off the credit settings within FinOps, it will either warn/deny generating sales order) Generate Sales Order Once your submission has been approved, you will need to generate a sales order in FinOps/AX You will receive a pop-up notifying you the sales order was created successfully in FinOps/AX Once order is acted upon in FinOps, you can go into the line details within CE/CRM and it will give more information on the split group allocations (quantities, dates shipped, etc) so the person in CE/CRM has access to some of that detail","title":"Enter Sales Order Lines"},{"location":"CRM-End-To-End-Scenarios/#work-order","text":"The work order is a type of sales order where the Ag Retailer will be performing a service. A work order requires more detail than a basic sales order. 1. Orders 2. Work Orders 3. Generate New 4. Populate applicable fields - Account - Customer Operation - Customer Site - Auto Print \u2013 printer logic exists to automatically print a report remotely would be needed when a hard copy is necessary for the remote location to send with the driver - Sales Site \u2013 party who is responsible for the sale of the product - Application Site \u2013 party performing task - Application Operation \u2013 type of work being done (synced with AgSync) - Application Date \u2013 anticipated application date of the product - Application Window \u2013 for chemical product this is important because depending on stage of the crop, it could cause harm if applied outside of a specific timeframe - Crop \u2013 crop product will be applied to - Order Status - Planned \u2013 occurring in the future - Booked \u2013 occurring in the future - Released \u2013 moved to queue to get done and application date is set - Scheduled \u2013 it will happen today or tomorrow and has been assigned to an applicator - In-Progress \u2013 product was administered partially and due to some unforeseen event, the job was not completed and requires further attention - Completed Pending Review \u2013 application is complete - Archived - Rejected - Work Order ID \u2013 generated number out of AgSync. - Dispensing Order Number \u2013 only comes into effect if there is a blender/Kahler integration. This number is created when the picking list / mixed ticket is dispatched out to the warehouse. - Ordering Notes - Notes that are specific to the field (ex. Approach on NW Corner) - Notes that are specific to application (ex. Spray when wind is coming from NW to ensure surrounding susceptible fields are not sprayed) - Application Notes \u2013 notes or observation that equipment operator made while in the field 5. Save","title":"Work Order"},{"location":"CRM-End-To-End-Scenarios/#enter-work-order-lines","text":"Work Order Lines tab Add new line Populate applicable fields Sales Sites Customer Product Pests \u2013 when spraying chemicals some states require documentation that states purpose of application Application Site Quantity Submit for Approval \u2013 if this is an integrated order from AgSync or from some third-party dispatch, the submit for approval function/button would be gone but if you generate in CRM you would see submit for approval If you open a work order line, you will be able to view the Work Order Completion Tab which provides more information on the application and applicator. Application Worker Application License Rolling Stock - equipment that was used to perform application Weather data Required by law to be tracked Wind Speed Wind Direction Temperature Humidity Completion date Start/End Times","title":"Enter Work Order Lines"},{"location":"CRM-configuration/","text":"Configuration Setup CRM To begin configuration setup in CRM, first import LevCore Solution followed by importing Agronomy Solution. Migrate the ESG Configuration data using the Configuration Migration Tool. This tool can be downloaded at https://docs.microsoft.com/en-us/dynamics365/customer-engagement/developer/download-tools-nuget Ensure an Application User has been created with admin security roles assigned. If integrating records from CRM to AX, you will need to create steps on the service endpoint using the Plugin Registration tool. Steps will also need to be created on plugins which require the pricing service. The configuration will look like this: { \"clientappid\": \"[Client AppID from AD]\", \"clientappsecret\": \"[secret from AD]\", \"tenant\": \"https://login.microsoftonline.com/5555a5b1-fbt8-465b-ad9d-21e21129e610/oauth2/token\", \"uristring\": \"https://[environment subdomain].cloudax.dynamics.com/api/services/LevPricingServices/PricingService/getPricing\", \"resource\": \"https://[environment subdomain].cloudax.dynamics.com\", \"username\": \"John.smith@email.com\", \"password\": \"plaintextpassword\" } Setup the data through integrations, create it in CRM, or import data packets. Entities in pink must be set up in CRM. Entities in yellow will integrate over from FinOps. Entities in green will integrate from Agsync. Once item categories have been either created or imported in, the filtered xmls on the Plans and Batch Plans will need to be updated to reflect the item category GUIDs within your environment. The Proposal OOB Proposal line Subgrids will also require filter updates to reflect the Item Category's in your environment.","title":"CRM Platform Configuration"},{"location":"CRM-configuration/#configuration-setup-crm","text":"To begin configuration setup in CRM, first import LevCore Solution followed by importing Agronomy Solution. Migrate the ESG Configuration data using the Configuration Migration Tool. This tool can be downloaded at https://docs.microsoft.com/en-us/dynamics365/customer-engagement/developer/download-tools-nuget Ensure an Application User has been created with admin security roles assigned. If integrating records from CRM to AX, you will need to create steps on the service endpoint using the Plugin Registration tool. Steps will also need to be created on plugins which require the pricing service. The configuration will look like this: { \"clientappid\": \"[Client AppID from AD]\", \"clientappsecret\": \"[secret from AD]\", \"tenant\": \"https://login.microsoftonline.com/5555a5b1-fbt8-465b-ad9d-21e21129e610/oauth2/token\", \"uristring\": \"https://[environment subdomain].cloudax.dynamics.com/api/services/LevPricingServices/PricingService/getPricing\", \"resource\": \"https://[environment subdomain].cloudax.dynamics.com\", \"username\": \"John.smith@email.com\", \"password\": \"plaintextpassword\" } Setup the data through integrations, create it in CRM, or import data packets. Entities in pink must be set up in CRM. Entities in yellow will integrate over from FinOps. Entities in green will integrate from Agsync. Once item categories have been either created or imported in, the filtered xmls on the Plans and Batch Plans will need to be updated to reflect the item category GUIDs within your environment. The Proposal OOB Proposal line Subgrids will also require filter updates to reflect the Item Category's in your environment.","title":"Configuration Setup CRM"},{"location":"Class.Method.Template/","text":"ClassName.MethodName Method Namespace: [Enter Namespace Name] Assemblies: [Enter Assembly FileName] Describe the method here Overloads Overload Description MethodName (ParameterType1 Parameter1) description of overload MethodName (ParameterType1 Parameter1, ParameterType2 Parameter2) description of overload MethodName (ParameterType1 Parameter1) description of overload public Return MethodName<TA, TB>(ParameterType1 Parameter1); Parameters Returns Exceptions Examples MethodName (ParameterType1 Parameter1, ParameterType2 Parameter2) description of overload public Return MethodName<TA, TB>(ParameterType1 Parameter1, ParameterType2 Parameter2); Parameters Returns Exceptions Examples","title":"ClassName.MethodName Method"},{"location":"Class.Method.Template/#classnamemethodname-method","text":"Namespace: [Enter Namespace Name] Assemblies: [Enter Assembly FileName] Describe the method here","title":"ClassName.MethodName Method"},{"location":"Class.Method.Template/#overloads","text":"Overload Description MethodName (ParameterType1 Parameter1) description of overload MethodName (ParameterType1 Parameter1, ParameterType2 Parameter2) description of overload","title":"Overloads"},{"location":"Class.Method.Template/#methodnameparametertype1-parameter1","text":"description of overload public Return MethodName<TA, TB>(ParameterType1 Parameter1);","title":"MethodName(ParameterType1 Parameter1)"},{"location":"Class.Method.Template/#parameters","text":"","title":"Parameters"},{"location":"Class.Method.Template/#returns","text":"","title":"Returns"},{"location":"Class.Method.Template/#exceptions","text":"","title":"Exceptions"},{"location":"Class.Method.Template/#examples","text":"","title":"Examples"},{"location":"Class.Method.Template/#methodnameparametertype1-parameter1-parametertype2-parameter2","text":"description of overload public Return MethodName<TA, TB>(ParameterType1 Parameter1, ParameterType2 Parameter2);","title":"MethodName(ParameterType1 Parameter1, ParameterType2 Parameter2)"},{"location":"Class.Method.Template/#parameters_1","text":"","title":"Parameters"},{"location":"Class.Method.Template/#returns_1","text":"","title":"Returns"},{"location":"Class.Method.Template/#exceptions_1","text":"","title":"Exceptions"},{"location":"Class.Method.Template/#examples_1","text":"","title":"Examples"},{"location":"CloseInventory/","text":"Close Inventory Brief introduction of the module, component or feature being documented. This document explains ... How to Close Inventory Go to Inventory Management > Periodic Tasks > Closing and Adjustment. Click Close Procedure. Click Close Inventory. Expand the Run in the background section. In the Close Inventory up to field, enter a date. Click OK. Click Yes. Click Cancel.","title":"Close Inventory"},{"location":"CloseInventory/#close-inventory","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Close Inventory"},{"location":"CloseInventory/#how-to-close-inventory","text":"Go to Inventory Management > Periodic Tasks > Closing and Adjustment. Click Close Procedure. Click Close Inventory. Expand the Run in the background section. In the Close Inventory up to field, enter a date. Click OK. Click Yes. Click Cancel.","title":"How to Close Inventory"},{"location":"CommandLineParameters/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"CommandLineParameters/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"CommandLineParameters/#overview","text":"","title":"Overview"},{"location":"CommandLineParameters/#main-point-1","text":"","title":"Main Point 1"},{"location":"CommandLineParameters/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"Commissions/","text":"Commissions Brief introduction of the module, component or feature being documented. This document explains ... Commissions Go to Sales and marketing > Commissions > Commission Calculation. Click New. In the item relation field, enter or select a value. In the customer relation field, enter or select a value. In the sales rep. relation field, enter or select a value. In the Discount field, select an option. In the commission percentage field, enter a number. In the From field, enter a date. In the To field, enter a date. Click Save","title":"Commissions"},{"location":"Commissions/#commissions","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Commissions"},{"location":"Commissions/#commissions_1","text":"Go to Sales and marketing > Commissions > Commission Calculation. Click New. In the item relation field, enter or select a value. In the customer relation field, enter or select a value. In the sales rep. relation field, enter or select a value. In the Discount field, select an option. In the commission percentage field, enter a number. In the From field, enter a date. In the To field, enter a date. Click Save","title":"Commissions"},{"location":"Commodities/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Levridge Commodities"},{"location":"Commodities/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Commodities/#overview","text":"","title":"Overview"},{"location":"Commodities/#main-point-1","text":"","title":"Main Point 1"},{"location":"Commodities/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"ConfigurationTemplate/","text":"Custom Mapping Assemblies Config Settings Example { ConfigEntry } Definition ConfigEntry Not Required Default:","title":"Custom Mapping Assemblies Config Settings"},{"location":"ConfigurationTemplate/#custom-mapping-assemblies-config-settings","text":"","title":"Custom Mapping Assemblies Config Settings"},{"location":"ConfigurationTemplate/#example","text":"{ ConfigEntry }","title":"Example"},{"location":"ConfigurationTemplate/#definition","text":"","title":"Definition"},{"location":"ConfigurationTemplate/#configentry","text":"Not Required Default:","title":"ConfigEntry"},{"location":"ConfigureAuthentication/","text":"Configure Authentication Register your application To register your application and manually add the app's registration information to your solution, follow these steps: Sign in to the Azure portal using either a work or school account, or a personal Microsoft account. If your account gives you access to more than one tenant, select your account in the top right corner, and set your portal session to the desired Azure AD tenant. Navigate to the Microsoft identity platform for developers App registrations page. Select New registration. When the Register an application page appears, enter your application's registration information: In the Name section, enter a meaningful application name that will be displayed to users of the app, for example AspNetCore-Quickstart. In Redirect URI, add https://localhost:44321/, and select Register. Select the Authentication menu, and then add the following information: In Redirect URIs, add https://localhost:44321/signin-oidc, and select Save. In the Advanced settings section, set Logout URL to https://localhost:44321/signout-oidc. Under Implicit grant, check ID tokens. Select Save. Create a section in Appsettings.json named AzureAd . \"AzureAd\": { \"Instance\": \"https://login.microsoftonline.com/\", \"Domain\": \"yourdomain.com\", \"TenantId\": \"00000000-0000-0000-0000-000000000000\", \"ClientId\": \"00000000-0000-0000-0000-000000000000\", \"CallbackPath\": \"/signin-oidc\" } Taken from Quickstart: Add sign-in with Microsoft to an ASP.NET Core web app .","title":"Configure Authentication"},{"location":"ConfigureAuthentication/#configure-authentication","text":"","title":"Configure Authentication"},{"location":"ConfigureAuthentication/#register-your-application","text":"To register your application and manually add the app's registration information to your solution, follow these steps: Sign in to the Azure portal using either a work or school account, or a personal Microsoft account. If your account gives you access to more than one tenant, select your account in the top right corner, and set your portal session to the desired Azure AD tenant. Navigate to the Microsoft identity platform for developers App registrations page. Select New registration. When the Register an application page appears, enter your application's registration information: In the Name section, enter a meaningful application name that will be displayed to users of the app, for example AspNetCore-Quickstart. In Redirect URI, add https://localhost:44321/, and select Register. Select the Authentication menu, and then add the following information: In Redirect URIs, add https://localhost:44321/signin-oidc, and select Save. In the Advanced settings section, set Logout URL to https://localhost:44321/signout-oidc. Under Implicit grant, check ID tokens. Select Save. Create a section in Appsettings.json named AzureAd . \"AzureAd\": { \"Instance\": \"https://login.microsoftonline.com/\", \"Domain\": \"yourdomain.com\", \"TenantId\": \"00000000-0000-0000-0000-000000000000\", \"ClientId\": \"00000000-0000-0000-0000-000000000000\", \"CallbackPath\": \"/signin-oidc\" } Taken from Quickstart: Add sign-in with Microsoft to an ASP.NET Core web app .","title":"Register your application"},{"location":"Configuring-Levridge-Entity-Event-Endpoint/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"Configuring-Levridge-Entity-Event-Endpoint/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Configuring-Levridge-Entity-Event-Endpoint/#overview","text":"","title":"Overview"},{"location":"Configuring-Levridge-Entity-Event-Endpoint/#main-point-1","text":"","title":"Main Point 1"},{"location":"Configuring-Levridge-Entity-Event-Endpoint/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"Configuring-Levridge-Entity-Events/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"Configuring-Levridge-Entity-Events/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Configuring-Levridge-Entity-Events/#overview","text":"","title":"Overview"},{"location":"Configuring-Levridge-Entity-Events/#main-point-1","text":"","title":"Main Point 1"},{"location":"Configuring-Levridge-Entity-Events/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"ControllerSecurity/","text":"Configuring Controller Security Overview Levridge has provided configurable security for our controllers. Once a controller is secured each instance of the Integration Framework in which it is used must be configured in the Active Directory to expose the API. Here is a link to the Microsoft documentation that explains the process of registering an application in Azure Active Directory. Application Managed Identity If the Levridge Integration Framework is deployed in an Azure tenant Microsoft recommends using a managed identity. This makes is much simpler to manage access to Azure resources such as the Azure Service Bus, Azure Key Vault and Azure Configuration Serivice. To setup a system managed identity, use the instructions provided here . You will still need to provide a ClientId . To obtain a ClientId you will need to turn on Security in the Azure Portal. Follow the instructions here to enable security. In one of the steps it has you select the Express option for Azure Active Directory. This creates an Application Registration for you. You can also select an existing Application Registration if you have already created one for the app service. It is the ClientId of the Application Registration that will be used in the AzureAd node of the appsettings.json file. Application Permissions (Roles) Since controllers are generally called by applications that are not using the Azure Active Directory to authenticate users we have configured our controllers to utilize Application Permissions rather than Delegated permissions . Exposing Application Permissions To expose application permissions you must add one or more roles to the registered application manifest. Use this link for specific instructions. Don't forget to provide admin consent. Assigning Application Permissions Once you have exposed application permissions you will need to assign those permissions to the application that will be calling the API. You will assign Application Permissions as opposed to Delegated Permisions. Use this link for specific instructions. Configuring Authorized Roles Once the role(s) are defined as application permissions and the calling application is assigned the necessary permissions you will need to add the role(s) to the InstanceConfig appsettings.json . Configure AzureAd Settings You will need to provide the information necessary to utilize Azure AD to authenticate calls to the controller. See AzureAd Settings for more information. Enabling Security on a Controller At the time of this writing (5/15/2020) we only have security enabled on the default controller. Be careful about enabling security on controllers. Many of the controllers are called by applcations that expect anonymous access. To enable security you will need to add the following attribute to the controller class: [Authorize(AuthenticationSchemes = OpenIdConnectDefaults.AuthenticationScheme + \",\" + JwtBearerDefaults.AuthenticationScheme)] You can simply add the JwtBearer authentication scheme but then you will not be able to access the API from a browser. Allowing Anonymous Access If you have enabled security on a controller but you want certain actions to allow anonymous access you can add the [AllowAnonymous] attribute to the method. If you want all but a few actions to allow anonymous access you can simply add the [Authorize] attribute only to the actions that you want to secure and don't add it to the class. Be sure to specify the Authentication Schemes you want to use or it will simply use the default which is OpenIdConnect.","title":"Configuring Controller Security"},{"location":"ControllerSecurity/#configuring-controller-security","text":"","title":"Configuring Controller Security"},{"location":"ControllerSecurity/#overview","text":"Levridge has provided configurable security for our controllers. Once a controller is secured each instance of the Integration Framework in which it is used must be configured in the Active Directory to expose the API. Here is a link to the Microsoft documentation that explains the process of registering an application in Azure Active Directory.","title":"Overview"},{"location":"ControllerSecurity/#application-managed-identity","text":"If the Levridge Integration Framework is deployed in an Azure tenant Microsoft recommends using a managed identity. This makes is much simpler to manage access to Azure resources such as the Azure Service Bus, Azure Key Vault and Azure Configuration Serivice. To setup a system managed identity, use the instructions provided here . You will still need to provide a ClientId . To obtain a ClientId you will need to turn on Security in the Azure Portal. Follow the instructions here to enable security. In one of the steps it has you select the Express option for Azure Active Directory. This creates an Application Registration for you. You can also select an existing Application Registration if you have already created one for the app service. It is the ClientId of the Application Registration that will be used in the AzureAd node of the appsettings.json file.","title":"Application Managed Identity"},{"location":"ControllerSecurity/#application-permissions-roles","text":"Since controllers are generally called by applications that are not using the Azure Active Directory to authenticate users we have configured our controllers to utilize Application Permissions rather than Delegated permissions .","title":"Application Permissions (Roles)"},{"location":"ControllerSecurity/#exposing-application-permissions","text":"To expose application permissions you must add one or more roles to the registered application manifest. Use this link for specific instructions. Don't forget to provide admin consent.","title":"Exposing Application Permissions"},{"location":"ControllerSecurity/#assigning-application-permissions","text":"Once you have exposed application permissions you will need to assign those permissions to the application that will be calling the API. You will assign Application Permissions as opposed to Delegated Permisions. Use this link for specific instructions.","title":"Assigning Application Permissions"},{"location":"ControllerSecurity/#configuring-authorized-roles","text":"Once the role(s) are defined as application permissions and the calling application is assigned the necessary permissions you will need to add the role(s) to the InstanceConfig appsettings.json .","title":"Configuring Authorized Roles"},{"location":"ControllerSecurity/#configure-azuread-settings","text":"You will need to provide the information necessary to utilize Azure AD to authenticate calls to the controller. See AzureAd Settings for more information.","title":"Configure AzureAd Settings"},{"location":"ControllerSecurity/#enabling-security-on-a-controller","text":"At the time of this writing (5/15/2020) we only have security enabled on the default controller. Be careful about enabling security on controllers. Many of the controllers are called by applcations that expect anonymous access. To enable security you will need to add the following attribute to the controller class: [Authorize(AuthenticationSchemes = OpenIdConnectDefaults.AuthenticationScheme + \",\" + JwtBearerDefaults.AuthenticationScheme)] You can simply add the JwtBearer authentication scheme but then you will not be able to access the API from a browser.","title":"Enabling Security on a Controller"},{"location":"ControllerSecurity/#allowing-anonymous-access","text":"If you have enabled security on a controller but you want certain actions to allow anonymous access you can add the [AllowAnonymous] attribute to the method. If you want all but a few actions to allow anonymous access you can simply add the [Authorize] attribute only to the actions that you want to secure and don't add it to the class. Be sure to specify the Authentication Schemes you want to use or it will simply use the default which is OpenIdConnect.","title":"Allowing Anonymous Access"},{"location":"Controllers/","text":"Controllers Settings Controllers section is a json object in the appsettings.json file used by the Levridge Integration Framework to define which controllers to load for the current Levridge Integration Framework instance. Example \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" }, Definition Controllers The controllers json object is comma delimited list of json objects that define which controllers to load for the current Levridge Integration Framework instance. Each json object contains a name and an assembly name. The name is not used by the system, but is used to provide a human friendly name for the assembly referenced with it. In the example above, the Controllers object informs the Levridge Integration Framework to load two assemblies: - \"Levridge.Integration.Host.DefaultController\" - \"Levridge.Integration.Host.AgSyncController\" See Also Controller Security","title":"Controllers Settings"},{"location":"Controllers/#controllers-settings","text":"Controllers section is a json object in the appsettings.json file used by the Levridge Integration Framework to define which controllers to load for the current Levridge Integration Framework instance.","title":"Controllers Settings"},{"location":"Controllers/#example","text":"\"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"AgSyncConroller\": \"Levridge.Integration.Host.AgSyncController\" },","title":"Example"},{"location":"Controllers/#definition","text":"","title":"Definition"},{"location":"Controllers/#controllers","text":"The controllers json object is comma delimited list of json objects that define which controllers to load for the current Levridge Integration Framework instance. Each json object contains a name and an assembly name. The name is not used by the system, but is used to provide a human friendly name for the assembly referenced with it. In the example above, the Controllers object informs the Levridge Integration Framework to load two assemblies: - \"Levridge.Integration.Host.DefaultController\" - \"Levridge.Integration.Host.AgSyncController\"","title":"Controllers"},{"location":"Controllers/#see-also","text":"Controller Security","title":"See Also"},{"location":"Create-Split-Group-in-F%26O/","text":"Create a New Split Group Overview There should be some text here. Steps Steps Expected Result 1. Navigate to Accounts Receivable > Setup >Agriculture > Split Groups The split groups grid will display. 2. From the top menu bar click the +New button. A fly-out menu on the right sidebar will appear. The split group code field will automatically be assigned a sequential number sequence. 3. Select/change the Start Date to reflect the split group start date by clicking on the calendar icon and choosing a date or enter a date manually. The start date will default to today's date but can be changed to the actual start date. Once a date is selected from the calendar or manually a date should appear in the Start Date field. 4. Select/change the End Date to reflect the split group end date by clicking on the calendar icon and choosing a date or enter a date manually. The end date will default to the system's infinity date but can be changed to the actual end date. Once a date is selected from the calendar or manually, a date should appear in the End Date field. This field should always contain a date later than the start date. Narrative","title":"Create a New Split Group"},{"location":"Create-Split-Group-in-F%26O/#create-a-new-split-group","text":"","title":"Create a New Split Group"},{"location":"Create-Split-Group-in-F%26O/#overview","text":"There should be some text here.","title":"Overview"},{"location":"Create-Split-Group-in-F%26O/#steps","text":"Steps Expected Result 1. Navigate to Accounts Receivable > Setup >Agriculture > Split Groups The split groups grid will display. 2. From the top menu bar click the +New button. A fly-out menu on the right sidebar will appear. The split group code field will automatically be assigned a sequential number sequence. 3. Select/change the Start Date to reflect the split group start date by clicking on the calendar icon and choosing a date or enter a date manually. The start date will default to today's date but can be changed to the actual start date. Once a date is selected from the calendar or manually a date should appear in the Start Date field. 4. Select/change the End Date to reflect the split group end date by clicking on the calendar icon and choosing a date or enter a date manually. The end date will default to the system's infinity date but can be changed to the actual end date. Once a date is selected from the calendar or manually, a date should appear in the End Date field. This field should always contain a date later than the start date.","title":"Steps"},{"location":"Create-Split-Group-in-F%26O/#narrative","text":"","title":"Narrative"},{"location":"CreateProcurementCategory/","text":"Creating a Procurement Category Brief introduction of the module, component or feature being documented. This document explains ... How to Create a Procurement Category, Assign an Item, and Assign a GL Go to Product Information Management > Setup > Categories and Attributes > Category Hierarchies. In the list, find and select the desired record. In the list, click the link in the selected row. Click New category node. In the Name field, type a value. Click Save. Click Save. Click Add. Use the Quick Filter to find records. For example, filter on the Product number field with a value of '1987'. In the list, mark the selected row. Click Add. Click OK. Close the page. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the Item number field with a value of '1987'. Click Product categories. Click New. In the Category hierarchy field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Category field, enter or select a value. In the tree, select 'Landus (New Category)\\Monsanto (New Category)'. Click OK. Click Save. Click Delete. Click Save. Close the page. Close the page. Go to Inventory Management > Setup > Posting > Posting. Click the Purchase order tab. In the Select field, select an option. Click New. In the list, mark the selected row. In the Item code field, select an option. In the Category relation field, enter or select a value. In the tree, select 'Lanuds (New Category)\\Monsanto (New Category)'. Click OK. In the Main account field, specify the desired values. Click Save. Close the page.","title":"Create a Procurement Category"},{"location":"CreateProcurementCategory/#creating-a-procurement-category","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Creating a Procurement Category"},{"location":"CreateProcurementCategory/#how-to-create-a-procurement-category-assign-an-item-and-assign-a-gl","text":"Go to Product Information Management > Setup > Categories and Attributes > Category Hierarchies. In the list, find and select the desired record. In the list, click the link in the selected row. Click New category node. In the Name field, type a value. Click Save. Click Save. Click Add. Use the Quick Filter to find records. For example, filter on the Product number field with a value of '1987'. In the list, mark the selected row. Click Add. Click OK. Close the page. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the Item number field with a value of '1987'. Click Product categories. Click New. In the Category hierarchy field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Category field, enter or select a value. In the tree, select 'Landus (New Category)\\Monsanto (New Category)'. Click OK. Click Save. Click Delete. Click Save. Close the page. Close the page. Go to Inventory Management > Setup > Posting > Posting. Click the Purchase order tab. In the Select field, select an option. Click New. In the list, mark the selected row. In the Item code field, select an option. In the Category relation field, enter or select a value. In the tree, select 'Lanuds (New Category)\\Monsanto (New Category)'. Click OK. In the Main account field, specify the desired values. Click Save. Close the page.","title":"How to Create a Procurement Category, Assign an Item, and Assign a GL"},{"location":"CreateProcurementHierarchy/","text":"Create Procurement Hierarchy Brief introduction of the module, component or feature being documented. This document explains ... How to Create Procurement Hierarchy Go to Product Information Management > Setup > Categories and Attributes > Category Hierarchies. Click New. In the Name field, type a value. In the Description field, type a value. Click Create. Click New Category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. In the tree, select 'Procurement'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement\\Agronomy'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement\\Feed'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. Expand the Products section. In the tree, select 'Procurement\\Agronomy\\Fert'. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. In the list, find and select the desired record. Click Add. Click OK. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. Click OK. Click Save.","title":"Create a Procurement Hierarchy"},{"location":"CreateProcurementHierarchy/#create-procurement-hierarchy","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Create Procurement Hierarchy"},{"location":"CreateProcurementHierarchy/#how-to-create-procurement-hierarchy","text":"Go to Product Information Management > Setup > Categories and Attributes > Category Hierarchies. Click New. In the Name field, type a value. In the Description field, type a value. Click Create. Click New Category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. In the tree, select 'Procurement'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement\\Agronomy'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. In the tree, select 'Procurement\\Feed'. Click New category node. In the Name field, type a value. In the Friendly name field, type a value. Click Save. Expand the Products section. In the tree, select 'Procurement\\Agronomy\\Fert'. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. In the list, find and select the desired record. Click Add. Click OK. Click Add. In the list, find and select the desired record. In the list, find and select the desired record. In the list, find and select the desired record. In the list, find and select the desired record. Click Add. Click OK. Click Save.","title":"How to Create Procurement Hierarchy"},{"location":"CreatePurchaseRequistionAndConsolidation/","text":"Create a Purchase Requisition and Consolidation Brief introduction of the module, component or feature being documented. This document explains ... How to Create a Purchase Requisition and Consolidation Go to Procurement and sourcing > Purchase Requisitions > All purchase requisitions. Click New. In the Name field, type a value. Click OK. In the Reason field, enter or select a value. In the list, click the link in the selected row. Click Add line. In the list, mark the selected row. In the Item number field, type a value. In the Quantity field, enter a number. Click Save. Click the Inventory Dimensions tab. In the Site field, type a value. In the Warehouse field, enter or select a value. In the list, click the link in the selected row. Click Save. Click Workflow to open the drop dialog. Click Submit. Click Workflow to open the drop dialog. Close the page. Click Workflow to open the drog dialog. Click Approve. Close the page. How to Create a Purchase Consolidation Go to Procurement and Sourcing > Purchase Requisitions > Approved Purchase requisition processing > Consolidation Opportunities. Click New to open the drop dialog. In the Name field, type a value. Click Ok. Click Add to opportunity. In the list, find and select the desired record. In the list, find and select the desired record. Click OK. Click Close Opportunity. In the list, mark the selected row. In the Consolidation quotation number field, type a value. In the list, find and select the desired record. In the list, find and select the desired record. In the Consolidation quotation number field, type a value. In the list, find and select the desired record. In the list, unmark the selected row. In the list, mark the selected row. In the Vendor account field, enter or select a value. In the list, click the link in the selected row. In the list, find and select the desired record. In the Vendor account field, type a value. In the list, find and select the desired record. In the list, unmark the selected row. In the list, mark the selected row. In the Consolidation quotation number field, type a value. In the list, mark or unmark all rows. Click Close opportunity. In the list, mark or unmark all rows. Click Create Purchase Order.","title":"Create a Purchase Requisition and Consolidation"},{"location":"CreatePurchaseRequistionAndConsolidation/#create-a-purchase-requisition-and-consolidation","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Create a Purchase Requisition and Consolidation"},{"location":"CreatePurchaseRequistionAndConsolidation/#how-to-create-a-purchase-requisition-and-consolidation","text":"Go to Procurement and sourcing > Purchase Requisitions > All purchase requisitions. Click New. In the Name field, type a value. Click OK. In the Reason field, enter or select a value. In the list, click the link in the selected row. Click Add line. In the list, mark the selected row. In the Item number field, type a value. In the Quantity field, enter a number. Click Save. Click the Inventory Dimensions tab. In the Site field, type a value. In the Warehouse field, enter or select a value. In the list, click the link in the selected row. Click Save. Click Workflow to open the drop dialog. Click Submit. Click Workflow to open the drop dialog. Close the page. Click Workflow to open the drog dialog. Click Approve. Close the page.","title":"How to Create a Purchase Requisition and Consolidation"},{"location":"CreatePurchaseRequistionAndConsolidation/#how-to-create-a-purchase-consolidation","text":"Go to Procurement and Sourcing > Purchase Requisitions > Approved Purchase requisition processing > Consolidation Opportunities. Click New to open the drop dialog. In the Name field, type a value. Click Ok. Click Add to opportunity. In the list, find and select the desired record. In the list, find and select the desired record. Click OK. Click Close Opportunity. In the list, mark the selected row. In the Consolidation quotation number field, type a value. In the list, find and select the desired record. In the list, find and select the desired record. In the Consolidation quotation number field, type a value. In the list, find and select the desired record. In the list, unmark the selected row. In the list, mark the selected row. In the Vendor account field, enter or select a value. In the list, click the link in the selected row. In the list, find and select the desired record. In the Vendor account field, type a value. In the list, find and select the desired record. In the list, unmark the selected row. In the list, mark the selected row. In the Consolidation quotation number field, type a value. In the list, mark or unmark all rows. Click Close opportunity. In the list, mark or unmark all rows. Click Create Purchase Order.","title":"How to Create a Purchase Consolidation"},{"location":"CustomPluginAssemblyConfig/","text":"Custom Plugin Assemblies Config Settings The CustomPluginAssemblies configuration node is used to define any custom plugin assemblies to be loaded by the integration framework and the class method to call to register the custom plugin from the assembly. This node is a list (not an array) of named CustomPluginAssemblyConfig json objects. Example \"CustomPluginAssemblies\": { \"CustomFieldsAssembly\": { \"Path\": \".\\\\plugins\", \"AssemblyName\": \"Levridge.Integration.IntegrationService.Mapping.CustomFields\", \"Namespace\": \"Levridge.Integration.IntegrationService.Mapping.CustomFields\", \"ClassName\": \"CustomFieldsEntityMapBuilderExtensions\", \"MethodName\": \"AddCustomFields\" } }, Definition The CustomMappingAssemblies node above has a single CustomPluginAssemblyConfig object named \"CustomeFieldAssembly\". Name Required Default: No default value. This is the name of the custom mapping assembly configuration. Each configuration in the list must have a unique name. Because you can have multiple classes and or multiple methods we do not use the AssemblyName as the configuration name. Path Not Required Default: The path of Levridge.Integration.Host This is the path for the custom plugin assembly. It can be specified as an absolute path or a relative path. The relative path is relative to the current execution directory. (Directory.GetCurrentDirectory()) AssemblyName Required Default: No default value. This is the actual name of the assembly, not the file name. In the current version the file name is assumed to be the \"[AssemblyName].dll\". Do not add the file extension or a file path to this value. NameSpace Required Default: No default value. This property must contain the namespace that contains the class. This value will be added to the class name to obtain the class type. ClassName Required Default: No default value. This property is the name of the class that contains the method used to register the custom mapping. Do not include the namespace. The namespace will be added to the class name to obtain the type. MethodName Required Default: No default value. This property is the name of the method that will be called on the class that is used to register the custom mapping. Do not include the class name here.","title":"Custom Plugin Assemblies Config Settings"},{"location":"CustomPluginAssemblyConfig/#custom-plugin-assemblies-config-settings","text":"The CustomPluginAssemblies configuration node is used to define any custom plugin assemblies to be loaded by the integration framework and the class method to call to register the custom plugin from the assembly. This node is a list (not an array) of named CustomPluginAssemblyConfig json objects.","title":"Custom Plugin Assemblies Config Settings"},{"location":"CustomPluginAssemblyConfig/#example","text":"\"CustomPluginAssemblies\": { \"CustomFieldsAssembly\": { \"Path\": \".\\\\plugins\", \"AssemblyName\": \"Levridge.Integration.IntegrationService.Mapping.CustomFields\", \"Namespace\": \"Levridge.Integration.IntegrationService.Mapping.CustomFields\", \"ClassName\": \"CustomFieldsEntityMapBuilderExtensions\", \"MethodName\": \"AddCustomFields\" } },","title":"Example"},{"location":"CustomPluginAssemblyConfig/#definition","text":"The CustomMappingAssemblies node above has a single CustomPluginAssemblyConfig object named \"CustomeFieldAssembly\".","title":"Definition"},{"location":"CustomPluginAssemblyConfig/#name","text":"Required Default: No default value. This is the name of the custom mapping assembly configuration. Each configuration in the list must have a unique name. Because you can have multiple classes and or multiple methods we do not use the AssemblyName as the configuration name.","title":"Name"},{"location":"CustomPluginAssemblyConfig/#path","text":"Not Required Default: The path of Levridge.Integration.Host This is the path for the custom plugin assembly. It can be specified as an absolute path or a relative path. The relative path is relative to the current execution directory. (Directory.GetCurrentDirectory())","title":"Path"},{"location":"CustomPluginAssemblyConfig/#assemblyname","text":"Required Default: No default value. This is the actual name of the assembly, not the file name. In the current version the file name is assumed to be the \"[AssemblyName].dll\". Do not add the file extension or a file path to this value.","title":"AssemblyName"},{"location":"CustomPluginAssemblyConfig/#namespace","text":"Required Default: No default value. This property must contain the namespace that contains the class. This value will be added to the class name to obtain the class type.","title":"NameSpace"},{"location":"CustomPluginAssemblyConfig/#classname","text":"Required Default: No default value. This property is the name of the class that contains the method used to register the custom mapping. Do not include the namespace. The namespace will be added to the class name to obtain the type.","title":"ClassName"},{"location":"CustomPluginAssemblyConfig/#methodname","text":"Required Default: No default value. This property is the name of the method that will be called on the class that is used to register the custom mapping. Do not include the class name here.","title":"MethodName"},{"location":"CustomerCreation/","text":"Customer Creation Brief introduction of the module, component or feature being documented. This document explains ... Customer Creation Go to Accounts receivable > Customers > All Customers. Click New. Click OK. In the First name field, type a value. In the Last name field, type a value. In the Customer group field, enter or select a value. In the list, click the link in the selected row. In the Terms of payment field, enter or select a value. In the list, click the link in the selected row. In the ZIP/postal code field, type a value. In the Street field, type a value. In the Street field, type a value. Click Save. Expand the Addresses section. Click Add. In the Description field, type a value. In the Contact number/address field, type a value. Select the Primary check box. Click Add. In the Type field, select an option. In the Contact number/address field, type a value. Expand the Credit and collections section. In the Credit limit field, enter a number. In the Credit rating field, type a value. In the Method of payment field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. Expand the Financial dimensions section. In the LocationSite value field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Close the page.","title":"Customer Creation"},{"location":"CustomerCreation/#customer-creation","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Customer Creation"},{"location":"CustomerCreation/#customer-creation_1","text":"Go to Accounts receivable > Customers > All Customers. Click New. Click OK. In the First name field, type a value. In the Last name field, type a value. In the Customer group field, enter or select a value. In the list, click the link in the selected row. In the Terms of payment field, enter or select a value. In the list, click the link in the selected row. In the ZIP/postal code field, type a value. In the Street field, type a value. In the Street field, type a value. Click Save. Expand the Addresses section. Click Add. In the Description field, type a value. In the Contact number/address field, type a value. Select the Primary check box. Click Add. In the Type field, select an option. In the Contact number/address field, type a value. Expand the Credit and collections section. In the Credit limit field, enter a number. In the Credit rating field, type a value. In the Method of payment field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. Expand the Financial dimensions section. In the LocationSite value field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Close the page.","title":"Customer Creation"},{"location":"CustomerCreationOrganization/","text":"Customer Creation Organzation Brief introduction of the module, component or feature being documented. This document explains ... Customer Creation Organization Go to Accounts Receivable > Customers > All Customers. Click New. Click OK. In the Type field, select an option. Click OK. In the Name field, type a value. In the Customer group field, enter or select a value. In the list, select row 2. In the list, click the link in the select row. In the Terms of Payment field, enter or select a value. In the list, click the link in the select row. In the ZIP/postal code field, type a value. In the Street field, type a value. Click Save. Click Show more fields. Click Add. In the Description field, type a value. In the Contact number/address field, type a value. Select the Primary check box. Click Add. In the Type field, select an option. In the Contact number/address field, type a value. In the Sales group field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Method of payment field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. In the LocationSite value field, enter or select a value. In the list, click the link in the selected row. Click Save.","title":"Customer Creation Organization"},{"location":"CustomerCreationOrganization/#customer-creation-organzation","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Customer Creation Organzation"},{"location":"CustomerCreationOrganization/#customer-creation-organization","text":"Go to Accounts Receivable > Customers > All Customers. Click New. Click OK. In the Type field, select an option. Click OK. In the Name field, type a value. In the Customer group field, enter or select a value. In the list, select row 2. In the list, click the link in the select row. In the Terms of Payment field, enter or select a value. In the list, click the link in the select row. In the ZIP/postal code field, type a value. In the Street field, type a value. Click Save. Click Show more fields. Click Add. In the Description field, type a value. In the Contact number/address field, type a value. Select the Primary check box. Click Add. In the Type field, select an option. In the Contact number/address field, type a value. In the Sales group field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Method of payment field, enter or select a value. In the list, select row 3. In the list, click the link in the selected row. In the LocationSite value field, enter or select a value. In the list, click the link in the selected row. Click Save.","title":"Customer Creation Organization"},{"location":"CustomerTemplate/","text":"Customer Template Brief introduction of the module, component or feature being documented. This document explains ... Customer Template Close the page. Go to Accounts Receivable > Customers > All Customers. In the list, find and select the desired record. Click Record Info. Click New. In the list, find and select the desired record. Select the Is Default check box. Click OK. Click Cancel.","title":"Customer Template"},{"location":"CustomerTemplate/#customer-template","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Customer Template"},{"location":"CustomerTemplate/#customer-template_1","text":"Close the page. Go to Accounts Receivable > Customers > All Customers. In the list, find and select the desired record. Click Record Info. Click New. In the list, find and select the desired record. Select the Is Default check box. Click OK. Click Cancel.","title":"Customer Template"},{"location":"D365-CRM-to-D365-F%26O/","text":"D365 CRM to D365 F&O Setup To integrate from D365 CRM to D365 F&O you will need to: - Configure Azure Service Bus Endpoint in CRM - Configure Azure Service Bus plug-in on the appropriate entities - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic - Create a subscription on the topic above Note: Because CRM does not support sending messages to topics with subscriptions that require sessions, it is important to make sure that the subscription is created without enabling sessions. In order to support message ordering without the use of sessions the TopicDescription.SupportOrdering property must be set to true on the topic. You will need to use the service bus explorer to set this. Configuration In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with CRM data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with F&O data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }","title":"D365 CRM to D365 F&O"},{"location":"D365-CRM-to-D365-F%26O/#d365-crm-to-d365-fo","text":"","title":"D365 CRM to D365 F&amp;O"},{"location":"D365-CRM-to-D365-F%26O/#setup","text":"To integrate from D365 CRM to D365 F&O you will need to: - Configure Azure Service Bus Endpoint in CRM - Configure Azure Service Bus plug-in on the appropriate entities - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic - Create a subscription on the topic above Note: Because CRM does not support sending messages to topics with subscriptions that require sessions, it is important to make sure that the subscription is created without enabling sessions. In order to support message ordering without the use of sessions the TopicDescription.SupportOrdering property must be set to true on the topic. You will need to use the service bus explorer to set this.","title":"Setup"},{"location":"D365-CRM-to-D365-F%26O/#configuration","text":"In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with CRM data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with F&O data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }","title":"Configuration"},{"location":"D365-F%26O-to-D365-CRM/","text":"D365 F&O to D365 CRM Setup To integrate from D365 F&O to D365 CRM you will need to: - Configure Event Endpoint in F&O - configure Levridge Entity Events - Create an application ID for the integration framework to authenticate to D365 CRM - Create an application user in D365 CRM and assign the proper role(s) - Create an Azure Service bus topic - Create a subscription on the topic above Configuration In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with F&O data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" }","title":"D365 F&O to D365 CRM"},{"location":"D365-F%26O-to-D365-CRM/#d365-fo-to-d365-crm","text":"","title":"D365 F&amp;O to D365 CRM"},{"location":"D365-F%26O-to-D365-CRM/#setup","text":"To integrate from D365 F&O to D365 CRM you will need to: - Configure Event Endpoint in F&O - configure Levridge Entity Events - Create an application ID for the integration framework to authenticate to D365 CRM - Create an application user in D365 CRM and assign the proper role(s) - Create an Azure Service bus topic - Create a subscription on the topic above","title":"Setup"},{"location":"D365-F%26O-to-D365-CRM/#configuration","text":"In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with F&O data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" }","title":"Configuration"},{"location":"Deploy-Integration-As-A-Service/","text":"Introduction This webhost application can be run in three modes: As a web application (in Azure or IIS) As a console application As a service Run as a service To run as a service it must be installed. To install as a service you must get the code and place it in the folder from which you want the service to run. The simplest way to get the code is to get the zip file from the latest build. Here are some instructsion for getting the latest code. Get the zip file and unzip it into the folder from which you want the service to run. Deployed with the code should bethree powershell scripts: InstallService.ps1 - this script will install the service InstallEventSource.ps1 - this script will install an event source on the Application EventLog on the local machine RemoveService.ps1 - this script will uninstall / remove the service InstallService.ps1 This script installs a service and sets it to automatically run on startup. It accepts the following command line parameters: PublishPath - the path to the folder from which you want the service to run ServiceUser - user account under which the service will run (default = $env:computername+\"\\IntegrationHost\") ServiceName - the name of the service (default = \"Levridge.Integration.Host\") ServiceDescription - the description for the service (default = \"Levridge Integration Host Service\") ServiceDisplayName - the display name for the service (default = \"Levridge Integration Host\") SourceName - the source name under which EventLog entries should be logged (default = $ServiceName) This script will also execute the InstallEventSource.ps1 InstallEventSource.ps1 This script will install the specified EventLog source. It accepts the following command line parameter: SourceName - the source name under which EventLog entries should be logged (default = \"Levridge.Integration.Host\") RemoveService.ps1 This script will remove the specified service. It accepts the following command line parameter: ServiceName Command line parameters This application can be run with the following command line parameters: debug (-d) - This will cause the application to wait for a debugger to be attached before it continues. This can be helpful to debug startup issues for services or web applications. service (-s) - This will cause the application to run as a service (if the debugger is not attached). SourceName (sn) - This will cause the application to use the specified source name for the application EventLog Source Name. If no source name is specified, the default application source name is use.","title":"Introduction"},{"location":"Deploy-Integration-As-A-Service/#introduction","text":"This webhost application can be run in three modes: As a web application (in Azure or IIS) As a console application As a service","title":"Introduction"},{"location":"Deploy-Integration-As-A-Service/#run-as-a-service","text":"To run as a service it must be installed. To install as a service you must get the code and place it in the folder from which you want the service to run. The simplest way to get the code is to get the zip file from the latest build. Here are some instructsion for getting the latest code. Get the zip file and unzip it into the folder from which you want the service to run. Deployed with the code should bethree powershell scripts: InstallService.ps1 - this script will install the service InstallEventSource.ps1 - this script will install an event source on the Application EventLog on the local machine RemoveService.ps1 - this script will uninstall / remove the service","title":"Run as a service"},{"location":"Deploy-Integration-As-A-Service/#installserviceps1","text":"This script installs a service and sets it to automatically run on startup. It accepts the following command line parameters: PublishPath - the path to the folder from which you want the service to run ServiceUser - user account under which the service will run (default = $env:computername+\"\\IntegrationHost\") ServiceName - the name of the service (default = \"Levridge.Integration.Host\") ServiceDescription - the description for the service (default = \"Levridge Integration Host Service\") ServiceDisplayName - the display name for the service (default = \"Levridge Integration Host\") SourceName - the source name under which EventLog entries should be logged (default = $ServiceName) This script will also execute the InstallEventSource.ps1","title":"InstallService.ps1"},{"location":"Deploy-Integration-As-A-Service/#installeventsourceps1","text":"This script will install the specified EventLog source. It accepts the following command line parameter: SourceName - the source name under which EventLog entries should be logged (default = \"Levridge.Integration.Host\")","title":"InstallEventSource.ps1"},{"location":"Deploy-Integration-As-A-Service/#removeserviceps1","text":"This script will remove the specified service. It accepts the following command line parameter: ServiceName","title":"RemoveService.ps1"},{"location":"Deploy-Integration-As-A-Service/#command-line-parameters","text":"This application can be run with the following command line parameters: debug (-d) - This will cause the application to wait for a debugger to be attached before it continues. This can be helpful to debug startup issues for services or web applications. service (-s) - This will cause the application to run as a service (if the debugger is not attached). SourceName (sn) - This will cause the application to use the specified source name for the application EventLog Source Name. If no source name is specified, the default application source name is use.","title":"Command line parameters"},{"location":"Deploy-Integration-Framework-as-Zip-File/","text":"Deploy Integration Framework as a Zip File At Levridge we build the Integration Framework every night. The output of the build is stored at \\\\devvmhost\\releases . Each build has two folders, \"Integration Framework Main\" and \"Levridge Main\". The integration framework is in the \"drop\" sub-folder of \"Integration Framework Main\". The entire integration framework is contained in the Levridge.Integration.Host.zip file. To deploy the build: Open a browser and navigate to https://<App Service Name>.scm.azurewebsites.net/ZipDeployUI example: https://levdevag.scm.azurewebsites.net/ZipDeployUI From the \"Integration Main\\drop\" folder drag the Levridge.Integration.Host.zip and drop it on the file explorer area on the web page. When deployment is in progress, an icon in the top right corner shows you the progress in percentage. The page also shows verbose messages for the operation below the explorer area. When it is finished, the last deployment message should say \"Deployment successful\". Because this will overwrite the appsettings.json you will need to updated the settings to your desired configuration. Resources Microsoft documentation","title":"Deploy Integration Framework as Zip File"},{"location":"Deploy-Integration-Framework-as-Zip-File/#deploy-integration-framework-as-a-zip-file","text":"At Levridge we build the Integration Framework every night. The output of the build is stored at \\\\devvmhost\\releases . Each build has two folders, \"Integration Framework Main\" and \"Levridge Main\". The integration framework is in the \"drop\" sub-folder of \"Integration Framework Main\". The entire integration framework is contained in the Levridge.Integration.Host.zip file. To deploy the build: Open a browser and navigate to https://<App Service Name>.scm.azurewebsites.net/ZipDeployUI example: https://levdevag.scm.azurewebsites.net/ZipDeployUI From the \"Integration Main\\drop\" folder drag the Levridge.Integration.Host.zip and drop it on the file explorer area on the web page. When deployment is in progress, an icon in the top right corner shows you the progress in percentage. The page also shows verbose messages for the operation below the explorer area. When it is finished, the last deployment message should say \"Deployment successful\". Because this will overwrite the appsettings.json you will need to updated the settings to your desired configuration.","title":"Deploy Integration Framework as a Zip File"},{"location":"Deploy-Integration-Framework-as-Zip-File/#resources","text":"Microsoft documentation","title":"Resources"},{"location":"Deploying-Integration-Framework/","text":"Deploying the Integration Framework There are several ways to deploy the integration framework. Since the framework is a standard Azure App Service we can use any of the deployment options available. The simplest deployment is to deploy a zip file . Select one of the following options for more information on Deploying to Azure: Deploy as Zip file Deploy via FTP Deploy with Script The Integration Framework can also be deployed as a Windows Service . In order to integrate with D365 you must register the integration framework in Active Directory. Here are some articles that explain how to do that: - https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal - https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/use-single-tenant-server-server-authentication#azure-application-registration - https://docs.microsoft.com/en-us/azure/active-directory/azuread-dev/v1-protocols-oauth-code#register-your-application-with-your-ad-tenant In order to access certain Azure resources like Azure Key Vault you will need to make sure your App Service has a system-assigned identity . Next Steps Create Service Bus Configure the application","title":"Deploying the Integration Framework"},{"location":"Deploying-Integration-Framework/#deploying-the-integration-framework","text":"There are several ways to deploy the integration framework. Since the framework is a standard Azure App Service we can use any of the deployment options available. The simplest deployment is to deploy a zip file . Select one of the following options for more information on Deploying to Azure: Deploy as Zip file Deploy via FTP Deploy with Script The Integration Framework can also be deployed as a Windows Service . In order to integrate with D365 you must register the integration framework in Active Directory. Here are some articles that explain how to do that: - https://docs.microsoft.com/en-us/azure/active-directory/develop/howto-create-service-principal-portal - https://docs.microsoft.com/en-us/powerapps/developer/common-data-service/use-single-tenant-server-server-authentication#azure-application-registration - https://docs.microsoft.com/en-us/azure/active-directory/azuread-dev/v1-protocols-oauth-code#register-your-application-with-your-ad-tenant In order to access certain Azure resources like Azure Key Vault you will need to make sure your App Service has a system-assigned identity .","title":"Deploying the Integration Framework"},{"location":"Deploying-Integration-Framework/#next-steps","text":"Create Service Bus Configure the application","title":"Next Steps"},{"location":"DeployingCDS/","text":"Introduction the Levridge Integration Framework uses the CDS repository to store reference data. Because CDS licenses are included with every Dynamics 365 user, this should not result in an additional licensing fees to our customers. This document explains the steps necessary to deploy CDS to a customer environment. Deployment Overview The following steps are necessary to deploy the CDS solutions and data to customer. Create the CDS Environment Create the CDS Database Set Data Loss Prevention policies Configure database security Deploy Solution Deploy Applications Setup Users Import Data","title":"Deploying CDS"},{"location":"DeployingCDS/#introduction","text":"the Levridge Integration Framework uses the CDS repository to store reference data. Because CDS licenses are included with every Dynamics 365 user, this should not result in an additional licensing fees to our customers. This document explains the steps necessary to deploy CDS to a customer environment.","title":"Introduction"},{"location":"DeployingCDS/#deployment","text":"","title":"Deployment"},{"location":"DeployingCDS/#overview","text":"The following steps are necessary to deploy the CDS solutions and data to customer. Create the CDS Environment Create the CDS Database Set Data Loss Prevention policies Configure database security Deploy Solution Deploy Applications Setup Users Import Data","title":"Overview"},{"location":"DeployingCustomFieldMappingAssemblies/","text":"Deploying Custom Plugin Assemblies This document explains how to deploy a custom plugin assembly. Custom plugins can be used for numerous purposes, but the most common is for field mapping assemblies. See Integrating Custom Fields for instructions on how to create a custom field mapping assembly. Overview If you have developed custom plugin assembly you will have to deploy it to a Levridge Integration Framework instance. You will need to deploy the assembly library and any custom dependencies you may have built. Deployment It is important to deploy only the custom assemblies and not any referenced assemblies that are shared with the Levridge Integration Framework. The referenced assemblies will already be deployed with the Levridge Integration Framework. To avoid deploying the shared referenced assemblies, be sure to follow the instructions in the section titled Update the references to be excluded from deployment . You can use visual studio to deploy to a local folder or use Azure DevOps to obtain a zipped folder or your custom assemblies. You will need to copy the custom assemblies into the same folder as the Levridge Integration Framework. Configuration You will need to add a CustomMappingAssemblies node to the appsettings.json file.","title":"Deploying Custom Field Mapping Assemblies"},{"location":"DeployingCustomFieldMappingAssemblies/#deploying-custom-plugin-assemblies","text":"This document explains how to deploy a custom plugin assembly. Custom plugins can be used for numerous purposes, but the most common is for field mapping assemblies. See Integrating Custom Fields for instructions on how to create a custom field mapping assembly.","title":"Deploying Custom Plugin Assemblies"},{"location":"DeployingCustomFieldMappingAssemblies/#overview","text":"If you have developed custom plugin assembly you will have to deploy it to a Levridge Integration Framework instance. You will need to deploy the assembly library and any custom dependencies you may have built.","title":"Overview"},{"location":"DeployingCustomFieldMappingAssemblies/#deployment","text":"It is important to deploy only the custom assemblies and not any referenced assemblies that are shared with the Levridge Integration Framework. The referenced assemblies will already be deployed with the Levridge Integration Framework. To avoid deploying the shared referenced assemblies, be sure to follow the instructions in the section titled Update the references to be excluded from deployment . You can use visual studio to deploy to a local folder or use Azure DevOps to obtain a zipped folder or your custom assemblies. You will need to copy the custom assemblies into the same folder as the Levridge Integration Framework.","title":"Deployment"},{"location":"DeployingCustomFieldMappingAssemblies/#configuration","text":"You will need to add a CustomMappingAssemblies node to the appsettings.json file.","title":"Configuration"},{"location":"EntityMap.AddFieldMap/","text":"EntityMap.AddFieldMap Method Namespace: Levridge.Integration.IntegrationService.Mapping Assemblies: Levridge.Integration.IntegrationService.Mapping.dll Adds a field map to an EntityMap. A field map contains the defintion of the source and target fields to be mapped and any transformation code necessary to perform the map. Overloads Overload Description AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, TB> transformA2B, Func<IEntityField, IEntityField, TA> transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TB> transformA2B, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TA> transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB); Parameters Returns Exceptions Examples AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, TB> transformA2B, Func<IEntityField, IEntityField, TA> transformB2A); Parameters Returns Exceptions Examples AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TB> transformA2B, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TA> transformB2A); Parameters Returns Exceptions Examples","title":"EntityMap.AddFieldMap Method"},{"location":"EntityMap.AddFieldMap/#entitymapaddfieldmap-method","text":"Namespace: Levridge.Integration.IntegrationService.Mapping Assemblies: Levridge.Integration.IntegrationService.Mapping.dll Adds a field map to an EntityMap. A field map contains the defintion of the source and target fields to be mapped and any transformation code necessary to perform the map.","title":"EntityMap.AddFieldMap Method"},{"location":"EntityMap.AddFieldMap/#overloads","text":"Overload Description AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, TB> transformA2B, Func<IEntityField, IEntityField, TA> transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TB> transformA2B, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TA> transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. AddFieldMap (IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources.","title":"Overloads"},{"location":"EntityMap.AddFieldMap/#addfieldmapientityfield-sourcefielda-ientityfield-sourcefieldb","text":"Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB);","title":"AddFieldMap(IEntityField sourceFieldA, IEntityField sourceFieldB)"},{"location":"EntityMap.AddFieldMap/#parameters","text":"","title":"Parameters"},{"location":"EntityMap.AddFieldMap/#returns","text":"","title":"Returns"},{"location":"EntityMap.AddFieldMap/#exceptions","text":"","title":"Exceptions"},{"location":"EntityMap.AddFieldMap/#examples","text":"","title":"Examples"},{"location":"EntityMap.AddFieldMap/#addfieldmapientityfield-sourcefielda-ientityfield-sourcefieldb-func-transforma2b-func-transformb2a","text":"Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, TB> transformA2B, Func<IEntityField, IEntityField, TA> transformB2A);","title":"AddFieldMap(IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A)"},{"location":"EntityMap.AddFieldMap/#parameters_1","text":"","title":"Parameters"},{"location":"EntityMap.AddFieldMap/#returns_1","text":"","title":"Returns"},{"location":"EntityMap.AddFieldMap/#exceptions_1","text":"","title":"Exceptions"},{"location":"EntityMap.AddFieldMap/#examples_1","text":"","title":"Examples"},{"location":"EntityMap.AddFieldMap/#addfieldmapientityfield-sourcefielda-ientityfield-sourcefieldb-func-transforma2b-func-transformb2a_1","text":"Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. transformA2B and transformB2A take ISourceConfiguration parameters to access the source and target data sources. public IFieldMap AddFieldMap<TA, TB>(IEntityField sourceFieldA, IEntityField sourceFieldB, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TB> transformA2B, Func<IEntityField, IEntityField, ISourceConfiguration, ISourceConfiguration, TA> transformB2A);","title":"AddFieldMap(IEntityField sourceFieldA, IEntityField sourceFieldB, Func transformA2B, Func transformB2A)"},{"location":"EntityMap.AddFieldMap/#parameters_2","text":"","title":"Parameters"},{"location":"EntityMap.AddFieldMap/#returns_2","text":"","title":"Returns"},{"location":"EntityMap.AddFieldMap/#exceptions_2","text":"","title":"Exceptions"},{"location":"EntityMap.AddFieldMap/#examples_2","text":"","title":"Examples"},{"location":"EntityMapBuilderExtensions.AddEntityMap/","text":"EntityMapBuilderExtensions.AddEntityMap Method Namespace: Levridge.Integration.IntegrationService.Mapping Assemblies: Levridge.Integration.IntegrationService.Mapping.dll Adds an entity to the EntityMap. An entity map contains the defintion of the source and target entities to be mapped and the necessary code to configure the field maps for the entity. Overloads Overload Description AddEntityMap (this IEntityMapBuilder builder, Action > configure) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action configure) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations. AddEntityMap (this IEntityMapBuilder builder, Action > configure) Adds an Entity Map to the IEntityMapBuilder and provides a configuration action to configure the Entity Mapping. public static IEntityMapBuilder AddEntityMap<TLeft, TRight>(this IEntityMapBuilder builder, Action<EntityMap<TLeft, TRight>> configure); Parameters Returns Exceptions Examples AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action configure) Adds an Entity Map to the IEntityMapBuilder and provides a configuration action to configure the Entity Mapping. public static IEntityMapBuilder AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action<EntityMap> configure); Parameters Returns Exceptions Examples","title":"EntityMapBuilderExtensions.AddEntityMap Method"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#entitymapbuilderextensionsaddentitymap-method","text":"Namespace: Levridge.Integration.IntegrationService.Mapping Assemblies: Levridge.Integration.IntegrationService.Mapping.dll Adds an entity to the EntityMap. An entity map contains the defintion of the source and target entities to be mapped and the necessary code to configure the field maps for the entity.","title":"EntityMapBuilderExtensions.AddEntityMap Method"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#overloads","text":"Overload Description AddEntityMap (this IEntityMapBuilder builder, Action > configure) Maps sourceFieldA to sourceFieldB using the default assignment sourceFieldB = sourceFieldA. AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action configure) Maps sourceFieldA to sourceFieldB using the transformA2B and transformB2A parameters to provide the transformations.","title":"Overloads"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#addentitymapthis-ientitymapbuilder-builder-action-configure","text":"Adds an Entity Map to the IEntityMapBuilder and provides a configuration action to configure the Entity Mapping. public static IEntityMapBuilder AddEntityMap<TLeft, TRight>(this IEntityMapBuilder builder, Action<EntityMap<TLeft, TRight>> configure);","title":"AddEntityMap(this IEntityMapBuilder builder, Action configure)"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#parameters","text":"","title":"Parameters"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#returns","text":"","title":"Returns"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#exceptions","text":"","title":"Exceptions"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#examples","text":"","title":"Examples"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#addentitymapthis-ientitymapbuilder-builder-string-entitytypea-string-entitytypeb-action-configure","text":"Adds an Entity Map to the IEntityMapBuilder and provides a configuration action to configure the Entity Mapping. public static IEntityMapBuilder AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action<EntityMap> configure);","title":"AddEntityMap(this IEntityMapBuilder builder, string entityTypeA, string entityTypeB, Action configure)"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#parameters_1","text":"","title":"Parameters"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#returns_1","text":"","title":"Returns"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#exceptions_1","text":"","title":"Exceptions"},{"location":"EntityMapBuilderExtensions.AddEntityMap/#examples_1","text":"","title":"Examples"},{"location":"Environment-variables/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"Environment-variables/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Environment-variables/#overview","text":"","title":"Overview"},{"location":"Environment-variables/#main-point-1","text":"","title":"Main Point 1"},{"location":"Environment-variables/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"EnvironmentsPlanning/","text":"Environments Planning A standard D365 implementation is used when launching a Levridge environment plan. The standard D365 implementation guidelines are captured in the Stoneridge Software Asset Library . Overview D365 is set up with Levridge sitting on top of the functionality. With the start of a new project, the team performs a technical review of what is required and outlines a plan that fits the client\u2019s needs. The team utilizes the latest Microsoft Environment planning when implementing a new project due to information continually being revised and updated. The Microsoft Environment planning provides an overview of various aspects that you must consider while you plan for your project's environment. To help guarantee a successful cloud implementation, it is important that you discuss and plan your environment early in the project. Getting Started Configure your Azure Subscription Create a D365 Subscription Create Azure Active Directory accounts Request vCPU quota increase for planned environments Azure VM Quota Increase Deploy your Azure DevOps project Microsoft Azure Dev Ops Create a security token using your D365Admin account (Used for integration with Lifecycle Services) Deploy your Lifecycle Services project (D365 licensing required) Microsoft Dynamics Lifecycle Services Complete the Lifecycle Services Onboarding workflow Includes DevOps integration and Azure integration for environment deployments Project Onboarding Deploy environments Deployed via Lifecycle Services Lifecycle Services (LCS) user guide Configure Levridge Integrations Levridge Integration Deployment Procedures D365 F&O System Requirements Azure Tenant Azure Active Directory Accounts D365Admin D365Test1 D365Test2 LevridgeIntegrations Azure Execution Account (Manage Azure VM schedules) Lifecycle Services Project (included with D365 licensing) Azure DevOps (Cloud based) D365 F&O Environments (Deploy from Lifecycle Services) D365 CE Environments (Deploy from 365 Admin Portal) Azure Integration Components Document Routing Agent (Installed on local infrastructure to support server-based network printing) Power BI Subscription","title":"Environments Planning"},{"location":"EnvironmentsPlanning/#environments-planning","text":"A standard D365 implementation is used when launching a Levridge environment plan. The standard D365 implementation guidelines are captured in the Stoneridge Software Asset Library .","title":"Environments Planning"},{"location":"EnvironmentsPlanning/#overview","text":"D365 is set up with Levridge sitting on top of the functionality. With the start of a new project, the team performs a technical review of what is required and outlines a plan that fits the client\u2019s needs. The team utilizes the latest Microsoft Environment planning when implementing a new project due to information continually being revised and updated. The Microsoft Environment planning provides an overview of various aspects that you must consider while you plan for your project's environment. To help guarantee a successful cloud implementation, it is important that you discuss and plan your environment early in the project.","title":"Overview"},{"location":"EnvironmentsPlanning/#getting-started","text":"Configure your Azure Subscription Create a D365 Subscription Create Azure Active Directory accounts Request vCPU quota increase for planned environments Azure VM Quota Increase Deploy your Azure DevOps project Microsoft Azure Dev Ops Create a security token using your D365Admin account (Used for integration with Lifecycle Services) Deploy your Lifecycle Services project (D365 licensing required) Microsoft Dynamics Lifecycle Services Complete the Lifecycle Services Onboarding workflow Includes DevOps integration and Azure integration for environment deployments Project Onboarding Deploy environments Deployed via Lifecycle Services Lifecycle Services (LCS) user guide Configure Levridge Integrations Levridge Integration Deployment Procedures","title":"Getting Started"},{"location":"EnvironmentsPlanning/#d365-fo-system-requirements","text":"Azure Tenant Azure Active Directory Accounts D365Admin D365Test1 D365Test2 LevridgeIntegrations Azure Execution Account (Manage Azure VM schedules) Lifecycle Services Project (included with D365 licensing) Azure DevOps (Cloud based) D365 F&O Environments (Deploy from Lifecycle Services) D365 CE Environments (Deploy from 365 Admin Portal) Azure Integration Components Document Routing Agent (Installed on local infrastructure to support server-based network printing) Power BI Subscription","title":"D365 F&amp;O System Requirements"},{"location":"Equity/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Levridge Equity Accounting"},{"location":"Equity/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Equity/#overview","text":"","title":"Overview"},{"location":"Equity/#main-point-1","text":"","title":"Main Point 1"},{"location":"Equity/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"Feed/","text":"Feed Overview Main Point 1 Sub Point 1.1","title":"Levridge Feed"},{"location":"Feed/#feed","text":"","title":"Feed"},{"location":"Feed/#overview","text":"","title":"Overview"},{"location":"Feed/#main-point-1","text":"","title":"Main Point 1"},{"location":"Feed/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"Field-Integration/","text":"Field Integration The Field integration is a unidirectional integration that receives messages to create a Levridge Customer Site using a configured Customer Site Type that represents a customer field. Overview The Field Integration API is a Webhook that receives a posted message that is used to create a new Customer Site in Levridge. API POST /api/field HTTP/1.1 Host: [Customer Integration Framework Host] Content-Type: application/json { \"growerID\": \"CUS-000071\", \"growerUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f170\", \"farmID\": \"COP000010\", \"farmUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f171\", \"fieldID\": \"CST-000150\", \"fieldUuid\":\"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\", \"fieldName\": \"Test Field Type\", \"fieldWkt\" : \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\", \"farmableAcres\" : 19.5 } Authentication Error Codes Rate limit Message Example { \"growerID\": \"CUS-000071\", \"growerUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f170\", \"farmID\": \"COP000010\", \"farmUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f171\", \"fieldID\": \"CST-000150\", \"fieldUuid\":\"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\", \"fieldName\": \"Test Field Type\", \"fieldWkt\" : \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\", \"farmableAcres\" : 19.5 } Message Schema 1 { 2 \"definitions\": {}, 3 \"$schema\": \"http://json-schema.org/draft-07/schema#\", 4 \"$id\": \"http://example.com/root.json\", 5 \"type\": \"object\", 6 \"title\": \"The Root Schema\", 7 \"required\": [ 8 \"growerID\", 9 \"farmID\", 10 \"fieldID\", 11 \"fieldName\" 12 ], 13 \"properties\": { 14 \"growerID\": { 15 \"$id\": \"#/properties/growerID\", 16 \"type\": \"string\", 17 \"title\": \"The Growerid Schema\", 18 \"default\": \"\", 19 \"examples\": [ 20 \"CUS-000071\" 21 ], 22 \"pattern\": \"^(.*)$\" 23 }, 24 \"growerUuid\": { 25 \"$id\": \"#/properties/growerUuid\", 26 \"type\": \"string\", 27 \"title\": \"The Groweruuid Schema\", 28 \"default\": \"\", 29 \"examples\": [ 30 \"\" 31 ], 32 \"pattern\": \"^(.*)$\" 33 }, 34 \"farmID\": { 35 \"$id\": \"#/properties/farmID\", 36 \"type\": \"string\", 37 \"title\": \"The Farmid Schema\", 38 \"default\": \"\", 39 \"examples\": [ 40 \"COP000010\" 41 ], 42 \"pattern\": \"^(.*)$\" 43 }, 44 \"farmUuid\": { 45 \"$id\": \"#/properties/farmUuid\", 46 \"type\": \"string\", 47 \"title\": \"The Farmuuid Schema\", 48 \"default\": \"\", 49 \"examples\": [ 50 \"\" 51 ], 52 \"pattern\": \"^(.*)$\" 53 }, 54 \"fieldID\": { 55 \"$id\": \"#/properties/fieldID\", 56 \"type\": \"string\", 57 \"title\": \"The Fieldid Schema\", 58 \"default\": \"\", 59 \"examples\": [ 60 \"CST-000150\" 61 ], 62 \"pattern\": \"^(.*)$\" 63 }, 64 \"fieldUuid\": { 65 \"$id\": \"#/properties/fieldUuid\", 66 \"type\": \"string\", 67 \"title\": \"The Fielduuid Schema\", 68 \"default\": \"\", 69 \"examples\": [ 70 \"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\" 71 ], 72 \"pattern\": \"^(.*)$\" 73 }, 74 \"fieldName\": { 75 \"$id\": \"#/properties/fieldName\", 76 \"type\": \"string\", 77 \"title\": \"The Fieldname Schema\", 78 \"default\": \"\", 79 \"examples\": [ 80 \"Test Field Type\" 81 ], 82 \"pattern\": \"^(.*)$\" 83 }, 84 \"fieldWkt\": { 85 \"$id\": \"#/properties/fieldWkt\", 86 \"type\": \"string\", 87 \"title\": \"The Fieldwkt Schema\", 88 \"default\": \"\", 89 \"examples\": [ 90 \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\" 91 ], 92 \"pattern\": \"^(.*)$\" 93 }, 94 \"farmableAcres\": { 95 \"$id\": \"#/properties/farmableAcres\", 96 \"type\": \"number\", 97 \"title\": \"The Farmableacres Schema\", 98 \"default\": 0.0, 99 \"examples\": [ 100 19.5 101 ] 102 } 103 } 104 } Configuration In the appsettings.json you will need to define a section named \"Levridge.Integration.Host.FieldController\". The controller looks for this section to get the Service Bus information needed to place messages into a Topic. You can run the Field to CRM integration in the same instance simply by pointing the SourceConfig.ServiceBusConfigName to \"Levridge.Integration.Host.FieldController\" also, or a section that defines a connection to the same topic the controller is sending the message to. For the instance that handles the integration mapping the SourceConfig and TargetConfig nodes should be setup as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": \"\", \"SystemName\": \"Field\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" } In the appsettings.json you will need to add the assembly into the list of controllers. It doesn't matter what name you assign to the assembly entry but the assembly name must be \"Levridge.Integration.Host.FieldController\". In the example below the assembly is named \"FieldController\". (i.e. \"FieldController\": \"Levridge.Integration.Host.FieldController\") \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"FieldController\": \"Levridge.Integration.Host.FieldController\" } The \"Controllers\" section above will load the DefaultController and the FieldController. { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"FieldController\": \"Levridge.Integration.Host.FieldController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfiguration\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Levridge.Integration.Host.FieldController\", \"ODataConfigName\": \"CDS\", \"SystemName\": \"Field\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsCRM\", \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\", \"CDSConfigName\": \"CDS\" }, \"DynamicsCRM\": { \"UriString\": \"https://localhost\", \"ActiveDirectoryResource\": \"https://[Customer CRM Instance].crm.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/2e14a5b1-fbf8-415b-bc7d-93e20829e510\", \"ActiveDirectoryClientAppId\": \"[Application ID]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret]\", \"ODataEntityPath\": \"https://[Customer CRM Instance].crm.dynamics.com/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.DynamicsCRM\", \"AssemblyFile\": \"Levridge.ODataDataSources.DynamicsCRM.dll\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.DynamicsCRM\", \"MetadataResource\": \"CRMMetadata.xml\" }, \"CDS\": { \"UriString\": \"https://localhost\", \"ActiveDirectoryResource\": \"https://[Customer CDS Instance].api.crm.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/2e14a5b1-fbf8-415b-bc7d-93e20829e510\", \"ActiveDirectoryClientAppId\": \"[Application ID]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret]\", \"ODataEntityPath\": \"https://[Customer CDS Instance].api.crm.dynamics.com/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"AzureTableConfiguration\": { \"ConnectionString\": \"DefaultEndpointsProtocol=https;AccountName=levridgegeneralstorage;AccountKey=MFkzIfLUU1KyCMxfZVPk7HelhWlC0TZyBnFDMEty4y3D4YnqgA4RHSHu8es+R91C/MmDNjtuKJ1x8yDMJ4vLGA==;EndpointSuffix=core.windows.net\", \"Table\": \"FinOpsAndCRM\" }, \"Levridge.Integration.Host.FieldController\": { // used by Webhook \"ConnectionString\": \"Endpoint=sb://[Customer Service Bus Instance].servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=[Customer Access Key]\", \"TopicName\": \"[Customer Topic Name]\", \"SubscriptionName\": \"[Customer Subscription Name]\", \"RequiresSession\": true, \"CustomerSiteTypeCode\": \"[CustomerSite TypeCode from FinOps]\", \"IdOption\": \"FieldId\" } }","title":"Field Integration"},{"location":"Field-Integration/#field-integration","text":"The Field integration is a unidirectional integration that receives messages to create a Levridge Customer Site using a configured Customer Site Type that represents a customer field.","title":"Field Integration"},{"location":"Field-Integration/#overview","text":"The Field Integration API is a Webhook that receives a posted message that is used to create a new Customer Site in Levridge.","title":"Overview"},{"location":"Field-Integration/#api","text":"POST /api/field HTTP/1.1 Host: [Customer Integration Framework Host] Content-Type: application/json { \"growerID\": \"CUS-000071\", \"growerUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f170\", \"farmID\": \"COP000010\", \"farmUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f171\", \"fieldID\": \"CST-000150\", \"fieldUuid\":\"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\", \"fieldName\": \"Test Field Type\", \"fieldWkt\" : \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\", \"farmableAcres\" : 19.5 }","title":"API"},{"location":"Field-Integration/#authentication","text":"","title":"Authentication"},{"location":"Field-Integration/#error-codes","text":"","title":"Error Codes"},{"location":"Field-Integration/#rate-limit","text":"","title":"Rate limit"},{"location":"Field-Integration/#message-example","text":"{ \"growerID\": \"CUS-000071\", \"growerUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f170\", \"farmID\": \"COP000010\", \"farmUuid\": \"5ddf9e57-b1ba-4af5-90bf-e9454e87f171\", \"fieldID\": \"CST-000150\", \"fieldUuid\":\"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\", \"fieldName\": \"Test Field Type\", \"fieldWkt\" : \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\", \"farmableAcres\" : 19.5 }","title":"Message Example"},{"location":"Field-Integration/#message-schema","text":"1 { 2 \"definitions\": {}, 3 \"$schema\": \"http://json-schema.org/draft-07/schema#\", 4 \"$id\": \"http://example.com/root.json\", 5 \"type\": \"object\", 6 \"title\": \"The Root Schema\", 7 \"required\": [ 8 \"growerID\", 9 \"farmID\", 10 \"fieldID\", 11 \"fieldName\" 12 ], 13 \"properties\": { 14 \"growerID\": { 15 \"$id\": \"#/properties/growerID\", 16 \"type\": \"string\", 17 \"title\": \"The Growerid Schema\", 18 \"default\": \"\", 19 \"examples\": [ 20 \"CUS-000071\" 21 ], 22 \"pattern\": \"^(.*)$\" 23 }, 24 \"growerUuid\": { 25 \"$id\": \"#/properties/growerUuid\", 26 \"type\": \"string\", 27 \"title\": \"The Groweruuid Schema\", 28 \"default\": \"\", 29 \"examples\": [ 30 \"\" 31 ], 32 \"pattern\": \"^(.*)$\" 33 }, 34 \"farmID\": { 35 \"$id\": \"#/properties/farmID\", 36 \"type\": \"string\", 37 \"title\": \"The Farmid Schema\", 38 \"default\": \"\", 39 \"examples\": [ 40 \"COP000010\" 41 ], 42 \"pattern\": \"^(.*)$\" 43 }, 44 \"farmUuid\": { 45 \"$id\": \"#/properties/farmUuid\", 46 \"type\": \"string\", 47 \"title\": \"The Farmuuid Schema\", 48 \"default\": \"\", 49 \"examples\": [ 50 \"\" 51 ], 52 \"pattern\": \"^(.*)$\" 53 }, 54 \"fieldID\": { 55 \"$id\": \"#/properties/fieldID\", 56 \"type\": \"string\", 57 \"title\": \"The Fieldid Schema\", 58 \"default\": \"\", 59 \"examples\": [ 60 \"CST-000150\" 61 ], 62 \"pattern\": \"^(.*)$\" 63 }, 64 \"fieldUuid\": { 65 \"$id\": \"#/properties/fieldUuid\", 66 \"type\": \"string\", 67 \"title\": \"The Fielduuid Schema\", 68 \"default\": \"\", 69 \"examples\": [ 70 \"5ddf9e57-b1ba-4af5-90bf-e9454e87f172\" 71 ], 72 \"pattern\": \"^(.*)$\" 73 }, 74 \"fieldName\": { 75 \"$id\": \"#/properties/fieldName\", 76 \"type\": \"string\", 77 \"title\": \"The Fieldname Schema\", 78 \"default\": \"\", 79 \"examples\": [ 80 \"Test Field Type\" 81 ], 82 \"pattern\": \"^(.*)$\" 83 }, 84 \"fieldWkt\": { 85 \"$id\": \"#/properties/fieldWkt\", 86 \"type\": \"string\", 87 \"title\": \"The Fieldwkt Schema\", 88 \"default\": \"\", 89 \"examples\": [ 90 \"MULTIPOLYGON(((-97.027808062981 46.999026392986,-97.017851703117 46.998792242651,-97.018023364494 46.991884346149,-97.027636401605 46.991767255461,-97.027808062981 46.999026392986)))\" 91 ], 92 \"pattern\": \"^(.*)$\" 93 }, 94 \"farmableAcres\": { 95 \"$id\": \"#/properties/farmableAcres\", 96 \"type\": \"number\", 97 \"title\": \"The Farmableacres Schema\", 98 \"default\": 0.0, 99 \"examples\": [ 100 19.5 101 ] 102 } 103 } 104 }","title":"Message Schema"},{"location":"Field-Integration/#configuration","text":"In the appsettings.json you will need to define a section named \"Levridge.Integration.Host.FieldController\". The controller looks for this section to get the Service Bus information needed to place messages into a Topic. You can run the Field to CRM integration in the same instance simply by pointing the SourceConfig.ServiceBusConfigName to \"Levridge.Integration.Host.FieldController\" also, or a section that defines a connection to the same topic the controller is sending the message to. For the instance that handles the integration mapping the SourceConfig and TargetConfig nodes should be setup as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": \"\", \"SystemName\": \"Field\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" } In the appsettings.json you will need to add the assembly into the list of controllers. It doesn't matter what name you assign to the assembly entry but the assembly name must be \"Levridge.Integration.Host.FieldController\". In the example below the assembly is named \"FieldController\". (i.e. \"FieldController\": \"Levridge.Integration.Host.FieldController\") \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"FieldController\": \"Levridge.Integration.Host.FieldController\" } The \"Controllers\" section above will load the DefaultController and the FieldController. { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"FieldController\": \"Levridge.Integration.Host.FieldController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfiguration\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Levridge.Integration.Host.FieldController\", \"ODataConfigName\": \"CDS\", \"SystemName\": \"Field\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsCRM\", \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\", \"CDSConfigName\": \"CDS\" }, \"DynamicsCRM\": { \"UriString\": \"https://localhost\", \"ActiveDirectoryResource\": \"https://[Customer CRM Instance].crm.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/2e14a5b1-fbf8-415b-bc7d-93e20829e510\", \"ActiveDirectoryClientAppId\": \"[Application ID]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret]\", \"ODataEntityPath\": \"https://[Customer CRM Instance].crm.dynamics.com/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.DynamicsCRM\", \"AssemblyFile\": \"Levridge.ODataDataSources.DynamicsCRM.dll\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.DynamicsCRM\", \"MetadataResource\": \"CRMMetadata.xml\" }, \"CDS\": { \"UriString\": \"https://localhost\", \"ActiveDirectoryResource\": \"https://[Customer CDS Instance].api.crm.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/2e14a5b1-fbf8-415b-bc7d-93e20829e510\", \"ActiveDirectoryClientAppId\": \"[Application ID]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret]\", \"ODataEntityPath\": \"https://[Customer CDS Instance].api.crm.dynamics.com/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"AzureTableConfiguration\": { \"ConnectionString\": \"DefaultEndpointsProtocol=https;AccountName=levridgegeneralstorage;AccountKey=MFkzIfLUU1KyCMxfZVPk7HelhWlC0TZyBnFDMEty4y3D4YnqgA4RHSHu8es+R91C/MmDNjtuKJ1x8yDMJ4vLGA==;EndpointSuffix=core.windows.net\", \"Table\": \"FinOpsAndCRM\" }, \"Levridge.Integration.Host.FieldController\": { // used by Webhook \"ConnectionString\": \"Endpoint=sb://[Customer Service Bus Instance].servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=[Customer Access Key]\", \"TopicName\": \"[Customer Topic Name]\", \"SubscriptionName\": \"[Customer Subscription Name]\", \"RequiresSession\": true, \"CustomerSiteTypeCode\": \"[CustomerSite TypeCode from FinOps]\", \"IdOption\": \"FieldId\" } }","title":"Configuration"},{"location":"Field-Reveal/","text":"Field Reveal Integration There are two aspects of integration with Field Reveal . Recommendations Fields Recommendation Integrations The Recommendation Integration is a general integration provided by the Levridge API. Field Reveal has built the capabillites to send a perscription for a specific field to Levridge through our Recommendation Integration API . Field Integrations The Field Integration is a general integration provided by the Levridge API. Field Reveal has built the capabillites to send field information to Levridge through our Field Integration API .","title":"Field Reveal"},{"location":"Field-Reveal/#field-reveal-integration","text":"There are two aspects of integration with Field Reveal . Recommendations Fields","title":"Field Reveal Integration"},{"location":"Field-Reveal/#recommendation-integrations","text":"The Recommendation Integration is a general integration provided by the Levridge API. Field Reveal has built the capabillites to send a perscription for a specific field to Levridge through our Recommendation Integration API .","title":"Recommendation Integrations"},{"location":"Field-Reveal/#field-integrations","text":"The Field Integration is a general integration provided by the Levridge API. Field Reveal has built the capabillites to send field information to Levridge through our Field Integration API .","title":"Field Integrations"},{"location":"HowtoupdateLevridgeScale/","text":"How to Update Levridge Scale Prerequisites An older Version of Levridge Scale must be installed and configured Setup Download the new version installer exe file Right click and Run as Administrator Agree to terms and click Install When the install is complete, click Finish Open IIS On the LevScaleAPI and LevPrint Application Pools, right click > Advanced settings In the Identity field select Custom account > Set and enter username and password Open Services On the LevHardwareInterfaceService and LevScaleClient services , right click > Properties Click the Log On tab Enter account and password and click OK. If the account is part of a directory, click Browse. Then enter the username and click Check Names. Check the configuration of appsettings Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers In the LevScaleAPI and LevScaleClient folders, configure appsettings.json Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services In the AxToScaleIntegration and ScaleToAxIntegration folders configure appsettings.json Restart the PC","title":"How to Update Levridge Scale"},{"location":"HowtoupdateLevridgeScale/#how-to-update-levridge-scale","text":"","title":"How to Update Levridge Scale"},{"location":"HowtoupdateLevridgeScale/#prerequisites","text":"An older Version of Levridge Scale must be installed and configured","title":"Prerequisites"},{"location":"HowtoupdateLevridgeScale/#setup","text":"Download the new version installer exe file Right click and Run as Administrator Agree to terms and click Install When the install is complete, click Finish Open IIS On the LevScaleAPI and LevPrint Application Pools, right click > Advanced settings In the Identity field select Custom account > Set and enter username and password Open Services On the LevHardwareInterfaceService and LevScaleClient services , right click > Properties Click the Log On tab Enter account and password and click OK. If the account is part of a directory, click Browse. Then enter the username and click Check Names. Check the configuration of appsettings Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers In the LevScaleAPI and LevScaleClient folders, configure appsettings.json Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services In the AxToScaleIntegration and ScaleToAxIntegration folders configure appsettings.json Restart the PC","title":"Setup"},{"location":"InstanceConfig/","text":"InstanceConfig Settings InstanceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework. Example \"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfiguration\", \"LogRequestsAndResponses\": true, \"EnableAppInsightsAdaptiveSampling\": true, \"HttpClientTimeout\": 100, \"AcceptedApiRoles\":[ \"access_as_application\" ] } Definition InstanceConfig The node in the appsettings.json file does not actually need to be named \"InstanceConfig\". You can use a command line parameter to specify the node name (section name) that contains the InstanceConfig data. No matter the name, the instance config section must contain the following attributes: AzureTableConfiguration LogRequestsAndResponses EnableAppInsightsAdaptiveSampling HttpClientTimeout AcceptedApiRoles AzureTableConfiguration Required The AzureTableConfiguration attribute contains a string that specifies the configuration node (section) that holds the Azure Table configuration used by the current instance of the Integration Framework. This must point to a node that is a AzureTableEntityConfiguration json object LogRequestsAndResponses Optional Default = false The LogRequestsAndResponses attribute contains a boolean that specifies whether or not to log the requests and responses of the controllers in the current instance of the Integration Framework. EnableAppInsightsAdaptiveSampling Optional Default = true The EnableAppInsightsAdaptiveSampling attribute contains a boolean that specifies whether or not to enable application insights adaptive sampling. If this is disabled all the messages logged to Application Insights. This should only be used during troubleshooting and testing because the cost for Application Insights is billed based on volume. The default state is \"true\" which means that adaptive sampling is enabled by default. See Sampling in Application Insights for more information. HttpClientTimeout Optional Default = 100 seconds The HttpClientTimeout attribute specifies the number of seconds to use for the timeout on all HTTP Client calls in the integration framework. The default is 100 seconds. In some cases this is not enough time under heavy load, particularly the Agsync to FinOps work order integration. To change this set the value to an integer value that represents the number of seconds you want for the timeout. AcceptedApiRoles Optional Default = Empty Array The AcceptedApiRoles attribute specifies what roles in the Active Directory Application Registration are accepted as adequate permissions to authorize an application to interact with secured APIs on this integration instance. AzureAdSection Optional Default = \"AzureAD\" The name of the section that contains the AzureAD configuration options used for AzureAD authentication.","title":"InstanceConfig Settings"},{"location":"InstanceConfig/#instanceconfig-settings","text":"InstanceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework.","title":"InstanceConfig Settings"},{"location":"InstanceConfig/#example","text":"\"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfiguration\", \"LogRequestsAndResponses\": true, \"EnableAppInsightsAdaptiveSampling\": true, \"HttpClientTimeout\": 100, \"AcceptedApiRoles\":[ \"access_as_application\" ] }","title":"Example"},{"location":"InstanceConfig/#definition","text":"","title":"Definition"},{"location":"InstanceConfig/#instanceconfig","text":"The node in the appsettings.json file does not actually need to be named \"InstanceConfig\". You can use a command line parameter to specify the node name (section name) that contains the InstanceConfig data. No matter the name, the instance config section must contain the following attributes: AzureTableConfiguration LogRequestsAndResponses EnableAppInsightsAdaptiveSampling HttpClientTimeout AcceptedApiRoles","title":"InstanceConfig"},{"location":"InstanceConfig/#azuretableconfiguration","text":"Required The AzureTableConfiguration attribute contains a string that specifies the configuration node (section) that holds the Azure Table configuration used by the current instance of the Integration Framework. This must point to a node that is a AzureTableEntityConfiguration json object","title":"AzureTableConfiguration"},{"location":"InstanceConfig/#logrequestsandresponses","text":"Optional Default = false The LogRequestsAndResponses attribute contains a boolean that specifies whether or not to log the requests and responses of the controllers in the current instance of the Integration Framework.","title":"LogRequestsAndResponses"},{"location":"InstanceConfig/#enableappinsightsadaptivesampling","text":"Optional Default = true The EnableAppInsightsAdaptiveSampling attribute contains a boolean that specifies whether or not to enable application insights adaptive sampling. If this is disabled all the messages logged to Application Insights. This should only be used during troubleshooting and testing because the cost for Application Insights is billed based on volume. The default state is \"true\" which means that adaptive sampling is enabled by default. See Sampling in Application Insights for more information.","title":"EnableAppInsightsAdaptiveSampling"},{"location":"InstanceConfig/#httpclienttimeout","text":"Optional Default = 100 seconds The HttpClientTimeout attribute specifies the number of seconds to use for the timeout on all HTTP Client calls in the integration framework. The default is 100 seconds. In some cases this is not enough time under heavy load, particularly the Agsync to FinOps work order integration. To change this set the value to an integer value that represents the number of seconds you want for the timeout.","title":"HttpClientTimeout"},{"location":"InstanceConfig/#acceptedapiroles","text":"Optional Default = Empty Array The AcceptedApiRoles attribute specifies what roles in the Active Directory Application Registration are accepted as adequate permissions to authorize an application to interact with secured APIs on this integration instance.","title":"AcceptedApiRoles"},{"location":"InstanceConfig/#azureadsection","text":"Optional Default = \"AzureAD\" The name of the section that contains the AzureAD configuration options used for AzureAD authentication.","title":"AzureAdSection"},{"location":"IntegratingCustomFields/","text":"Introduction In many implementations a client will have specific needs that require custom fields to be added to existing entities or custom behavior for an existing field in an integration. This document shows how to create a custom field extension to have those custom fields integrated when the entity is being integrated. Overview In order to integrate custom fields you will need to create a Visual Studio solution with upto three projects: Custom Source Proxy Project Contains the proxy for the source datasource with the custom fields in the entities This project is only necessary if there are custom fields in the source. If your customizations only include custom behavior for existing fields then a custom source proxy will not be needed. Custom Destination Proxy Project Contains the proxy for the desitination datasource with the custom fields in the entities This project is only necessary if there are custom fields in the destination. If your customizations only include custom behavior for existing fields then a custom destination proxy will not be needed. Custom Mapping Project Contains the code need to map the integration for the custom fields between the source and destination entities Note: If there are no custom fields involved and you are only defining custom behavior for existing fields you will not need new proxies. You only need a proxy to define the metadata for custom fields. Please see Deploying Custom Field Mapping Assemblies for information on deploying the custom mapping assembly. Tutorial Create the Solution The first step is to create a Visual Studio solution for the custom mapping. In Visual Studio, create a new C# Class Library (.NET Core). You may want to give the solution a different name than the project. In our example, the customer is Comstock so we will name the solution \"ComstockCustomMapping\" and the project Levridge.Integration.IntegrationService.Mapping.Comstock. We recommend you use this naming convention for your custom mapping project: Levridge.Integration.IntegrationService.Mapping.[clientname]. Create the Source Proxy Project Create the Destination Proxy Project Add References to the Custom Mapping Project The Levridge packages are published to our DevOps Artifacts so you will need to add a Nuget source for those packages. This is done in Visual Studio from Tools/Options/NuGet Package Manager/Package Sources. The source is https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages-beta/nuget/v3/index.json If you are working the LevDevelopment branch. If you are working in the customer's repository you should use 'https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages/nuget/v3/index.json' which is the released version of the packages. You will need to add the following Nuget references to your custom mapping project: Levridge.EntityFramework Levridge.Integration.IntegrationService.Abstractions Levridge.Integration.IntegrationService.Mapping Microsoft.Extensions.DependencyInjection System.ComponentModel.Composition Note: The Levridge packages are available from our Azure DevOps Artifacts repository. The URL for released packages is https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages/nuget/v3/index.json Add Source and Destination Datasource References to Custom Mapping Project You will need to reference the destination data source project in order to have access to any Field types and other types used during mapping. If your datasource is CRM you would include this reference: * Levridge.ODataDataSources.CRMODataDataSource If your datasource is F&O you would include this reference: * Levridge.DynamicsAxDataSource Update the references to be excluded from deployment These references will be needed for the build process, but we will want to use the libraries provided by the standard deployment and not deploy our own copy of the libraries with the custom mapping assemblies. To accomplish this, we let the msbuild system know to exclude these libraries from the runtime deployment by adding <ExcludeAssets>runtime</ExcludeAssets> to the <PackageReference> node for each package. You should have an <ItemGroup> node that looks somthing like this. <ItemGroup> <PackageReference Include=\"Levridge.EntityFramework\" Version=\"2.0.10\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.Integration.IntegrationService.Abstractions\" Version=\"1.0.0\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.Integration.IntegrationService.Mapping\" Version=\"1.0.0\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.ODataDataSources.CRMODataDataSource\" Version=\"2.1.15\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Microsoft.Extensions.DependencyInjection\" Version=\"3.0.2\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> </ItemGroup> Add a reference to the two datasource proxy projects Your custom mapping methods will need to access the source and data entities so you will need to add a reference to the two proxy projects you created in sections Create the Source Proxy Project and Create the Destination Proxy Project If you do not need a custom proxy project you should add a reference package to the correct Levridge nuget package. The F&O and CRM packages are: * Levridge.DynamicsAxDataSource * Levridge.ODataDataSources.DynamicsCRM Create An EntityMapBuilderExtension class We need to have a class that will contain the necessary mapping methods for the custom fields being added to the integration. Create a public class This can not be a static class because Microsoft MEF won't export a static class. Add the [Export] attribute to the class The Export attribute is in the System.ComponentModel.Composition that was added in the section Add References to the Custom Mapping Project Name the class We recommend using something like [client]CustomFieldsEntityMapping. The actual name is not important, orther than to be clear the purpose of the class. In our example we named the class ContosoCustomFieldsEntityMapping . Add a public static void method that takes a single IServiceCollection parameter. In our example we added the following method: public static void AddContosoCustomMaps(IServiceCollection services) Add a private static method that takes a single IEntityMapBuilder parameter and returns an IEntityMapBuilder and takes two generic parameters. In our example we added the following method: private static IEntityMapBuilder AddContosoCustomFieldsToMaps<TSource, TTarget>(IEntityMapBuilder builder) Add the following code to the public static method created in step 3 above: var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapping.AddContosoCustomFieldsToMaps (builder);` The second line should reference the current class and the method you created in step 4 above. Here is our complete method in the example: public static void AddLandusCustomMaps(IServiceCollection services) { var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapping.AddContosoCustomFieldsToMaps (builder); } Note: The namespaces AxEntities and CRMEntities should reference your custom proxies if you created them otherwise it should reference the packaged Levridge provided proxy Add the following code to the private static method created in step 4 above: if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapping)); The first block validates the parameter. The last line calls a method on a helper class to invoke all the mapping methods on the class we are now building. Here is our complete method in the example: private static IEntityMapBuilder AddContosoCustomFieldsToMaps (IEntityMapBuilder builder) { if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapping)); } Create mapping methods Create a private static method that a single IEntityMapBuilder parameter and returns an IEntityMapBuilder Name the method Map[SourceEntity]_[DestinationEntity]. In our example we added the following method: private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) This method will add the custom field mapping for CustomerV3 to lev_customer Add an [EntityMapMethod] Attribute to the map method Add mapping code in the map method The mapping code is split into two levels: - AddEntityMap The structure of the AddEntityMap is an extension method on IEntityMapBuilder that takes two generic parameters for the source and target entities and an Action method parameter used to configure the EntityMap by adding field maps for the entities. - AddFieldMap AddFieldMap is a method on EntityMap . There are several that takes two generic parameters for the source field type and target field type and an Action method parameter used to configure the EntityMap by adding field maps for the entities. Here is an example method that adds mapping for CustomerV3 to lev_customer: private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.lev_customer>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevInCareOf)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_incareof))); em.AddMapReferencedField(nameof(AxEntities.CustomerV3), nameof(AxEntities.CustomerV3.LevPrintName)); }); return builder; } Example Mapping using System; using Microsoft.Extensions.DependencyInjection; using Levridge.EntityFramework; using Levridge.ODataDataSources; using Levridge.Integration.IntegrationService.Abstractions; using AxEntities = ContosoCustomFields.Microsoft.Dynamics.DataEntities; using CRMEntities = ContosoCustomFields.ODataDataSources.DynamicsCRM; using System.ComponentModel.Composition; namespace Levridge.Integration.IntegrationService.Mapping.ContosoCustomFields { [Export] public class ContosoCustomFieldsEntityMapBuilderExtensions { public static void AddContosoCustomMaps(IServiceCollection services) { var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapBuilderExtensions.AddContosoCustomFieldsToMaps<AxEntities.CustomerV3, CRMEntities.lev_customer>(builder); } private static IEntityMapBuilder AddContosoCustomFieldsToMaps<TSource, TTarget>(IEntityMapBuilder builder) { if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapBuilderExtensions)); } [EntityMapMethod] private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.lev_customer>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevInCareOf)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_incareof))); em.AddMapReferencedField(nameof(AxEntities.CustomerV3), nameof(AxEntities.CustomerV3.LevPrintName)); }); return builder; } [EntityMapMethod] private static IEntityMapBuilder MapCustomerV3_account(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.account>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.account.name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); }); return builder; } [EntityMapMethod] private static IEntityMapBuilder MapInventSite_lev_companysite(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.InventSite, CRMEntities.lev_companysite>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.InventSite.LevRegionId)), new CRMODataField<String>(nameof(CRMEntities.lev_companysite.stn_region))); }); return builder; } } } Deploying the Custom Mapping Assemblies To deploy the custom assembly you simply copy the output of the mapping assembly to the same directory that contains the Levridge.Integration.Host assemblies. See Deploying Custom Field Mapping Assemblies for more information.","title":"Integrating Custom Fields"},{"location":"IntegratingCustomFields/#introduction","text":"In many implementations a client will have specific needs that require custom fields to be added to existing entities or custom behavior for an existing field in an integration. This document shows how to create a custom field extension to have those custom fields integrated when the entity is being integrated.","title":"Introduction"},{"location":"IntegratingCustomFields/#overview","text":"In order to integrate custom fields you will need to create a Visual Studio solution with upto three projects: Custom Source Proxy Project Contains the proxy for the source datasource with the custom fields in the entities This project is only necessary if there are custom fields in the source. If your customizations only include custom behavior for existing fields then a custom source proxy will not be needed. Custom Destination Proxy Project Contains the proxy for the desitination datasource with the custom fields in the entities This project is only necessary if there are custom fields in the destination. If your customizations only include custom behavior for existing fields then a custom destination proxy will not be needed. Custom Mapping Project Contains the code need to map the integration for the custom fields between the source and destination entities Note: If there are no custom fields involved and you are only defining custom behavior for existing fields you will not need new proxies. You only need a proxy to define the metadata for custom fields. Please see Deploying Custom Field Mapping Assemblies for information on deploying the custom mapping assembly.","title":"Overview"},{"location":"IntegratingCustomFields/#tutorial","text":"","title":"Tutorial"},{"location":"IntegratingCustomFields/#create-the-solution","text":"The first step is to create a Visual Studio solution for the custom mapping. In Visual Studio, create a new C# Class Library (.NET Core). You may want to give the solution a different name than the project. In our example, the customer is Comstock so we will name the solution \"ComstockCustomMapping\" and the project Levridge.Integration.IntegrationService.Mapping.Comstock. We recommend you use this naming convention for your custom mapping project: Levridge.Integration.IntegrationService.Mapping.[clientname].","title":"Create the Solution"},{"location":"IntegratingCustomFields/#create-the-source-proxy-project","text":"","title":"Create the Source Proxy Project"},{"location":"IntegratingCustomFields/#create-the-destination-proxy-project","text":"","title":"Create the Destination Proxy Project"},{"location":"IntegratingCustomFields/#add-references-to-the-custom-mapping-project","text":"The Levridge packages are published to our DevOps Artifacts so you will need to add a Nuget source for those packages. This is done in Visual Studio from Tools/Options/NuGet Package Manager/Package Sources. The source is https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages-beta/nuget/v3/index.json If you are working the LevDevelopment branch. If you are working in the customer's repository you should use 'https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages/nuget/v3/index.json' which is the released version of the packages. You will need to add the following Nuget references to your custom mapping project: Levridge.EntityFramework Levridge.Integration.IntegrationService.Abstractions Levridge.Integration.IntegrationService.Mapping Microsoft.Extensions.DependencyInjection System.ComponentModel.Composition Note: The Levridge packages are available from our Azure DevOps Artifacts repository. The URL for released packages is https://pkgs.dev.azure.com/stoneridgesoftware/Levridge/_packaging/LevridgePackages/nuget/v3/index.json","title":"Add References to the Custom Mapping Project"},{"location":"IntegratingCustomFields/#add-source-and-destination-datasource-references-to-custom-mapping-project","text":"You will need to reference the destination data source project in order to have access to any Field types and other types used during mapping. If your datasource is CRM you would include this reference: * Levridge.ODataDataSources.CRMODataDataSource If your datasource is F&O you would include this reference: * Levridge.DynamicsAxDataSource","title":"Add Source and Destination Datasource References to Custom Mapping Project"},{"location":"IntegratingCustomFields/#update-the-references-to-be-excluded-from-deployment","text":"These references will be needed for the build process, but we will want to use the libraries provided by the standard deployment and not deploy our own copy of the libraries with the custom mapping assemblies. To accomplish this, we let the msbuild system know to exclude these libraries from the runtime deployment by adding <ExcludeAssets>runtime</ExcludeAssets> to the <PackageReference> node for each package. You should have an <ItemGroup> node that looks somthing like this. <ItemGroup> <PackageReference Include=\"Levridge.EntityFramework\" Version=\"2.0.10\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.Integration.IntegrationService.Abstractions\" Version=\"1.0.0\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.Integration.IntegrationService.Mapping\" Version=\"1.0.0\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Levridge.ODataDataSources.CRMODataDataSource\" Version=\"2.1.15\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> <PackageReference Include=\"Microsoft.Extensions.DependencyInjection\" Version=\"3.0.2\"> <ExcludeAssets>runtime</ExcludeAssets> </PackageReference> </ItemGroup>","title":"Update the references to be excluded from deployment"},{"location":"IntegratingCustomFields/#add-a-reference-to-the-two-datasource-proxy-projects","text":"Your custom mapping methods will need to access the source and data entities so you will need to add a reference to the two proxy projects you created in sections Create the Source Proxy Project and Create the Destination Proxy Project If you do not need a custom proxy project you should add a reference package to the correct Levridge nuget package. The F&O and CRM packages are: * Levridge.DynamicsAxDataSource * Levridge.ODataDataSources.DynamicsCRM","title":"Add a reference to the two datasource proxy projects"},{"location":"IntegratingCustomFields/#create-an-entitymapbuilderextension-class","text":"We need to have a class that will contain the necessary mapping methods for the custom fields being added to the integration. Create a public class This can not be a static class because Microsoft MEF won't export a static class. Add the [Export] attribute to the class The Export attribute is in the System.ComponentModel.Composition that was added in the section Add References to the Custom Mapping Project Name the class We recommend using something like [client]CustomFieldsEntityMapping. The actual name is not important, orther than to be clear the purpose of the class. In our example we named the class ContosoCustomFieldsEntityMapping . Add a public static void method that takes a single IServiceCollection parameter. In our example we added the following method: public static void AddContosoCustomMaps(IServiceCollection services) Add a private static method that takes a single IEntityMapBuilder parameter and returns an IEntityMapBuilder and takes two generic parameters. In our example we added the following method: private static IEntityMapBuilder AddContosoCustomFieldsToMaps<TSource, TTarget>(IEntityMapBuilder builder) Add the following code to the public static method created in step 3 above: var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapping.AddContosoCustomFieldsToMaps (builder);` The second line should reference the current class and the method you created in step 4 above. Here is our complete method in the example: public static void AddLandusCustomMaps(IServiceCollection services) { var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapping.AddContosoCustomFieldsToMaps (builder); } Note: The namespaces AxEntities and CRMEntities should reference your custom proxies if you created them otherwise it should reference the packaged Levridge provided proxy Add the following code to the private static method created in step 4 above: if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapping)); The first block validates the parameter. The last line calls a method on a helper class to invoke all the mapping methods on the class we are now building. Here is our complete method in the example: private static IEntityMapBuilder AddContosoCustomFieldsToMaps (IEntityMapBuilder builder) { if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapping)); } Create mapping methods Create a private static method that a single IEntityMapBuilder parameter and returns an IEntityMapBuilder Name the method Map[SourceEntity]_[DestinationEntity]. In our example we added the following method: private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) This method will add the custom field mapping for CustomerV3 to lev_customer Add an [EntityMapMethod] Attribute to the map method Add mapping code in the map method The mapping code is split into two levels: - AddEntityMap The structure of the AddEntityMap is an extension method on IEntityMapBuilder that takes two generic parameters for the source and target entities and an Action method parameter used to configure the EntityMap by adding field maps for the entities. - AddFieldMap AddFieldMap is a method on EntityMap . There are several that takes two generic parameters for the source field type and target field type and an Action method parameter used to configure the EntityMap by adding field maps for the entities. Here is an example method that adds mapping for CustomerV3 to lev_customer: private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.lev_customer>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevInCareOf)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_incareof))); em.AddMapReferencedField(nameof(AxEntities.CustomerV3), nameof(AxEntities.CustomerV3.LevPrintName)); }); return builder; }","title":"Create An EntityMapBuilderExtension class"},{"location":"IntegratingCustomFields/#example-mapping","text":"using System; using Microsoft.Extensions.DependencyInjection; using Levridge.EntityFramework; using Levridge.ODataDataSources; using Levridge.Integration.IntegrationService.Abstractions; using AxEntities = ContosoCustomFields.Microsoft.Dynamics.DataEntities; using CRMEntities = ContosoCustomFields.ODataDataSources.DynamicsCRM; using System.ComponentModel.Composition; namespace Levridge.Integration.IntegrationService.Mapping.ContosoCustomFields { [Export] public class ContosoCustomFieldsEntityMapBuilderExtensions { public static void AddContosoCustomMaps(IServiceCollection services) { var builder = new EntityMapBuilder(services); ContosoCustomFieldsEntityMapBuilderExtensions.AddContosoCustomFieldsToMaps<AxEntities.CustomerV3, CRMEntities.lev_customer>(builder); } private static IEntityMapBuilder AddContosoCustomFieldsToMaps<TSource, TTarget>(IEntityMapBuilder builder) { if (builder == null) { throw new ArgumentNullException(nameof(builder)); } return EntityMapBuilderHelper.InvokeMappingMethods(builder, typeof(ContosoCustomFieldsEntityMapBuilderExtensions)); } [EntityMapMethod] private static IEntityMapBuilder MapCustomerV3_lev_customer(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.lev_customer>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevInCareOf)), new CRMODataField<String>(nameof(CRMEntities.lev_customer.lev_incareof))); em.AddMapReferencedField(nameof(AxEntities.CustomerV3), nameof(AxEntities.CustomerV3.LevPrintName)); }); return builder; } [EntityMapMethod] private static IEntityMapBuilder MapCustomerV3_account(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.CustomerV3, CRMEntities.account>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.CustomerV3.LevPrintName)), new CRMODataField<String>(nameof(CRMEntities.account.name)), (a, b) => { String printName = a.Value; String organizationName = (String)a.FieldEntity[nameof(AxEntities.CustomerV3.OrganizationName)].Value; return String.IsNullOrEmpty(printName) ? organizationName : printName; }, (b, a) => { throw new IntegrationNotSupportedException(); }); }); return builder; } [EntityMapMethod] private static IEntityMapBuilder MapInventSite_lev_companysite(IEntityMapBuilder builder) { builder.AddEntityMap<AxEntities.InventSite, CRMEntities.lev_companysite>(em => { em.AddFieldMap<String, String>( new JSONField<String>(nameof(AxEntities.InventSite.LevRegionId)), new CRMODataField<String>(nameof(CRMEntities.lev_companysite.stn_region))); }); return builder; } } }","title":"Example Mapping"},{"location":"IntegratingCustomFields/#deploying-the-custom-mapping-assemblies","text":"To deploy the custom assembly you simply copy the output of the mapping assembly to the same directory that contains the Levridge.Integration.Host assemblies. See Deploying Custom Field Mapping Assemblies for more information.","title":"Deploying the Custom Mapping Assemblies"},{"location":"Integration%20Template/","text":"Title of Integration This should be a short, one paragraph description of the integration being documented. Overview A more detailed overview should included here. This overview should describe the integration and any unique details for this integration. API This section should include detailed documentation of the API. Configuration This section should include detailed documentation for configuring the integration. (Optional) Deployment This section should include any instructions necessary to deploy this integration. This section may not be needed if the deployment follows a standard deployment process that is documented elsewhere. In this case it would be helpful to direct the reader to that standard documentation.","title":"Title of Integration"},{"location":"Integration%20Template/#title-of-integration","text":"This should be a short, one paragraph description of the integration being documented.","title":"Title of Integration"},{"location":"Integration%20Template/#overview","text":"A more detailed overview should included here. This overview should describe the integration and any unique details for this integration.","title":"Overview"},{"location":"Integration%20Template/#api","text":"This section should include detailed documentation of the API.","title":"API"},{"location":"Integration%20Template/#configuration","text":"This section should include detailed documentation for configuring the integration.","title":"Configuration"},{"location":"Integration%20Template/#optional-deployment","text":"This section should include any instructions necessary to deploy this integration. This section may not be needed if the deployment follows a standard deployment process that is documented elsewhere. In this case it would be helpful to direct the reader to that standard documentation.","title":"(Optional) Deployment"},{"location":"Integration-Overview/","text":"Introduction The Levridge integration framework provides integration between Dynamics365 Finance and SCM and Dynamics 365 Customer Engagement and 3rd party applications. This document provides and overview of the integration framework and links to the documents that exist for the framework. Overview The Levridge Integration Framework is an entity syncronization framework. It provides a means to synchronize data at an entity level between multiple data sources. All integrations that use the framework follow the same pattern: 1. A data source has an integration event 2. The data source responds to the integration event by sending one or more entities to the service bus. 3. The service bus publishes the message(s) to each subscription 4. An instance of the integration framework receives the message(s) from a subscription 5. The integration framework transforms the message if needed 6. The integration framework sends the message to the target data source The Levridge Integration Framework uses a Publish and Subscribe messaging pattern . We use the Azure Service Bus to provide the publish and subscribe mechanism. The Levridge Integration Framework is most commonly run in the cloud as an Azure App Serivce . It can also run as a windows service or as an IIS application. See this article to learn more about the deployment options. Integrations Currently we support the following integrations: D365 F&O to D365 CRM D365 CRM to D365 F&O Scale Agsync Kahler Surety oneWeigh Field Reveal Levridge CRM Remote Printing Service Environments Planning A standard D365 implementation is used when launching a Levridge environment plan. The D365 F&O System Requirements and what one needs to start a project are outlined in Environments Planning . Levridge Integration System Requirements Azure App Registrations One each for the Production and Test environments Azure App Registrations Azure Service Bus Namespace One each for the Production and Test environments Configure both using the Standard Pricing Tier Topics/Subscriptions will be determined based on integration within scope for the project Documentation Azure Service Bus Overview Azure Service Bus topics and subscriptions Azure App Service Plan One each for Production and Test environments Use a Standard tier for the Test environment Use a Premium V2 tier for the Production environment Additional sizing will be reviewed during the implemenation Azure App Service Plan overview Individual Azure App Services will be deployed to these App Service Plans Azure App Services Separate App Services will be deployed for each integrating application Once deployed and configured we will then deploy the Levridge Integration Framework to each Separate Levridge Integration Framework configuration will be required App Services pricing is included in the App Service Plan tier pricing (see App Service Plan overview above) Azure Storage Account Levridge Integrations utilize Azure Storage Accounts in multiple areas One each required for the Production and Test environments Use the General Purpose V2 account type Azure Storage Account overview Azure Key Vault One key vault is required. Can be used by both the Production and Test environments Azure Key Vault overview","title":"Overview"},{"location":"Integration-Overview/#introduction","text":"The Levridge integration framework provides integration between Dynamics365 Finance and SCM and Dynamics 365 Customer Engagement and 3rd party applications. This document provides and overview of the integration framework and links to the documents that exist for the framework.","title":"Introduction"},{"location":"Integration-Overview/#overview","text":"The Levridge Integration Framework is an entity syncronization framework. It provides a means to synchronize data at an entity level between multiple data sources. All integrations that use the framework follow the same pattern: 1. A data source has an integration event 2. The data source responds to the integration event by sending one or more entities to the service bus. 3. The service bus publishes the message(s) to each subscription 4. An instance of the integration framework receives the message(s) from a subscription 5. The integration framework transforms the message if needed 6. The integration framework sends the message to the target data source The Levridge Integration Framework uses a Publish and Subscribe messaging pattern . We use the Azure Service Bus to provide the publish and subscribe mechanism. The Levridge Integration Framework is most commonly run in the cloud as an Azure App Serivce . It can also run as a windows service or as an IIS application. See this article to learn more about the deployment options.","title":"Overview"},{"location":"Integration-Overview/#integrations","text":"Currently we support the following integrations: D365 F&O to D365 CRM D365 CRM to D365 F&O Scale Agsync Kahler Surety oneWeigh Field Reveal Levridge CRM Remote Printing Service","title":"Integrations"},{"location":"Integration-Overview/#environments-planning","text":"A standard D365 implementation is used when launching a Levridge environment plan. The D365 F&O System Requirements and what one needs to start a project are outlined in Environments Planning .","title":"Environments Planning"},{"location":"Integration-Overview/#levridge-integration-system-requirements","text":"Azure App Registrations One each for the Production and Test environments Azure App Registrations Azure Service Bus Namespace One each for the Production and Test environments Configure both using the Standard Pricing Tier Topics/Subscriptions will be determined based on integration within scope for the project Documentation Azure Service Bus Overview Azure Service Bus topics and subscriptions Azure App Service Plan One each for Production and Test environments Use a Standard tier for the Test environment Use a Premium V2 tier for the Production environment Additional sizing will be reviewed during the implemenation Azure App Service Plan overview Individual Azure App Services will be deployed to these App Service Plans Azure App Services Separate App Services will be deployed for each integrating application Once deployed and configured we will then deploy the Levridge Integration Framework to each Separate Levridge Integration Framework configuration will be required App Services pricing is included in the App Service Plan tier pricing (see App Service Plan overview above) Azure Storage Account Levridge Integrations utilize Azure Storage Accounts in multiple areas One each required for the Production and Test environments Use the General Purpose V2 account type Azure Storage Account overview Azure Key Vault One key vault is required. Can be used by both the Production and Test environments Azure Key Vault overview","title":"Levridge Integration System Requirements"},{"location":"Kahler/","text":"Kahler Integration The Kahler integration is a bidirectional integration that consists of a Topic for Dispensing Work Orders that go from D365 F&O to Kahler and Dispensing Work Records that go from Kahler to D365 F&O with the goal of margin control and recognizing revenue across site locations. Overview Because this is a bidirectional integration there are two instances of the integration running to handle the entire integration. There is one integration instance for each direction. One aspect of Kahler that is different from other integrations is the D365 F&O to Kahler instance must run on premise because the Kahler system runs behind the firewall. This should be deployed as a service. Another aspect that is different is that each location should only get the messages from the topic that apply to that location. This is done with a filter on the service bus topic subscription. In order for the filter to work the Levridge Entity Event must be configured to expose the branch property on the message. Required Resources Security permissions to access sales orders, transfer orders, and transportation maangement system in D365 F&O Security permissions and access to Kahler's system Setup To integrate to and from Kahler and D365 F&O you will need to: Create an Azure Service bus topic for Dispensing Work Orders (D365 F&O to Kahler) Create an Azure Service bus topic for Dispensing Work Records (Kahler to D365 F&O) Create a subscription on the Dispensing Work Order topic for each Branch that has a Kahler mixer Create a filter on the subscription for each Branch Create a subscription on the Dispensing Work Record topic for integration back to F&O Configure Event Endpoint in F&O Configure Levridge Entity Events You will need to be sure to provide properties on the event to allow filtering by Branch Create an application ID for the integration framework to authenticate to D365 F&O Create an Azure Active Directory Application in D365 F&O Set up Azure Key Vault / Overview Deploy the Levridge Integration Framework as a service at each Branch that has a Kahler mixer Configuration for Kahler on Premise This configuration will need to be on premise with the Kahler mixer. The on-premise instance will handle the Dispensing Work Order from D365 F&O to Kahler and the Webhook that receives Dispensing Work Records from Kahler. The configuration of D365 F&O is required to release to Kahler. Within the release product itself, default warehouses must be defined to ensure that under Manage Inventory default warehouses are set up with a dispensing method to be able to ship to a Kahler. The dispensing method is a 1:1 ration (1 warehouse 1 dispensing method). This configuration produces a URL that is an identifier for each Kahler. Each Kahler instance has its own URL and that URL must be attached to the product to ensure it is sent to the correct web hub. In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with Dispensing Work Order service bus topic]\", \"ODataConfigName\": \"[section name with F&O data configuration]\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with Kahler data configuration]\", \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"Kahler\", \"Direction\": \"Target\" } Here is a sample template for the entire appsettings.json file used for the on-premise deployment of the integration from FinOps to Kahler: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"KahlerConroller\": \"Levridge.Integration.Host.KahlerController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"ApplicationInsights\": { \"InstrumentationKey\": \"08f05bc5-e901-4c19-8358-286bdcedf35e\" }, \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Order\", //[section name with Dispensing Work Order service bus topic] \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"Kahler End Point\", //[section name with Kahler data configuration], \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"Kahler\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Kahler End Point\": { \"UriString\": \"[URL to Local Kahler]\" }, \"Dispensing Work Order\": { \"ConnectionString\": \"[connection string to Dispensing Work Order Topic]\", \"TopicName\": \"[Dispensing Work Order Topic Name]\", \"SubscriptionName\": \"[Subscription Name for the Branch]\", \"RequiresSession\": true }, \"CDS\": { \"UriString\": \"[URL to CDS or Localhost]\", \"ActiveDirectoryResource\": \"[URL to CDS]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to CDS]/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"Levridge.Integration.Host.KahlerController\": { \"ConnectionString\": \"[connection string to Dispensing Work Record Topic]\", \"TopicName\": \"[Dispensing Work Record Topic Name]\", \"RequiresSession\": true } } Controllers This section contains a list of controllers that will be loaded by the current instance. In addition to the default controller that we always want to load, we want the system to load the Kahler controller. The names (on the left) are not significant and are used only for debugging. The values (on the right) are significant. It must be the name of the assembly that should be loaded for the controller. InstanceConfig InstanceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework. SourceConfig The source config will represent the data being send from D365 F&O. Currently, the Dispensing Work Order is the only entity sent from F&O. In the future the topic may also include master data that is sent to Kahler. The ODataConfigName is not currently being used but is a required value. So point it to the section that contains the connection information to D365 F&O. TargetConfig The target config will represent the data endpoint for the local Kahler mixer. The \"ODataConfigName\" should point to a section that contains the Kahler REST endpoint. Levridge.Integration.Host.KahlerController This section is used by the Kahler controller to be able to send messages to the proper topic to be handled by the integration framework and written to D365 F&O. Configuration for Kahler in Azure This instance can be a single instance running in the cloud. This instance will handle the Dispensing Work Record from Kahler to D365 F&O. In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with Dispensing Work Record service bus topic]\" \"ODataConfigName\": \"\", \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with F&O data configuration]\", \"CDSConfigName\": \"[section name with CDS configuration]\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" } Here is a template of the full appsettings.json file used for the Kahler integration from the Webhook to FinOps: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\" }, \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Record\", //[section name with Dispensing Work Record service bus topic] \"ODataConfigName\": \"\", \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"CDSConfigName\": \"CDS\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Dispensing Work Record\": { \"ConnectionString\": \"[connection string to Dispensing Work Record Topic]\", \"TopicName\": \"[Dispensing Work Record Topic Name]\", \"SubscriptionName\": \"[Subscription Name for Integration to D365 F&O]\", \"RequiresSession\": true } } Dispensing Method Configuration Release Products Grid Highlight line Manage Inventory Warehouse Tab Warehouse Items Dispensing Method field Select the warehouse that should be tied to the dispensing method Select the appropriate configure dispensing method Add Kahler specific URL If the URL is not setup properly for each product, the product could be sent to an incorrect Kahler location. This step is critical to ensure the setup and configurations are accurate. Sales Order Statuses Planned (generated sales order) Booked Released (order is sent to dispatcher work board) Scheduled (generates dispensing work record and assigns application site) Completed Once the order is in a scheduled status, it will generate a dispnsing work record which kicks off the integration to send the product to Kahler. Once Kahler completes the dispatching of product and the onsite work is completed, the work order status is updated to either completed, pending, or review. Data is populated in the work order completion tab in F&O. Work Order Completion Rolling stock ID (task completion equipment) Weather information Humidity Temperature Wind speed Wind direction Pests Acreage completed Start and end times Acmount of actual product applied Once the work is completed by the dispatcher, the work order status updated to the final completion stage (complete/verify). Picking List Within each order, there is a possibility of multiple picking lists. Picking lists annotate the amount of batches/truck loads left Kahler and the mix in each truck. Picking lists allow one to know how many loads are being used. There are two bill options: 1. Bill what Kahler said was used 2. Bill for what the machine stated was used Transportation Management System (TMS) has the ability to generate a freight bill after Kahler sends the picking lists to ensure the third party contractor delivering the product is paid. The steps below outline the process: 1. Data from Kahler creates a picking list 2. Load creation in TMS 3. Generate freight bill invoiceable to the third party contractor Packing Order A packing slip is generated for the work order in an invoiceable status. Packing orders can take place either in the complete, pending, review status or in the complete, verify status. Generate Order Manually The below outlines the steps required to generate a manual order. 1. Create a sales order. The information collected in the sales order includes: - Who the grower is - The inventory location the product is being picked up at 2. Generate product to be shipped to Kahler - Individual products - Custom configuration BOM - Select configuration BOM - Product and supply - Configure line - Configure selected item (product type and amount) - Click OK (BOM is generated) - Select blending site - Save - Explode BOM back out 3. Warehouse items tab - Release for dispensing - Generates dispensing ID - Order is sent to Kahler 4. Manually pack, slip, and post Manual Transfer Order Transfer orders allow product to be moved from one site to another. The below outlines the process: 1. Inventory management 2. Transfer order 3. Populate \"From\" and \"To\" warehouses 4. Add line 5. Select product and amont of product to be transferred 6. Save Ship 7. Release for dispensing 8. Transfer order is sent to Kahler to act on physical shipping of the product.","title":"Kahler"},{"location":"Kahler/#kahler-integration","text":"The Kahler integration is a bidirectional integration that consists of a Topic for Dispensing Work Orders that go from D365 F&O to Kahler and Dispensing Work Records that go from Kahler to D365 F&O with the goal of margin control and recognizing revenue across site locations.","title":"Kahler Integration"},{"location":"Kahler/#overview","text":"Because this is a bidirectional integration there are two instances of the integration running to handle the entire integration. There is one integration instance for each direction. One aspect of Kahler that is different from other integrations is the D365 F&O to Kahler instance must run on premise because the Kahler system runs behind the firewall. This should be deployed as a service. Another aspect that is different is that each location should only get the messages from the topic that apply to that location. This is done with a filter on the service bus topic subscription. In order for the filter to work the Levridge Entity Event must be configured to expose the branch property on the message.","title":"Overview"},{"location":"Kahler/#required-resources","text":"Security permissions to access sales orders, transfer orders, and transportation maangement system in D365 F&O Security permissions and access to Kahler's system","title":"Required Resources"},{"location":"Kahler/#setup","text":"To integrate to and from Kahler and D365 F&O you will need to: Create an Azure Service bus topic for Dispensing Work Orders (D365 F&O to Kahler) Create an Azure Service bus topic for Dispensing Work Records (Kahler to D365 F&O) Create a subscription on the Dispensing Work Order topic for each Branch that has a Kahler mixer Create a filter on the subscription for each Branch Create a subscription on the Dispensing Work Record topic for integration back to F&O Configure Event Endpoint in F&O Configure Levridge Entity Events You will need to be sure to provide properties on the event to allow filtering by Branch Create an application ID for the integration framework to authenticate to D365 F&O Create an Azure Active Directory Application in D365 F&O Set up Azure Key Vault / Overview Deploy the Levridge Integration Framework as a service at each Branch that has a Kahler mixer","title":"Setup"},{"location":"Kahler/#configuration-for-kahler-on-premise","text":"This configuration will need to be on premise with the Kahler mixer. The on-premise instance will handle the Dispensing Work Order from D365 F&O to Kahler and the Webhook that receives Dispensing Work Records from Kahler. The configuration of D365 F&O is required to release to Kahler. Within the release product itself, default warehouses must be defined to ensure that under Manage Inventory default warehouses are set up with a dispensing method to be able to ship to a Kahler. The dispensing method is a 1:1 ration (1 warehouse 1 dispensing method). This configuration produces a URL that is an identifier for each Kahler. Each Kahler instance has its own URL and that URL must be attached to the product to ensure it is sent to the correct web hub. In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with Dispensing Work Order service bus topic]\", \"ODataConfigName\": \"[section name with F&O data configuration]\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with Kahler data configuration]\", \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"Kahler\", \"Direction\": \"Target\" } Here is a sample template for the entire appsettings.json file used for the on-premise deployment of the integration from FinOps to Kahler: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"KahlerConroller\": \"Levridge.Integration.Host.KahlerController\" }, \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"ApplicationInsights\": { \"InstrumentationKey\": \"08f05bc5-e901-4c19-8358-286bdcedf35e\" }, \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Order\", //[section name with Dispensing Work Order service bus topic] \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"Kahler End Point\", //[section name with Kahler data configuration], \"CDSConfigName\": \"[section name with CDS data configuration]\", \"SystemName\": \"Kahler\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Kahler End Point\": { \"UriString\": \"[URL to Local Kahler]\" }, \"Dispensing Work Order\": { \"ConnectionString\": \"[connection string to Dispensing Work Order Topic]\", \"TopicName\": \"[Dispensing Work Order Topic Name]\", \"SubscriptionName\": \"[Subscription Name for the Branch]\", \"RequiresSession\": true }, \"CDS\": { \"UriString\": \"[URL to CDS or Localhost]\", \"ActiveDirectoryResource\": \"[URL to CDS]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to CDS]/api/data/v9.0/\", \"AssemblyName\": \"Levridge.ODataDataSources.CDS\", \"ClientClassesNameSpace\": \"Levridge.ODataDataSources.CDS\", \"MetadataResource\": \"CDSMetadata.xml\" }, \"Levridge.Integration.Host.KahlerController\": { \"ConnectionString\": \"[connection string to Dispensing Work Record Topic]\", \"TopicName\": \"[Dispensing Work Record Topic Name]\", \"RequiresSession\": true } }","title":"Configuration for Kahler on Premise"},{"location":"Kahler/#controllers","text":"This section contains a list of controllers that will be loaded by the current instance. In addition to the default controller that we always want to load, we want the system to load the Kahler controller. The names (on the left) are not significant and are used only for debugging. The values (on the right) are significant. It must be the name of the assembly that should be loaded for the controller.","title":"Controllers"},{"location":"Kahler/#instanceconfig","text":"InstanceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework.","title":"InstanceConfig"},{"location":"Kahler/#sourceconfig","text":"The source config will represent the data being send from D365 F&O. Currently, the Dispensing Work Order is the only entity sent from F&O. In the future the topic may also include master data that is sent to Kahler. The ODataConfigName is not currently being used but is a required value. So point it to the section that contains the connection information to D365 F&O.","title":"SourceConfig"},{"location":"Kahler/#targetconfig","text":"The target config will represent the data endpoint for the local Kahler mixer. The \"ODataConfigName\" should point to a section that contains the Kahler REST endpoint.","title":"TargetConfig"},{"location":"Kahler/#levridgeintegrationhostkahlercontroller","text":"This section is used by the Kahler controller to be able to send messages to the proper topic to be handled by the integration framework and written to D365 F&O.","title":"Levridge.Integration.Host.KahlerController"},{"location":"Kahler/#configuration-for-kahler-in-azure","text":"This instance can be a single instance running in the cloud. This instance will handle the Dispensing Work Record from Kahler to D365 F&O. In the appsettings.json you will need to define the InstanceConfig SourceConfig and TargetConfig nodes as follows: \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"[section name with Dispensing Work Record service bus topic]\" \"ODataConfigName\": \"\", \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"[section name with F&O data configuration]\", \"CDSConfigName\": \"[section name with CDS configuration]\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" } Here is a template of the full appsettings.json file used for the Kahler integration from the Webhook to FinOps: { \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\" }, \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Debug\": { \"LogLevel\": { \"Default\": \"Information\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Information\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"InstanceConfig\": { \"AzureTableConfiguration\": \"[section name to Azure Table Configuration\", \"LogRequestsAndResponses\": [true or false] \"EnableAppInsightsAdaptiveSampling\": [true or false] }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Record\", //[section name with Dispensing Work Record service bus topic] \"ODataConfigName\": \"\", \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"CDSConfigName\": \"CDS\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": \"[URL to D365 F&O]\", \"ActiveDirectoryResource\": \"[URL to D365 F&O]\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": \"[Application ID used to register the application in AD]\", \"ActiveDirectoryClientAppSecret\": \"[Client Secret generated for the Application ID in AD]\", \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Dispensing Work Record\": { \"ConnectionString\": \"[connection string to Dispensing Work Record Topic]\", \"TopicName\": \"[Dispensing Work Record Topic Name]\", \"SubscriptionName\": \"[Subscription Name for Integration to D365 F&O]\", \"RequiresSession\": true } }","title":"Configuration for Kahler in Azure"},{"location":"Kahler/#dispensing-method-configuration","text":"Release Products Grid Highlight line Manage Inventory Warehouse Tab Warehouse Items Dispensing Method field Select the warehouse that should be tied to the dispensing method Select the appropriate configure dispensing method Add Kahler specific URL If the URL is not setup properly for each product, the product could be sent to an incorrect Kahler location. This step is critical to ensure the setup and configurations are accurate.","title":"Dispensing Method Configuration"},{"location":"Kahler/#sales-order-statuses","text":"Planned (generated sales order) Booked Released (order is sent to dispatcher work board) Scheduled (generates dispensing work record and assigns application site) Completed Once the order is in a scheduled status, it will generate a dispnsing work record which kicks off the integration to send the product to Kahler. Once Kahler completes the dispatching of product and the onsite work is completed, the work order status is updated to either completed, pending, or review. Data is populated in the work order completion tab in F&O.","title":"Sales Order Statuses"},{"location":"Kahler/#work-order-completion","text":"Rolling stock ID (task completion equipment) Weather information Humidity Temperature Wind speed Wind direction Pests Acreage completed Start and end times Acmount of actual product applied Once the work is completed by the dispatcher, the work order status updated to the final completion stage (complete/verify).","title":"Work Order Completion"},{"location":"Kahler/#picking-list","text":"Within each order, there is a possibility of multiple picking lists. Picking lists annotate the amount of batches/truck loads left Kahler and the mix in each truck. Picking lists allow one to know how many loads are being used. There are two bill options: 1. Bill what Kahler said was used 2. Bill for what the machine stated was used Transportation Management System (TMS) has the ability to generate a freight bill after Kahler sends the picking lists to ensure the third party contractor delivering the product is paid. The steps below outline the process: 1. Data from Kahler creates a picking list 2. Load creation in TMS 3. Generate freight bill invoiceable to the third party contractor","title":"Picking List"},{"location":"Kahler/#packing-order","text":"A packing slip is generated for the work order in an invoiceable status. Packing orders can take place either in the complete, pending, review status or in the complete, verify status.","title":"Packing Order"},{"location":"Kahler/#generate-order-manually","text":"The below outlines the steps required to generate a manual order. 1. Create a sales order. The information collected in the sales order includes: - Who the grower is - The inventory location the product is being picked up at 2. Generate product to be shipped to Kahler - Individual products - Custom configuration BOM - Select configuration BOM - Product and supply - Configure line - Configure selected item (product type and amount) - Click OK (BOM is generated) - Select blending site - Save - Explode BOM back out 3. Warehouse items tab - Release for dispensing - Generates dispensing ID - Order is sent to Kahler 4. Manually pack, slip, and post","title":"Generate Order Manually"},{"location":"Kahler/#manual-transfer-order","text":"Transfer orders allow product to be moved from one site to another. The below outlines the process: 1. Inventory management 2. Transfer order 3. Populate \"From\" and \"To\" warehouses 4. Add line 5. Select product and amont of product to be transferred 6. Save Ship 7. Release for dispensing 8. Transfer order is sent to Kahler to act on physical shipping of the product.","title":"Manual Transfer Order"},{"location":"Levridge-CRM-Remote-Printing-Service/","text":"","title":"Levridge CRM Remote Printing Service"},{"location":"Logging/","text":"Logging Settings This document describes how to configure logging for the Levridge Integration Framework Overview The Levridge Integration Framework utilizes the standard ASP.NET Core logging capabilities. Our primary target for logging is Azure Application Insights however we can also log to the Windows Event Log. This can be usefull if the integration framework is running as a windows service and does not have highspeed internet access to send log data to Application Insights. Log Settings In the appsettings.json file there is a \"Logging\" section that defines the log settings for the various logging providers. A typical logging section may look like this. \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Debug\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Trace\" } }, \"LogLevel\": { \"Default\": \"Warning\" } }, Unless you are using Debug or Console logging the only setting you need to be concerned with is the ApplicationInsights object. In a typical production environment you will want this set to \"Information\" or \"Warning\" rather than trace. However, to troubleshoot issues you may need to set this to \"Trace\". Valid Log Levels Here are the valid log level settings: Setting Description Trace Logs that contain the most detailed messages. These messages may contain sensitive application data. These messages are disabled by default and should never be enabled in a production environment. Debug Logs that are used for interactive investigation during development. These logs should primarily contain information useful for debugging and have no long-term value. Information Logs that track the general flow of the application. These logs should have long-term value. Warning Logs that highlight an abnormal or unexpected event in the application flow, but do not otherwise cause the application execution to stop. Error Logs that highlight when the current flow of execution is stopped due to a failure. These should indicate a failure in the current activity, not an application-wide failure. Critical Logs that describe an unrecoverable application or system crash, or a catastrophic failure that requires immediate attention. None Not used for writing log messages. Specifies that a logging category should not write any messages. Levridge Guidance for using Log Levels In order to provide a consistent user experience when using the configuration to adjust the log levels we need to have a consistent practice accross all of our code for what information is logged at what level. Generally speaking we would like to have logging set to Information in production unless there is a need to troubleshoot a specific issue. At this level we should be able to see all errors and warnings along with usefull information for basic troubleshooting. Here is what Levridge is logging at the different levels: Trace Log variable states, parameters & request and response payloads as Trace items. Use trace to log verbose information and large payloads. These items may can cause performance issues during normal operation. Debug Log any information that inidates the basic flow of the code. Examples include something like \"Entering POST method\" or \"Enabling authentication.\" This is general information that helps someone follow the flow of the code and can be useful in determining what is happening when an error occures. Information Log specific state information. For example \"Recieved Order 1234\" or \"Enabling AzureAd authentication scheme.\" These messages provide specific instance and state information. For example, in the trace section we showed an example \"Enabling authenticaction\". The represents the current code that is executing but not any instance or state information. On the other hand, logging \"Enabling AzureAd authentication scheme\" tells us which type of authenticaion is being enabled. Warning Log abnormal situations that do not warrent stopping the application and do not leave the application in an unkown state. Error Log error conditions from which we can recover. Critical Log all exceptions as critical. Include as much state information as possible to help with troubleshooting the root cause of the exception. Application Insights Instrumentation Key Application Insights uses an Intrumentation Key to specify the Application Insights resource to use for logging. If the integration framework is deployed to Azure and Application Insights is enabled, the Instrumentation Key will be specified in the environment variables. However, if the Integration is deployed on premise an Instrumentation Key must be specified for the Application Insights logging provider to send the log data to the correct Application Insights resource. \"ApplicationInsights\": { \"InstrumentationKey\": \"[Application Insights Instrumentation Key]\" }, This section is at the top level and not in the Logging section. Here is an example of a partial appsettings.json file. \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"ApplicationInsights\": { \"InstrumentationKey\": \"1a2b3c4d-5e6f-4b24-9308-4dff05f1cd02\" },","title":"Logging Settings"},{"location":"Logging/#logging-settings","text":"This document describes how to configure logging for the Levridge Integration Framework","title":"Logging Settings"},{"location":"Logging/#overview","text":"The Levridge Integration Framework utilizes the standard ASP.NET Core logging capabilities. Our primary target for logging is Azure Application Insights however we can also log to the Windows Event Log. This can be usefull if the integration framework is running as a windows service and does not have highspeed internet access to send log data to Application Insights.","title":"Overview"},{"location":"Logging/#log-settings","text":"In the appsettings.json file there is a \"Logging\" section that defines the log settings for the various logging providers. A typical logging section may look like this. \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Debug\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Console\": { \"IncludeScopes\": true, \"LogLevel\": { \"Default\": \"Trace\" } }, \"LogLevel\": { \"Default\": \"Warning\" } }, Unless you are using Debug or Console logging the only setting you need to be concerned with is the ApplicationInsights object. In a typical production environment you will want this set to \"Information\" or \"Warning\" rather than trace. However, to troubleshoot issues you may need to set this to \"Trace\".","title":"Log Settings"},{"location":"Logging/#valid-log-levels","text":"Here are the valid log level settings: Setting Description Trace Logs that contain the most detailed messages. These messages may contain sensitive application data. These messages are disabled by default and should never be enabled in a production environment. Debug Logs that are used for interactive investigation during development. These logs should primarily contain information useful for debugging and have no long-term value. Information Logs that track the general flow of the application. These logs should have long-term value. Warning Logs that highlight an abnormal or unexpected event in the application flow, but do not otherwise cause the application execution to stop. Error Logs that highlight when the current flow of execution is stopped due to a failure. These should indicate a failure in the current activity, not an application-wide failure. Critical Logs that describe an unrecoverable application or system crash, or a catastrophic failure that requires immediate attention. None Not used for writing log messages. Specifies that a logging category should not write any messages.","title":"Valid Log Levels"},{"location":"Logging/#levridge-guidance-for-using-log-levels","text":"In order to provide a consistent user experience when using the configuration to adjust the log levels we need to have a consistent practice accross all of our code for what information is logged at what level. Generally speaking we would like to have logging set to Information in production unless there is a need to troubleshoot a specific issue. At this level we should be able to see all errors and warnings along with usefull information for basic troubleshooting. Here is what Levridge is logging at the different levels:","title":"Levridge Guidance for using Log Levels"},{"location":"Logging/#trace","text":"Log variable states, parameters & request and response payloads as Trace items. Use trace to log verbose information and large payloads. These items may can cause performance issues during normal operation.","title":"Trace"},{"location":"Logging/#debug","text":"Log any information that inidates the basic flow of the code. Examples include something like \"Entering POST method\" or \"Enabling authentication.\" This is general information that helps someone follow the flow of the code and can be useful in determining what is happening when an error occures.","title":"Debug"},{"location":"Logging/#information","text":"Log specific state information. For example \"Recieved Order 1234\" or \"Enabling AzureAd authentication scheme.\" These messages provide specific instance and state information. For example, in the trace section we showed an example \"Enabling authenticaction\". The represents the current code that is executing but not any instance or state information. On the other hand, logging \"Enabling AzureAd authentication scheme\" tells us which type of authenticaion is being enabled.","title":"Information"},{"location":"Logging/#warning","text":"Log abnormal situations that do not warrent stopping the application and do not leave the application in an unkown state.","title":"Warning"},{"location":"Logging/#error","text":"Log error conditions from which we can recover.","title":"Error"},{"location":"Logging/#critical","text":"Log all exceptions as critical. Include as much state information as possible to help with troubleshooting the root cause of the exception.","title":"Critical"},{"location":"Logging/#application-insights-instrumentation-key","text":"Application Insights uses an Intrumentation Key to specify the Application Insights resource to use for logging. If the integration framework is deployed to Azure and Application Insights is enabled, the Instrumentation Key will be specified in the environment variables. However, if the Integration is deployed on premise an Instrumentation Key must be specified for the Application Insights logging provider to send the log data to the correct Application Insights resource. \"ApplicationInsights\": { \"InstrumentationKey\": \"[Application Insights Instrumentation Key]\" }, This section is at the top level and not in the Logging section. Here is an example of a partial appsettings.json file. \"Logging\": { \"ApplicationInsights\": { \"LogLevel\": { \"Default\": \"Trace\" } \"LogLevel\": { \"Default\": \"Information\" } }, \"AllowedHosts\": \"*\", \"ApplicationInsights\": { \"InstrumentationKey\": \"1a2b3c4d-5e6f-4b24-9308-4dff05f1cd02\" },","title":"Application Insights Instrumentation Key"},{"location":"ODataConfig/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"ODataConfig/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"ODataConfig/#overview","text":"","title":"Overview"},{"location":"ODataConfig/#main-point-1","text":"","title":"Main Point 1"},{"location":"ODataConfig/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"PreparingCDSForDeployment/","text":"Introduction The Levridge Integration Framework uses the CDS repository to store reference data. We need to provide deployment packages that include solutions, applications and data that can be used to deploy the CDS components to the customer. This document explains the steps necessary to package CDS for deployment to a customer environment. Overview The steps necessary to prepare the CDS components for deployment are: 1. Create the Solution 2. Create the application packages 3. Create the export schemas 4. Export the data 5. Check assets into source control Create Solution Create Application Packages Create Export Schemas Export Data Check-In Assets","title":"Introduction"},{"location":"PreparingCDSForDeployment/#introduction","text":"The Levridge Integration Framework uses the CDS repository to store reference data. We need to provide deployment packages that include solutions, applications and data that can be used to deploy the CDS components to the customer. This document explains the steps necessary to package CDS for deployment to a customer environment.","title":"Introduction"},{"location":"PreparingCDSForDeployment/#overview","text":"The steps necessary to prepare the CDS components for deployment are: 1. Create the Solution 2. Create the application packages 3. Create the export schemas 4. Export the data 5. Check assets into source control","title":"Overview"},{"location":"PreparingCDSForDeployment/#create-solution","text":"","title":"Create Solution"},{"location":"PreparingCDSForDeployment/#create-application-packages","text":"","title":"Create Application Packages"},{"location":"PreparingCDSForDeployment/#create-export-schemas","text":"","title":"Create Export Schemas"},{"location":"PreparingCDSForDeployment/#export-data","text":"","title":"Export Data"},{"location":"PreparingCDSForDeployment/#check-in-assets","text":"","title":"Check-In Assets"},{"location":"PublishCatalog/","text":"Publish Catalog Brief introduction of the module, component or feature being documented. This document explains ... How to Publish a Catalog Go to Procurement and Sourcing > Catalogs > Procurement Catalogs. In the list, find and select the desired record. Click Publish Catalog.","title":"Publish Catalog"},{"location":"PublishCatalog/#publish-catalog","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Publish Catalog"},{"location":"PublishCatalog/#how-to-publish-a-catalog","text":"Go to Procurement and Sourcing > Catalogs > Procurement Catalogs. In the list, find and select the desired record. Click Publish Catalog.","title":"How to Publish a Catalog"},{"location":"PurchasingPolicyAssignment/","text":"Purchasing Policy Assignment Brief introduction of the module, component or feature being documented. This document explains ... How to Purchase Policy Assignments Close the page. Go to Procuremnet and Sourcing > Setup > Policies > Purchasing Policies. In the list, click the link in the selected row. In the list, click the link in the selected row. Click Cancel. In the list, find and select the desired record. In the list, click the link in the selected row. In the tree, select 'Landus\\Monsanto'. Click Add. Click OK. Click Save. Close the page.","title":"Purchasing Policy Assignment"},{"location":"PurchasingPolicyAssignment/#purchasing-policy-assignment","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Purchasing Policy Assignment"},{"location":"PurchasingPolicyAssignment/#how-to-purchase-policy-assignments","text":"Close the page. Go to Procuremnet and Sourcing > Setup > Policies > Purchasing Policies. In the list, click the link in the selected row. In the list, click the link in the selected row. Click Cancel. In the list, find and select the desired record. In the list, click the link in the selected row. In the tree, select 'Landus\\Monsanto'. Click Add. Click OK. Click Save. Close the page.","title":"How to Purchase Policy Assignments"},{"location":"RFQ/","text":"RFQ Brief introduction of the module, component or feature being documented. This document explains ... RFQ Go to Procurement and sourcing > Requests for quotations > All requests for quotations. Click New. In the Solicitation type field, enter or select a value. In the list, click the link in the selected row. In the Requesting department field, type a value. In the warehouse field, type a value. Click OK. In the list, mark the selected row. In the Item number field, type a value. In the Quantity field, enter a number. In the Lines or header field, select an option. In the list, mark the selected row. In the Vendor account field, enter or select a value. In the list, click the link in the selected row. Click Add. In the list, mark the selected row. In the Vendor account field, enter or select a value. Close the page. In the Vendor account field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Click Save. Click Send. In the list, mark the selected row. Click OK. Close the page. Close the page. Close the page. Close the page. Click Manage replies. Click Edit. Click Edit RFQ reply. In the list, mark the selected row. In the Unit price field, enter a number. Expand the Line details section. Click Submit. In the list, find and select the desired record. Click Edit. Click Edit RFQ reply. In the list, mark the selected row. In the Unit price field, enter a number. Click Submit. Close the page. Refresh the page. Click Compare replies. In the Show field, select an option. Select the mark check box. Click Accept. In the list, mark the selected row. Click OK. In the list, mark the selected row. Click OK. Close the page. Close the page. Refresh the page. Close the page. Close the page. Go to Procurement and sourving > Purchase orders > All purchase orders. In the list, find and select the desired record. In the list, click the link in the selected row.","title":"RFQ"},{"location":"RFQ/#rfq","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"RFQ"},{"location":"RFQ/#rfq_1","text":"Go to Procurement and sourcing > Requests for quotations > All requests for quotations. Click New. In the Solicitation type field, enter or select a value. In the list, click the link in the selected row. In the Requesting department field, type a value. In the warehouse field, type a value. Click OK. In the list, mark the selected row. In the Item number field, type a value. In the Quantity field, enter a number. In the Lines or header field, select an option. In the list, mark the selected row. In the Vendor account field, enter or select a value. In the list, click the link in the selected row. Click Add. In the list, mark the selected row. In the Vendor account field, enter or select a value. Close the page. In the Vendor account field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Click Save. Click Send. In the list, mark the selected row. Click OK. Close the page. Close the page. Close the page. Close the page. Click Manage replies. Click Edit. Click Edit RFQ reply. In the list, mark the selected row. In the Unit price field, enter a number. Expand the Line details section. Click Submit. In the list, find and select the desired record. Click Edit. Click Edit RFQ reply. In the list, mark the selected row. In the Unit price field, enter a number. Click Submit. Close the page. Refresh the page. Click Compare replies. In the Show field, select an option. Select the mark check box. Click Accept. In the list, mark the selected row. Click OK. In the list, mark the selected row. Click OK. Close the page. Close the page. Refresh the page. Close the page. Close the page. Go to Procurement and sourving > Purchase orders > All purchase orders. In the list, find and select the desired record. In the list, click the link in the selected row.","title":"RFQ"},{"location":"ReadMe%20%282%29/","text":"Introduction The Levridge integration framework provides integration between Dynamics365 Finance and Operations and Dynamics 365 Customer Engagement and 3rd party applications. This document provides and overview of the integration framework and links to the document that exists for the framework. Overview The Levridge Integration Framework is an entity syncronization framework. It provides a means to synchronize data at an entity level between multiple data sources. All integrations that use the framework follow the same pattern: 1. A data source has an integration event 2. The data source responds to the integration event by sending one or more entities to the service bus. 3. The service bus publishes the message(s) to each subscription 4. An instance of the integration framework receives the message(s) from a subscription 5. The integration framework transforms the message it if needed 6. The integration framework sends the message to the target data source Integrations Currently we support the following integrations: - D365 F&O to D365 CRM - D365 CRM to D365 F&O - Kahler - Agsync - oneWeigh - Field Reveal - Surety - Levridge Scale House D365 F&O to D365 CRM Setup To integrate from D365 F&O to D365 CRM you will need to: - configure Levridge Entity Events - Create an application ID for the integration framework to authenticate to D365 CRM - Create an application user in D365 CRM and assign the proper role(s) - Create an Azure Service bus topic - Create a subscription on the topic above Configuration In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with F&O data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" } D365 CRM to D365 F&O Setup To integrate from D365 CRM to D365 F&O you will need to: - Configure Azure Service Bus Endpoint in CRM - Configure Azure Service Bus plugin on the appropriate entities - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic - Create a subscription on the topic above Configuration In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with CRM data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with F&O data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" } Kahler The Kahler integration is a bidirectional integration that consists of a Topic for Dispensing Work Orders that go from D365 F&O to Kahler and Dispensing Work Records that go from Kahler to D365 F&O. This means there are two instances of the integration running to handle the entire integration. One aspect of Kahler that is different from other integrations is the D365 F&O to Kahler instance must run on premise because the Kahler system runs behind the firewall. This should be deployed as a service. Another aspect that is different is that each location should only get the messages from the topic that apply to that location. This is done with a filter on the service bus topic subscription. In order for the filter to work the Levridge Entity Event must be configured to expose the branch property on the message. Setup To integrate to and from Kahler and D365 F&O you will need to: - Configure Levridge Entity Events - You will need to be sure to provide properties on the event to allow filtering by Branch - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic for Dispensing Work Orders (D365 F&O to Kahler) - Create an Azure Service bus topic for Dispensing Work Records (Kahler to D365 F&O) - Create a subscription on the Dispensing Work Order topic for each Branch that has a Kahler mixer - Create a filter on the subscription for each Branch - Create a subscription on the Dispensing Work Record topic for integration back to F&O - Deploy the Levridge Integration Framework as a service at each Branch that has a Kahler mixer Configuration for Kahler on Premise This configuration will need to be on premise with the Kahler mixer. In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"KahlerConroller\": \"Levridge.Integration.Host.KahlerController\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Order\", //[section name with Dispensing Work Order service bus topic] \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"Kahler End Point\", //[section name with Kahler data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"Kahler\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": [URL to D365 F&O], \"ActiveDirectoryResource\": [URL to D365 F&O], \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": [Application ID used to register the application in AD], \"ActiveDirectoryClientAppSecret\": [Client Secret genrated for the Application ID in AD], \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Kahler End Point\": { \"UriString\": [URL to Local Kahler] }, \"Dispensing Work Order\": { \"ConnectionString\": [connection string to Dispensing Work Order Topic], \"TopicName\": [Dispensing Work Order Topic Name], \"SubscriptionName\": [Subscription Name for the Branch], \"RequiresSession\": true }, \"Levridge.Integration.Host.KahlerController\": { \"ConnectionString\": [connection string to Dispensing Work Record Topic], \"TopicName\": [Dispensing Work Record Topic Name], \"RequiresSession\": true } Controllers This section contains a list of controllers that will be loaded by the current instance. In addition to the default controller that we alwasy want to load, we want the system to load the Kahler controller. The names (on the left) are not significant and are used only for debugging. The values (on the right) are significant. It must be the name of the assembly that should be loaded for the controller. SourceConfig The source config will represent the data being send from D365 F&O. Currently, the Dispensing Work Order is the only entity sent from F&O. In the future the topic may also include master data that is sent to Kahler. The ODataConfigName is not currently being used but is a required value. So point it to the section that contains the connection information to D365 F&O. TargetConfig The target config will represent the data endpoint for the local Kahler mixer. The \"ODataConfigName\" should point to a section that contains the Kahler REST endpoint. Levridge.Integration.Host.KahlerController This section is used by the Kahler controller to be able to send messages to the proper topic to be handled by the integration framework and written to D365 F&O Configuration for Kahler in Azure This instance can be a single instance runing in the cloud. In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Record\", //[section name with Dispensing Work Record service bus topic] \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": [URL to D365 F&O], \"ActiveDirectoryResource\": [URL to D365 F&O], \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": [Application ID used to register the application in AD], \"ActiveDirectoryClientAppSecret\": [Client Secret genrated for the Application ID in AD], \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Dispensing Work Record\": { \"ConnectionString\": [connection string to Dispensing Work Record Topic], \"TopicName\": [Dispensing Work Record Topic Name], \"SubscriptionName\": [Subscription Name for Integration to D365 F&O], \"RequiresSession\": true } Agsync oneWeigh Field Reveal Surety Levridge Scale House","title":"Introduction"},{"location":"ReadMe%20%282%29/#introduction","text":"The Levridge integration framework provides integration between Dynamics365 Finance and Operations and Dynamics 365 Customer Engagement and 3rd party applications. This document provides and overview of the integration framework and links to the document that exists for the framework.","title":"Introduction"},{"location":"ReadMe%20%282%29/#overview","text":"The Levridge Integration Framework is an entity syncronization framework. It provides a means to synchronize data at an entity level between multiple data sources. All integrations that use the framework follow the same pattern: 1. A data source has an integration event 2. The data source responds to the integration event by sending one or more entities to the service bus. 3. The service bus publishes the message(s) to each subscription 4. An instance of the integration framework receives the message(s) from a subscription 5. The integration framework transforms the message it if needed 6. The integration framework sends the message to the target data source","title":"Overview"},{"location":"ReadMe%20%282%29/#integrations","text":"Currently we support the following integrations: - D365 F&O to D365 CRM - D365 CRM to D365 F&O - Kahler - Agsync - oneWeigh - Field Reveal - Surety - Levridge Scale House","title":"Integrations"},{"location":"ReadMe%20%282%29/#d365-fo-to-d365-crm","text":"","title":"D365 F&amp;O to D365 CRM"},{"location":"ReadMe%20%282%29/#setup","text":"To integrate from D365 F&O to D365 CRM you will need to: - configure Levridge Entity Events - Create an application ID for the integration framework to authenticate to D365 CRM - Create an application user in D365 CRM and assign the proper role(s) - Create an Azure Service bus topic - Create a subscription on the topic above","title":"Setup"},{"location":"ReadMe%20%282%29/#configuration","text":"In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with F&O data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with CRM data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Target\" }","title":"Configuration"},{"location":"ReadMe%20%282%29/#d365-crm-to-d365-fo","text":"","title":"D365 CRM to D365 F&amp;O"},{"location":"ReadMe%20%282%29/#setup_1","text":"To integrate from D365 CRM to D365 F&O you will need to: - Configure Azure Service Bus Endpoint in CRM - Configure Azure Service Bus plugin on the appropriate entities - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic - Create a subscription on the topic above","title":"Setup"},{"location":"ReadMe%20%282%29/#configuration_1","text":"In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": [section name with service bus topic], \"ODataConfigName\": [section name with CRM data configuration], \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": [section name with F&O data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }","title":"Configuration"},{"location":"ReadMe%20%282%29/#kahler","text":"The Kahler integration is a bidirectional integration that consists of a Topic for Dispensing Work Orders that go from D365 F&O to Kahler and Dispensing Work Records that go from Kahler to D365 F&O. This means there are two instances of the integration running to handle the entire integration. One aspect of Kahler that is different from other integrations is the D365 F&O to Kahler instance must run on premise because the Kahler system runs behind the firewall. This should be deployed as a service. Another aspect that is different is that each location should only get the messages from the topic that apply to that location. This is done with a filter on the service bus topic subscription. In order for the filter to work the Levridge Entity Event must be configured to expose the branch property on the message.","title":"Kahler"},{"location":"ReadMe%20%282%29/#setup_2","text":"To integrate to and from Kahler and D365 F&O you will need to: - Configure Levridge Entity Events - You will need to be sure to provide properties on the event to allow filtering by Branch - Create an application ID for the integration framework to authenticate to D365 F&O - Create an Azure Active Directory Application in D365 F&O - Create an Azure Service bus topic for Dispensing Work Orders (D365 F&O to Kahler) - Create an Azure Service bus topic for Dispensing Work Records (Kahler to D365 F&O) - Create a subscription on the Dispensing Work Order topic for each Branch that has a Kahler mixer - Create a filter on the subscription for each Branch - Create a subscription on the Dispensing Work Record topic for integration back to F&O - Deploy the Levridge Integration Framework as a service at each Branch that has a Kahler mixer","title":"Setup"},{"location":"ReadMe%20%282%29/#configuration-for-kahler-on-premise","text":"This configuration will need to be on premise with the Kahler mixer. In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"Controllers\": { \"HostController\": \"Levridge.Integration.Host.DefaultController\", \"KahlerConroller\": \"Levridge.Integration.Host.KahlerController\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Order\", //[section name with Dispensing Work Order service bus topic] \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"Kahler End Point\", //[section name with Kahler data configuration], \"CDSConfigName\": [section name with CDS data configuration], \"SystemName\": \"Kahler\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": [URL to D365 F&O], \"ActiveDirectoryResource\": [URL to D365 F&O], \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": [Application ID used to register the application in AD], \"ActiveDirectoryClientAppSecret\": [Client Secret genrated for the Application ID in AD], \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Kahler End Point\": { \"UriString\": [URL to Local Kahler] }, \"Dispensing Work Order\": { \"ConnectionString\": [connection string to Dispensing Work Order Topic], \"TopicName\": [Dispensing Work Order Topic Name], \"SubscriptionName\": [Subscription Name for the Branch], \"RequiresSession\": true }, \"Levridge.Integration.Host.KahlerController\": { \"ConnectionString\": [connection string to Dispensing Work Record Topic], \"TopicName\": [Dispensing Work Record Topic Name], \"RequiresSession\": true }","title":"Configuration for Kahler on Premise"},{"location":"ReadMe%20%282%29/#controllers","text":"This section contains a list of controllers that will be loaded by the current instance. In addition to the default controller that we alwasy want to load, we want the system to load the Kahler controller. The names (on the left) are not significant and are used only for debugging. The values (on the right) are significant. It must be the name of the assembly that should be loaded for the controller.","title":"Controllers"},{"location":"ReadMe%20%282%29/#sourceconfig","text":"The source config will represent the data being send from D365 F&O. Currently, the Dispensing Work Order is the only entity sent from F&O. In the future the topic may also include master data that is sent to Kahler. The ODataConfigName is not currently being used but is a required value. So point it to the section that contains the connection information to D365 F&O.","title":"SourceConfig"},{"location":"ReadMe%20%282%29/#targetconfig","text":"The target config will represent the data endpoint for the local Kahler mixer. The \"ODataConfigName\" should point to a section that contains the Kahler REST endpoint.","title":"TargetConfig"},{"location":"ReadMe%20%282%29/#levridgeintegrationhostkahlercontroller","text":"This section is used by the Kahler controller to be able to send messages to the proper topic to be handled by the integration framework and written to D365 F&O","title":"Levridge.Integration.Host.KahlerController"},{"location":"ReadMe%20%282%29/#configuration-for-kahler-in-azure","text":"This instance can be a single instance runing in the cloud. In the appsettings.json you will need to define the SourceConfig and TargetConfig nodes as follows: \"SourceConfig\": { \"ServiceBusConfigName\": \"Dispensing Work Record\", //[section name with Dispensing Work Record service bus topic] \"SystemName\": \"Kahler\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"DynamicsAX\", //[section name with F&O data configuration] \"SystemName\": \"DynamicsAX\", \"Direction\": \"Target\" }, \"DynamicsAX\": { \"UriString\": [URL to D365 F&O], \"ActiveDirectoryResource\": [URL to D365 F&O], \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/[Customer_Tenant_ID]\", \"ActiveDirectoryClientAppId\": [Application ID used to register the application in AD], \"ActiveDirectoryClientAppSecret\": [Client Secret genrated for the Application ID in AD], \"ODataEntityPath\": \"[URL to D365 F&O]/data/\" }, \"Dispensing Work Record\": { \"ConnectionString\": [connection string to Dispensing Work Record Topic], \"TopicName\": [Dispensing Work Record Topic Name], \"SubscriptionName\": [Subscription Name for Integration to D365 F&O], \"RequiresSession\": true }","title":"Configuration for Kahler in Azure"},{"location":"ReadMe%20%282%29/#agsync","text":"","title":"Agsync"},{"location":"ReadMe%20%282%29/#oneweigh","text":"","title":"oneWeigh"},{"location":"ReadMe%20%282%29/#field-reveal","text":"","title":"Field Reveal"},{"location":"ReadMe%20%282%29/#surety","text":"","title":"Surety"},{"location":"ReadMe%20%282%29/#levridge-scale-house","text":"","title":"Levridge Scale House"},{"location":"Recommendation-Integration/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"Recommendation-Integration/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Recommendation-Integration/#overview","text":"","title":"Overview"},{"location":"Recommendation-Integration/#main-point-1","text":"","title":"Main Point 1"},{"location":"Recommendation-Integration/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"Scale-Overview/","text":"Levridge Scale Overview The purpose of Levridge Scale is to receive all the data measured at the scales at ag retailer locations and incorporate it into a scale ticket which can be printed out and given to the grower, while also bringing the scale ticket into the Dynamics 365 ERP system. Within the accounting technology solution, the contents of the scale ticket can be accounted for and posted against contracts the grower has with the ag retailer. The LevridgeScaleApp structure is a browser-based Scale application with the functionality of being able to operate as a server or as a desktop. 1. IIS (Internet Information Services) which is a Microsoft web server. 2. A Windows desktop, which is a background Windows service. The functionality is chosen based on the specific requirements of the clients. If the client\u2019s functionality only includes a Windows desktop station, Levridge Scale App can be run as a service capability as not every scale will have a server. Scale Settings Configuration How to Install Levridge Scale How to Update Levridge Scale ScaleHead Hardware Setup for Rice Lake 920i and Rice Lake 1280 Scale Appsettings Configuration IIS Server Functionality If LevridgeScaleApp is ran as a server, it would operate with a Reverse Proxy. This is very important for implementation purposes. Required server information include the Printer Server and API Server. Clients are always classified as \u201cserver\u201d regardless if operating as a service or server. The intent is the client operates to serve content to the client. The three servers are: 1. LevScaleAPI - This server handles all the back-end calls. This is where the integration framework communications with the scale. O-Data calls which are in turn the integration framework. O-Data is very necessary due to the ability to operate with other ERP systems. 2. LevScaleClient 3. LevScalePrint - This server renders all the reports for printing. It communicates with the client printer service. This is within the .net framework. Desktop Environment Service Functionality The five services within a Windows desktop environment include: 1. LevEstimatedService - This handles O-Data calls to Dynamics F&O to receive the estimated ticket information. 2. LevPrintClient - Can install the LevPrintService to any computer within a client\u2019s Intranet. It has the capability of rendering reports at any location if the LevPrintClient is registered at the specific location. This also includes the Zebra printing capability. 3. LevridgeAXToScale - Along with LevridgeScaleToAX is the integration framework. The only difference between LevridgeScaleToAX is the app settings: LevridgeAXToScale being the source target and LevScaletoAX being the target source. - They are both provided in the package as there can be many integration systems. The ratio would be one LevridgeAXToScale and one for the current desktop or LevScale instance. This enables F&O to broadcast all internal information that is necessary. LevridgeAXToScale would be looking at the specific service bus channel. It will then write into the LevScale through the LevScaleAPI. 4. LevridgeScaleToAX - This is the inverse of LevridgeAXToScale and is an optional criterion to install. This acts like a funnel. 5. LevScale - LevScale is the defining factor between a server and service. LevScaleClient and LevScale are executing the same file path and processes. This is operating a straight web server without the reverse proxy capability. Scale Ticket Types Inbound Grain Outbound Grain Agronomy Sales Transfer Weight Only Trucks in Yard These will be shown \"in the yard\" since they are uncompleted tickets that have not been printed. Scale Ticket History This is the history of printed tickets from today and the previous day. Application Configuration This is where the settings to change Site, Print, Etc. are located. Delivery Sheets Here you can view and create delivery sheets for grain tickets. The scale tickets and delivery sheets will sync both ways between F&O and the scale app. Create Scale Tickets http://levscaledev.corp.stoneridgesoftware.com/","title":"Scale Overview"},{"location":"Scale-Overview/#levridge-scale-overview","text":"The purpose of Levridge Scale is to receive all the data measured at the scales at ag retailer locations and incorporate it into a scale ticket which can be printed out and given to the grower, while also bringing the scale ticket into the Dynamics 365 ERP system. Within the accounting technology solution, the contents of the scale ticket can be accounted for and posted against contracts the grower has with the ag retailer. The LevridgeScaleApp structure is a browser-based Scale application with the functionality of being able to operate as a server or as a desktop. 1. IIS (Internet Information Services) which is a Microsoft web server. 2. A Windows desktop, which is a background Windows service. The functionality is chosen based on the specific requirements of the clients. If the client\u2019s functionality only includes a Windows desktop station, Levridge Scale App can be run as a service capability as not every scale will have a server. Scale Settings Configuration How to Install Levridge Scale How to Update Levridge Scale ScaleHead Hardware Setup for Rice Lake 920i and Rice Lake 1280 Scale Appsettings Configuration","title":"Levridge Scale Overview"},{"location":"Scale-Overview/#iis-server-functionality","text":"If LevridgeScaleApp is ran as a server, it would operate with a Reverse Proxy. This is very important for implementation purposes. Required server information include the Printer Server and API Server. Clients are always classified as \u201cserver\u201d regardless if operating as a service or server. The intent is the client operates to serve content to the client. The three servers are: 1. LevScaleAPI - This server handles all the back-end calls. This is where the integration framework communications with the scale. O-Data calls which are in turn the integration framework. O-Data is very necessary due to the ability to operate with other ERP systems. 2. LevScaleClient 3. LevScalePrint - This server renders all the reports for printing. It communicates with the client printer service. This is within the .net framework.","title":"IIS Server Functionality"},{"location":"Scale-Overview/#desktop-environment-service-functionality","text":"The five services within a Windows desktop environment include: 1. LevEstimatedService - This handles O-Data calls to Dynamics F&O to receive the estimated ticket information. 2. LevPrintClient - Can install the LevPrintService to any computer within a client\u2019s Intranet. It has the capability of rendering reports at any location if the LevPrintClient is registered at the specific location. This also includes the Zebra printing capability. 3. LevridgeAXToScale - Along with LevridgeScaleToAX is the integration framework. The only difference between LevridgeScaleToAX is the app settings: LevridgeAXToScale being the source target and LevScaletoAX being the target source. - They are both provided in the package as there can be many integration systems. The ratio would be one LevridgeAXToScale and one for the current desktop or LevScale instance. This enables F&O to broadcast all internal information that is necessary. LevridgeAXToScale would be looking at the specific service bus channel. It will then write into the LevScale through the LevScaleAPI. 4. LevridgeScaleToAX - This is the inverse of LevridgeAXToScale and is an optional criterion to install. This acts like a funnel. 5. LevScale - LevScale is the defining factor between a server and service. LevScaleClient and LevScale are executing the same file path and processes. This is operating a straight web server without the reverse proxy capability.","title":"Desktop Environment Service Functionality"},{"location":"Scale-Overview/#scale-ticket-types","text":"Inbound Grain Outbound Grain Agronomy Sales Transfer Weight Only","title":"Scale Ticket Types"},{"location":"Scale-Overview/#trucks-in-yard","text":"These will be shown \"in the yard\" since they are uncompleted tickets that have not been printed.","title":"Trucks in Yard"},{"location":"Scale-Overview/#scale-ticket-history","text":"This is the history of printed tickets from today and the previous day.","title":"Scale Ticket History"},{"location":"Scale-Overview/#application-configuration","text":"This is where the settings to change Site, Print, Etc. are located.","title":"Application Configuration"},{"location":"Scale-Overview/#delivery-sheets","text":"Here you can view and create delivery sheets for grain tickets. The scale tickets and delivery sheets will sync both ways between F&O and the scale app.","title":"Delivery Sheets"},{"location":"Scale-Overview/#create-scale-tickets","text":"http://levscaledev.corp.stoneridgesoftware.com/","title":"Create Scale Tickets"},{"location":"ScaleHeadHardwareSetup/","text":"Scale Hardware Setup Rice Lake 920i Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = 1 Hostname = <ip address of scalehead> Port = 10001 TypeId = TcpIPClientStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService Rice Lake 1280 Configure the 1280 Access the Scale UI in a browser. http://* :3000 In the Menu go to Configuration > Communications Select Ethernet, TCP Client 2 Remote Address = < ip address of Levridge Scale PC > Remote Port Number = 10001 Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = 1 Hostname = <ip address of scalehead> Port = 10001 TypeId = TcpIPCStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService Serial Connection Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = COM1 Speed = 9600 DataBits = 8 StopBits = 1 Parity = N FlowControl = 0 TypeId = SerialStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService","title":"Scale Hardware Setup"},{"location":"ScaleHeadHardwareSetup/#scale-hardware-setup","text":"","title":"Scale Hardware Setup"},{"location":"ScaleHeadHardwareSetup/#rice-lake-920i","text":"Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = 1 Hostname = <ip address of scalehead> Port = 10001 TypeId = TcpIPClientStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService","title":"Rice Lake 920i"},{"location":"ScaleHeadHardwareSetup/#rice-lake-1280","text":"Configure the 1280 Access the Scale UI in a browser. http://* :3000 In the Menu go to Configuration > Communications Select Ethernet, TCP Client 2 Remote Address = < ip address of Levridge Scale PC > Remote Port Number = 10001 Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = 1 Hostname = <ip address of scalehead> Port = 10001 TypeId = TcpIPCStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService","title":"Rice Lake 1280"},{"location":"ScaleHeadHardwareSetup/#serial-connection","text":"Add the Equipment Information In Levridge Scale, click Application Configuration > Equipment Management Click Create New Set Is active = Yes Set Is scale = Yes Enter Equipment Name - this is the name that will show in the UI and on printed reports Equipment description - not used Location - not used Custom character = L Click Save, then edit for the next two fields to be visible Equipment response type ID = 4 Return response type ID = 5 Service URL = http://localhost:5000 Click Save Add the Equipment Field Details From Equipment Management, click Edit on the Equipment record Click Equipment Field Details Click Create New Name = \"weight\" SequenceId = 1 Check the box by OutputStreamTypeId FieldName = \"weight\" StringLength = 30 ReturnTypeResult = String Click Create Click Back to Equipment Add the Connection Details Click Connection Details Name = COM1 Speed = 9600 DataBits = 8 StopBits = 1 Parity = N FlowControl = 0 TypeId = SerialStream Click Submit Create a Workstation In LevridgeScale, click Application Configuration > Workstation Management Click Create New Enter a Workstation name, ex. \"Ws1\" Click Create Click Edit Under Equipment, mark the box next to the Scale Click Save Configure the Hardware Service with the Workstation name Navigate to the folder LevridgeScaleHouse\\Services\\HardwareInterface Open appsettings.json Enter the WorkstationName, example: \"WorkstationName\" : \"Ws1\" Restart Hardware service Open (Windows) Services Restart LevScaleHardwareService","title":"Serial Connection"},{"location":"ServiceBusConfiguration/","text":"ServiceBusConfiguration The ServiceBusConfiguration object is used to configure a connection to a service bus queue or topic. Example \"prodagsyncmasterdata\": { \"ConnectionString\": \"Endpoint=[Customer Servicebus Connection String]\", \"TopicName\": \"[Customer Servicebus Topic]\", \"SubscriptionName\": \"[Customer Servicebus Topic Subscription]\", \"MaxConcurrentCount\":10 }, Definition ConnectionString TopicName SubscriptionName MaxConcurrentCount The maximum number of messages that will be allowed to be processed simultaneously.","title":"ServiceBusConfiguration"},{"location":"ServiceBusConfiguration/#servicebusconfiguration","text":"The ServiceBusConfiguration object is used to configure a connection to a service bus queue or topic.","title":"ServiceBusConfiguration"},{"location":"ServiceBusConfiguration/#example","text":"\"prodagsyncmasterdata\": { \"ConnectionString\": \"Endpoint=[Customer Servicebus Connection String]\", \"TopicName\": \"[Customer Servicebus Topic]\", \"SubscriptionName\": \"[Customer Servicebus Topic Subscription]\", \"MaxConcurrentCount\":10 },","title":"Example"},{"location":"ServiceBusConfiguration/#definition","text":"","title":"Definition"},{"location":"ServiceBusConfiguration/#connectionstring","text":"","title":"ConnectionString"},{"location":"ServiceBusConfiguration/#topicname","text":"","title":"TopicName"},{"location":"ServiceBusConfiguration/#subscriptionname","text":"","title":"SubscriptionName"},{"location":"ServiceBusConfiguration/#maxconcurrentcount","text":"The maximum number of messages that will be allowed to be processed simultaneously.","title":"MaxConcurrentCount"},{"location":"SetupCostVariances/","text":"Setup Cost Variances Brief introduction of the module, component or feature being documented. This document explains ... How to Setup Cost Variances Close the page. Go to Cost Management > Ledger Integration Policies Setup > Posting. Click the Standard cost variance tab. In the Select field, select an option.","title":"Setup Cost Variances"},{"location":"SetupCostVariances/#setup-cost-variances","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Setup Cost Variances"},{"location":"SetupCostVariances/#how-to-setup-cost-variances","text":"Close the page. Go to Cost Management > Ledger Integration Policies Setup > Posting. Click the Standard cost variance tab. In the Select field, select an option.","title":"How to Setup Cost Variances"},{"location":"SetupStandardCost/","text":"Setup a Standard Cost Brief introduction of the module, component or feature being documented. This document explains ... How to Setup a Standard Cost Use the Quick Filter to find records. For example, filter on the Item number field with a value of 'harness'. Click Item price. Click New. In the list, mark the selected row. In the Version field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Site field, type a value. In the Price field, enter a number. Click Save. Click the Active prices tab. Click the Pending prices tab. On the Action Pane, click Options. Close the page. Refresh the page. Click Item price. Click Activate pending price(s). Click the Active prices tab.","title":"Setup a Standard Cost"},{"location":"SetupStandardCost/#setup-a-standard-cost","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Setup a Standard Cost"},{"location":"SetupStandardCost/#how-to-setup-a-standard-cost","text":"Use the Quick Filter to find records. For example, filter on the Item number field with a value of 'harness'. Click Item price. Click New. In the list, mark the selected row. In the Version field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Site field, type a value. In the Price field, enter a number. Click Save. Click the Active prices tab. Click the Pending prices tab. On the Action Pane, click Options. Close the page. Refresh the page. Click Item price. Click Activate pending price(s). Click the Active prices tab.","title":"How to Setup a Standard Cost"},{"location":"SourceConfig/","text":"SourceConfig Settings SourceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction. Example \"SourceConfig\": { \"ServiceBusConfigName\": \"Levridge.Integration.Host.SuretyController\", \"ODataConfigName\": \"DynamicsCRM\", \"SystemName\": \"Surety\", \"Direction\": \"Source\" } Definition SourceConfig The node in the appsettings.json file does not actually need to be named \"SourceConfig\". You can use a command line parameter to specify the node name (section name) that contains the SourceConfig data. No matter the name, the source config section must contain the following attributes: - ServiceBusConfigName - ODataConfigName - CDSConfigName - SystemName - Direction ServiceBusConfigName The ServiceBusConfigName attribute contains a string that specifies the json object (configuration section) that holds the service bus configuration used by the Source of the Integration Interaction. This must point to a node that is a ServiceBusConfig json object ODataConfigName The ODataConfigName attribute contains a string that specifies the json object (configuration section) that holds the data configuration used by the Source of the Integration Interaction. This must point to a node that is a ODataConfig json object CDSConfigName The CDSConfigName attribute contains a string that specifies the json object (configuration section) that holds the CDS configuration used by the Source of the Integration Interaction. This must point to a node that is a CDSConfig json object SystemName The SystemName attribute holds a string value that represents the source system name. It must be one of the names recognized by the SystemName enumeration . Direction The direction is either Soruce or Target. This must be specified since the SourceConfig Node can have any name so the direction of the configuration may not be clear from the name.","title":"SourceConfig Settings"},{"location":"SourceConfig/#sourceconfig-settings","text":"SourceConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction.","title":"SourceConfig Settings"},{"location":"SourceConfig/#example","text":"\"SourceConfig\": { \"ServiceBusConfigName\": \"Levridge.Integration.Host.SuretyController\", \"ODataConfigName\": \"DynamicsCRM\", \"SystemName\": \"Surety\", \"Direction\": \"Source\" }","title":"Example"},{"location":"SourceConfig/#definition","text":"","title":"Definition"},{"location":"SourceConfig/#sourceconfig","text":"The node in the appsettings.json file does not actually need to be named \"SourceConfig\". You can use a command line parameter to specify the node name (section name) that contains the SourceConfig data. No matter the name, the source config section must contain the following attributes: - ServiceBusConfigName - ODataConfigName - CDSConfigName - SystemName - Direction","title":"SourceConfig"},{"location":"SourceConfig/#servicebusconfigname","text":"The ServiceBusConfigName attribute contains a string that specifies the json object (configuration section) that holds the service bus configuration used by the Source of the Integration Interaction. This must point to a node that is a ServiceBusConfig json object","title":"ServiceBusConfigName"},{"location":"SourceConfig/#odataconfigname","text":"The ODataConfigName attribute contains a string that specifies the json object (configuration section) that holds the data configuration used by the Source of the Integration Interaction. This must point to a node that is a ODataConfig json object","title":"ODataConfigName"},{"location":"SourceConfig/#cdsconfigname","text":"The CDSConfigName attribute contains a string that specifies the json object (configuration section) that holds the CDS configuration used by the Source of the Integration Interaction. This must point to a node that is a CDSConfig json object","title":"CDSConfigName"},{"location":"SourceConfig/#systemname","text":"The SystemName attribute holds a string value that represents the source system name. It must be one of the names recognized by the SystemName enumeration .","title":"SystemName"},{"location":"SourceConfig/#direction","text":"The direction is either Soruce or Target. This must be specified since the SourceConfig Node can have any name so the direction of the configuration may not be clear from the name.","title":"Direction"},{"location":"Surety/","text":"Surety","title":"Surety"},{"location":"Surety/#surety","text":"","title":"Surety"},{"location":"SystemName/","text":"SystemName SystemName is an enumerated value that is used in the Source and Target configurations to configure which integrations get loaded into the current integration framework instance. The valid values are: None : No integrations will be loaded DynamicsAX : The integrations for Dynamics 365 Finance and Operations will be loaded as either the Source or the Target depending on which config node it appears. DynamicsCRM : The integrations for Dynamics 365 Customer Engagement will be loaded as either the Source or the Target depending on which config node it appears. ScaleHouse : The integrations for the Levridge Scale Application will be loaded as either the Source or the Target depending on which config node it appears. OneWeigh : The integrations for OneWeigh will be loaded as either the Source or the Target depending on which config node it appears. AgSync : The integrations for Agsync will be loaded as either the Source or the Target depending on which config node it appears. Recommendation : The integrations for Recommendations will be loaded as the Source. This is not a valid value for the Target configuration. Field : The integrations for Fields will be loaded as the Source. This is not a valid value for the Target configuration. Surety : The integrations for Surety will be loaded as the Source. This is not a valid value for the Target configuration. Kahler : The integrations for Kahler will be loaded as either the Source or the Target depending on which config node it appears.","title":"SystemName"},{"location":"SystemName/#systemname","text":"SystemName is an enumerated value that is used in the Source and Target configurations to configure which integrations get loaded into the current integration framework instance. The valid values are: None : No integrations will be loaded DynamicsAX : The integrations for Dynamics 365 Finance and Operations will be loaded as either the Source or the Target depending on which config node it appears. DynamicsCRM : The integrations for Dynamics 365 Customer Engagement will be loaded as either the Source or the Target depending on which config node it appears. ScaleHouse : The integrations for the Levridge Scale Application will be loaded as either the Source or the Target depending on which config node it appears. OneWeigh : The integrations for OneWeigh will be loaded as either the Source or the Target depending on which config node it appears. AgSync : The integrations for Agsync will be loaded as either the Source or the Target depending on which config node it appears. Recommendation : The integrations for Recommendations will be loaded as the Source. This is not a valid value for the Target configuration. Field : The integrations for Fields will be loaded as the Source. This is not a valid value for the Target configuration. Surety : The integrations for Surety will be loaded as the Source. This is not a valid value for the Target configuration. Kahler : The integrations for Kahler will be loaded as either the Source or the Target depending on which config node it appears.","title":"SystemName"},{"location":"TargetConfig/","text":"Target Config Settings TargetConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction. Example \"TargetConfig\": { \"ODataConfigName\": \"DynamicsCRM\", \"CDSConfigName\": \"CDS\", \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" } Definition TargetConfig The node in the appsettings.json file does not actually need to be named \"TargetConfig\". You can use a command line parameter to specify the node name (section name) that contains the TargetConfig data. No matter the name, the source config section must contain the following attributes: - ODataConfigName - CDSConfigName - SystemName - Direction ODataConfigName The ODataConfigName attribute contains a string that specifies the json object (configuration section) that holds the data configuration used by the Source of the Integration Interaction. This must point to a node that is a ODataConfig json object CDSConfigName The CDSConfigName attribute contains a string that specifies the json object (configuration section) that holds the CDS configuration used by the Target of the Integration Interaction. This must point to a node that is a CDSConfig json object SystemName The SystemName attribute holds a string value that represents the source system name. It must be one of the names recognized by the SystemName enumeration . Direction The direction is either Soruce or Target. This must be specified since the TargetConfig Node can have any name so the direction of the configuration may not be clear from the name.","title":"Target Config Settings"},{"location":"TargetConfig/#target-config-settings","text":"TargetConfig is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction.","title":"Target Config Settings"},{"location":"TargetConfig/#example","text":"\"TargetConfig\": { \"ODataConfigName\": \"DynamicsCRM\", \"CDSConfigName\": \"CDS\", \"SystemName\": \"DynamicsCRM\", \"Direction\": \"Source\" }","title":"Example"},{"location":"TargetConfig/#definition","text":"","title":"Definition"},{"location":"TargetConfig/#targetconfig","text":"The node in the appsettings.json file does not actually need to be named \"TargetConfig\". You can use a command line parameter to specify the node name (section name) that contains the TargetConfig data. No matter the name, the source config section must contain the following attributes: - ODataConfigName - CDSConfigName - SystemName - Direction","title":"TargetConfig"},{"location":"TargetConfig/#odataconfigname","text":"The ODataConfigName attribute contains a string that specifies the json object (configuration section) that holds the data configuration used by the Source of the Integration Interaction. This must point to a node that is a ODataConfig json object","title":"ODataConfigName"},{"location":"TargetConfig/#cdsconfigname","text":"The CDSConfigName attribute contains a string that specifies the json object (configuration section) that holds the CDS configuration used by the Target of the Integration Interaction. This must point to a node that is a CDSConfig json object","title":"CDSConfigName"},{"location":"TargetConfig/#systemname","text":"The SystemName attribute holds a string value that represents the source system name. It must be one of the names recognized by the SystemName enumeration .","title":"SystemName"},{"location":"TargetConfig/#direction","text":"The direction is either Soruce or Target. This must be specified since the TargetConfig Node can have any name so the direction of the configuration may not be clear from the name.","title":"Direction"},{"location":"Template/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"Template/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"Template/#overview","text":"","title":"Overview"},{"location":"Template/#main-point-1","text":"","title":"Main Point 1"},{"location":"Template/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"TradeAgreementsPriceGroup/","text":"Trade Agreements Price Group Brief introduction of the module, component or feature being documented. This document explains ... Trade Agreements Price Group Go to Inventory Management > Setup > Price/Discount > Customer Price/Discount Groups. Click New. In the Price Groups field, type a value. In the Name field, type a value. On the Action Pane, click Trade Agreements. Click Save. On the Action Pane, click Trade Agreements. Click View Sales Prices. Close the page. One the Action Pane, click Trade Agreements. Click View Trade Agreements (sales). Close the page. On the Action Pane, click Trade Agreements. Close the page. Go to Product Information Management > Products > Released Products. In the list, click the link in the select row. Close the page. Go to Accounts Receivable > Customers > All customers. In the list, find and select the desired record. In the list, click the link in the selected row. Click Edit. In the Price field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. Click Save. Close the page. Go to Inventory Management > Setup > Price/Discount > Customer Price/Discount Groups. In the list, find and select the desired record. On the Action Pane, click Trade Agreements. Click Create Trade Agreements. Click New. In the Name field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Click Lines. In the list, mark the selected row. In the Party code type field, select an option. In the Account selection field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Item relation field, enter or select a value. Close the page. In the Item relation field, type a value. In the Site field, type a value. In the Warehouse field, type a value. In the Amount in currency field, enter a number. Click Post. Click OK. Refresh the page. Close the page. On the Action Pane, click Trade Agreements. Click View sales prices. Close the page. Close the page. Go to Accounts receivable > Orders > All sales orders. In the list, find and select the desired record. Click New.","title":"Trade Agreements Price Group"},{"location":"TradeAgreementsPriceGroup/#trade-agreements-price-group","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Trade Agreements Price Group"},{"location":"TradeAgreementsPriceGroup/#trade-agreements-price-group_1","text":"Go to Inventory Management > Setup > Price/Discount > Customer Price/Discount Groups. Click New. In the Price Groups field, type a value. In the Name field, type a value. On the Action Pane, click Trade Agreements. Click Save. On the Action Pane, click Trade Agreements. Click View Sales Prices. Close the page. One the Action Pane, click Trade Agreements. Click View Trade Agreements (sales). Close the page. On the Action Pane, click Trade Agreements. Close the page. Go to Product Information Management > Products > Released Products. In the list, click the link in the select row. Close the page. Go to Accounts Receivable > Customers > All customers. In the list, find and select the desired record. In the list, click the link in the selected row. Click Edit. In the Price field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. Click Save. Close the page. Go to Inventory Management > Setup > Price/Discount > Customer Price/Discount Groups. In the list, find and select the desired record. On the Action Pane, click Trade Agreements. Click Create Trade Agreements. Click New. In the Name field, enter or select a value. In the list, select row 5. In the list, click the link in the selected row. Click Lines. In the list, mark the selected row. In the Party code type field, select an option. In the Account selection field, enter or select a value. In the list, select row 2. In the list, click the link in the selected row. In the Item relation field, enter or select a value. Close the page. In the Item relation field, type a value. In the Site field, type a value. In the Warehouse field, type a value. In the Amount in currency field, enter a number. Click Post. Click OK. Refresh the page. Close the page. On the Action Pane, click Trade Agreements. Click View sales prices. Close the page. Close the page. Go to Accounts receivable > Orders > All sales orders. In the list, find and select the desired record. Click New.","title":"Trade Agreements Price Group"},{"location":"Unit-Testing-Entity-Mappings/","text":"Introduction This library provides the base classes and utility classes to help you bild unit tests for the integration framework. It contains classes in the following categories: * Mapping Unit Test Helper Classes * Service Bus Helper and Mock classes * Integration Test Helper Classes Mapping Unit Test Helper Classes EntityMapBuilderExtensionsTestHelper The EntityMapBuilderExtensionsTestHelper class contains static methods you can use to obtain an EntityMapProvider<> for a particular scenario and methods to execute A2B and B2A synchronization using the EntityMapProvider<> obtained. To create a unit test that can test a mapping scenario, reference this library in your test project. Then create a unit test using the following steps: Call GetEntityMapProvider (Type entityMapBuilderType, string methodName) passing the source target template parameter types as defined on the mapping method along with the class that contains the mapping method and the name of the mapping method that you want to test. For example, to test the mapping for AxEntities.ScaleTicketGradeFactor and ScaleHouseEntities.ScaleTicketGradeFactor make the following call: var mapProvider = EntityMapBuilderExtensionsTestHelper.GetEntityMapProvider<AxEntities.ScaleTicketGradeFactor, ScaleHouseEntities.ScaleTicketGradeFactor>(typeof(AxToScaleEntityMapBuilderExtensions), \"MapAXScaleTicketGradeFactor_ScaleHouseScaleTicketGradeFactor\"); Instantiate and populate the entities you want to use for mapping. I prefer to use the [MemberData] attribute to provide multiple instances for testing. See this article for example on providing data for unit tests. Use the EntityMapProvider<> to perform the mapping by calling one of the transform methods on The EntityMapBuilderExtensionsTestHelper class. For example, to test the B2A mapping for the previous example use the following code: AXentity = EntityMapBuilderExtensionsTestHelper.TransformB2A(mapProvider, ScaleEntity, AXentity); Assert - check the mapped values In order to test the expected values you should have an instance of the target object with the expected values and then get the transformed object from the target entity and compare the two. You can pass in an object with the expected values using the MemberData method. Example: // Get target object var targetObject = AXentity.GetEntityAsDotNetType<AxEntities.ScaleTicketGradeFactor>(); // Assert Assert.NotNull(targetObject); Assert.Equal(expectedResult.GradeFactorId, targetObject.GradeFactorId); Assert.Equal(expectedResult.GradeFactorValue, targetObject.GradeFactorValue); Assert.Equal(expectedResult.TicketNumber, targetObject.TicketNumber); Assert.Equal(expectedResult.LineNumber, targetObject.LineNumber); Using MemberData to Provide Unit Test Data If you want to use the MemberData method for building data to use in your unit tests (you can refer to this article for an over view) here are some ideas. 1. Create Methods to Instantiate and Populate the Source and Expected Target Objects I would recommend creating a private static method on your test class that recieves parameters that can be used to initialize the class with the desired values. If you need several parameters you can put them in an object array or Key Value pair or even a dictionary. Example: private static AxEntities.ScaleTicketGradeFactor GetAxTicketGradeFactorObject(int line, string id, string value, string ticketNumber) { return new AxEntities.ScaleTicketGradeFactor() { LineNumber = line, GradeFactorId = id, GradeFactorValue = decimal.Parse(value), TicketNumber = ticketNumber }; } 2. Create Methods to Instantiate and Populate the Source and Target Entities Once you have a populated source object you can use it to instantiate and initialize a source Entity. Example: private static Entity GetAxTicketGradeFactorEntity(AxEntities.ScaleTicketGradeFactor scaleTicketGradeFactor = null) { var axScaleTicketGradeFactor = scaleTicketGradeFactor ?? new AxEntities.ScaleTicketGradeFactor(); Entity entity = DynamicsAxEntities.Instance.GetScaleTicketGradeFactorEntity(); entity.CreateAndPopulateEntityFields(typeof(JSONField<>), axScaleTicketGradeFactor); return entity; } As you can see, if an object is provided, it is used to initialize the Entity. Otherwise a default object is used. 3. Implement the MemberData Method As described in this article for an over view) the MemberData method must return IEnumerable<object[]> . You can craete a method that uses the methods described in the previous steps to create source & target entities along with a target expected object. Then you can define that method using the [MemberData] attribute. Here is an example MemberData method: public static IEnumerable<object[]> GetSynchronizeA2BGradeFactorData() { return new List<object[]> { new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(1, \"A\", \"8\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(1, \"A\", \"8\", \"0000169\") }, new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(2, \"AB\", \"0.3\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(2, \"AB\", \"0.3\", \"0000169\") }, new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(3, \"AS\", \"31.3\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(3, \"AS\", \"31.3\", \"0000169\") } }; } Example Unit Test Here is an example unit test that tests Ticket Grade Factor entities from the ScaleHouse application to F&O. [Theory] [MemberData(nameof(GetSynchronizeB2AGradeFactorData))] public void MapScaleTicketGradeFactor_SynchronizeB2AGradeFactor_CorrectMapping( Entity AXentity, // AX ticket grade factor Entity ScaleEntity, // Scale house ticket grade factor AxEntities.ScaleTicketGradeFactor expectedResult) { // Arrange var mapProvider = EntityMapBuilderExtensionsTestHelper.GetEntityMapProvider<AxEntities.ScaleTicketGradeFactor, ScaleHouseEntities.ScaleTicketGradeFactor> (typeof(AxToScaleEntityMapBuilderExtensions), \"MapAXScaleTicketGradeFactor_ScaleHouseScaleTicketGradeFactor\"); //Act // Transform AXentity = EntityMapBuilderExtensionsTestHelper.TransformB2A(mapProvider, ScaleEntity, AXentity); // Get target object var targetObject = AXentity.GetEntityAsDotNetType<AxEntities.ScaleTicketGradeFactor>(); // Assert Assert.NotNull(targetObject); Assert.Equal(expectedResult.GradeFactorId, targetObject.GradeFactorId); Assert.Equal(expectedResult.GradeFactorValue, targetObject.GradeFactorValue); Assert.Equal(expectedResult.TicketNumber, targetObject.TicketNumber); Assert.Equal(expectedResult.LineNumber, targetObject.LineNumber); }","title":"Introduction"},{"location":"Unit-Testing-Entity-Mappings/#introduction","text":"This library provides the base classes and utility classes to help you bild unit tests for the integration framework. It contains classes in the following categories: * Mapping Unit Test Helper Classes * Service Bus Helper and Mock classes * Integration Test Helper Classes","title":"Introduction"},{"location":"Unit-Testing-Entity-Mappings/#mapping-unit-test-helper-classes","text":"","title":"Mapping Unit Test Helper Classes"},{"location":"Unit-Testing-Entity-Mappings/#entitymapbuilderextensionstesthelper","text":"The EntityMapBuilderExtensionsTestHelper class contains static methods you can use to obtain an EntityMapProvider<> for a particular scenario and methods to execute A2B and B2A synchronization using the EntityMapProvider<> obtained. To create a unit test that can test a mapping scenario, reference this library in your test project. Then create a unit test using the following steps: Call GetEntityMapProvider (Type entityMapBuilderType, string methodName) passing the source target template parameter types as defined on the mapping method along with the class that contains the mapping method and the name of the mapping method that you want to test. For example, to test the mapping for AxEntities.ScaleTicketGradeFactor and ScaleHouseEntities.ScaleTicketGradeFactor make the following call: var mapProvider = EntityMapBuilderExtensionsTestHelper.GetEntityMapProvider<AxEntities.ScaleTicketGradeFactor, ScaleHouseEntities.ScaleTicketGradeFactor>(typeof(AxToScaleEntityMapBuilderExtensions), \"MapAXScaleTicketGradeFactor_ScaleHouseScaleTicketGradeFactor\"); Instantiate and populate the entities you want to use for mapping. I prefer to use the [MemberData] attribute to provide multiple instances for testing. See this article for example on providing data for unit tests. Use the EntityMapProvider<> to perform the mapping by calling one of the transform methods on The EntityMapBuilderExtensionsTestHelper class. For example, to test the B2A mapping for the previous example use the following code: AXentity = EntityMapBuilderExtensionsTestHelper.TransformB2A(mapProvider, ScaleEntity, AXentity); Assert - check the mapped values In order to test the expected values you should have an instance of the target object with the expected values and then get the transformed object from the target entity and compare the two. You can pass in an object with the expected values using the MemberData method. Example: // Get target object var targetObject = AXentity.GetEntityAsDotNetType<AxEntities.ScaleTicketGradeFactor>(); // Assert Assert.NotNull(targetObject); Assert.Equal(expectedResult.GradeFactorId, targetObject.GradeFactorId); Assert.Equal(expectedResult.GradeFactorValue, targetObject.GradeFactorValue); Assert.Equal(expectedResult.TicketNumber, targetObject.TicketNumber); Assert.Equal(expectedResult.LineNumber, targetObject.LineNumber);","title":"EntityMapBuilderExtensionsTestHelper"},{"location":"Unit-Testing-Entity-Mappings/#using-memberdata-to-provide-unit-test-data","text":"If you want to use the MemberData method for building data to use in your unit tests (you can refer to this article for an over view) here are some ideas.","title":"Using MemberData to Provide Unit Test Data"},{"location":"Unit-Testing-Entity-Mappings/#1-create-methods-to-instantiate-and-populate-the-source-and-expected-target-objects","text":"I would recommend creating a private static method on your test class that recieves parameters that can be used to initialize the class with the desired values. If you need several parameters you can put them in an object array or Key Value pair or even a dictionary. Example: private static AxEntities.ScaleTicketGradeFactor GetAxTicketGradeFactorObject(int line, string id, string value, string ticketNumber) { return new AxEntities.ScaleTicketGradeFactor() { LineNumber = line, GradeFactorId = id, GradeFactorValue = decimal.Parse(value), TicketNumber = ticketNumber }; }","title":"1. Create Methods to Instantiate and Populate the Source and Expected Target Objects"},{"location":"Unit-Testing-Entity-Mappings/#2-create-methods-to-instantiate-and-populate-the-source-and-target-entities","text":"Once you have a populated source object you can use it to instantiate and initialize a source Entity. Example: private static Entity GetAxTicketGradeFactorEntity(AxEntities.ScaleTicketGradeFactor scaleTicketGradeFactor = null) { var axScaleTicketGradeFactor = scaleTicketGradeFactor ?? new AxEntities.ScaleTicketGradeFactor(); Entity entity = DynamicsAxEntities.Instance.GetScaleTicketGradeFactorEntity(); entity.CreateAndPopulateEntityFields(typeof(JSONField<>), axScaleTicketGradeFactor); return entity; } As you can see, if an object is provided, it is used to initialize the Entity. Otherwise a default object is used.","title":"2. Create Methods to Instantiate and Populate the Source and Target Entities"},{"location":"Unit-Testing-Entity-Mappings/#3-implement-the-memberdata-method","text":"As described in this article for an over view) the MemberData method must return IEnumerable<object[]> . You can craete a method that uses the methods described in the previous steps to create source & target entities along with a target expected object. Then you can define that method using the [MemberData] attribute. Here is an example MemberData method: public static IEnumerable<object[]> GetSynchronizeA2BGradeFactorData() { return new List<object[]> { new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(1, \"A\", \"8\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(1, \"A\", \"8\", \"0000169\") }, new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(2, \"AB\", \"0.3\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(2, \"AB\", \"0.3\", \"0000169\") }, new object[] { GetAxTicketGradeFactorEntity(GetAxTicketGradeFactorObject(3, \"AS\", \"31.3\", \"0000169\")), GetScaleHouseGradeFactorEntity(), GetScaleHouseTicketGradeFactorObject(3, \"AS\", \"31.3\", \"0000169\") } }; }","title":"3. Implement the MemberData Method"},{"location":"Unit-Testing-Entity-Mappings/#example-unit-test","text":"Here is an example unit test that tests Ticket Grade Factor entities from the ScaleHouse application to F&O. [Theory] [MemberData(nameof(GetSynchronizeB2AGradeFactorData))] public void MapScaleTicketGradeFactor_SynchronizeB2AGradeFactor_CorrectMapping( Entity AXentity, // AX ticket grade factor Entity ScaleEntity, // Scale house ticket grade factor AxEntities.ScaleTicketGradeFactor expectedResult) { // Arrange var mapProvider = EntityMapBuilderExtensionsTestHelper.GetEntityMapProvider<AxEntities.ScaleTicketGradeFactor, ScaleHouseEntities.ScaleTicketGradeFactor> (typeof(AxToScaleEntityMapBuilderExtensions), \"MapAXScaleTicketGradeFactor_ScaleHouseScaleTicketGradeFactor\"); //Act // Transform AXentity = EntityMapBuilderExtensionsTestHelper.TransformB2A(mapProvider, ScaleEntity, AXentity); // Get target object var targetObject = AXentity.GetEntityAsDotNetType<AxEntities.ScaleTicketGradeFactor>(); // Assert Assert.NotNull(targetObject); Assert.Equal(expectedResult.GradeFactorId, targetObject.GradeFactorId); Assert.Equal(expectedResult.GradeFactorValue, targetObject.GradeFactorValue); Assert.Equal(expectedResult.TicketNumber, targetObject.TicketNumber); Assert.Equal(expectedResult.LineNumber, targetObject.LineNumber); }","title":"Example Unit Test"},{"location":"UploadStandardCostPricing/","text":"Upload Standard Cost Pricing Overview INSERT How to Upload Standard Cost Pricing Go to Cost Management > Predetermined cost policies setup > Costing Versions. In the list, find and select the desired record. Click Price Click Item Price. Click the Active Prices tab. Click the Pending Prices tab. Click New. In the list, mark the selected row. In the item number field, type a value. In the Site field, type a value. In the Price field, enter a number. Click Save. Click Open in Microsoft Office. Click Pending item prices (100). Click Download. Click Open in Microsoft Office. Click Pending Item Prices. Click Download. Refresh the page. In the list, mark or unmark all rows. Click Activate pending price(s). Click the Active prices tab. Close the page. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the item number field with a value of 'harness'. On the Action Pane, click Manage Inventory. On the Action pane, click Manage Costs. Click Item price. In the list, find and select the desired record.","title":"Upload Standard Cost Pricing"},{"location":"UploadStandardCostPricing/#upload-standard-cost-pricing","text":"","title":"Upload Standard Cost Pricing"},{"location":"UploadStandardCostPricing/#overview","text":"INSERT","title":"Overview"},{"location":"UploadStandardCostPricing/#how-to-upload-standard-cost-pricing","text":"Go to Cost Management > Predetermined cost policies setup > Costing Versions. In the list, find and select the desired record. Click Price Click Item Price. Click the Active Prices tab. Click the Pending Prices tab. Click New. In the list, mark the selected row. In the item number field, type a value. In the Site field, type a value. In the Price field, enter a number. Click Save. Click Open in Microsoft Office. Click Pending item prices (100). Click Download. Click Open in Microsoft Office. Click Pending Item Prices. Click Download. Refresh the page. In the list, mark or unmark all rows. Click Activate pending price(s). Click the Active prices tab. Close the page. Close the page. Go to Product Information Management > Products > Released Products. Use the Quick Filter to find records. For example, filter on the item number field with a value of 'harness'. On the Action Pane, click Manage Inventory. On the Action pane, click Manage Costs. Click Item price. In the list, find and select the desired record.","title":"How to Upload Standard Cost Pricing"},{"location":"UuidCompositeRequest/","text":"UuidCompositeRequest The UuidCompositeRequest object is used by the AgsyncUUID controller to make a request for UUID values based on SyncId values passed in the request. JSON Defintion JSON Example { \"accountId\": \"ABC\", \"accountName\": \"Levridge - Barnesville\", \"growerId\": \"CUS-100442\", \"growerName\": \"Captain Cook Farms\", \"farmId\": \"COP100263\", \"farmeName\": \"Captain Cook Farms\", \"fieldId\": \"CST-400312\", \"fieldName\": \"CC Veggie Field NE\" } JSON Schema { \"$schema\": \"http://json-schema.org/draft-07/schema\", \"$id\": \"http://example.com/example.json\", \"type\": \"object\", \"readOnly\": false, \"writeOnly\": false, \"minProperties\": 0, \"title\": \"UuidCompositeRequest\", \"description\": \"This schema comprises the entire JSON document for a Composite Request\", \"additionalProperties\": true, \"required\": [ \"accountId\" ], \"properties\": { \"accountId\": { \"$id\": \"#/properties/accountId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountId Schema\", \"description\": \"The Sync Id for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"SCG1\" ] }, \"accountName\": { \"$id\": \"#/properties/accountName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountName Schema\", \"description\": \"This is an optional name for the account\", \"default\": \"\", \"examples\": [ \"Alexandria\" ] }, \"growerId\": { \"$id\": \"#/properties/growerId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerId Schema\", \"description\": \"The Sync Id for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"CUS-100347\" ] }, \"growerName\": { \"$id\": \"#/properties/growerName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerName Schema\", \"description\": \"This is an optional name for the Grower\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"farmId\": { \"$id\": \"#/properties/farmId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmId Schema\", \"description\": \"The Sync Id for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"COP100208\" ] }, \"farmeName\": { \"$id\": \"#/properties/farmeName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmeName Schema\", \"description\": \"This is an optional name for the Farm\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"fieldId\": { \"$id\": \"#/properties/fieldId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldId Schema\", \"description\": \"The Sync Id for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"CST-000026\" ] }, \"fieldName\": { \"$id\": \"#/properties/fieldName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldName Schema\", \"description\": \"This is an optional name for the Field\", \"default\": \"\", \"examples\": [ \"NW 40\" ] } } }","title":"UuidCompositeRequest"},{"location":"UuidCompositeRequest/#uuidcompositerequest","text":"The UuidCompositeRequest object is used by the AgsyncUUID controller to make a request for UUID values based on SyncId values passed in the request.","title":"UuidCompositeRequest"},{"location":"UuidCompositeRequest/#json-defintion","text":"","title":"JSON Defintion"},{"location":"UuidCompositeRequest/#json-example","text":"{ \"accountId\": \"ABC\", \"accountName\": \"Levridge - Barnesville\", \"growerId\": \"CUS-100442\", \"growerName\": \"Captain Cook Farms\", \"farmId\": \"COP100263\", \"farmeName\": \"Captain Cook Farms\", \"fieldId\": \"CST-400312\", \"fieldName\": \"CC Veggie Field NE\" }","title":"JSON Example"},{"location":"UuidCompositeRequest/#json-schema","text":"{ \"$schema\": \"http://json-schema.org/draft-07/schema\", \"$id\": \"http://example.com/example.json\", \"type\": \"object\", \"readOnly\": false, \"writeOnly\": false, \"minProperties\": 0, \"title\": \"UuidCompositeRequest\", \"description\": \"This schema comprises the entire JSON document for a Composite Request\", \"additionalProperties\": true, \"required\": [ \"accountId\" ], \"properties\": { \"accountId\": { \"$id\": \"#/properties/accountId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountId Schema\", \"description\": \"The Sync Id for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"SCG1\" ] }, \"accountName\": { \"$id\": \"#/properties/accountName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountName Schema\", \"description\": \"This is an optional name for the account\", \"default\": \"\", \"examples\": [ \"Alexandria\" ] }, \"growerId\": { \"$id\": \"#/properties/growerId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerId Schema\", \"description\": \"The Sync Id for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"CUS-100347\" ] }, \"growerName\": { \"$id\": \"#/properties/growerName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerName Schema\", \"description\": \"This is an optional name for the Grower\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"farmId\": { \"$id\": \"#/properties/farmId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmId Schema\", \"description\": \"The Sync Id for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"COP100208\" ] }, \"farmeName\": { \"$id\": \"#/properties/farmeName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmeName Schema\", \"description\": \"This is an optional name for the Farm\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"fieldId\": { \"$id\": \"#/properties/fieldId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldId Schema\", \"description\": \"The Sync Id for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"CST-000026\" ] }, \"fieldName\": { \"$id\": \"#/properties/fieldName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldName Schema\", \"description\": \"This is an optional name for the Field\", \"default\": \"\", \"examples\": [ \"NW 40\" ] } } }","title":"JSON Schema"},{"location":"UuidCompositeResponse/","text":"UuidCompositResponse The UuidCompositResponse object is used by the AgsyncUUID controller to return UUID values based on SyncId values passed in the request. JSON Defintion JSON Example { \"accountId\": \"BAR\", \"accountUuid\": \"336a8049-853c-4992-8382-e77e8868e208\", \"accountGuid\": \"000ad538-0000-0000-0000-000000000000\", \"accountName\": null, \"growerId\": \"CUS-100442\", \"growerUuid\": \"63ffb30a-aaf6-4cbe-83b7-95765aa2c5e4\", \"growerGuid\": \"000ceb06-0000-0000-0000-000000000000\", \"growerName\": null, \"farmId\": \"COP100263\", \"farmUuid\": \"d4334cd1-1a1f-4484-94d6-246645e07196\", \"farmGuid\": \"000ceb07-0000-0000-0000-000000000000\", \"farmName\": null, \"fieldId\": \"CST-400312\", \"fieldUuid\": \"9e0f0647-c21a-495a-92a2-9d0aaaf2bc8f\", \"fieldGuid\": \"001a5c8a-0000-0000-0000-000000000000\", \"fieldName\": null } JSON Schema { \"$schema\": \"http://json-schema.org/draft-07/schema\", \"$id\": \"http://example.com/example.json\", \"type\": \"object\", \"readOnly\": false, \"writeOnly\": false, \"minProperties\": 0, \"title\": \"The UuidCompositeResponse Schema\", \"description\": \"The root schema comprises the entire JSON document for Composite Response\", \"additionalProperties\": true, \"required\": [], \"properties\": { \"accountId\": { \"$id\": \"#/properties/accountId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountId Schema\", \"description\": \"The Sync Id for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"SCG1\" ] }, \"accountUuid\": { \"$id\": \"#/properties/accountUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountUuid Schema\", \"description\": \"The UUID for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"e0485a5d-f6c1-4a0e-824a-1abffbcfaa9\" ] }, \"accountGuid\": { \"$id\": \"#/properties/accountGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountGuid Schema\", \"description\": \"The GUID for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"000c33a4-0000-0000-0000-000000000000\" ] }, \"accountName\": { \"$id\": \"#/properties/accountName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountName Schema\", \"description\": \"This is an optional name for the account\", \"default\": \"\", \"examples\": [ \"Alexandria\" ] }, \"growerId\": { \"$id\": \"#/properties/growerId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerId Schema\", \"description\": \"The Sync Id for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"CUS-100347\" ] }, \"growerUuid\": { \"$id\": \"#/properties/growerUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerUuid Schema\", \"description\": \"The UUID for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"ad5ee735-c783-45d3-9b7a-5e7b089b1fbf\" ] }, \"growerGuid\": { \"$id\": \"#/properties/growerGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerGuid Schema\", \"description\": \"The GUID for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"000cd991-0000-0000-0000-000000000000\" ] }, \"growerName\": { \"$id\": \"#/properties/growerName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerName Schema\", \"description\": \"This is an optional name for the grower\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"farmId\": { \"$id\": \"#/properties/farmId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmId Schema\", \"description\": \"The Sync Id for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"COP100208\" ] }, \"farmUuid\": { \"$id\": \"#/properties/farmUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmUuid Schema\", \"description\": \"The UUID for the Grower (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"1f7b3ecc-e2eb-4724-b9ec-f0b756d21566\" ] }, \"farmGuid\": { \"$id\": \"#/properties/farmGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmGuid Schema\", \"description\": \"The GUID for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"000cd992-0000-0000-0000-000000000000\" ] }, \"farmeName\": { \"$id\": \"#/properties/farmeName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmeName Schema\", \"description\": \"This is an optional name for the farm\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"fieldId\": { \"$id\": \"#/properties/fieldId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldId Schema\", \"description\": \"The Sync Id for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"CST-000026\" ] }, \"fieldUuid\": { \"$id\": \"#/properties/fieldUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldUuid Schema\", \"description\": \"The UUID for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"2ac15a5a-2c8a-4f65-b5fe-3706637937ec\" ] }, \"fieldGuid\": { \"$id\": \"#/properties/fieldGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldGuid Schema\", \"description\": \"The GUID for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"001a4769-0000-0000-0000-000000000000\" ] }, \"fieldName\": { \"$id\": \"#/properties/fieldName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldName Schema\", \"description\": \"This is an optional name for the field\", \"default\": \"\", \"examples\": [ \"NW 40\" ] } } }","title":"UuidCompositResponse"},{"location":"UuidCompositeResponse/#uuidcompositresponse","text":"The UuidCompositResponse object is used by the AgsyncUUID controller to return UUID values based on SyncId values passed in the request.","title":"UuidCompositResponse"},{"location":"UuidCompositeResponse/#json-defintion","text":"","title":"JSON Defintion"},{"location":"UuidCompositeResponse/#json-example","text":"{ \"accountId\": \"BAR\", \"accountUuid\": \"336a8049-853c-4992-8382-e77e8868e208\", \"accountGuid\": \"000ad538-0000-0000-0000-000000000000\", \"accountName\": null, \"growerId\": \"CUS-100442\", \"growerUuid\": \"63ffb30a-aaf6-4cbe-83b7-95765aa2c5e4\", \"growerGuid\": \"000ceb06-0000-0000-0000-000000000000\", \"growerName\": null, \"farmId\": \"COP100263\", \"farmUuid\": \"d4334cd1-1a1f-4484-94d6-246645e07196\", \"farmGuid\": \"000ceb07-0000-0000-0000-000000000000\", \"farmName\": null, \"fieldId\": \"CST-400312\", \"fieldUuid\": \"9e0f0647-c21a-495a-92a2-9d0aaaf2bc8f\", \"fieldGuid\": \"001a5c8a-0000-0000-0000-000000000000\", \"fieldName\": null }","title":"JSON Example"},{"location":"UuidCompositeResponse/#json-schema","text":"{ \"$schema\": \"http://json-schema.org/draft-07/schema\", \"$id\": \"http://example.com/example.json\", \"type\": \"object\", \"readOnly\": false, \"writeOnly\": false, \"minProperties\": 0, \"title\": \"The UuidCompositeResponse Schema\", \"description\": \"The root schema comprises the entire JSON document for Composite Response\", \"additionalProperties\": true, \"required\": [], \"properties\": { \"accountId\": { \"$id\": \"#/properties/accountId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountId Schema\", \"description\": \"The Sync Id for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"SCG1\" ] }, \"accountUuid\": { \"$id\": \"#/properties/accountUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountUuid Schema\", \"description\": \"The UUID for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"e0485a5d-f6c1-4a0e-824a-1abffbcfaa9\" ] }, \"accountGuid\": { \"$id\": \"#/properties/accountGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountGuid Schema\", \"description\": \"The GUID for the Account (FinOps Branch)\", \"default\": \"\", \"examples\": [ \"000c33a4-0000-0000-0000-000000000000\" ] }, \"accountName\": { \"$id\": \"#/properties/accountName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The AccountName Schema\", \"description\": \"This is an optional name for the account\", \"default\": \"\", \"examples\": [ \"Alexandria\" ] }, \"growerId\": { \"$id\": \"#/properties/growerId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerId Schema\", \"description\": \"The Sync Id for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"CUS-100347\" ] }, \"growerUuid\": { \"$id\": \"#/properties/growerUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerUuid Schema\", \"description\": \"The UUID for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"ad5ee735-c783-45d3-9b7a-5e7b089b1fbf\" ] }, \"growerGuid\": { \"$id\": \"#/properties/growerGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerGuid Schema\", \"description\": \"The GUID for the Grower (FinOps Customer)\", \"default\": \"\", \"examples\": [ \"000cd991-0000-0000-0000-000000000000\" ] }, \"growerName\": { \"$id\": \"#/properties/growerName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The GrowerName Schema\", \"description\": \"This is an optional name for the grower\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"farmId\": { \"$id\": \"#/properties/farmId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmId Schema\", \"description\": \"The Sync Id for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"COP100208\" ] }, \"farmUuid\": { \"$id\": \"#/properties/farmUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmUuid Schema\", \"description\": \"The UUID for the Grower (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"1f7b3ecc-e2eb-4724-b9ec-f0b756d21566\" ] }, \"farmGuid\": { \"$id\": \"#/properties/farmGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmGuid Schema\", \"description\": \"The GUID for the Farm (FinOps Customer Operation)\", \"default\": \"\", \"examples\": [ \"000cd992-0000-0000-0000-000000000000\" ] }, \"farmeName\": { \"$id\": \"#/properties/farmeName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FarmeName Schema\", \"description\": \"This is an optional name for the farm\", \"default\": \"\", \"examples\": [ \"Bjorklund Land & Cattle\" ] }, \"fieldId\": { \"$id\": \"#/properties/fieldId\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldId Schema\", \"description\": \"The Sync Id for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"CST-000026\" ] }, \"fieldUuid\": { \"$id\": \"#/properties/fieldUuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldUuid Schema\", \"description\": \"The UUID for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"2ac15a5a-2c8a-4f65-b5fe-3706637937ec\" ] }, \"fieldGuid\": { \"$id\": \"#/properties/fieldGuid\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldGuid Schema\", \"description\": \"The GUID for the Field (FinOps Customer Site)\", \"default\": \"\", \"examples\": [ \"001a4769-0000-0000-0000-000000000000\" ] }, \"fieldName\": { \"$id\": \"#/properties/fieldName\", \"type\": \"string\", \"readOnly\": false, \"writeOnly\": false, \"minLength\": 0, \"title\": \"The FieldName Schema\", \"description\": \"This is an optional name for the field\", \"default\": \"\", \"examples\": [ \"NW 40\" ] } } }","title":"JSON Schema"},{"location":"about/","text":"","title":"About"},{"location":"agsyncConfigObject/","text":"agsync Settings agsync is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the integration of Agsync Workorders to FinOps. Example \"agsync\": { \"MustUseWktProcessor\": true, \"ConnectionString\": \"Endpoint=[Customer Servicebus Connection String]\", \"TopicName\": \"[Customer Servicebus Topic]\", \"SubscriptionName\": \"[Customer Servicebus Topic Subscription]\", \"PrefetchCount\": 5, \"RequiresSession\": [true/false], \"RedirectUri\": \"[Agsync Integration Base URL]/api/AgsyncAuth\", \"TokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"AuthorizeUrl\": \"https://auth.agsync.com/core/connect/authorize\", \"baseUri\": \"https://fields.agsync.com/api/\", \"rejectUri\": \"https://orders.agsync.com/api/orders/\", \"ClientId\": \"[Agsync assigned client ID]\", \"ClientPass\": \"[Agsync assigned client password]\", \"VaultURL\": \"[Integration Framework Key Vault URL]\", \"AgSyncTokenKey\": \"[Vault Key Used for Access Token]\" \"WktUrl\": \"[Agsync Integration Base URL]/api/WktProcessor\", \"ProcessStatuses\": \"Plan,Released,Canceled,Scheduled,Rejected,Completed,Accepted\", \"MustUseCustomerSite\": true } Definition MustUseWktProcessor The MustUseWktProcessor attribute contains a bollean that specifies whether or not to process the WKT sent in the workorder from Agsync to FinOps. ConnectionString TopicName SubscriptionName PrefetchCount RequiresSession RedirectUri TokenUrl AuthorizeUrl baseUri rejectUri ClientId ClientPass VaultURL AgSyncTokenKey ProcessStatuses Not Required Place a comma delimited list of statuses that should be processed by the controller. It is important to make sure the capitalization is correct (Title Case) because it does an exact match. Deafult: \"Planned,Released,Canceled,Scheduled,Rejected,Completed,Accepted\" MustUseCustomerSite Not Required Set this value to true to require a valid customer site on work orders. Set this value to false to ignore the customer site on work orders. Default: true","title":"agsync Settings"},{"location":"agsyncConfigObject/#agsync-settings","text":"agsync is an object in the appsettings.json file used by the Levridge Integration Framework to define the configuration for the integration of Agsync Workorders to FinOps.","title":"agsync Settings"},{"location":"agsyncConfigObject/#example","text":"\"agsync\": { \"MustUseWktProcessor\": true, \"ConnectionString\": \"Endpoint=[Customer Servicebus Connection String]\", \"TopicName\": \"[Customer Servicebus Topic]\", \"SubscriptionName\": \"[Customer Servicebus Topic Subscription]\", \"PrefetchCount\": 5, \"RequiresSession\": [true/false], \"RedirectUri\": \"[Agsync Integration Base URL]/api/AgsyncAuth\", \"TokenUrl\": \"https://auth.agsync.com/core/connect/token\", \"AuthorizeUrl\": \"https://auth.agsync.com/core/connect/authorize\", \"baseUri\": \"https://fields.agsync.com/api/\", \"rejectUri\": \"https://orders.agsync.com/api/orders/\", \"ClientId\": \"[Agsync assigned client ID]\", \"ClientPass\": \"[Agsync assigned client password]\", \"VaultURL\": \"[Integration Framework Key Vault URL]\", \"AgSyncTokenKey\": \"[Vault Key Used for Access Token]\" \"WktUrl\": \"[Agsync Integration Base URL]/api/WktProcessor\", \"ProcessStatuses\": \"Plan,Released,Canceled,Scheduled,Rejected,Completed,Accepted\", \"MustUseCustomerSite\": true }","title":"Example"},{"location":"agsyncConfigObject/#definition","text":"","title":"Definition"},{"location":"agsyncConfigObject/#mustusewktprocessor","text":"The MustUseWktProcessor attribute contains a bollean that specifies whether or not to process the WKT sent in the workorder from Agsync to FinOps.","title":"MustUseWktProcessor"},{"location":"agsyncConfigObject/#connectionstring","text":"","title":"ConnectionString"},{"location":"agsyncConfigObject/#topicname","text":"","title":"TopicName"},{"location":"agsyncConfigObject/#subscriptionname","text":"","title":"SubscriptionName"},{"location":"agsyncConfigObject/#prefetchcount","text":"","title":"PrefetchCount"},{"location":"agsyncConfigObject/#requiressession","text":"","title":"RequiresSession"},{"location":"agsyncConfigObject/#redirecturi","text":"","title":"RedirectUri"},{"location":"agsyncConfigObject/#tokenurl","text":"","title":"TokenUrl"},{"location":"agsyncConfigObject/#authorizeurl","text":"","title":"AuthorizeUrl"},{"location":"agsyncConfigObject/#baseuri","text":"","title":"baseUri"},{"location":"agsyncConfigObject/#rejecturi","text":"","title":"rejectUri"},{"location":"agsyncConfigObject/#clientid","text":"","title":"ClientId"},{"location":"agsyncConfigObject/#clientpass","text":"","title":"ClientPass"},{"location":"agsyncConfigObject/#vaulturl","text":"","title":"VaultURL"},{"location":"agsyncConfigObject/#agsynctokenkey","text":"","title":"AgSyncTokenKey"},{"location":"agsyncConfigObject/#processstatuses","text":"Not Required Place a comma delimited list of statuses that should be processed by the controller. It is important to make sure the capitalization is correct (Title Case) because it does an exact match. Deafult: \"Planned,Released,Canceled,Scheduled,Rejected,Completed,Accepted\"","title":"ProcessStatuses"},{"location":"agsyncConfigObject/#mustusecustomersite","text":"Not Required Set this value to true to require a valid customer site on work orders. Set this value to false to ignore the customer site on work orders. Default: true","title":"MustUseCustomerSite"},{"location":"appsettings.json/","text":"appsettings.json The appsettings.json is a configuration file that is used in standard Microsoft Configuration for ASP.NET Core to provide application settings. This document explains the various json objects used in the appsettings.json file. Overview AzureAd The AzureAd section provides the necesary information for authentication. see AzureAd Settings Controllers The controllers section provides a list of json objects that define which controllers to load for the current Levridge Integration Framework instance. See Controllers Settings Logging The Levridge Integration Framework utilizes the standard ASP.NET Core logging capabilities. The Logging section defines the logging settings for the various logging providers being used. See Logging Settings InstanceConfig The InstanceConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework. See InstanceConfig Settings SourceConfig The SourceConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction. See SourceConfig Settings TargetConfig The TargetConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Target of an integration interaction. See TargetConfig Settings","title":"appsettings.json"},{"location":"appsettings.json/#appsettingsjson","text":"The appsettings.json is a configuration file that is used in standard Microsoft Configuration for ASP.NET Core to provide application settings. This document explains the various json objects used in the appsettings.json file.","title":"appsettings.json"},{"location":"appsettings.json/#overview","text":"","title":"Overview"},{"location":"appsettings.json/#azuread","text":"The AzureAd section provides the necesary information for authentication. see AzureAd Settings","title":"AzureAd"},{"location":"appsettings.json/#controllers","text":"The controllers section provides a list of json objects that define which controllers to load for the current Levridge Integration Framework instance. See Controllers Settings","title":"Controllers"},{"location":"appsettings.json/#logging","text":"The Levridge Integration Framework utilizes the standard ASP.NET Core logging capabilities. The Logging section defines the logging settings for the various logging providers being used. See Logging Settings","title":"Logging"},{"location":"appsettings.json/#instanceconfig","text":"The InstanceConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Current Instance of the integration framework. See InstanceConfig Settings","title":"InstanceConfig"},{"location":"appsettings.json/#sourceconfig","text":"The SourceConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Source of an integration interaction. See SourceConfig Settings","title":"SourceConfig"},{"location":"appsettings.json/#targetconfig","text":"The TargetConfig section is a json object used by the Levridge Integration Framework to define the configuration for the Target of an integration interaction. See TargetConfig Settings","title":"TargetConfig"},{"location":"command-line-arguments/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"command-line-arguments/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"command-line-arguments/#overview","text":"","title":"Overview"},{"location":"command-line-arguments/#main-point-1","text":"","title":"Main Point 1"},{"location":"command-line-arguments/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"hostsettings.json/","text":"Introduction Brief introduction of the module, component or feature being documented. This document explains ... Overview Main Point 1 Sub Point 1.1","title":"Introduction"},{"location":"hostsettings.json/#introduction","text":"Brief introduction of the module, component or feature being documented. This document explains ...","title":"Introduction"},{"location":"hostsettings.json/#overview","text":"","title":"Overview"},{"location":"hostsettings.json/#main-point-1","text":"","title":"Main Point 1"},{"location":"hostsettings.json/#sub-point-11","text":"","title":"Sub Point 1.1"},{"location":"how-to-install-levridge-scale/","text":"How to Install Levridge Scale Prerequisites Windows user account needs to have local admin rights and a password PC needs to have an internet connection Disable any security add-ons (Bitdefender, etc.) Whenever prompted to use a browser, use Chrome Install SqlExpress using the 'Basic' installation SQL is located in the Master Scale App Install folder It was downloaded from https://go.microsoft.com/fwlink/?linkid=866658 The SQLEXPRESS connection string will default to Server=localhost\\SQLEXPRESS;Database=master;Trusted_Connection=True; If IIS is not enabled, enable IIS through Control panel>Programs and Features>Turn Windows feature on or off>Internet Information Services. Check the root box for Internet Information Services and let is select the defaults. Ensure everything under IIS>World Wide Web Services>Application Development Features is checked. If you receive an error, when downloading IIS you may need to make a change in the registry: Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\WindowsUpdate\\AU Set \"UseWUServer\" to 0 Install Levridge Scale Run the Levridge Scale House Install.exe Right click and Run as Administrator Agree to terms and click Install When the installer displays \"Installation Successfully Completed\", click Close Configure Settings reference the 2. Levridge Scale Appsettings document 1. Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers 2. In the API and Client folders, configure appsettings.json 3. Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services 4. In AxToScaleIntegration and HardwareInterface folders, configure appsettings.json Log into Services Oepn IIS In Application Pools, right click DefaultAppPool and click Stop On the left under Sites, rick click Default Web Site>Manager Website>Stop On the left select Application Pools, on the right do the follow steps for BOTH LevScaleAPI and LevPrint Right click>Advanced settings In the Identity field select Custom account>Set and enter username and password. Use the username and password. Open (Windows) Services There should be 4 new services installed: LevAxToScaleService LevHardwareService LevPrinterService LevScaleClient Set the Startup Type to \"Automatic (Delayed Start)\" On the LevHardwareService and LevScaleClient services, change the Log on for EACH service: Right click on the service>Properties Select the Log On tab Select account and password Click Apply and OK Restart the machine. When it restarts, the services will start automatically and the database will be created. Access Levridge Scale In a web browser, go to http://localhost to access Levridge Scale Sync data from F&O In F&O, Create an Event Frameowrk endpoint definition for scale Service Bus endpoint: Endpoint:=sb://example.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx= Enter the Topic name Endpoint type: Topic Session Required: Yes Enabled: Yes Create an Event Framework event and sync all scale entities, referenced in Scale Integration","title":"How to install levridge scale"},{"location":"how-to-install-levridge-scale/#how-to-install-levridge-scale","text":"","title":"How to Install Levridge Scale"},{"location":"how-to-install-levridge-scale/#prerequisites","text":"Windows user account needs to have local admin rights and a password PC needs to have an internet connection Disable any security add-ons (Bitdefender, etc.) Whenever prompted to use a browser, use Chrome Install SqlExpress using the 'Basic' installation SQL is located in the Master Scale App Install folder It was downloaded from https://go.microsoft.com/fwlink/?linkid=866658 The SQLEXPRESS connection string will default to Server=localhost\\SQLEXPRESS;Database=master;Trusted_Connection=True; If IIS is not enabled, enable IIS through Control panel>Programs and Features>Turn Windows feature on or off>Internet Information Services. Check the root box for Internet Information Services and let is select the defaults. Ensure everything under IIS>World Wide Web Services>Application Development Features is checked. If you receive an error, when downloading IIS you may need to make a change in the registry: Computer\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Microsoft\\Windows\\WindowsUpdate\\AU Set \"UseWUServer\" to 0","title":"Prerequisites"},{"location":"how-to-install-levridge-scale/#install-levridge-scale","text":"Run the Levridge Scale House Install.exe Right click and Run as Administrator Agree to terms and click Install When the installer displays \"Installation Successfully Completed\", click Close","title":"Install Levridge Scale"},{"location":"how-to-install-levridge-scale/#configure-settings","text":"reference the 2. Levridge Scale Appsettings document 1. Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers 2. In the API and Client folders, configure appsettings.json 3. Open file explorer and go to C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services 4. In AxToScaleIntegration and HardwareInterface folders, configure appsettings.json","title":"Configure Settings"},{"location":"how-to-install-levridge-scale/#log-into-services","text":"Oepn IIS In Application Pools, right click DefaultAppPool and click Stop On the left under Sites, rick click Default Web Site>Manager Website>Stop On the left select Application Pools, on the right do the follow steps for BOTH LevScaleAPI and LevPrint Right click>Advanced settings In the Identity field select Custom account>Set and enter username and password. Use the username and password. Open (Windows) Services There should be 4 new services installed: LevAxToScaleService LevHardwareService LevPrinterService LevScaleClient Set the Startup Type to \"Automatic (Delayed Start)\" On the LevHardwareService and LevScaleClient services, change the Log on for EACH service: Right click on the service>Properties Select the Log On tab Select account and password Click Apply and OK Restart the machine. When it restarts, the services will start automatically and the database will be created.","title":"Log into Services"},{"location":"how-to-install-levridge-scale/#access-levridge-scale","text":"In a web browser, go to http://localhost to access Levridge Scale","title":"Access Levridge Scale"},{"location":"how-to-install-levridge-scale/#sync-data-from-fo","text":"In F&O, Create an Event Frameowrk endpoint definition for scale Service Bus endpoint: Endpoint:=sb://example.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx= Enter the Topic name Endpoint type: Topic Session Required: Yes Enabled: Yes Create an Event Framework event and sync all scale entities, referenced in Scale Integration","title":"Sync data from F&amp;O"},{"location":"oneWeigh/","text":"oneWeigh","title":"oneWeigh"},{"location":"oneWeigh/#oneweigh","text":"","title":"oneWeigh"},{"location":"print-service/","text":"Print Service Installing Print Service Application To first install print service application, open Visual Studio. In Visual Studio, the print service is checked-in at \"$/Levridge/CRM/Main/PrintService\". Double click this and map it to a path on your machine. In Visual Studio, click Build > Build Solution. Activate the service as detailed below in PowerShell: Right click on the windows icon and select \"Windows PowerShell (Admin)\" Enter the following command once. Be sure to substitute the local path! New-Service-Name\"PrintService\"-\"{Your Local path to project}\\PrintService\\bin\\Debug\\PrintService.exe-k netsvcs\" Locating Printer Network Name If a printer is a network device, its name will be more difficult to locate. Use these steps to find the name that the Print Service application will use to print: Go to control panel and locate the setting titled \"Devices and Printers\" (Note: Not all setting are in this screenshot. This view is set to \"Small icons\") Navigate to the list of print options on your computer and select the device of your choice. The full network name that is required for the code is listed once you select the printer. (Highlighted in yellow below) Using Print Service Application After initial setup, use one of the following two options to start the Application. PowerShell Following the first setup, you can enter the following command into PowerShell instead. Start-Service-Name\"PrintService\" Services App. Use Windows+R to select \"services.msc\" to open Services Management Console. Right click on PrintService and select \"start\" Setting Up a New Printer To set up a new printer, new parameters will need to be setup. To add the parameters, open the app.config file in the project and add the following: ServiceBusConnectionString ServiceBusTopicSubscription ServiceBusTopic PrinterName SiteID Two parameters will also need to be updated. These two need to be changed for the printer that is being printed to. The Site ID is the customer site code from CRM. For debugging the Service, we can use the Windows Event Viewer. Go to Administrative tools in the Control Panel and Open Event Viewer. Additional Information and Documentation In CRM on the sales ordered details header, there is an Auto Print Field. Set to Yes and click save. The sales order will then print.","title":"Print Service"},{"location":"print-service/#print-service","text":"","title":"Print Service"},{"location":"print-service/#installing-print-service-application","text":"To first install print service application, open Visual Studio. In Visual Studio, the print service is checked-in at \"$/Levridge/CRM/Main/PrintService\". Double click this and map it to a path on your machine. In Visual Studio, click Build > Build Solution. Activate the service as detailed below in PowerShell: Right click on the windows icon and select \"Windows PowerShell (Admin)\" Enter the following command once. Be sure to substitute the local path! New-Service-Name\"PrintService\"-\"{Your Local path to project}\\PrintService\\bin\\Debug\\PrintService.exe-k netsvcs\"","title":"Installing Print Service Application"},{"location":"print-service/#locating-printer-network-name","text":"If a printer is a network device, its name will be more difficult to locate. Use these steps to find the name that the Print Service application will use to print: Go to control panel and locate the setting titled \"Devices and Printers\" (Note: Not all setting are in this screenshot. This view is set to \"Small icons\") Navigate to the list of print options on your computer and select the device of your choice. The full network name that is required for the code is listed once you select the printer. (Highlighted in yellow below)","title":"Locating Printer Network Name"},{"location":"print-service/#using-print-service-application","text":"After initial setup, use one of the following two options to start the Application. PowerShell Following the first setup, you can enter the following command into PowerShell instead. Start-Service-Name\"PrintService\" Services App. Use Windows+R to select \"services.msc\" to open Services Management Console. Right click on PrintService and select \"start\"","title":"Using Print Service Application"},{"location":"print-service/#setting-up-a-new-printer","text":"To set up a new printer, new parameters will need to be setup. To add the parameters, open the app.config file in the project and add the following: ServiceBusConnectionString ServiceBusTopicSubscription ServiceBusTopic PrinterName SiteID Two parameters will also need to be updated. These two need to be changed for the printer that is being printed to. The Site ID is the customer site code from CRM. For debugging the Service, we can use the Windows Event Viewer. Go to Administrative tools in the Control Panel and Open Event Viewer.","title":"Setting Up a New Printer"},{"location":"print-service/#additional-information-and-documentation","text":"In CRM on the sales ordered details header, there is an Auto Print Field. Set to Yes and click save. The sales order will then print.","title":"Additional Information and Documentation"},{"location":"scale-appsettings-configuration/","text":"Scale Appsettings Configuration Configure Appsettings Files Configure the appsettings.json file in the following default locations: C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers\\LevScaleClient C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers\\LevScaleAPI C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services\\AxToScaleIntegration C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services\\HardwareInterface LevScaleClient { \"GeneratedDb\": \"C:\\\\LevridgeScaleHouse\\\\sql\", \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\" }, \"WipProcessInterval\": 10000, \"WipCleanupInterval\": 86400000, \"Logging\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Warning\" } }, \"ServiceBusSettings\": { \"ServiceBusConnectionString\": //Enter the endpoint for the service bus for integration from Levridge Scale to F&O \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"scaletofo\" }, \"WebAPI\": { \"Port\": 80, \"URL\": \"http://localhost:8080\", }, \"Printer\": { \"DataSource\": \"Server=.;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\", \"ReportPath\": \"./\" }, \"ScaleInterface\": { \"UriString\": \"http://localhost:44323/\", \"TLSVersion\": \"\" }, \"LogLocationCleanup\": { /// <summary> /// The location of the log folder. /// </summary> /// <remarks>The default value is 'C:\\Temp'.</remarks> \"LogFolder\": \"C:\\\\Temp\", /// <summary> /// The time to wait (in minutes) before clearing old logs from the reporting location. /// </summary> /// <remarks>The default is 1,440 mintues (24 hours).</remarks> \"RecheckInterval\": 2880, /// <summary> /// Log files may be deleted that are older than this many mintues.. /// </summary> /// <remarks>The default is 2,880 minutes (24 hours).</remarks> \"RemoveAfter\": 2880, /// <summary> /// The file filter used when clearing old report files. /// </summary> /// <remarks>The default is \"*\".</remarks> \"FileFilter\": \"*.txt\", /// <summary> /// The file search options. /// </summary> /// <remarks>The default is <see cref=\"SearchOption.TopDirectoryOnly\"/></remarks> \"FileSearchOptions\": \"TopDirectoryOnly\" }, \"Log4Net\": { \"xml\": \"log4net.xml\" }, \"DynamicsAX\": { //Enter the connection details for F&O \"UriString\": \"https://landusuat.sandbox.operations.dynamics.com/\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53-9376bxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b393xxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1cJLcxxxx=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"https://landusuat.sandbox.operations.dynamics.com/data/\", \"DataAreaId\": \"100\" } } LevScaleAPI { \"AllowedHosts\": \"*\", \"GeneratedDb\": \"C:\\\\LevridgeScaleHouse\\\\sql\", \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\" }, \"WipProcessInterval\": 10000, \"WipCleanupInterval\": 86400000, \"Logging\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Warning\" } }, \"ServiceBusSettings\": { \"ServiceBusConnectionString\": //Enter the endpoint for the service bus for integration from Levridge Scale to F&O \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"scaletofo\" }, \"WebAPI\": { \"Port\": 80, \"URL\": \"http://localhost:8080\", }, \"Printer\": { \"DataSource\": \"Server=.;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\", \"ReportPath\": \"./\" }, \"ScaleInterface\": { \"UriString\": \"http://localhost:44323/\", \"TLSVersion\": \"\" }, \"Log4Net\": { \"xml\": \"log4net.xml\" } } AxToScaleIntegration { \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Console\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Debug\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"ApplicationInsights\": { \"InstrumentationKey\": \"\" }, \"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfigurationAX\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"AxToScale\", \"ODataConfigName\": \"DynamicsAX\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"ScaleOData\", \"SystemName\": \"ScaleHouse\", \"Direction\": \"Target\" }, //Enter the connection details for F&O \"DynamicsAX\": { \"UriString\": \"https://landusuat.sandbox.operations.dynamics.com/\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53xxxxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b39381xxxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1xxxxxI=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"https://landusuat.sandbox.operations.dynamics.com/data/\", \"DataAreaId\": \"100\" }, //Enter the Active Directory details for F&O. Leave the default values for UriString and ODataEntityPath \"ScaleOData\": { \"UriString\": \"http://localhost:8080/odata\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53-9376xxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b3xxxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1cJLcxxxxx=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"http://localhost:8080/odata\" }, \"AxToScale\": { \"ConnectionString\": //Enter the endpoint for the service bus for integration from F&O to Levridge Scale \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"axtoscale\", //Enter the Subscription name for the service bus \"SubscriptionName\": \"000\", \"RequiresSession\": true } } HardwareInterface { \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;\" }, \"Logging\": { \"LogLevel\": { \"Default\": \"Warning\" } }, \"AllowedHosts\": \"*\", \"Hardware\": { \"HubUrl\": \"http://localhost:80/scalehub\", \"WorkstationName\" : \"Ws1\" } }","title":"Scale Appsettings Configuration"},{"location":"scale-appsettings-configuration/#scale-appsettings-configuration","text":"","title":"Scale Appsettings Configuration"},{"location":"scale-appsettings-configuration/#configure-appsettings-files","text":"Configure the appsettings.json file in the following default locations: C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers\\LevScaleClient C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Servers\\LevScaleAPI C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services\\AxToScaleIntegration C:\\Program Files (x86)\\Levridge\\LevridgeScaleHouse\\Services\\HardwareInterface","title":"Configure Appsettings Files"},{"location":"scale-appsettings-configuration/#levscaleclient","text":"{ \"GeneratedDb\": \"C:\\\\LevridgeScaleHouse\\\\sql\", \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\" }, \"WipProcessInterval\": 10000, \"WipCleanupInterval\": 86400000, \"Logging\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Warning\" } }, \"ServiceBusSettings\": { \"ServiceBusConnectionString\": //Enter the endpoint for the service bus for integration from Levridge Scale to F&O \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"scaletofo\" }, \"WebAPI\": { \"Port\": 80, \"URL\": \"http://localhost:8080\", }, \"Printer\": { \"DataSource\": \"Server=.;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\", \"ReportPath\": \"./\" }, \"ScaleInterface\": { \"UriString\": \"http://localhost:44323/\", \"TLSVersion\": \"\" }, \"LogLocationCleanup\": { /// <summary> /// The location of the log folder. /// </summary> /// <remarks>The default value is 'C:\\Temp'.</remarks> \"LogFolder\": \"C:\\\\Temp\", /// <summary> /// The time to wait (in minutes) before clearing old logs from the reporting location. /// </summary> /// <remarks>The default is 1,440 mintues (24 hours).</remarks> \"RecheckInterval\": 2880, /// <summary> /// Log files may be deleted that are older than this many mintues.. /// </summary> /// <remarks>The default is 2,880 minutes (24 hours).</remarks> \"RemoveAfter\": 2880, /// <summary> /// The file filter used when clearing old report files. /// </summary> /// <remarks>The default is \"*\".</remarks> \"FileFilter\": \"*.txt\", /// <summary> /// The file search options. /// </summary> /// <remarks>The default is <see cref=\"SearchOption.TopDirectoryOnly\"/></remarks> \"FileSearchOptions\": \"TopDirectoryOnly\" }, \"Log4Net\": { \"xml\": \"log4net.xml\" }, \"DynamicsAX\": { //Enter the connection details for F&O \"UriString\": \"https://landusuat.sandbox.operations.dynamics.com/\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53-9376bxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b393xxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1cJLcxxxx=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"https://landusuat.sandbox.operations.dynamics.com/data/\", \"DataAreaId\": \"100\" } }","title":"LevScaleClient"},{"location":"scale-appsettings-configuration/#levscaleapi","text":"{ \"AllowedHosts\": \"*\", \"GeneratedDb\": \"C:\\\\LevridgeScaleHouse\\\\sql\", \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\" }, \"WipProcessInterval\": 10000, \"WipCleanupInterval\": 86400000, \"Logging\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Warning\" } }, \"ServiceBusSettings\": { \"ServiceBusConnectionString\": //Enter the endpoint for the service bus for integration from Levridge Scale to F&O \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"scaletofo\" }, \"WebAPI\": { \"Port\": 80, \"URL\": \"http://localhost:8080\", }, \"Printer\": { \"DataSource\": \"Server=.;Initial Catalog=LevScale;Trusted_Connection=True;MultipleActiveResultSets=true;\", \"ReportPath\": \"./\" }, \"ScaleInterface\": { \"UriString\": \"http://localhost:44323/\", \"TLSVersion\": \"\" }, \"Log4Net\": { \"xml\": \"log4net.xml\" } }","title":"LevScaleAPI"},{"location":"scale-appsettings-configuration/#axtoscaleintegration","text":"{ \"Logging\": { \"Debug\": { \"LogLevel\": { \"Default\": \"Trace\" } }, \"Console\": { \"IncludeScopes\": false, \"LogLevel\": { \"Default\": \"Debug\" } }, \"LogLevel\": { \"Default\": \"Information\" } }, \"ApplicationInsights\": { \"InstrumentationKey\": \"\" }, \"InstanceConfig\": { \"AzureTableConfiguration\": \"AzureTableConfigurationAX\" }, \"SourceConfig\": { \"ServiceBusConfigName\": \"AxToScale\", \"ODataConfigName\": \"DynamicsAX\", \"SystemName\": \"DynamicsAX\", \"Direction\": \"Source\" }, \"TargetConfig\": { \"ODataConfigName\": \"ScaleOData\", \"SystemName\": \"ScaleHouse\", \"Direction\": \"Target\" }, //Enter the connection details for F&O \"DynamicsAX\": { \"UriString\": \"https://landusuat.sandbox.operations.dynamics.com/\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53xxxxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b39381xxxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1xxxxxI=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"https://landusuat.sandbox.operations.dynamics.com/data/\", \"DataAreaId\": \"100\" }, //Enter the Active Directory details for F&O. Leave the default values for UriString and ODataEntityPath \"ScaleOData\": { \"UriString\": \"http://localhost:8080/odata\", \"ActiveDirectoryResource\": \"https://landusuat.sandbox.operations.dynamics.com\", \"ActiveDirectoryTenant\": \"https://login.microsoftonline.com/bb671371-5d5c-4dca-9c53-9376xxxxx\", \"ActiveDirectoryClientAppId\": \"ef8c69c1-0d35-40eb-aec9-b3xxxxx\", \"ActiveDirectoryClientAppSecret\": \"4ZpHiXn0k2Nx9vnsgmJq+uYbT4drRL1cJLcxxxxx=\", \"TLSVersion\": \"\", \"ODataEntityPath\": \"http://localhost:8080/odata\" }, \"AxToScale\": { \"ConnectionString\": //Enter the endpoint for the service bus for integration from F&O to Levridge Scale \"Endpoint=sb://integration.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=PG5SCOfZHIKQ7rmRmSdKwGe2OW27hRhxxxxxx=\", //Enter the Topic name for the service bus \"TopicName\": \"axtoscale\", //Enter the Subscription name for the service bus \"SubscriptionName\": \"000\", \"RequiresSession\": true } }","title":"AxToScaleIntegration"},{"location":"scale-appsettings-configuration/#hardwareinterface","text":"{ \"ConnectionStrings\": { \"DefaultConnection\": \"Data Source=.\\\\SQLEXPRESS;Initial Catalog=LevScale;Trusted_Connection=True;\" }, \"Logging\": { \"LogLevel\": { \"Default\": \"Warning\" } }, \"AllowedHosts\": \"*\", \"Hardware\": { \"HubUrl\": \"http://localhost:80/scalehub\", \"WorkstationName\" : \"Ws1\" } }","title":"HardwareInterface"},{"location":"scale-integration/","text":"Levridge Scale Integration Azure service bus explorer for Integration Down: F&O to scale Up: Scale to F&O Appsettings.json - configuration file, edit file to switch between up and down Integration F&O to scale Here is the Integration List which lists the entities needed when integrating F&O to scale through System administration > Setup > Event Framework > Event framework events. 1. System administration > Setup > Event framework > Event framework events 2. Run azure service bus Down 3. Run IntegrationConsole.cmd Integration scale to F&O Run azure service bus Up Run IntegrationConsole.cmd When Print is clicked on the scale app, the ticket will then sync to F&O. Scale Entities for Integration Agronomy Release LevUnitOfMeasureEntity HcmWorkerEntity LevScaleReleaseProductsEntity LevHazardousMaterialsTableEntity CustCustomerV3Entity LevSplitGroupEntity LevSplitGroupLinesEntity LevAccountToOperationRelationshipEntity LevCustomerOperationEntity LevCustomerSiteEntity LevRollingStockV2Entity LevFreightCarrierEntity LevInventSiteEntity LevWarehouseEntity LevScaleOperatorEntity LevScaleHouseSalesOrderEntity LevScaleHouseScaleTicketEntity: Add a filter for: Table Scale tickets; Field Ticket type; Criteria Transfer origin","title":"Levridge Scale House"},{"location":"scale-integration/#levridge-scale-integration","text":"","title":"Levridge Scale Integration"},{"location":"scale-integration/#azure-service-bus-explorer-for-integration","text":"Down: F&O to scale Up: Scale to F&O Appsettings.json - configuration file, edit file to switch between up and down","title":"Azure service bus explorer for Integration"},{"location":"scale-integration/#integration-fo-to-scale","text":"Here is the Integration List which lists the entities needed when integrating F&O to scale through System administration > Setup > Event Framework > Event framework events. 1. System administration > Setup > Event framework > Event framework events 2. Run azure service bus Down 3. Run IntegrationConsole.cmd","title":"Integration F&amp;O to scale"},{"location":"scale-integration/#integration-scale-to-fo","text":"Run azure service bus Up Run IntegrationConsole.cmd When Print is clicked on the scale app, the ticket will then sync to F&O.","title":"Integration scale to F&amp;O"},{"location":"scale-integration/#scale-entities-for-integration","text":"","title":"Scale Entities for Integration"},{"location":"scale-integration/#agronomy-release","text":"LevUnitOfMeasureEntity HcmWorkerEntity LevScaleReleaseProductsEntity LevHazardousMaterialsTableEntity CustCustomerV3Entity LevSplitGroupEntity LevSplitGroupLinesEntity LevAccountToOperationRelationshipEntity LevCustomerOperationEntity LevCustomerSiteEntity LevRollingStockV2Entity LevFreightCarrierEntity LevInventSiteEntity LevWarehouseEntity LevScaleOperatorEntity LevScaleHouseSalesOrderEntity LevScaleHouseScaleTicketEntity: Add a filter for: Table Scale tickets; Field Ticket type; Criteria Transfer origin","title":"Agronomy Release"},{"location":"scale-settings-configuration/","text":"Scale Settings Configuration Settings Under Application Configuration>Settings - Site: Choose a site from the drop down to assign site ID to the scale app - Number Prefix: Enter in the number ID of the Site in FO - Scale: Leave as default value of 1 - Company Name: Enter company name - Company Location/Address: Enter in correct company address - Company Carrier: Use this to Select the transport that is set up in F&O to trasnport Transfer Tickets: Company Name - Logo: Click on this to choose a picture file: Sizing IS being updated for logo - Printer Server: Address of the Printer Server, Default value is http://localhost:8081 - Printer Service: Address of the Printer Service, Default value is: http://localhost:4343/printerservice - Report File Location: Location of where PDF versions of tickets are stored. Default value is C:\\Temp\\Reports . Will have to create this file folder on your local machine. - Organization: DataAreaID of F&O, enter in 100 - IsDriverOn: If this is toggled on, all ticket types will default to having the flag on unless manually changed by the scale operator. If set to no, \"Driver-on\" flag will not be displayed on the ticket window. - Enable Spot Pricing: Further Development of Grain Functionality required. Field does not need to be filled in for agronomy. - Enable Disposition: Further Development of Grain Functionality required. Field does not need to be filled in for agronomy. - Scale Unit: Use drop down list to select LB - Max Weight: Enter in the max weight of the scale head. - Incr. Wt: This is what increments the scale head will display weights, i.e. 20 lbs. Printer Settings Under Application Configuration>Printer Settings. This window is used to choose the correct printers for each of your scale heads at a location, and to choose a corresponding menu color to know which scale head you are working with in your window. The printer settings you choose in this window will then default in when you choose that scale on the Application start page. Note: This setup is required. The printer selection can be changed to any printer on the Start page, but default printer setup is required to be able to print scale tickets. To Set up the Printer Settings for a Scale: Choose the scale you want to set up from the drop down on the top of the page. Choose your printers for both your Tickets and BOL. Using the printer Type can change between a full page printout vs. a receipt printout. Choose the number of copies that you want to print with each completed ticket. Choose a background Color for that specific scale-head to make sure the correct scale is being used to complete and print tickets. Click save to complete these changes. Customer Short List Under Application Configuration>Customer Short list Shows a list of all customers in the scale database in alphabetical order. Checking the Box next to a customer will put that customer into the drop-down list on all the scale ticket types in order to reduce load times because not all customers will be loading in the customer account drop-down. To add a customer to the short list manually, check the box next to their name, and click submit on the bottom left corner of the page. Gross Quantity Settings Under Application Configuration>Gross Quantity Settings Manually set up in scale to show the gross quantity conversions of certain products, i.e. lbs to gallons. To create a new gross quantity for a product: 1. Click create new on the top left of the page under INDEX 2. Choose the item ID for the correct item you want to add a quantity to 3. In Factor, enter the correct number. If you were to say a gallon of product is equal to 8 pounds, you would enter 8. The conversion is lbs/Unit of measure. The units of measure come from your FO system. 4. Choose your Commodity Unit of Measure. 5. Click Create. To edit a previously created Gross quantity, click Edit next to the GQ that you want to change and when you have finished editing it, click the blue \"Edit\" button to save it. To delete a previously created GQ, click delete next to the GQ. Confirm the delete by clicking the red \"Delete\" button.","title":"Scale Settings Configuration"},{"location":"scale-settings-configuration/#scale-settings-configuration","text":"","title":"Scale Settings Configuration"},{"location":"scale-settings-configuration/#settings","text":"Under Application Configuration>Settings - Site: Choose a site from the drop down to assign site ID to the scale app - Number Prefix: Enter in the number ID of the Site in FO - Scale: Leave as default value of 1 - Company Name: Enter company name - Company Location/Address: Enter in correct company address - Company Carrier: Use this to Select the transport that is set up in F&O to trasnport Transfer Tickets: Company Name - Logo: Click on this to choose a picture file: Sizing IS being updated for logo - Printer Server: Address of the Printer Server, Default value is http://localhost:8081 - Printer Service: Address of the Printer Service, Default value is: http://localhost:4343/printerservice - Report File Location: Location of where PDF versions of tickets are stored. Default value is C:\\Temp\\Reports . Will have to create this file folder on your local machine. - Organization: DataAreaID of F&O, enter in 100 - IsDriverOn: If this is toggled on, all ticket types will default to having the flag on unless manually changed by the scale operator. If set to no, \"Driver-on\" flag will not be displayed on the ticket window. - Enable Spot Pricing: Further Development of Grain Functionality required. Field does not need to be filled in for agronomy. - Enable Disposition: Further Development of Grain Functionality required. Field does not need to be filled in for agronomy. - Scale Unit: Use drop down list to select LB - Max Weight: Enter in the max weight of the scale head. - Incr. Wt: This is what increments the scale head will display weights, i.e. 20 lbs.","title":"Settings"},{"location":"scale-settings-configuration/#printer-settings","text":"Under Application Configuration>Printer Settings. This window is used to choose the correct printers for each of your scale heads at a location, and to choose a corresponding menu color to know which scale head you are working with in your window. The printer settings you choose in this window will then default in when you choose that scale on the Application start page. Note: This setup is required. The printer selection can be changed to any printer on the Start page, but default printer setup is required to be able to print scale tickets.","title":"Printer Settings"},{"location":"scale-settings-configuration/#to-set-up-the-printer-settings-for-a-scale","text":"Choose the scale you want to set up from the drop down on the top of the page. Choose your printers for both your Tickets and BOL. Using the printer Type can change between a full page printout vs. a receipt printout. Choose the number of copies that you want to print with each completed ticket. Choose a background Color for that specific scale-head to make sure the correct scale is being used to complete and print tickets. Click save to complete these changes.","title":"To Set up the Printer Settings for a Scale:"},{"location":"scale-settings-configuration/#customer-short-list","text":"Under Application Configuration>Customer Short list Shows a list of all customers in the scale database in alphabetical order. Checking the Box next to a customer will put that customer into the drop-down list on all the scale ticket types in order to reduce load times because not all customers will be loading in the customer account drop-down. To add a customer to the short list manually, check the box next to their name, and click submit on the bottom left corner of the page.","title":"Customer Short List"},{"location":"scale-settings-configuration/#gross-quantity-settings","text":"Under Application Configuration>Gross Quantity Settings Manually set up in scale to show the gross quantity conversions of certain products, i.e. lbs to gallons. To create a new gross quantity for a product: 1. Click create new on the top left of the page under INDEX 2. Choose the item ID for the correct item you want to add a quantity to 3. In Factor, enter the correct number. If you were to say a gallon of product is equal to 8 pounds, you would enter 8. The conversion is lbs/Unit of measure. The units of measure come from your FO system. 4. Choose your Commodity Unit of Measure. 5. Click Create. To edit a previously created Gross quantity, click Edit next to the GQ that you want to change and when you have finished editing it, click the blue \"Edit\" button to save it. To delete a previously created GQ, click delete next to the GQ. Confirm the delete by clicking the red \"Delete\" button.","title":"Gross Quantity Settings"},{"location":"web.config/","text":"Web.config File Overview The web.config file only applies to Integration Framework instances that are hosted as a web application. Typically these are hosted in Azure but can also be hosted on-premise in IIS. Although Microsoft documentation claims that the web.config file has been replaced , Azure App Services still use it as the means to start the application service. It should not contain any application configuration settings. The web.config file is an XML file that contains a element. Web.Config Elements \\ \\ This is the main element that contains the other elements \\ \\<\\location> This element contains the relative path for the web server \\ \\<\\system.webserver> Contains the handlers and aspNetCore elements \\ \\<\\handlers> Defines the element for the web server. \\<aspNetCore\\> Defines the path to the web server assembly and standard output logging information. Set stdoutLogEnable to \"true\" to write standard out logging to files in the relative location pointed to by the stdoutLogFile attribute. To specify command-line attributes add them to the processPath attribuute on the aspNetCore element. For example, to specify the name for the InstanceConfig node change the processPath to look like this: processPath=\".\\Levridge.Integration.Host.exe -i=MyInstanceConfig\" Sample <?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <location path=\".\" inheritInChildApplications=\"false\"> <system.webServer> <handlers> <add name=\"aspNetCore\" path=\"*\" verb=\"*\" modules=\"AspNetCoreModuleV2\" resourceType=\"Unspecified\" /> </handlers> <aspNetCore processPath=\".\\Levridge.Integration.Host.exe\" stdoutLogEnabled=\"false\" stdoutLogFile=\".\\logs\\stdout\" /> </system.webServer> </location> </configuration>","title":"Web.config File"},{"location":"web.config/#webconfig-file","text":"","title":"Web.config File"},{"location":"web.config/#overview","text":"The web.config file only applies to Integration Framework instances that are hosted as a web application. Typically these are hosted in Azure but can also be hosted on-premise in IIS. Although Microsoft documentation claims that the web.config file has been replaced , Azure App Services still use it as the means to start the application service. It should not contain any application configuration settings. The web.config file is an XML file that contains a element.","title":"Overview"},{"location":"web.config/#webconfig-elements","text":"","title":"Web.Config Elements"},{"location":"web.config/#_1","text":"This is the main element that contains the other elements","title":"\\\\"},{"location":"web.config/#location","text":"This element contains the relative path for the web server","title":"\\\\&lt;\\location&gt;"},{"location":"web.config/#systemwebserver","text":"Contains the handlers and aspNetCore elements","title":"\\\\&lt;\\system.webserver&gt;"},{"location":"web.config/#handlers","text":"Defines the element for the web server.","title":"\\\\&lt;\\handlers&gt;"},{"location":"web.config/#aspnetcore","text":"Defines the path to the web server assembly and standard output logging information. Set stdoutLogEnable to \"true\" to write standard out logging to files in the relative location pointed to by the stdoutLogFile attribute. To specify command-line attributes add them to the processPath attribuute on the aspNetCore element. For example, to specify the name for the InstanceConfig node change the processPath to look like this: processPath=\".\\Levridge.Integration.Host.exe -i=MyInstanceConfig\"","title":"\\&lt;aspNetCore\\>"},{"location":"web.config/#sample","text":"<?xml version=\"1.0\" encoding=\"utf-8\"?> <configuration> <location path=\".\" inheritInChildApplications=\"false\"> <system.webServer> <handlers> <add name=\"aspNetCore\" path=\"*\" verb=\"*\" modules=\"AspNetCoreModuleV2\" resourceType=\"Unspecified\" /> </handlers> <aspNetCore processPath=\".\\Levridge.Integration.Host.exe\" stdoutLogEnabled=\"false\" stdoutLogFile=\".\\logs\\stdout\" /> </system.webServer> </location> </configuration>","title":"Sample"}]}